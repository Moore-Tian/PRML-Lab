2024-01-01 18:08:18,040	44k	INFO	{'train': {'log_interval': 200, 'eval_interval': 800, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 20, 'fp16_run': False, 'half_type': 'fp16', 'lr_decay': 0.999875, 'segment_size': 10240, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 512, 'port': '8001', 'keep_ckpts': 3, 'all_in_mem': True, 'vol_aug': False}, 'data': {'training_files': 'filelists/train.txt', 'validation_files': 'filelists/val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 44100, 'filter_length': 2048, 'hop_length': 512, 'win_length': 2048, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 22050, 'unit_interpolate_mode': 'nearest'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4, 4], 'n_layers_q': 3, 'n_layers_trans_flow': 3, 'n_flow_layer': 4, 'use_spectral_norm': False, 'gin_channels': 768, 'ssl_dim': 768, 'n_speakers': 1, 'vocoder_name': 'nsf-hifigan', 'speech_encoder': 'vec768l12', 'speaker_embedding': False, 'vol_embedding': False, 'use_depthwise_conv': False, 'flow_share_parameter': False, 'use_automatic_f0_prediction': True, 'use_transformer_flow': False}, 'spk': {'Ganyu': 0}, 'model_dir': './logs/44k'}
2024-01-01 18:08:23,458	44k	INFO	Loaded checkpoint './logs/44k/G_0.pth' (iteration 1)
2024-01-01 18:08:23,756	44k	INFO	Loaded checkpoint './logs/44k/D_0.pth' (iteration 1)
2024-01-01 18:08:55,797	44k	INFO	====> Epoch: 1, cost 37.76 s
2024-01-01 18:09:17,578	44k	INFO	====> Epoch: 2, cost 21.78 s
2024-01-01 18:09:39,681	44k	INFO	====> Epoch: 3, cost 22.10 s
2024-01-01 18:10:01,637	44k	INFO	====> Epoch: 4, cost 21.96 s
2024-01-01 18:10:23,578	44k	INFO	====> Epoch: 5, cost 21.94 s
2024-01-01 18:10:45,587	44k	INFO	====> Epoch: 6, cost 22.01 s
2024-01-01 18:11:07,677	44k	INFO	====> Epoch: 7, cost 22.09 s
2024-01-01 18:11:29,903	44k	INFO	Train Epoch: 8 [96%]
2024-01-01 18:11:29,905	44k	INFO	Losses: [1.911226749420166, 2.5756399631500244, 5.965522289276123, 41.6710319519043, 3.461453437805176], step: 200, lr: 9.991253280566489e-05, reference_loss: 55.58487319946289
2024-01-01 18:11:30,353	44k	INFO	====> Epoch: 8, cost 22.68 s
2024-01-01 18:11:52,476	44k	INFO	====> Epoch: 9, cost 22.12 s
2024-01-01 18:12:14,552	44k	INFO	====> Epoch: 10, cost 22.08 s
2024-01-01 18:12:36,621	44k	INFO	====> Epoch: 11, cost 22.07 s
2024-01-01 18:12:58,695	44k	INFO	====> Epoch: 12, cost 22.07 s
2024-01-01 18:13:20,751	44k	INFO	====> Epoch: 13, cost 22.06 s
2024-01-01 18:13:42,868	44k	INFO	====> Epoch: 14, cost 22.12 s
2024-01-01 18:14:05,023	44k	INFO	====> Epoch: 15, cost 22.16 s
2024-01-01 18:14:26,981	44k	INFO	Train Epoch: 16 [96%]
2024-01-01 18:14:26,983	44k	INFO	Losses: [1.188895583152771, 4.316000938415527, 8.061378479003906, 39.06858825683594, 2.295426368713379], step: 400, lr: 9.981266397366609e-05, reference_loss: 54.93029022216797
2024-01-01 18:14:27,380	44k	INFO	====> Epoch: 16, cost 22.36 s
2024-01-01 18:14:49,389	44k	INFO	====> Epoch: 17, cost 22.01 s
2024-01-01 18:15:11,561	44k	INFO	====> Epoch: 18, cost 22.17 s
2024-01-01 18:15:33,693	44k	INFO	====> Epoch: 19, cost 22.13 s
2024-01-01 18:15:55,799	44k	INFO	====> Epoch: 20, cost 22.11 s
2024-01-01 18:16:17,922	44k	INFO	====> Epoch: 21, cost 22.12 s
2024-01-01 18:16:40,002	44k	INFO	====> Epoch: 22, cost 22.08 s
2024-01-01 18:17:02,167	44k	INFO	====> Epoch: 23, cost 22.16 s
2024-01-01 18:17:24,307	44k	INFO	Train Epoch: 24 [96%]
2024-01-01 18:17:24,309	44k	INFO	Losses: [1.5634422302246094, 3.404541254043579, 7.57033109664917, 37.6618537902832, 2.1610124111175537], step: 600, lr: 9.971289496681757e-05, reference_loss: 52.36117935180664
2024-01-01 18:17:24,901	44k	INFO	====> Epoch: 24, cost 22.73 s
2024-01-01 18:17:47,032	44k	INFO	====> Epoch: 25, cost 22.13 s
2024-01-01 18:18:09,245	44k	INFO	====> Epoch: 26, cost 22.21 s
2024-01-01 18:18:31,588	44k	INFO	====> Epoch: 27, cost 22.34 s
2024-01-01 18:18:53,886	44k	INFO	====> Epoch: 28, cost 22.30 s
2024-01-01 18:19:16,145	44k	INFO	====> Epoch: 29, cost 22.26 s
2024-01-01 18:19:38,371	44k	INFO	====> Epoch: 30, cost 22.23 s
2024-01-01 18:20:00,464	44k	INFO	====> Epoch: 31, cost 22.09 s
2024-01-01 18:20:22,686	44k	INFO	Train Epoch: 32 [96%]
2024-01-01 18:20:22,687	44k	INFO	Losses: [1.4523104429244995, 3.5005791187286377, 7.547430038452148, 30.578271865844727, 1.4374399185180664], step: 800, lr: 9.961322568533789e-05, reference_loss: 44.516029357910156
2024-01-01 18:20:30,948	44k	INFO	Saving model and optimizer state at iteration 32 to ./logs/44k/G_800.pth
2024-01-01 18:20:32,111	44k	INFO	Saving model and optimizer state at iteration 32 to ./logs/44k/D_800.pth
2024-01-01 18:20:32,592	44k	INFO	====> Epoch: 32, cost 32.13 s
2024-01-01 18:20:54,698	44k	INFO	====> Epoch: 33, cost 22.11 s
2024-01-01 18:21:16,923	44k	INFO	====> Epoch: 34, cost 22.22 s
2024-01-01 18:21:38,938	44k	INFO	====> Epoch: 35, cost 22.01 s
2024-01-01 18:22:00,873	44k	INFO	====> Epoch: 36, cost 21.94 s
2024-01-01 18:22:22,816	44k	INFO	====> Epoch: 37, cost 21.94 s
2024-01-01 18:22:44,767	44k	INFO	====> Epoch: 38, cost 21.95 s
2024-01-01 18:23:06,766	44k	INFO	====> Epoch: 39, cost 22.00 s
2024-01-01 18:23:28,867	44k	INFO	Train Epoch: 40 [96%]
2024-01-01 18:23:28,869	44k	INFO	Losses: [2.1256940364837646, 2.441232919692993, 5.135645866394043, 32.29430389404297, 1.1876354217529297], step: 1000, lr: 9.951365602954526e-05, reference_loss: 43.18450927734375
2024-01-01 18:23:29,261	44k	INFO	====> Epoch: 40, cost 22.50 s
2024-01-01 18:23:51,451	44k	INFO	====> Epoch: 41, cost 22.19 s
2024-01-01 18:24:13,844	44k	INFO	====> Epoch: 42, cost 22.39 s
2024-01-01 18:24:35,926	44k	INFO	====> Epoch: 43, cost 22.08 s
2024-01-01 18:24:57,988	44k	INFO	====> Epoch: 44, cost 22.06 s
2024-01-01 18:25:19,969	44k	INFO	====> Epoch: 45, cost 21.98 s
2024-01-01 18:25:42,044	44k	INFO	====> Epoch: 46, cost 22.07 s
2024-01-01 18:26:04,185	44k	INFO	====> Epoch: 47, cost 22.14 s
2024-01-01 18:26:26,377	44k	INFO	Train Epoch: 48 [96%]
2024-01-01 18:26:26,379	44k	INFO	Losses: [2.5651350021362305, 2.204832077026367, 3.8605690002441406, 28.35487937927246, 1.0650498867034912], step: 1200, lr: 9.941418589985758e-05, reference_loss: 38.05046463012695
2024-01-01 18:26:26,767	44k	INFO	====> Epoch: 48, cost 22.58 s
2024-01-01 18:26:48,905	44k	INFO	====> Epoch: 49, cost 22.14 s
2024-01-01 18:27:11,077	44k	INFO	====> Epoch: 50, cost 22.17 s
2024-01-01 18:27:33,243	44k	INFO	====> Epoch: 51, cost 22.17 s
2024-01-01 18:27:55,577	44k	INFO	====> Epoch: 52, cost 22.33 s
2024-01-01 18:28:17,768	44k	INFO	====> Epoch: 53, cost 22.19 s
2024-01-01 18:28:39,944	44k	INFO	====> Epoch: 54, cost 22.18 s
2024-01-01 18:29:02,107	44k	INFO	====> Epoch: 55, cost 22.16 s
2024-01-01 18:29:24,279	44k	INFO	Train Epoch: 56 [96%]
2024-01-01 18:29:24,281	44k	INFO	Losses: [2.3284168243408203, 2.1982016563415527, 4.720405578613281, 29.84638023376465, 0.8919984102249146], step: 1400, lr: 9.931481519679228e-05, reference_loss: 39.98540496826172
2024-01-01 18:29:24,679	44k	INFO	====> Epoch: 56, cost 22.57 s
2024-01-01 18:29:46,780	44k	INFO	====> Epoch: 57, cost 22.10 s
2024-01-01 18:30:08,861	44k	INFO	====> Epoch: 58, cost 22.08 s
2024-01-01 18:30:30,801	44k	INFO	====> Epoch: 59, cost 21.94 s
2024-01-01 18:30:52,703	44k	INFO	====> Epoch: 60, cost 21.90 s
2024-01-01 18:31:14,793	44k	INFO	====> Epoch: 61, cost 22.09 s
2024-01-01 18:31:37,134	44k	INFO	====> Epoch: 62, cost 22.34 s
2024-01-01 18:31:59,249	44k	INFO	====> Epoch: 63, cost 22.11 s
2024-01-01 18:32:21,332	44k	INFO	Train Epoch: 64 [96%]
2024-01-01 18:32:21,334	44k	INFO	Losses: [2.7164604663848877, 2.178039789199829, 3.1159605979919434, 28.398937225341797, 0.9057544469833374], step: 1600, lr: 9.921554382096622e-05, reference_loss: 37.31515121459961
2024-01-01 18:32:27,319	44k	INFO	Saving model and optimizer state at iteration 64 to ./logs/44k/G_1600.pth
2024-01-01 18:32:28,250	44k	INFO	Saving model and optimizer state at iteration 64 to ./logs/44k/D_1600.pth
2024-01-01 18:32:28,698	44k	INFO	====> Epoch: 64, cost 29.45 s
2024-01-01 18:32:50,768	44k	INFO	====> Epoch: 65, cost 22.07 s
2024-01-01 18:33:12,933	44k	INFO	====> Epoch: 66, cost 22.16 s
2024-01-01 18:33:35,153	44k	INFO	====> Epoch: 67, cost 22.22 s
2024-01-01 18:33:57,318	44k	INFO	====> Epoch: 68, cost 22.16 s
2024-01-01 18:34:19,544	44k	INFO	====> Epoch: 69, cost 22.23 s
2024-01-01 18:34:41,988	44k	INFO	====> Epoch: 70, cost 22.44 s
2024-01-01 18:35:04,194	44k	INFO	====> Epoch: 71, cost 22.21 s
2024-01-01 18:35:26,548	44k	INFO	Train Epoch: 72 [96%]
2024-01-01 18:35:26,549	44k	INFO	Losses: [2.0082569122314453, 2.059431552886963, 5.077313423156738, 29.873811721801758, 1.0705941915512085], step: 1800, lr: 9.911637167309565e-05, reference_loss: 40.08940887451172
2024-01-01 18:35:26,964	44k	INFO	====> Epoch: 72, cost 22.77 s
2024-01-01 18:35:49,139	44k	INFO	====> Epoch: 73, cost 22.17 s
2024-01-01 18:36:11,228	44k	INFO	====> Epoch: 74, cost 22.09 s
2024-01-01 18:36:33,244	44k	INFO	====> Epoch: 75, cost 22.02 s
2024-01-01 18:36:55,304	44k	INFO	====> Epoch: 76, cost 22.06 s
2024-01-01 18:37:17,392	44k	INFO	====> Epoch: 77, cost 22.09 s
2024-01-01 18:37:39,606	44k	INFO	====> Epoch: 78, cost 22.21 s
2024-01-01 18:38:01,848	44k	INFO	====> Epoch: 79, cost 22.24 s
2024-01-01 18:38:24,087	44k	INFO	Train Epoch: 80 [96%]
2024-01-01 18:38:24,089	44k	INFO	Losses: [2.4188435077667236, 2.1454544067382812, 4.216181755065918, 26.714099884033203, 1.0493439435958862], step: 2000, lr: 9.901729865399597e-05, reference_loss: 36.543922424316406
2024-01-01 18:38:24,663	44k	INFO	====> Epoch: 80, cost 22.82 s
2024-01-01 18:38:46,825	44k	INFO	====> Epoch: 81, cost 22.16 s
2024-01-01 18:39:09,023	44k	INFO	====> Epoch: 82, cost 22.20 s
2024-01-01 18:39:31,194	44k	INFO	====> Epoch: 83, cost 22.17 s
2024-01-01 18:39:53,408	44k	INFO	====> Epoch: 84, cost 22.21 s
2024-01-01 18:40:15,600	44k	INFO	====> Epoch: 85, cost 22.19 s
2024-01-01 18:40:37,827	44k	INFO	====> Epoch: 86, cost 22.23 s
2024-01-01 18:40:59,858	44k	INFO	====> Epoch: 87, cost 22.03 s
2024-01-01 18:41:21,843	44k	INFO	Train Epoch: 88 [96%]
2024-01-01 18:41:21,844	44k	INFO	Losses: [2.3881711959838867, 2.600928783416748, 5.1220703125, 25.06595230102539, 0.8529385328292847], step: 2200, lr: 9.891832466458178e-05, reference_loss: 36.03006362915039
2024-01-01 18:41:22,235	44k	INFO	====> Epoch: 88, cost 22.38 s
2024-01-01 18:41:44,430	44k	INFO	====> Epoch: 89, cost 22.19 s
2024-01-01 18:42:06,580	44k	INFO	====> Epoch: 90, cost 22.15 s
2024-01-01 18:42:28,651	44k	INFO	====> Epoch: 91, cost 22.07 s
2024-01-01 18:42:50,691	44k	INFO	====> Epoch: 92, cost 22.04 s
2024-01-01 18:43:12,778	44k	INFO	====> Epoch: 93, cost 22.09 s
2024-01-01 18:43:34,898	44k	INFO	====> Epoch: 94, cost 22.12 s
2024-01-01 18:43:57,086	44k	INFO	====> Epoch: 95, cost 22.19 s
2024-01-01 18:44:19,272	44k	INFO	Train Epoch: 96 [96%]
2024-01-01 18:44:19,274	44k	INFO	Losses: [2.635371446609497, 2.040389060974121, 3.9433462619781494, 27.076269149780273, 0.8101171255111694], step: 2400, lr: 9.881944960586671e-05, reference_loss: 36.505489349365234
2024-01-01 18:44:25,392	44k	INFO	Saving model and optimizer state at iteration 96 to ./logs/44k/G_2400.pth
2024-01-01 18:44:26,345	44k	INFO	Saving model and optimizer state at iteration 96 to ./logs/44k/D_2400.pth
2024-01-01 18:44:26,820	44k	INFO	====> Epoch: 96, cost 29.73 s
2024-01-01 18:44:49,168	44k	INFO	====> Epoch: 97, cost 22.35 s
2024-01-01 18:45:11,264	44k	INFO	====> Epoch: 98, cost 22.10 s
2024-01-01 18:45:33,338	44k	INFO	====> Epoch: 99, cost 22.07 s
2024-01-01 18:45:55,331	44k	INFO	====> Epoch: 100, cost 21.99 s
2024-01-01 18:46:17,450	44k	INFO	====> Epoch: 101, cost 22.12 s
2024-01-01 18:46:39,454	44k	INFO	====> Epoch: 102, cost 22.00 s
2024-01-01 18:47:01,402	44k	INFO	====> Epoch: 103, cost 21.95 s
2024-01-01 18:47:23,546	44k	INFO	Train Epoch: 104 [96%]
2024-01-01 18:47:23,548	44k	INFO	Losses: [2.094022512435913, 2.436845064163208, 5.453878879547119, 27.408220291137695, 0.9005779027938843], step: 2600, lr: 9.872067337896332e-05, reference_loss: 38.29354476928711
2024-01-01 18:47:23,935	44k	INFO	====> Epoch: 104, cost 22.53 s
2024-01-01 18:47:46,048	44k	INFO	====> Epoch: 105, cost 22.11 s
2024-01-01 18:48:08,151	44k	INFO	====> Epoch: 106, cost 22.10 s
2024-01-01 18:48:30,330	44k	INFO	====> Epoch: 107, cost 22.18 s
2024-01-01 18:48:52,493	44k	INFO	====> Epoch: 108, cost 22.16 s
2024-01-01 18:49:14,817	44k	INFO	====> Epoch: 109, cost 22.32 s
2024-01-01 18:49:37,286	44k	INFO	====> Epoch: 110, cost 22.47 s
2024-01-01 18:49:59,555	44k	INFO	====> Epoch: 111, cost 22.27 s
2024-01-01 18:50:21,828	44k	INFO	Train Epoch: 112 [96%]
2024-01-01 18:50:21,829	44k	INFO	Losses: [2.3606109619140625, 2.106257438659668, 3.8410894870758057, 22.212034225463867, 0.9064919352531433], step: 2800, lr: 9.862199588508305e-05, reference_loss: 31.426485061645508
2024-01-01 18:50:22,225	44k	INFO	====> Epoch: 112, cost 22.67 s
2024-01-01 18:50:44,466	44k	INFO	====> Epoch: 113, cost 22.24 s
2024-01-01 18:51:06,646	44k	INFO	====> Epoch: 114, cost 22.18 s
2024-01-01 18:51:28,741	44k	INFO	====> Epoch: 115, cost 22.10 s
2024-01-01 18:51:51,083	44k	INFO	====> Epoch: 116, cost 22.34 s
2024-01-01 18:52:13,360	44k	INFO	====> Epoch: 117, cost 22.28 s
2024-01-01 18:52:35,429	44k	INFO	====> Epoch: 118, cost 22.07 s
2024-01-01 18:52:57,456	44k	INFO	====> Epoch: 119, cost 22.03 s
2024-01-01 18:53:19,621	44k	INFO	Train Epoch: 120 [96%]
2024-01-01 18:53:19,623	44k	INFO	Losses: [2.7592525482177734, 2.2610697746276855, 4.328516006469727, 23.60684585571289, 0.9116635322570801], step: 3000, lr: 9.8523417025536e-05, reference_loss: 33.867347717285156
2024-01-01 18:53:20,010	44k	INFO	====> Epoch: 120, cost 22.55 s
2024-01-01 18:53:42,135	44k	INFO	====> Epoch: 121, cost 22.13 s
2024-01-01 18:54:04,293	44k	INFO	====> Epoch: 122, cost 22.16 s
2024-01-01 18:54:26,458	44k	INFO	====> Epoch: 123, cost 22.16 s
2024-01-01 18:54:48,683	44k	INFO	====> Epoch: 124, cost 22.23 s
2024-01-01 18:55:10,946	44k	INFO	====> Epoch: 125, cost 22.26 s
2024-01-01 18:55:33,187	44k	INFO	====> Epoch: 126, cost 22.24 s
2024-01-01 18:55:55,413	44k	INFO	====> Epoch: 127, cost 22.23 s
2024-01-01 18:56:17,620	44k	INFO	Train Epoch: 128 [96%]
2024-01-01 18:56:17,622	44k	INFO	Losses: [2.590489387512207, 2.3980321884155273, 4.555770397186279, 23.859638214111328, 0.8483787775039673], step: 3200, lr: 9.842493670173108e-05, reference_loss: 34.2523078918457
2024-01-01 18:56:23,607	44k	INFO	Saving model and optimizer state at iteration 128 to ./logs/44k/G_3200.pth
2024-01-01 18:56:24,544	44k	INFO	Saving model and optimizer state at iteration 128 to ./logs/44k/D_3200.pth
2024-01-01 18:56:25,035	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_800.pth
2024-01-01 18:56:25,074	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_800.pth
2024-01-01 18:56:25,074	44k	INFO	====> Epoch: 128, cost 29.66 s
2024-01-01 18:56:47,205	44k	INFO	====> Epoch: 129, cost 22.13 s
2024-01-01 18:57:09,284	44k	INFO	====> Epoch: 130, cost 22.08 s
2024-01-01 18:57:31,439	44k	INFO	====> Epoch: 131, cost 22.16 s
2024-01-01 18:57:53,671	44k	INFO	====> Epoch: 132, cost 22.23 s
2024-01-01 18:58:15,788	44k	INFO	====> Epoch: 133, cost 22.12 s
2024-01-01 18:58:37,938	44k	INFO	====> Epoch: 134, cost 22.15 s
2024-01-01 18:59:00,007	44k	INFO	====> Epoch: 135, cost 22.07 s
2024-01-01 18:59:22,047	44k	INFO	Train Epoch: 136 [96%]
2024-01-01 18:59:22,049	44k	INFO	Losses: [2.2065062522888184, 2.3372817039489746, 5.147519588470459, 24.061059951782227, 0.8580308556556702], step: 3400, lr: 9.832655481517557e-05, reference_loss: 34.61039733886719
2024-01-01 18:59:22,720	44k	INFO	====> Epoch: 136, cost 22.71 s
2024-01-01 18:59:44,894	44k	INFO	====> Epoch: 137, cost 22.17 s
2024-01-01 19:00:07,093	44k	INFO	====> Epoch: 138, cost 22.20 s
2024-01-01 19:00:29,117	44k	INFO	====> Epoch: 139, cost 22.02 s
2024-01-01 19:00:51,145	44k	INFO	====> Epoch: 140, cost 22.03 s
2024-01-01 19:01:13,332	44k	INFO	====> Epoch: 141, cost 22.19 s
2024-01-01 19:01:35,591	44k	INFO	====> Epoch: 142, cost 22.26 s
2024-01-01 19:01:57,705	44k	INFO	====> Epoch: 143, cost 22.11 s
2024-01-01 19:02:19,724	44k	INFO	Train Epoch: 144 [96%]
2024-01-01 19:02:19,726	44k	INFO	Losses: [2.4581332206726074, 2.131753444671631, 3.816476345062256, 21.176925659179688, 0.8922869563102722], step: 3600, lr: 9.822827126747529e-05, reference_loss: 30.475574493408203
2024-01-01 19:02:20,108	44k	INFO	====> Epoch: 144, cost 22.40 s
2024-01-01 19:02:42,229	44k	INFO	====> Epoch: 145, cost 22.12 s
2024-01-01 19:03:04,629	44k	INFO	====> Epoch: 146, cost 22.40 s
2024-01-01 19:03:26,911	44k	INFO	====> Epoch: 147, cost 22.28 s
2024-01-01 19:03:49,149	44k	INFO	====> Epoch: 148, cost 22.24 s
2024-01-01 19:04:11,330	44k	INFO	====> Epoch: 149, cost 22.18 s
2024-01-01 19:04:33,609	44k	INFO	====> Epoch: 150, cost 22.28 s
2024-01-01 19:04:55,795	44k	INFO	====> Epoch: 151, cost 22.19 s
2024-01-01 19:05:18,041	44k	INFO	Train Epoch: 152 [96%]
2024-01-01 19:05:18,043	44k	INFO	Losses: [2.542850971221924, 2.301788091659546, 5.071994304656982, 23.236366271972656, 0.8210133910179138], step: 3800, lr: 9.813008596033443e-05, reference_loss: 33.97401428222656
2024-01-01 19:05:18,441	44k	INFO	====> Epoch: 152, cost 22.65 s
2024-01-01 19:05:40,726	44k	INFO	====> Epoch: 153, cost 22.29 s
2024-01-01 19:06:03,024	44k	INFO	====> Epoch: 154, cost 22.30 s
2024-01-01 19:06:25,418	44k	INFO	====> Epoch: 155, cost 22.39 s
2024-01-01 19:06:47,972	44k	INFO	====> Epoch: 156, cost 22.55 s
2024-01-01 19:07:10,217	44k	INFO	====> Epoch: 157, cost 22.25 s
2024-01-01 19:07:32,470	44k	INFO	====> Epoch: 158, cost 22.25 s
2024-01-01 19:07:54,699	44k	INFO	====> Epoch: 159, cost 22.23 s
2024-01-01 19:08:16,867	44k	INFO	Train Epoch: 160 [96%]
2024-01-01 19:08:16,869	44k	INFO	Losses: [2.4432156085968018, 2.141319990158081, 3.939793109893799, 23.276418685913086, 0.7873393893241882], step: 4000, lr: 9.803199879555537e-05, reference_loss: 32.58808517456055
2024-01-01 19:08:22,564	44k	INFO	Saving model and optimizer state at iteration 160 to ./logs/44k/G_4000.pth
2024-01-01 19:08:23,512	44k	INFO	Saving model and optimizer state at iteration 160 to ./logs/44k/D_4000.pth
2024-01-01 19:08:24,000	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_1600.pth
2024-01-01 19:08:24,039	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_1600.pth
2024-01-01 19:08:24,039	44k	INFO	====> Epoch: 160, cost 29.34 s
2024-01-01 19:08:45,930	44k	INFO	====> Epoch: 161, cost 21.89 s
2024-01-01 19:09:07,843	44k	INFO	====> Epoch: 162, cost 21.91 s
2024-01-01 19:09:29,800	44k	INFO	====> Epoch: 163, cost 21.96 s
2024-01-01 19:09:51,902	44k	INFO	====> Epoch: 164, cost 22.10 s
2024-01-01 19:10:14,000	44k	INFO	====> Epoch: 165, cost 22.10 s
2024-01-01 19:10:36,131	44k	INFO	====> Epoch: 166, cost 22.13 s
2024-01-01 19:10:58,212	44k	INFO	====> Epoch: 167, cost 22.08 s
2024-01-01 19:11:20,312	44k	INFO	Train Epoch: 168 [96%]
2024-01-01 19:11:20,315	44k	INFO	Losses: [2.324568748474121, 2.140075922012329, 4.334049224853516, 21.089384078979492, 0.8595759868621826], step: 4200, lr: 9.79340096750387e-05, reference_loss: 30.747652053833008
2024-01-01 19:11:20,711	44k	INFO	====> Epoch: 168, cost 22.50 s
2024-01-01 19:11:42,823	44k	INFO	====> Epoch: 169, cost 22.11 s
2024-01-01 19:12:04,937	44k	INFO	====> Epoch: 170, cost 22.11 s
2024-01-01 19:12:27,081	44k	INFO	====> Epoch: 171, cost 22.14 s
2024-01-01 19:12:49,145	44k	INFO	====> Epoch: 172, cost 22.06 s
2024-01-01 19:13:11,169	44k	INFO	====> Epoch: 173, cost 22.02 s
2024-01-01 19:13:33,222	44k	INFO	====> Epoch: 174, cost 22.05 s
2024-01-01 19:13:55,327	44k	INFO	====> Epoch: 175, cost 22.10 s
2024-01-01 19:14:17,661	44k	INFO	Train Epoch: 176 [96%]
2024-01-01 19:14:17,662	44k	INFO	Losses: [2.4583635330200195, 2.0339977741241455, 3.9117987155914307, 20.01700782775879, 0.887787938117981], step: 4400, lr: 9.783611850078301e-05, reference_loss: 29.308956146240234
2024-01-01 19:14:18,061	44k	INFO	====> Epoch: 176, cost 22.73 s
2024-01-01 19:14:40,249	44k	INFO	====> Epoch: 177, cost 22.19 s
2024-01-01 19:15:02,441	44k	INFO	====> Epoch: 178, cost 22.19 s
2024-01-01 19:15:24,821	44k	INFO	====> Epoch: 179, cost 22.38 s
2024-01-01 19:15:47,062	44k	INFO	====> Epoch: 180, cost 22.24 s
2024-01-01 19:16:09,192	44k	INFO	====> Epoch: 181, cost 22.13 s
2024-01-01 19:16:31,396	44k	INFO	====> Epoch: 182, cost 22.20 s
2024-01-01 19:16:53,542	44k	INFO	====> Epoch: 183, cost 22.15 s
2024-01-01 19:17:15,515	44k	INFO	Train Epoch: 184 [96%]
2024-01-01 19:17:15,517	44k	INFO	Losses: [2.5074410438537598, 2.36724853515625, 4.7993621826171875, 21.63868522644043, 0.7816998958587646], step: 4600, lr: 9.773832517488488e-05, reference_loss: 32.09443664550781
2024-01-01 19:17:16,081	44k	INFO	====> Epoch: 184, cost 22.54 s
2024-01-01 19:17:38,051	44k	INFO	====> Epoch: 185, cost 21.97 s
2024-01-01 19:18:00,059	44k	INFO	====> Epoch: 186, cost 22.01 s
2024-01-01 19:18:22,092	44k	INFO	====> Epoch: 187, cost 22.03 s
2024-01-01 19:18:44,093	44k	INFO	====> Epoch: 188, cost 22.00 s
2024-01-01 19:19:06,066	44k	INFO	====> Epoch: 189, cost 21.97 s
2024-01-01 19:19:28,161	44k	INFO	====> Epoch: 190, cost 22.09 s
2024-01-01 19:19:50,279	44k	INFO	====> Epoch: 191, cost 22.12 s
2024-01-01 19:20:12,414	44k	INFO	Train Epoch: 192 [96%]
2024-01-01 19:20:12,416	44k	INFO	Losses: [2.613048791885376, 1.9846761226654053, 3.460036516189575, 20.490530014038086, 0.7035658955574036], step: 4800, lr: 9.764062959953878e-05, reference_loss: 29.251855850219727
2024-01-01 19:20:18,174	44k	INFO	Saving model and optimizer state at iteration 192 to ./logs/44k/G_4800.pth
2024-01-01 19:20:19,300	44k	INFO	Saving model and optimizer state at iteration 192 to ./logs/44k/D_4800.pth
2024-01-01 19:20:19,805	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_2400.pth
2024-01-01 19:20:19,844	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_2400.pth
2024-01-01 19:20:19,844	44k	INFO	====> Epoch: 192, cost 29.57 s
2024-01-01 19:20:41,995	44k	INFO	====> Epoch: 193, cost 22.15 s
2024-01-01 19:21:04,311	44k	INFO	====> Epoch: 194, cost 22.32 s
2024-01-01 19:21:26,561	44k	INFO	====> Epoch: 195, cost 22.25 s
2024-01-01 19:21:48,726	44k	INFO	====> Epoch: 196, cost 22.17 s
2024-01-01 19:22:10,770	44k	INFO	====> Epoch: 197, cost 22.04 s
2024-01-01 19:22:32,858	44k	INFO	====> Epoch: 198, cost 22.09 s
2024-01-01 19:22:54,948	44k	INFO	====> Epoch: 199, cost 22.09 s
2024-01-01 19:23:17,079	44k	INFO	Train Epoch: 200 [96%]
2024-01-01 19:23:17,080	44k	INFO	Losses: [2.322924852371216, 2.298352003097534, 4.846705436706543, 21.654308319091797, 0.7816141843795776], step: 5000, lr: 9.754303167703689e-05, reference_loss: 31.903905868530273
2024-01-01 19:23:17,575	44k	INFO	====> Epoch: 200, cost 22.63 s
2024-01-01 19:23:39,711	44k	INFO	====> Epoch: 201, cost 22.14 s
2024-01-01 19:24:01,915	44k	INFO	====> Epoch: 202, cost 22.20 s
2024-01-01 19:24:23,882	44k	INFO	====> Epoch: 203, cost 21.97 s
2024-01-01 19:24:45,831	44k	INFO	====> Epoch: 204, cost 21.95 s
2024-01-01 19:25:07,842	44k	INFO	====> Epoch: 205, cost 22.01 s
2024-01-01 19:25:29,905	44k	INFO	====> Epoch: 206, cost 22.06 s
2024-01-01 19:25:51,986	44k	INFO	====> Epoch: 207, cost 22.08 s
2024-01-01 19:26:14,014	44k	INFO	Train Epoch: 208 [96%]
2024-01-01 19:26:14,017	44k	INFO	Losses: [2.4297804832458496, 2.0914430618286133, 3.7756056785583496, 19.336843490600586, 0.8261855244636536], step: 5200, lr: 9.744553130976908e-05, reference_loss: 28.459857940673828
2024-01-01 19:26:14,500	44k	INFO	====> Epoch: 208, cost 22.51 s
2024-01-01 19:26:36,651	44k	INFO	====> Epoch: 209, cost 22.15 s
2024-01-01 19:26:58,726	44k	INFO	====> Epoch: 210, cost 22.08 s
2024-01-01 19:27:20,872	44k	INFO	====> Epoch: 211, cost 22.15 s
2024-01-01 19:27:43,099	44k	INFO	====> Epoch: 212, cost 22.23 s
2024-01-01 19:28:05,207	44k	INFO	====> Epoch: 213, cost 22.11 s
2024-01-01 19:28:27,356	44k	INFO	====> Epoch: 214, cost 22.15 s
2024-01-01 19:28:49,544	44k	INFO	====> Epoch: 215, cost 22.19 s
2024-01-01 19:29:11,637	44k	INFO	Train Epoch: 216 [96%]
2024-01-01 19:29:11,639	44k	INFO	Losses: [2.4460949897766113, 2.253084897994995, 5.495707035064697, 22.050397872924805, 0.7170935273170471], step: 5400, lr: 9.734812840022278e-05, reference_loss: 32.962379455566406
2024-01-01 19:29:12,032	44k	INFO	====> Epoch: 216, cost 22.49 s
2024-01-01 19:29:34,025	44k	INFO	====> Epoch: 217, cost 21.99 s
2024-01-01 19:29:56,154	44k	INFO	====> Epoch: 218, cost 22.13 s
2024-01-01 19:30:18,438	44k	INFO	====> Epoch: 219, cost 22.28 s
2024-01-01 19:30:40,660	44k	INFO	====> Epoch: 220, cost 22.22 s
2024-01-01 19:31:02,839	44k	INFO	====> Epoch: 221, cost 22.18 s
2024-01-01 19:31:25,146	44k	INFO	====> Epoch: 222, cost 22.31 s
2024-01-01 19:31:47,331	44k	INFO	====> Epoch: 223, cost 22.19 s
2024-01-01 19:32:09,447	44k	INFO	Train Epoch: 224 [96%]
2024-01-01 19:32:09,450	44k	INFO	Losses: [2.35783314704895, 2.1114935874938965, 4.442127227783203, 22.640928268432617, 0.6913269758224487], step: 5600, lr: 9.725082285098293e-05, reference_loss: 32.243709564208984
2024-01-01 19:32:15,157	44k	INFO	Saving model and optimizer state at iteration 224 to ./logs/44k/G_5600.pth
2024-01-01 19:32:16,106	44k	INFO	Saving model and optimizer state at iteration 224 to ./logs/44k/D_5600.pth
2024-01-01 19:32:16,613	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_3200.pth
2024-01-01 19:32:16,652	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_3200.pth
2024-01-01 19:32:16,652	44k	INFO	====> Epoch: 224, cost 29.32 s
2024-01-01 19:32:38,646	44k	INFO	====> Epoch: 225, cost 21.99 s
2024-01-01 19:33:00,614	44k	INFO	====> Epoch: 226, cost 21.97 s
2024-01-01 19:33:22,644	44k	INFO	====> Epoch: 227, cost 22.03 s
2024-01-01 19:33:44,673	44k	INFO	====> Epoch: 228, cost 22.03 s
2024-01-01 19:34:06,739	44k	INFO	====> Epoch: 229, cost 22.07 s
2024-01-01 19:34:28,932	44k	INFO	====> Epoch: 230, cost 22.19 s
2024-01-01 19:34:50,987	44k	INFO	====> Epoch: 231, cost 22.06 s
2024-01-01 19:35:13,219	44k	INFO	Train Epoch: 232 [96%]
2024-01-01 19:35:13,221	44k	INFO	Losses: [2.4362497329711914, 2.4210736751556396, 4.254622936248779, 20.063077926635742, 0.7554654479026794], step: 5800, lr: 9.715361456473177e-05, reference_loss: 29.93048858642578
2024-01-01 19:35:13,615	44k	INFO	====> Epoch: 232, cost 22.63 s
2024-01-01 19:35:35,805	44k	INFO	====> Epoch: 233, cost 22.19 s
2024-01-01 19:35:58,017	44k	INFO	====> Epoch: 234, cost 22.21 s
2024-01-01 19:36:20,192	44k	INFO	====> Epoch: 235, cost 22.18 s
2024-01-01 19:36:42,298	44k	INFO	====> Epoch: 236, cost 22.11 s
2024-01-01 19:37:04,408	44k	INFO	====> Epoch: 237, cost 22.11 s
2024-01-01 19:37:26,548	44k	INFO	====> Epoch: 238, cost 22.14 s
2024-01-01 19:37:48,692	44k	INFO	====> Epoch: 239, cost 22.14 s
2024-01-01 19:38:10,816	44k	INFO	Train Epoch: 240 [96%]
2024-01-01 19:38:10,818	44k	INFO	Losses: [2.2421553134918213, 2.2975573539733887, 4.79020881652832, 19.732336044311523, 0.7250698208808899], step: 6000, lr: 9.705650344424885e-05, reference_loss: 29.78732681274414
2024-01-01 19:38:11,391	44k	INFO	====> Epoch: 240, cost 22.70 s
2024-01-01 19:38:33,388	44k	INFO	====> Epoch: 241, cost 22.00 s
2024-01-01 19:38:55,402	44k	INFO	====> Epoch: 242, cost 22.01 s
2024-01-01 19:39:17,549	44k	INFO	====> Epoch: 243, cost 22.15 s
2024-01-01 19:39:39,757	44k	INFO	====> Epoch: 244, cost 22.21 s
2024-01-01 19:40:01,958	44k	INFO	====> Epoch: 245, cost 22.20 s
2024-01-01 19:40:24,176	44k	INFO	====> Epoch: 246, cost 22.22 s
2024-01-01 19:40:46,308	44k	INFO	====> Epoch: 247, cost 22.13 s
2024-01-01 19:41:08,551	44k	INFO	Train Epoch: 248 [96%]
2024-01-01 19:41:08,552	44k	INFO	Losses: [2.5059876441955566, 2.2508957386016846, 4.825827121734619, 20.55894660949707, 0.6107931137084961], step: 6200, lr: 9.695948939241093e-05, reference_loss: 30.75244903564453
2024-01-01 19:41:08,954	44k	INFO	====> Epoch: 248, cost 22.65 s
2024-01-01 19:41:31,455	44k	INFO	====> Epoch: 249, cost 22.50 s
2024-01-01 19:41:53,631	44k	INFO	====> Epoch: 250, cost 22.18 s
2024-01-01 19:42:15,755	44k	INFO	====> Epoch: 251, cost 22.12 s
2024-01-01 19:42:38,039	44k	INFO	====> Epoch: 252, cost 22.28 s
2024-01-01 19:43:00,218	44k	INFO	====> Epoch: 253, cost 22.18 s
2024-01-01 19:43:22,392	44k	INFO	====> Epoch: 254, cost 22.17 s
2024-01-01 19:43:44,550	44k	INFO	====> Epoch: 255, cost 22.16 s
2024-01-01 19:44:06,764	44k	INFO	Train Epoch: 256 [96%]
2024-01-01 19:44:06,766	44k	INFO	Losses: [2.35351300239563, 2.468076229095459, 4.028923034667969, 19.990976333618164, 0.6772820949554443], step: 6400, lr: 9.68625723121918e-05, reference_loss: 29.518770217895508
2024-01-01 19:44:12,705	44k	INFO	Saving model and optimizer state at iteration 256 to ./logs/44k/G_6400.pth
2024-01-01 19:44:13,642	44k	INFO	Saving model and optimizer state at iteration 256 to ./logs/44k/D_6400.pth
2024-01-01 19:44:14,143	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_4000.pth
2024-01-01 19:44:14,181	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_4000.pth
2024-01-01 19:44:14,182	44k	INFO	====> Epoch: 256, cost 29.63 s
2024-01-01 19:44:36,534	44k	INFO	====> Epoch: 257, cost 22.35 s
2024-01-01 19:44:58,545	44k	INFO	====> Epoch: 258, cost 22.01 s
2024-01-01 19:45:20,599	44k	INFO	====> Epoch: 259, cost 22.05 s
2024-01-01 19:45:42,567	44k	INFO	====> Epoch: 260, cost 21.97 s
2024-01-01 19:46:04,760	44k	INFO	====> Epoch: 261, cost 22.19 s
2024-01-01 19:46:26,906	44k	INFO	====> Epoch: 262, cost 22.15 s
2024-01-01 19:46:48,975	44k	INFO	====> Epoch: 263, cost 22.07 s
2024-01-01 19:47:11,019	44k	INFO	Train Epoch: 264 [96%]
2024-01-01 19:47:11,021	44k	INFO	Losses: [2.2821574211120605, 2.439901351928711, 5.182775497436523, 21.73285675048828, 0.7464649677276611], step: 6600, lr: 9.676575210666227e-05, reference_loss: 32.3841552734375
2024-01-01 19:47:11,418	44k	INFO	====> Epoch: 264, cost 22.44 s
2024-01-01 19:47:33,555	44k	INFO	====> Epoch: 265, cost 22.14 s
2024-01-01 19:47:55,806	44k	INFO	====> Epoch: 266, cost 22.25 s
2024-01-01 19:48:18,106	44k	INFO	====> Epoch: 267, cost 22.30 s
2024-01-01 19:48:40,392	44k	INFO	====> Epoch: 268, cost 22.29 s
2024-01-01 19:49:02,618	44k	INFO	====> Epoch: 269, cost 22.23 s
2024-01-01 19:49:24,964	44k	INFO	====> Epoch: 270, cost 22.35 s
2024-01-01 19:49:47,181	44k	INFO	====> Epoch: 271, cost 22.22 s
2024-01-01 19:50:09,429	44k	INFO	Train Epoch: 272 [96%]
2024-01-01 19:50:09,431	44k	INFO	Losses: [2.4424614906311035, 2.118983745574951, 3.813795566558838, 17.29857635498047, 0.7596245408058167], step: 6800, lr: 9.666902867899003e-05, reference_loss: 26.433441162109375
2024-01-01 19:50:09,825	44k	INFO	====> Epoch: 272, cost 22.64 s
2024-01-01 19:50:32,024	44k	INFO	====> Epoch: 273, cost 22.20 s
2024-01-01 19:50:54,434	44k	INFO	====> Epoch: 274, cost 22.41 s
2024-01-01 19:51:16,796	44k	INFO	====> Epoch: 275, cost 22.36 s
2024-01-01 19:51:39,159	44k	INFO	====> Epoch: 276, cost 22.36 s
2024-01-01 19:52:01,517	44k	INFO	====> Epoch: 277, cost 22.36 s
2024-01-01 19:52:23,894	44k	INFO	====> Epoch: 278, cost 22.38 s
2024-01-01 19:52:46,242	44k	INFO	====> Epoch: 279, cost 22.35 s
2024-01-01 19:53:08,629	44k	INFO	Train Epoch: 280 [96%]
2024-01-01 19:53:08,631	44k	INFO	Losses: [2.4984819889068604, 2.0001094341278076, 4.961931228637695, 21.21002197265625, 0.6946170330047607], step: 7000, lr: 9.657240193243954e-05, reference_loss: 31.36515998840332
2024-01-01 19:53:09,016	44k	INFO	====> Epoch: 280, cost 22.77 s
2024-01-01 19:53:31,181	44k	INFO	====> Epoch: 281, cost 22.17 s
2024-01-01 19:53:53,324	44k	INFO	====> Epoch: 282, cost 22.14 s
2024-01-01 19:54:15,458	44k	INFO	====> Epoch: 283, cost 22.13 s
2024-01-01 19:54:37,618	44k	INFO	====> Epoch: 284, cost 22.16 s
2024-01-01 19:54:59,845	44k	INFO	====> Epoch: 285, cost 22.23 s
2024-01-01 19:55:22,098	44k	INFO	====> Epoch: 286, cost 22.25 s
2024-01-01 19:55:44,286	44k	INFO	====> Epoch: 287, cost 22.19 s
2024-01-01 19:56:06,597	44k	INFO	Train Epoch: 288 [96%]
2024-01-01 19:56:06,598	44k	INFO	Losses: [2.6093971729278564, 2.2697913646698, 4.1925740242004395, 20.602619171142578, 0.5269720554351807], step: 7200, lr: 9.647587177037196e-05, reference_loss: 30.201353073120117
2024-01-01 19:56:12,930	44k	INFO	Saving model and optimizer state at iteration 288 to ./logs/44k/G_7200.pth
2024-01-01 19:56:13,881	44k	INFO	Saving model and optimizer state at iteration 288 to ./logs/44k/D_7200.pth
2024-01-01 19:56:14,392	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_4800.pth
2024-01-01 19:56:14,431	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_4800.pth
2024-01-01 19:56:14,431	44k	INFO	====> Epoch: 288, cost 30.15 s
2024-01-01 19:56:36,596	44k	INFO	====> Epoch: 289, cost 22.17 s
2024-01-01 19:56:58,774	44k	INFO	====> Epoch: 290, cost 22.18 s
2024-01-01 19:57:20,951	44k	INFO	====> Epoch: 291, cost 22.18 s
2024-01-01 19:57:42,946	44k	INFO	====> Epoch: 292, cost 21.99 s
2024-01-01 19:58:05,117	44k	INFO	====> Epoch: 293, cost 22.17 s
2024-01-01 19:58:27,341	44k	INFO	====> Epoch: 294, cost 22.22 s
2024-01-01 19:58:49,598	44k	INFO	====> Epoch: 295, cost 22.26 s
2024-01-01 19:59:11,832	44k	INFO	Train Epoch: 296 [96%]
2024-01-01 19:59:11,834	44k	INFO	Losses: [2.3965091705322266, 2.2852649688720703, 5.295224189758301, 20.591510772705078, 0.7329587936401367], step: 7400, lr: 9.637943809624507e-05, reference_loss: 31.301467895507812
2024-01-01 19:59:12,421	44k	INFO	====> Epoch: 296, cost 22.82 s
2024-01-01 19:59:34,657	44k	INFO	====> Epoch: 297, cost 22.24 s
2024-01-01 19:59:56,838	44k	INFO	====> Epoch: 298, cost 22.18 s
2024-01-01 20:00:18,969	44k	INFO	====> Epoch: 299, cost 22.13 s
2024-01-01 20:00:41,018	44k	INFO	====> Epoch: 300, cost 22.05 s
2024-01-01 20:01:03,183	44k	INFO	====> Epoch: 301, cost 22.17 s
2024-01-01 20:01:25,364	44k	INFO	====> Epoch: 302, cost 22.18 s
2024-01-01 20:01:47,570	44k	INFO	====> Epoch: 303, cost 22.21 s
2024-01-01 20:02:09,749	44k	INFO	Train Epoch: 304 [96%]
2024-01-01 20:02:09,751	44k	INFO	Losses: [2.4722044467926025, 2.0380101203918457, 3.917210578918457, 17.833232879638672, 0.7952064275741577], step: 7600, lr: 9.628310081361311e-05, reference_loss: 27.055864334106445
2024-01-01 20:02:10,149	44k	INFO	====> Epoch: 304, cost 22.58 s
2024-01-01 20:02:32,327	44k	INFO	====> Epoch: 305, cost 22.18 s
2024-01-01 20:02:54,653	44k	INFO	====> Epoch: 306, cost 22.33 s
2024-01-01 20:03:16,745	44k	INFO	====> Epoch: 307, cost 22.09 s
2024-01-01 20:03:38,838	44k	INFO	====> Epoch: 308, cost 22.09 s
2024-01-01 20:04:00,998	44k	INFO	====> Epoch: 309, cost 22.16 s
2024-01-01 20:04:23,138	44k	INFO	====> Epoch: 310, cost 22.14 s
2024-01-01 20:04:45,319	44k	INFO	====> Epoch: 311, cost 22.18 s
2024-01-01 20:05:07,504	44k	INFO	Train Epoch: 312 [96%]
2024-01-01 20:05:07,506	44k	INFO	Losses: [2.4512293338775635, 2.091151714324951, 4.897199630737305, 19.898414611816406, 0.5297833681106567], step: 7800, lr: 9.618685982612675e-05, reference_loss: 29.867778778076172
2024-01-01 20:05:07,883	44k	INFO	====> Epoch: 312, cost 22.56 s
2024-01-01 20:05:29,905	44k	INFO	====> Epoch: 313, cost 22.02 s
2024-01-01 20:05:52,005	44k	INFO	====> Epoch: 314, cost 22.10 s
2024-01-01 20:06:14,140	44k	INFO	====> Epoch: 315, cost 22.13 s
2024-01-01 20:06:36,486	44k	INFO	====> Epoch: 316, cost 22.35 s
2024-01-01 20:06:58,628	44k	INFO	====> Epoch: 317, cost 22.14 s
2024-01-01 20:07:20,745	44k	INFO	====> Epoch: 318, cost 22.12 s
2024-01-01 20:07:42,860	44k	INFO	====> Epoch: 319, cost 22.11 s
2024-01-01 20:08:05,078	44k	INFO	Train Epoch: 320 [96%]
2024-01-01 20:08:05,080	44k	INFO	Losses: [2.4397401809692383, 2.3847713470458984, 4.775332450866699, 20.950490951538086, 0.526067852973938], step: 8000, lr: 9.609071503753299e-05, reference_loss: 31.07640266418457
2024-01-01 20:08:11,209	44k	INFO	Saving model and optimizer state at iteration 320 to ./logs/44k/G_8000.pth
2024-01-01 20:08:12,144	44k	INFO	Saving model and optimizer state at iteration 320 to ./logs/44k/D_8000.pth
2024-01-01 20:08:12,658	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_5600.pth
2024-01-01 20:08:12,697	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_5600.pth
2024-01-01 20:08:12,698	44k	INFO	====> Epoch: 320, cost 29.84 s
2024-01-01 20:08:34,882	44k	INFO	====> Epoch: 321, cost 22.18 s
2024-01-01 20:08:57,070	44k	INFO	====> Epoch: 322, cost 22.19 s
2024-01-01 20:09:19,357	44k	INFO	====> Epoch: 323, cost 22.29 s
2024-01-01 20:09:41,869	44k	INFO	====> Epoch: 324, cost 22.51 s
2024-01-01 20:10:04,134	44k	INFO	====> Epoch: 325, cost 22.27 s
2024-01-01 20:10:26,362	44k	INFO	====> Epoch: 326, cost 22.23 s
2024-01-01 20:10:48,469	44k	INFO	====> Epoch: 327, cost 22.11 s
2024-01-01 20:11:10,694	44k	INFO	Train Epoch: 328 [96%]
2024-01-01 20:11:10,696	44k	INFO	Losses: [2.250359535217285, 2.5240094661712646, 5.459625244140625, 20.673139572143555, 0.6021283864974976], step: 8200, lr: 9.599466635167497e-05, reference_loss: 31.50926399230957
2024-01-01 20:11:11,091	44k	INFO	====> Epoch: 328, cost 22.62 s
2024-01-01 20:11:33,475	44k	INFO	====> Epoch: 329, cost 22.38 s
2024-01-01 20:11:55,874	44k	INFO	====> Epoch: 330, cost 22.40 s
2024-01-01 20:12:18,145	44k	INFO	====> Epoch: 331, cost 22.27 s
2024-01-01 20:12:40,370	44k	INFO	====> Epoch: 332, cost 22.22 s
2024-01-01 20:13:02,582	44k	INFO	====> Epoch: 333, cost 22.21 s
2024-01-01 20:13:24,855	44k	INFO	====> Epoch: 334, cost 22.27 s
2024-01-01 20:13:47,154	44k	INFO	====> Epoch: 335, cost 22.30 s
2024-01-01 20:14:09,590	44k	INFO	Train Epoch: 336 [96%]
2024-01-01 20:14:09,592	44k	INFO	Losses: [2.3941264152526855, 2.275237798690796, 4.358722686767578, 18.765522003173828, 0.6756108403205872], step: 8400, lr: 9.589871367249203e-05, reference_loss: 28.469221115112305
2024-01-01 20:14:09,983	44k	INFO	====> Epoch: 336, cost 22.83 s
2024-01-01 20:14:32,206	44k	INFO	====> Epoch: 337, cost 22.22 s
2024-01-01 20:14:54,562	44k	INFO	====> Epoch: 338, cost 22.36 s
2024-01-01 20:15:16,867	44k	INFO	====> Epoch: 339, cost 22.31 s
2024-01-01 20:15:39,124	44k	INFO	====> Epoch: 340, cost 22.26 s
2024-01-01 20:16:01,434	44k	INFO	====> Epoch: 341, cost 22.31 s
2024-01-01 20:16:23,860	44k	INFO	====> Epoch: 342, cost 22.43 s
2024-01-01 20:16:46,278	44k	INFO	====> Epoch: 343, cost 22.42 s
2024-01-01 20:17:08,560	44k	INFO	Train Epoch: 344 [96%]
2024-01-01 20:17:08,561	44k	INFO	Losses: [2.6376166343688965, 2.1353628635406494, 5.479111671447754, 20.641956329345703, 0.5682117342948914], step: 8600, lr: 9.580285690401946e-05, reference_loss: 31.46225929260254
2024-01-01 20:17:09,284	44k	INFO	====> Epoch: 344, cost 23.01 s
2024-01-01 20:17:31,429	44k	INFO	====> Epoch: 345, cost 22.14 s
2024-01-01 20:17:53,546	44k	INFO	====> Epoch: 346, cost 22.12 s
2024-01-01 20:18:15,817	44k	INFO	====> Epoch: 347, cost 22.27 s
2024-01-01 20:18:38,056	44k	INFO	====> Epoch: 348, cost 22.24 s
2024-01-01 20:19:00,171	44k	INFO	====> Epoch: 349, cost 22.12 s
2024-01-01 20:19:22,329	44k	INFO	====> Epoch: 350, cost 22.16 s
2024-01-01 20:19:44,542	44k	INFO	====> Epoch: 351, cost 22.21 s
2024-01-01 20:20:06,810	44k	INFO	Train Epoch: 352 [96%]
2024-01-01 20:20:06,812	44k	INFO	Losses: [2.377332925796509, 2.170384168624878, 4.790680408477783, 19.958187103271484, 0.471405565738678], step: 8800, lr: 9.570709595038851e-05, reference_loss: 29.767990112304688
2024-01-01 20:20:12,702	44k	INFO	Saving model and optimizer state at iteration 352 to ./logs/44k/G_8800.pth
2024-01-01 20:20:13,801	44k	INFO	Saving model and optimizer state at iteration 352 to ./logs/44k/D_8800.pth
2024-01-01 20:20:14,307	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_6400.pth
2024-01-01 20:20:14,346	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_6400.pth
2024-01-01 20:20:14,347	44k	INFO	====> Epoch: 352, cost 29.80 s
2024-01-01 20:20:36,639	44k	INFO	====> Epoch: 353, cost 22.29 s
2024-01-01 20:20:59,069	44k	INFO	====> Epoch: 354, cost 22.43 s
2024-01-01 20:21:21,398	44k	INFO	====> Epoch: 355, cost 22.33 s
2024-01-01 20:21:43,674	44k	INFO	====> Epoch: 356, cost 22.28 s
2024-01-01 20:22:05,933	44k	INFO	====> Epoch: 357, cost 22.26 s
2024-01-01 20:22:28,274	44k	INFO	====> Epoch: 358, cost 22.34 s
2024-01-01 20:22:50,560	44k	INFO	====> Epoch: 359, cost 22.29 s
2024-01-01 20:23:12,890	44k	INFO	Train Epoch: 360 [96%]
2024-01-01 20:23:12,892	44k	INFO	Losses: [2.2560007572174072, 2.4730801582336426, 5.480329513549805, 21.396791458129883, 0.6013977527618408], step: 9000, lr: 9.561143071582622e-05, reference_loss: 32.20759963989258
2024-01-01 20:23:13,283	44k	INFO	====> Epoch: 360, cost 22.72 s
2024-01-01 20:23:35,560	44k	INFO	====> Epoch: 361, cost 22.28 s
2024-01-01 20:23:57,990	44k	INFO	====> Epoch: 362, cost 22.43 s
2024-01-01 20:24:20,206	44k	INFO	====> Epoch: 363, cost 22.22 s
2024-01-01 20:24:42,418	44k	INFO	====> Epoch: 364, cost 22.21 s
2024-01-01 20:25:04,658	44k	INFO	====> Epoch: 365, cost 22.24 s
2024-01-01 20:25:26,881	44k	INFO	====> Epoch: 366, cost 22.22 s
2024-01-01 20:25:49,072	44k	INFO	====> Epoch: 367, cost 22.19 s
2024-01-01 20:26:11,279	44k	INFO	Train Epoch: 368 [96%]
2024-01-01 20:26:11,280	44k	INFO	Losses: [2.3146963119506836, 2.2447128295898438, 4.145709037780762, 16.72348976135254, 0.6895796656608582], step: 9200, lr: 9.551586110465545e-05, reference_loss: 26.118186950683594
2024-01-01 20:26:11,701	44k	INFO	====> Epoch: 368, cost 22.63 s
2024-01-01 20:26:33,948	44k	INFO	====> Epoch: 369, cost 22.25 s
2024-01-01 20:26:56,148	44k	INFO	====> Epoch: 370, cost 22.20 s
2024-01-01 20:27:18,355	44k	INFO	====> Epoch: 371, cost 22.21 s
2024-01-01 20:27:40,660	44k	INFO	====> Epoch: 372, cost 22.30 s
2024-01-01 20:28:02,799	44k	INFO	====> Epoch: 373, cost 22.14 s
2024-01-01 20:28:24,989	44k	INFO	====> Epoch: 374, cost 22.19 s
2024-01-01 20:28:47,282	44k	INFO	====> Epoch: 375, cost 22.29 s
2024-01-01 20:29:09,475	44k	INFO	Train Epoch: 376 [96%]
2024-01-01 20:29:09,477	44k	INFO	Losses: [2.4476728439331055, 2.1293540000915527, 5.084743022918701, 19.99417495727539, 0.5208724737167358], step: 9400, lr: 9.542038702129457e-05, reference_loss: 30.176816940307617
2024-01-01 20:29:09,882	44k	INFO	====> Epoch: 376, cost 22.60 s
2024-01-01 20:29:32,170	44k	INFO	====> Epoch: 377, cost 22.29 s
2024-01-01 20:29:54,507	44k	INFO	====> Epoch: 378, cost 22.34 s
2024-01-01 20:30:16,844	44k	INFO	====> Epoch: 379, cost 22.34 s
2024-01-01 20:30:39,194	44k	INFO	====> Epoch: 380, cost 22.35 s
2024-01-01 20:31:01,557	44k	INFO	====> Epoch: 381, cost 22.36 s
2024-01-01 20:31:24,020	44k	INFO	====> Epoch: 382, cost 22.46 s
2024-01-01 20:31:46,427	44k	INFO	====> Epoch: 383, cost 22.41 s
2024-01-01 20:32:08,844	44k	INFO	Train Epoch: 384 [96%]
2024-01-01 20:32:08,845	44k	INFO	Losses: [2.3892831802368164, 2.4435176849365234, 5.061960697174072, 20.54201889038086, 0.5804593563079834], step: 9600, lr: 9.532500837025758e-05, reference_loss: 31.017240524291992
2024-01-01 20:32:15,086	44k	INFO	Saving model and optimizer state at iteration 384 to ./logs/44k/G_9600.pth
2024-01-01 20:32:16,024	44k	INFO	Saving model and optimizer state at iteration 384 to ./logs/44k/D_9600.pth
2024-01-01 20:32:16,553	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_7200.pth
2024-01-01 20:32:16,592	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_7200.pth
2024-01-01 20:32:16,593	44k	INFO	====> Epoch: 384, cost 30.17 s
2024-01-01 20:32:38,893	44k	INFO	====> Epoch: 385, cost 22.30 s
2024-01-01 20:33:01,406	44k	INFO	====> Epoch: 386, cost 22.51 s
2024-01-01 20:33:23,803	44k	INFO	====> Epoch: 387, cost 22.40 s
2024-01-01 20:33:46,204	44k	INFO	====> Epoch: 388, cost 22.40 s
2024-01-01 20:34:08,660	44k	INFO	====> Epoch: 389, cost 22.46 s
2024-01-01 20:34:31,119	44k	INFO	====> Epoch: 390, cost 22.46 s
2024-01-01 20:34:53,449	44k	INFO	====> Epoch: 391, cost 22.33 s
2024-01-01 20:35:15,818	44k	INFO	Train Epoch: 392 [96%]
2024-01-01 20:35:15,820	44k	INFO	Losses: [2.264479875564575, 2.3968420028686523, 5.593777179718018, 20.339309692382812, 0.6090545654296875], step: 9800, lr: 9.522972505615393e-05, reference_loss: 31.203462600708008
2024-01-01 20:35:16,203	44k	INFO	====> Epoch: 392, cost 22.75 s
2024-01-01 20:35:38,489	44k	INFO	====> Epoch: 393, cost 22.29 s
2024-01-01 20:36:00,637	44k	INFO	====> Epoch: 394, cost 22.15 s
2024-01-01 20:36:23,006	44k	INFO	====> Epoch: 395, cost 22.37 s
2024-01-01 20:36:45,387	44k	INFO	====> Epoch: 396, cost 22.38 s
2024-01-01 20:37:07,760	44k	INFO	====> Epoch: 397, cost 22.37 s
2024-01-01 20:37:30,075	44k	INFO	====> Epoch: 398, cost 22.31 s
2024-01-01 20:37:52,427	44k	INFO	====> Epoch: 399, cost 22.35 s
2024-01-01 20:38:14,852	44k	INFO	Train Epoch: 400 [96%]
2024-01-01 20:38:14,853	44k	INFO	Losses: [2.4196534156799316, 2.3074216842651367, 4.1431121826171875, 16.803375244140625, 0.633793830871582], step: 10000, lr: 9.513453698368834e-05, reference_loss: 26.307357788085938
2024-01-01 20:38:15,483	44k	INFO	====> Epoch: 400, cost 23.06 s
2024-01-01 20:38:37,907	44k	INFO	====> Epoch: 401, cost 22.42 s
2024-01-01 20:39:00,291	44k	INFO	====> Epoch: 402, cost 22.38 s
2024-01-01 20:39:22,613	44k	INFO	====> Epoch: 403, cost 22.32 s
2024-01-01 20:39:44,909	44k	INFO	====> Epoch: 404, cost 22.30 s
2024-01-01 20:40:07,059	44k	INFO	====> Epoch: 405, cost 22.15 s
2024-01-01 20:40:29,290	44k	INFO	====> Epoch: 406, cost 22.23 s
2024-01-01 20:40:51,523	44k	INFO	====> Epoch: 407, cost 22.23 s
2024-01-01 20:41:13,743	44k	INFO	Train Epoch: 408 [96%]
2024-01-01 20:41:13,745	44k	INFO	Losses: [2.4154489040374756, 2.32399845123291, 5.2609357833862305, 18.77138328552246, 0.5715950727462769], step: 10200, lr: 9.503944405766085e-05, reference_loss: 29.343360900878906
2024-01-01 20:41:14,216	44k	INFO	====> Epoch: 408, cost 22.69 s
2024-01-01 20:41:36,640	44k	INFO	====> Epoch: 409, cost 22.42 s
2024-01-01 20:41:58,930	44k	INFO	====> Epoch: 410, cost 22.29 s
2024-01-01 20:42:21,132	44k	INFO	====> Epoch: 411, cost 22.20 s
2024-01-01 20:42:43,317	44k	INFO	====> Epoch: 412, cost 22.19 s
2024-01-01 20:43:05,675	44k	INFO	====> Epoch: 413, cost 22.36 s
2024-01-01 20:43:28,059	44k	INFO	====> Epoch: 414, cost 22.38 s
2024-01-01 20:43:50,497	44k	INFO	====> Epoch: 415, cost 22.44 s
2024-01-01 20:44:12,977	44k	INFO	Train Epoch: 416 [96%]
2024-01-01 20:44:12,978	44k	INFO	Losses: [2.412358283996582, 2.090876340866089, 4.408924579620361, 18.919679641723633, 0.48712703585624695], step: 10400, lr: 9.494444618296661e-05, reference_loss: 28.318965911865234
2024-01-01 20:44:19,189	44k	INFO	Saving model and optimizer state at iteration 416 to ./logs/44k/G_10400.pth
2024-01-01 20:44:20,118	44k	INFO	Saving model and optimizer state at iteration 416 to ./logs/44k/D_10400.pth
2024-01-01 20:44:20,637	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_8000.pth
2024-01-01 20:44:20,677	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_8000.pth
2024-01-01 20:44:20,677	44k	INFO	====> Epoch: 416, cost 30.18 s
2024-01-01 20:44:43,005	44k	INFO	====> Epoch: 417, cost 22.33 s
2024-01-01 20:45:05,147	44k	INFO	====> Epoch: 418, cost 22.14 s
2024-01-01 20:45:27,279	44k	INFO	====> Epoch: 419, cost 22.13 s
2024-01-01 20:45:49,366	44k	INFO	====> Epoch: 420, cost 22.09 s
2024-01-01 20:46:11,440	44k	INFO	====> Epoch: 421, cost 22.07 s
2024-01-01 20:46:33,692	44k	INFO	====> Epoch: 422, cost 22.25 s
2024-01-01 20:46:56,026	44k	INFO	====> Epoch: 423, cost 22.33 s
2024-01-01 20:47:18,374	44k	INFO	Train Epoch: 424 [96%]
2024-01-01 20:47:18,376	44k	INFO	Losses: [2.3065333366394043, 2.373253345489502, 5.386876106262207, 20.731863021850586, 0.5761843323707581], step: 10600, lr: 9.484954326459589e-05, reference_loss: 31.374711990356445
2024-01-01 20:47:18,783	44k	INFO	====> Epoch: 424, cost 22.76 s
2024-01-01 20:47:40,984	44k	INFO	====> Epoch: 425, cost 22.20 s
2024-01-01 20:48:03,213	44k	INFO	====> Epoch: 426, cost 22.23 s
2024-01-01 20:48:25,487	44k	INFO	====> Epoch: 427, cost 22.27 s
2024-01-01 20:48:47,734	44k	INFO	====> Epoch: 428, cost 22.25 s
2024-01-01 20:49:09,898	44k	INFO	====> Epoch: 429, cost 22.16 s
2024-01-01 20:49:32,153	44k	INFO	====> Epoch: 430, cost 22.25 s
2024-01-01 20:49:54,255	44k	INFO	====> Epoch: 431, cost 22.10 s
2024-01-01 20:50:16,350	44k	INFO	Train Epoch: 432 [96%]
2024-01-01 20:50:16,352	44k	INFO	Losses: [2.3530988693237305, 2.282266855239868, 4.263068675994873, 16.77876853942871, 0.5884910225868225], step: 10800, lr: 9.475473520763392e-05, reference_loss: 26.26569366455078
2024-01-01 20:50:16,826	44k	INFO	====> Epoch: 432, cost 22.57 s
2024-01-01 20:50:38,901	44k	INFO	====> Epoch: 433, cost 22.08 s
2024-01-01 20:51:00,957	44k	INFO	====> Epoch: 434, cost 22.06 s
2024-01-01 20:51:23,173	44k	INFO	====> Epoch: 435, cost 22.22 s
2024-01-01 20:51:45,394	44k	INFO	====> Epoch: 436, cost 22.22 s
2024-01-01 20:52:07,545	44k	INFO	====> Epoch: 437, cost 22.15 s
2024-01-01 20:52:29,613	44k	INFO	====> Epoch: 438, cost 22.07 s
2024-01-01 20:52:51,572	44k	INFO	====> Epoch: 439, cost 21.96 s
2024-01-01 20:53:13,657	44k	INFO	Train Epoch: 440 [96%]
2024-01-01 20:53:13,659	44k	INFO	Losses: [2.3763296604156494, 2.4488728046417236, 6.195146083831787, 19.92815589904785, 0.521185040473938], step: 11000, lr: 9.466002191726074e-05, reference_loss: 31.469690322875977
2024-01-01 20:53:14,139	44k	INFO	====> Epoch: 440, cost 22.57 s
2024-01-01 20:53:36,108	44k	INFO	====> Epoch: 441, cost 21.97 s
2024-01-01 20:53:58,125	44k	INFO	====> Epoch: 442, cost 22.02 s
2024-01-01 20:54:20,234	44k	INFO	====> Epoch: 443, cost 22.11 s
2024-01-01 20:54:42,247	44k	INFO	====> Epoch: 444, cost 22.01 s
2024-01-01 20:55:04,219	44k	INFO	====> Epoch: 445, cost 21.97 s
2024-01-01 20:55:26,261	44k	INFO	====> Epoch: 446, cost 22.04 s
2024-01-01 20:55:48,410	44k	INFO	====> Epoch: 447, cost 22.15 s
2024-01-01 20:56:10,551	44k	INFO	Train Epoch: 448 [96%]
2024-01-01 20:56:10,553	44k	INFO	Losses: [2.3956832885742188, 2.1782939434051514, 5.001526832580566, 19.125600814819336, 0.5348311066627502], step: 11200, lr: 9.456540329875122e-05, reference_loss: 29.235937118530273
2024-01-01 20:56:16,757	44k	INFO	Saving model and optimizer state at iteration 448 to ./logs/44k/G_11200.pth
2024-01-01 20:56:17,657	44k	INFO	Saving model and optimizer state at iteration 448 to ./logs/44k/D_11200.pth
2024-01-01 20:56:18,146	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_8800.pth
2024-01-01 20:56:18,184	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_8800.pth
2024-01-01 20:56:18,185	44k	INFO	====> Epoch: 448, cost 29.77 s
2024-01-01 20:56:40,061	44k	INFO	====> Epoch: 449, cost 21.88 s
2024-01-01 20:57:02,142	44k	INFO	====> Epoch: 450, cost 22.08 s
2024-01-01 20:57:24,223	44k	INFO	====> Epoch: 451, cost 22.08 s
2024-01-01 20:57:46,403	44k	INFO	====> Epoch: 452, cost 22.18 s
2024-01-01 20:58:08,609	44k	INFO	====> Epoch: 453, cost 22.21 s
2024-01-01 20:58:30,703	44k	INFO	====> Epoch: 454, cost 22.09 s
2024-01-01 20:58:52,878	44k	INFO	====> Epoch: 455, cost 22.18 s
2024-01-01 20:59:15,003	44k	INFO	Train Epoch: 456 [96%]
2024-01-01 20:59:15,005	44k	INFO	Losses: [2.4592103958129883, 2.288912773132324, 5.295100212097168, 20.128759384155273, 0.5875459909439087], step: 11400, lr: 9.44708792574749e-05, reference_loss: 30.7595272064209
2024-01-01 20:59:15,597	44k	INFO	====> Epoch: 456, cost 22.72 s
2024-01-01 20:59:37,817	44k	INFO	====> Epoch: 457, cost 22.22 s
2024-01-01 21:00:00,031	44k	INFO	====> Epoch: 458, cost 22.21 s
2024-01-01 21:00:22,176	44k	INFO	====> Epoch: 459, cost 22.15 s
2024-01-01 21:00:44,295	44k	INFO	====> Epoch: 460, cost 22.12 s
2024-01-01 21:01:06,385	44k	INFO	====> Epoch: 461, cost 22.09 s
2024-01-01 21:01:28,453	44k	INFO	====> Epoch: 462, cost 22.07 s
2024-01-01 21:01:50,489	44k	INFO	====> Epoch: 463, cost 22.04 s
2024-01-01 21:02:12,654	44k	INFO	Train Epoch: 464 [96%]
2024-01-01 21:02:12,655	44k	INFO	Losses: [2.393113136291504, 2.1084694862365723, 3.81069016456604, 15.984338760375977, 0.6227421164512634], step: 11600, lr: 9.437644969889592e-05, reference_loss: 24.919353485107422
2024-01-01 21:02:13,133	44k	INFO	====> Epoch: 464, cost 22.64 s
2024-01-01 21:02:35,246	44k	INFO	====> Epoch: 465, cost 22.11 s
2024-01-01 21:02:57,519	44k	INFO	====> Epoch: 466, cost 22.27 s
2024-01-01 21:03:19,713	44k	INFO	====> Epoch: 467, cost 22.19 s
2024-01-01 21:03:41,943	44k	INFO	====> Epoch: 468, cost 22.23 s
2024-01-01 21:04:04,159	44k	INFO	====> Epoch: 469, cost 22.22 s
2024-01-01 21:04:26,348	44k	INFO	====> Epoch: 470, cost 22.19 s
2024-01-01 21:04:48,481	44k	INFO	====> Epoch: 471, cost 22.13 s
2024-01-01 21:05:10,652	44k	INFO	Train Epoch: 472 [96%]
2024-01-01 21:05:10,654	44k	INFO	Losses: [2.4105799198150635, 2.3341422080993652, 5.112095832824707, 18.564119338989258, 0.45191726088523865], step: 11800, lr: 9.428211452857292e-05, reference_loss: 28.872854232788086
2024-01-01 21:05:11,059	44k	INFO	====> Epoch: 472, cost 22.58 s
2024-01-01 21:05:33,288	44k	INFO	====> Epoch: 473, cost 22.23 s
2024-01-01 21:05:55,353	44k	INFO	====> Epoch: 474, cost 22.06 s
2024-01-01 21:06:17,457	44k	INFO	====> Epoch: 475, cost 22.10 s
2024-01-01 21:06:39,574	44k	INFO	====> Epoch: 476, cost 22.12 s
2024-01-01 21:07:01,538	44k	INFO	====> Epoch: 477, cost 21.96 s
2024-01-01 21:07:23,797	44k	INFO	====> Epoch: 478, cost 22.26 s
2024-01-01 21:07:45,983	44k	INFO	====> Epoch: 479, cost 22.19 s
2024-01-01 21:08:08,136	44k	INFO	Train Epoch: 480 [96%]
2024-01-01 21:08:08,138	44k	INFO	Losses: [2.4643914699554443, 2.0738365650177, 4.354701042175293, 17.93437957763672, 0.43685030937194824], step: 12000, lr: 9.418787365215894e-05, reference_loss: 27.264158248901367
2024-01-01 21:08:14,048	44k	INFO	Saving model and optimizer state at iteration 480 to ./logs/44k/G_12000.pth
2024-01-01 21:08:14,971	44k	INFO	Saving model and optimizer state at iteration 480 to ./logs/44k/D_12000.pth
2024-01-01 21:08:15,466	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_9600.pth
2024-01-01 21:08:15,505	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_9600.pth
2024-01-01 21:08:15,506	44k	INFO	====> Epoch: 480, cost 29.52 s
2024-01-01 21:08:37,545	44k	INFO	====> Epoch: 481, cost 22.04 s
2024-01-01 21:08:59,478	44k	INFO	====> Epoch: 482, cost 21.93 s
2024-01-01 21:09:21,458	44k	INFO	====> Epoch: 483, cost 21.98 s
2024-01-01 21:09:43,799	44k	INFO	====> Epoch: 484, cost 22.34 s
2024-01-01 21:10:06,069	44k	INFO	====> Epoch: 485, cost 22.27 s
2024-01-01 21:10:28,362	44k	INFO	====> Epoch: 486, cost 22.29 s
2024-01-01 21:10:50,476	44k	INFO	====> Epoch: 487, cost 22.11 s
2024-01-01 21:11:12,714	44k	INFO	Train Epoch: 488 [96%]
2024-01-01 21:11:12,716	44k	INFO	Losses: [2.366119623184204, 2.498483657836914, 5.2925214767456055, 20.267972946166992, 0.5377789735794067], step: 12200, lr: 9.409372697540131e-05, reference_loss: 30.96287727355957
2024-01-01 21:11:13,121	44k	INFO	====> Epoch: 488, cost 22.64 s
2024-01-01 21:11:35,363	44k	INFO	====> Epoch: 489, cost 22.24 s
2024-01-01 21:11:57,650	44k	INFO	====> Epoch: 490, cost 22.29 s
2024-01-01 21:12:19,835	44k	INFO	====> Epoch: 491, cost 22.18 s
2024-01-01 21:12:41,955	44k	INFO	====> Epoch: 492, cost 22.12 s
2024-01-01 21:13:04,077	44k	INFO	====> Epoch: 493, cost 22.12 s
2024-01-01 21:13:26,286	44k	INFO	====> Epoch: 494, cost 22.21 s
2024-01-01 21:13:48,494	44k	INFO	====> Epoch: 495, cost 22.21 s
2024-01-01 21:14:10,914	44k	INFO	Train Epoch: 496 [96%]
2024-01-01 21:14:10,916	44k	INFO	Losses: [2.454807758331299, 2.0852766036987305, 4.1532745361328125, 16.396394729614258, 0.6293764114379883], step: 12400, lr: 9.399967440414155e-05, reference_loss: 25.719131469726562
2024-01-01 21:14:11,309	44k	INFO	====> Epoch: 496, cost 22.81 s
2024-01-01 21:14:33,446	44k	INFO	====> Epoch: 497, cost 22.14 s
2024-01-01 21:14:55,556	44k	INFO	====> Epoch: 498, cost 22.11 s
2024-01-01 21:15:17,715	44k	INFO	====> Epoch: 499, cost 22.16 s
2024-01-01 21:15:39,894	44k	INFO	====> Epoch: 500, cost 22.18 s
2024-01-01 21:16:01,966	44k	INFO	====> Epoch: 501, cost 22.07 s
2024-01-01 21:16:24,021	44k	INFO	====> Epoch: 502, cost 22.06 s
2024-01-01 21:16:46,059	44k	INFO	====> Epoch: 503, cost 22.04 s
2024-01-01 21:17:08,180	44k	INFO	Train Epoch: 504 [96%]
2024-01-01 21:17:08,182	44k	INFO	Losses: [2.2450661659240723, 2.5267536640167236, 5.869101047515869, 18.591400146484375, 0.486224502325058], step: 12600, lr: 9.39057158443153e-05, reference_loss: 29.71854591369629
2024-01-01 21:17:08,751	44k	INFO	====> Epoch: 504, cost 22.69 s
2024-01-01 21:17:30,881	44k	INFO	====> Epoch: 505, cost 22.13 s
2024-01-01 21:17:52,868	44k	INFO	====> Epoch: 506, cost 21.99 s
2024-01-01 21:18:14,828	44k	INFO	====> Epoch: 507, cost 21.96 s
2024-01-01 21:18:36,816	44k	INFO	====> Epoch: 508, cost 21.99 s
2024-01-01 21:18:58,925	44k	INFO	====> Epoch: 509, cost 22.11 s
2024-01-01 21:19:21,131	44k	INFO	====> Epoch: 510, cost 22.21 s
2024-01-01 21:19:43,311	44k	INFO	====> Epoch: 511, cost 22.18 s
2024-01-01 21:20:05,501	44k	INFO	Train Epoch: 512 [96%]
2024-01-01 21:20:05,503	44k	INFO	Losses: [2.418703079223633, 2.148345708847046, 4.204822063446045, 17.97359848022461, 0.41006290912628174], step: 12800, lr: 9.381185120195232e-05, reference_loss: 27.155532836914062
2024-01-01 21:20:11,213	44k	INFO	Saving model and optimizer state at iteration 512 to ./logs/44k/G_12800.pth
2024-01-01 21:20:12,316	44k	INFO	Saving model and optimizer state at iteration 512 to ./logs/44k/D_12800.pth
2024-01-01 21:20:12,814	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_10400.pth
2024-01-01 21:20:12,852	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_10400.pth
2024-01-01 21:20:12,853	44k	INFO	====> Epoch: 512, cost 29.54 s
2024-01-01 21:20:34,904	44k	INFO	====> Epoch: 513, cost 22.05 s
2024-01-01 21:20:56,931	44k	INFO	====> Epoch: 514, cost 22.03 s
2024-01-01 21:21:19,008	44k	INFO	====> Epoch: 515, cost 22.08 s
2024-01-01 21:21:40,951	44k	INFO	====> Epoch: 516, cost 21.94 s
2024-01-01 21:22:02,922	44k	INFO	====> Epoch: 517, cost 21.97 s
2024-01-01 21:22:24,933	44k	INFO	====> Epoch: 518, cost 22.01 s
2024-01-01 21:22:46,971	44k	INFO	====> Epoch: 519, cost 22.04 s
2024-01-01 21:23:09,241	44k	INFO	Train Epoch: 520 [96%]
2024-01-01 21:23:09,242	44k	INFO	Losses: [2.3291702270507812, 2.273209810256958, 5.865367889404297, 19.295486450195312, 0.5095900893211365], step: 13000, lr: 9.371808038317619e-05, reference_loss: 30.272823333740234
2024-01-01 21:23:09,649	44k	INFO	====> Epoch: 520, cost 22.68 s
2024-01-01 21:23:31,976	44k	INFO	====> Epoch: 521, cost 22.33 s
2024-01-01 21:23:54,353	44k	INFO	====> Epoch: 522, cost 22.38 s
2024-01-01 21:24:16,311	44k	INFO	====> Epoch: 523, cost 21.96 s
2024-01-01 21:24:38,499	44k	INFO	====> Epoch: 524, cost 22.19 s
2024-01-01 21:25:00,682	44k	INFO	====> Epoch: 525, cost 22.18 s
2024-01-01 21:25:22,805	44k	INFO	====> Epoch: 526, cost 22.12 s
2024-01-01 21:25:45,084	44k	INFO	====> Epoch: 527, cost 22.28 s
2024-01-01 21:26:07,398	44k	INFO	Train Epoch: 528 [96%]
2024-01-01 21:26:07,400	44k	INFO	Losses: [2.392857789993286, 2.302647590637207, 5.029829025268555, 18.233924865722656, 0.5753458142280579], step: 13200, lr: 9.362440329420433e-05, reference_loss: 28.534605026245117
2024-01-01 21:26:07,801	44k	INFO	====> Epoch: 528, cost 22.72 s
2024-01-01 21:26:30,026	44k	INFO	====> Epoch: 529, cost 22.23 s
2024-01-01 21:26:52,161	44k	INFO	====> Epoch: 530, cost 22.14 s
2024-01-01 21:27:14,336	44k	INFO	====> Epoch: 531, cost 22.18 s
2024-01-01 21:27:36,669	44k	INFO	====> Epoch: 532, cost 22.33 s
2024-01-01 21:27:58,735	44k	INFO	====> Epoch: 533, cost 22.07 s
2024-01-01 21:28:20,824	44k	INFO	====> Epoch: 534, cost 22.09 s
2024-01-01 21:28:42,938	44k	INFO	====> Epoch: 535, cost 22.11 s
2024-01-01 21:29:05,072	44k	INFO	Train Epoch: 536 [96%]
2024-01-01 21:29:05,074	44k	INFO	Losses: [2.580927610397339, 2.2518982887268066, 4.879303932189941, 17.480632781982422, 0.43186962604522705], step: 13400, lr: 9.353081984134796e-05, reference_loss: 27.624631881713867
2024-01-01 21:29:05,471	44k	INFO	====> Epoch: 536, cost 22.53 s
2024-01-01 21:29:27,667	44k	INFO	====> Epoch: 537, cost 22.20 s
2024-01-01 21:29:49,869	44k	INFO	====> Epoch: 538, cost 22.20 s
2024-01-01 21:30:12,096	44k	INFO	====> Epoch: 539, cost 22.23 s
2024-01-01 21:30:34,161	44k	INFO	====> Epoch: 540, cost 22.06 s
2024-01-01 21:30:56,181	44k	INFO	====> Epoch: 541, cost 22.02 s
2024-01-01 21:31:18,605	44k	INFO	====> Epoch: 542, cost 22.42 s
2024-01-01 21:31:40,890	44k	INFO	====> Epoch: 543, cost 22.29 s
2024-01-01 21:32:03,164	44k	INFO	Train Epoch: 544 [96%]
2024-01-01 21:32:03,166	44k	INFO	Losses: [2.424757242202759, 2.146695137023926, 4.917288303375244, 17.43876838684082, 0.44979071617126465], step: 13600, lr: 9.343732993101193e-05, reference_loss: 27.377300262451172
2024-01-01 21:32:09,367	44k	INFO	Saving model and optimizer state at iteration 544 to ./logs/44k/G_13600.pth
2024-01-01 21:32:10,304	44k	INFO	Saving model and optimizer state at iteration 544 to ./logs/44k/D_13600.pth
2024-01-01 21:32:10,831	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_11200.pth
2024-01-01 21:32:10,870	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_11200.pth
2024-01-01 21:32:10,871	44k	INFO	====> Epoch: 544, cost 29.98 s
2024-01-01 21:32:32,912	44k	INFO	====> Epoch: 545, cost 22.04 s
2024-01-01 21:32:54,957	44k	INFO	====> Epoch: 546, cost 22.04 s
2024-01-01 21:33:17,085	44k	INFO	====> Epoch: 547, cost 22.13 s
2024-01-01 21:33:39,140	44k	INFO	====> Epoch: 548, cost 22.06 s
2024-01-01 21:34:01,165	44k	INFO	====> Epoch: 549, cost 22.03 s
2024-01-01 21:34:23,419	44k	INFO	====> Epoch: 550, cost 22.25 s
2024-01-01 21:34:45,588	44k	INFO	====> Epoch: 551, cost 22.17 s
2024-01-01 21:35:07,808	44k	INFO	Train Epoch: 552 [96%]
2024-01-01 21:35:07,810	44k	INFO	Losses: [2.424504280090332, 2.325995445251465, 5.788670063018799, 18.77021598815918, 0.5617470741271973], step: 13800, lr: 9.334393346969463e-05, reference_loss: 29.871131896972656
2024-01-01 21:35:08,316	44k	INFO	====> Epoch: 552, cost 22.73 s
2024-01-01 21:35:30,491	44k	INFO	====> Epoch: 553, cost 22.17 s
2024-01-01 21:35:52,617	44k	INFO	====> Epoch: 554, cost 22.13 s
2024-01-01 21:36:14,765	44k	INFO	====> Epoch: 555, cost 22.15 s
2024-01-01 21:36:36,860	44k	INFO	====> Epoch: 556, cost 22.10 s
2024-01-01 21:36:59,016	44k	INFO	====> Epoch: 557, cost 22.16 s
2024-01-01 21:37:20,988	44k	INFO	====> Epoch: 558, cost 21.97 s
2024-01-01 21:37:42,992	44k	INFO	====> Epoch: 559, cost 22.00 s
2024-01-01 21:38:04,964	44k	INFO	Train Epoch: 560 [96%]
2024-01-01 21:38:04,966	44k	INFO	Losses: [2.3891196250915527, 2.3004958629608154, 4.465365409851074, 15.281355857849121, 0.7199852466583252], step: 14000, lr: 9.325063036398789e-05, reference_loss: 25.156322479248047
2024-01-01 21:38:05,519	44k	INFO	====> Epoch: 560, cost 22.53 s
2024-01-01 21:38:27,562	44k	INFO	====> Epoch: 561, cost 22.04 s
2024-01-01 21:38:49,685	44k	INFO	====> Epoch: 562, cost 22.12 s
2024-01-01 21:39:11,954	44k	INFO	====> Epoch: 563, cost 22.27 s
2024-01-01 21:39:34,156	44k	INFO	====> Epoch: 564, cost 22.20 s
2024-01-01 21:39:56,209	44k	INFO	====> Epoch: 565, cost 22.05 s
2024-01-01 21:40:18,323	44k	INFO	====> Epoch: 566, cost 22.11 s
2024-01-01 21:40:40,426	44k	INFO	====> Epoch: 567, cost 22.10 s
2024-01-01 21:41:02,553	44k	INFO	Train Epoch: 568 [96%]
2024-01-01 21:41:02,556	44k	INFO	Losses: [2.4432623386383057, 2.3651440143585205, 6.148503303527832, 18.664770126342773, 0.4371163249015808], step: 14200, lr: 9.315742052057694e-05, reference_loss: 30.058795928955078
2024-01-01 21:41:02,934	44k	INFO	====> Epoch: 568, cost 22.51 s
2024-01-01 21:41:25,215	44k	INFO	====> Epoch: 569, cost 22.28 s
2024-01-01 21:41:47,413	44k	INFO	====> Epoch: 570, cost 22.20 s
2024-01-01 21:42:09,523	44k	INFO	====> Epoch: 571, cost 22.11 s
2024-01-01 21:42:31,480	44k	INFO	====> Epoch: 572, cost 21.96 s
2024-01-01 21:42:53,597	44k	INFO	====> Epoch: 573, cost 22.12 s
2024-01-01 21:43:15,665	44k	INFO	====> Epoch: 574, cost 22.07 s
2024-01-01 21:43:37,737	44k	INFO	====> Epoch: 575, cost 22.07 s
2024-01-01 21:43:59,787	44k	INFO	Train Epoch: 576 [96%]
2024-01-01 21:43:59,789	44k	INFO	Losses: [2.397932291030884, 2.1406400203704834, 4.431959629058838, 16.865978240966797, 0.33339300751686096], step: 14400, lr: 9.306430384624031e-05, reference_loss: 26.169902801513672
2024-01-01 21:44:05,994	44k	INFO	Saving model and optimizer state at iteration 576 to ./logs/44k/G_14400.pth
2024-01-01 21:44:06,931	44k	INFO	Saving model and optimizer state at iteration 576 to ./logs/44k/D_14400.pth
2024-01-01 21:44:07,442	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_12000.pth
2024-01-01 21:44:07,481	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_12000.pth
2024-01-01 21:44:07,481	44k	INFO	====> Epoch: 576, cost 29.74 s
2024-01-01 21:44:29,775	44k	INFO	====> Epoch: 577, cost 22.29 s
2024-01-01 21:44:51,866	44k	INFO	====> Epoch: 578, cost 22.09 s
2024-01-01 21:45:13,948	44k	INFO	====> Epoch: 579, cost 22.08 s
2024-01-01 21:45:35,953	44k	INFO	====> Epoch: 580, cost 22.01 s
2024-01-01 21:45:57,879	44k	INFO	====> Epoch: 581, cost 21.93 s
2024-01-01 21:46:20,031	44k	INFO	====> Epoch: 582, cost 22.15 s
2024-01-01 21:46:42,225	44k	INFO	====> Epoch: 583, cost 22.19 s
2024-01-01 21:47:04,408	44k	INFO	Train Epoch: 584 [96%]
2024-01-01 21:47:04,410	44k	INFO	Losses: [2.349513292312622, 2.4249417781829834, 6.189594268798828, 19.055980682373047, 0.5142722129821777], step: 14600, lr: 9.297128024784965e-05, reference_loss: 30.534303665161133
2024-01-01 21:47:04,903	44k	INFO	====> Epoch: 584, cost 22.68 s
2024-01-01 21:47:27,037	44k	INFO	====> Epoch: 585, cost 22.13 s
2024-01-01 21:47:49,035	44k	INFO	====> Epoch: 586, cost 22.00 s
2024-01-01 21:48:11,043	44k	INFO	====> Epoch: 587, cost 22.01 s
2024-01-01 21:48:33,127	44k	INFO	====> Epoch: 588, cost 22.08 s
2024-01-01 21:48:55,329	44k	INFO	====> Epoch: 589, cost 22.20 s
2024-01-01 21:49:17,639	44k	INFO	====> Epoch: 590, cost 22.31 s
2024-01-01 21:49:39,836	44k	INFO	====> Epoch: 591, cost 22.20 s
2024-01-01 21:50:02,132	44k	INFO	Train Epoch: 592 [96%]
2024-01-01 21:50:02,134	44k	INFO	Losses: [2.3730571269989014, 2.258119583129883, 4.424271106719971, 15.228497505187988, 0.4645709693431854], step: 14800, lr: 9.287834963236974e-05, reference_loss: 24.748517990112305
2024-01-01 21:50:02,553	44k	INFO	====> Epoch: 592, cost 22.72 s
2024-01-01 21:50:24,807	44k	INFO	====> Epoch: 593, cost 22.25 s
2024-01-01 21:50:46,875	44k	INFO	====> Epoch: 594, cost 22.07 s
2024-01-01 21:51:09,053	44k	INFO	====> Epoch: 595, cost 22.18 s
2024-01-01 21:51:31,204	44k	INFO	====> Epoch: 596, cost 22.15 s
2024-01-01 21:51:53,356	44k	INFO	====> Epoch: 597, cost 22.15 s
2024-01-01 21:52:15,529	44k	INFO	====> Epoch: 598, cost 22.17 s
2024-01-01 21:52:37,730	44k	INFO	====> Epoch: 599, cost 22.20 s
2024-01-01 21:53:00,122	44k	INFO	Train Epoch: 600 [96%]
2024-01-01 21:53:00,123	44k	INFO	Losses: [2.4960005283355713, 2.3169994354248047, 6.047818660736084, 18.35710906982422, 0.3874242305755615], step: 15000, lr: 9.27855119068583e-05, reference_loss: 29.6053524017334
2024-01-01 21:53:00,539	44k	INFO	====> Epoch: 600, cost 22.81 s
2024-01-01 21:53:22,858	44k	INFO	====> Epoch: 601, cost 22.32 s
2024-01-01 21:53:44,954	44k	INFO	====> Epoch: 602, cost 22.10 s
2024-01-01 21:54:07,008	44k	INFO	====> Epoch: 603, cost 22.05 s
2024-01-01 21:54:29,140	44k	INFO	====> Epoch: 604, cost 22.13 s
2024-01-01 21:54:51,247	44k	INFO	====> Epoch: 605, cost 22.11 s
2024-01-01 21:55:13,284	44k	INFO	====> Epoch: 606, cost 22.04 s
2024-01-01 21:55:35,249	44k	INFO	====> Epoch: 607, cost 21.96 s
2024-01-01 21:55:57,181	44k	INFO	Train Epoch: 608 [96%]
2024-01-01 21:55:57,183	44k	INFO	Losses: [2.586784601211548, 1.9789764881134033, 4.1524658203125, 17.07574462890625, 0.3699299991130829], step: 15200, lr: 9.269276697846605e-05, reference_loss: 26.163902282714844
2024-01-01 21:56:02,802	44k	INFO	Saving model and optimizer state at iteration 608 to ./logs/44k/G_15200.pth
2024-01-01 21:56:03,723	44k	INFO	Saving model and optimizer state at iteration 608 to ./logs/44k/D_15200.pth
2024-01-01 21:56:04,206	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_12800.pth
2024-01-01 21:56:04,244	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_12800.pth
2024-01-01 21:56:04,245	44k	INFO	====> Epoch: 608, cost 29.00 s
2024-01-01 21:56:26,105	44k	INFO	====> Epoch: 609, cost 21.86 s
2024-01-01 21:56:48,056	44k	INFO	====> Epoch: 610, cost 21.95 s
2024-01-01 21:57:10,332	44k	INFO	====> Epoch: 611, cost 22.28 s
2024-01-01 21:57:32,741	44k	INFO	====> Epoch: 612, cost 22.41 s
2024-01-01 21:57:55,114	44k	INFO	====> Epoch: 613, cost 22.37 s
2024-01-01 21:58:17,380	44k	INFO	====> Epoch: 614, cost 22.27 s
2024-01-01 21:58:39,581	44k	INFO	====> Epoch: 615, cost 22.20 s
2024-01-01 21:59:01,802	44k	INFO	Train Epoch: 616 [96%]
2024-01-01 21:59:01,804	44k	INFO	Losses: [2.570136308670044, 2.3071014881134033, 5.573136329650879, 18.241741180419922, 0.48395058512687683], step: 15400, lr: 9.260011475443641e-05, reference_loss: 29.17606544494629
2024-01-01 21:59:02,363	44k	INFO	====> Epoch: 616, cost 22.78 s
2024-01-01 21:59:24,435	44k	INFO	====> Epoch: 617, cost 22.07 s
2024-01-01 21:59:46,611	44k	INFO	====> Epoch: 618, cost 22.18 s
2024-01-01 22:00:08,951	44k	INFO	====> Epoch: 619, cost 22.34 s
2024-01-01 22:00:31,248	44k	INFO	====> Epoch: 620, cost 22.30 s
2024-01-01 22:00:53,506	44k	INFO	====> Epoch: 621, cost 22.26 s
2024-01-01 22:01:15,627	44k	INFO	====> Epoch: 622, cost 22.12 s
2024-01-01 22:01:37,826	44k	INFO	====> Epoch: 623, cost 22.20 s
2024-01-01 22:02:00,088	44k	INFO	Train Epoch: 624 [96%]
2024-01-01 22:02:00,090	44k	INFO	Losses: [2.453162908554077, 2.19063401222229, 4.64223051071167, 16.238113403320312, 0.5838630795478821], step: 15600, lr: 9.250755514210558e-05, reference_loss: 26.108003616333008
2024-01-01 22:02:00,481	44k	INFO	====> Epoch: 624, cost 22.66 s
2024-01-01 22:02:22,790	44k	INFO	====> Epoch: 625, cost 22.31 s
2024-01-01 22:02:45,029	44k	INFO	====> Epoch: 626, cost 22.24 s
2024-01-01 22:03:07,154	44k	INFO	====> Epoch: 627, cost 22.12 s
2024-01-01 22:03:29,229	44k	INFO	====> Epoch: 628, cost 22.08 s
2024-01-01 22:03:51,273	44k	INFO	====> Epoch: 629, cost 22.04 s
2024-01-01 22:04:13,386	44k	INFO	====> Epoch: 630, cost 22.11 s
2024-01-01 22:04:35,463	44k	INFO	====> Epoch: 631, cost 22.08 s
2024-01-01 22:04:57,550	44k	INFO	Train Epoch: 632 [96%]
2024-01-01 22:04:57,553	44k	INFO	Losses: [2.639416217803955, 2.2597293853759766, 5.315829753875732, 17.153886795043945, 0.41513487696647644], step: 15800, lr: 9.24150880489024e-05, reference_loss: 27.78399658203125
2024-01-01 22:04:57,933	44k	INFO	====> Epoch: 632, cost 22.47 s
2024-01-01 22:05:20,223	44k	INFO	====> Epoch: 633, cost 22.29 s
2024-01-01 22:05:42,430	44k	INFO	====> Epoch: 634, cost 22.21 s
2024-01-01 22:06:04,652	44k	INFO	====> Epoch: 635, cost 22.22 s
2024-01-01 22:06:26,878	44k	INFO	====> Epoch: 636, cost 22.23 s
2024-01-01 22:06:49,032	44k	INFO	====> Epoch: 637, cost 22.15 s
2024-01-01 22:07:11,294	44k	INFO	====> Epoch: 638, cost 22.26 s
2024-01-01 22:07:33,501	44k	INFO	====> Epoch: 639, cost 22.21 s
2024-01-01 22:07:55,715	44k	INFO	Train Epoch: 640 [96%]
2024-01-01 22:07:55,717	44k	INFO	Losses: [2.419271469116211, 2.1039113998413086, 5.019392967224121, 16.734798431396484, 0.2803015112876892], step: 16000, lr: 9.232271338234815e-05, reference_loss: 26.557676315307617
2024-01-01 22:08:01,180	44k	INFO	Saving model and optimizer state at iteration 640 to ./logs/44k/G_16000.pth
2024-01-01 22:08:02,119	44k	INFO	Saving model and optimizer state at iteration 640 to ./logs/44k/D_16000.pth
2024-01-01 22:08:02,622	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_13600.pth
2024-01-01 22:08:02,661	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_13600.pth
2024-01-01 22:08:02,661	44k	INFO	====> Epoch: 640, cost 29.16 s
2024-01-01 22:08:24,944	44k	INFO	====> Epoch: 641, cost 22.28 s
2024-01-01 22:08:47,300	44k	INFO	====> Epoch: 642, cost 22.36 s
2024-01-01 22:09:09,711	44k	INFO	====> Epoch: 643, cost 22.41 s
2024-01-01 22:09:32,175	44k	INFO	====> Epoch: 644, cost 22.46 s
2024-01-01 22:09:54,343	44k	INFO	====> Epoch: 645, cost 22.17 s
2024-01-01 22:10:16,516	44k	INFO	====> Epoch: 646, cost 22.17 s
2024-01-01 22:10:38,634	44k	INFO	====> Epoch: 647, cost 22.12 s
2024-01-01 22:11:00,755	44k	INFO	Train Epoch: 648 [96%]
2024-01-01 22:11:00,757	44k	INFO	Losses: [2.4835104942321777, 2.1362903118133545, 5.93779182434082, 18.16204261779785, 0.3936993181705475], step: 16200, lr: 9.223043105005667e-05, reference_loss: 29.11333465576172
2024-01-01 22:11:01,230	44k	INFO	====> Epoch: 648, cost 22.60 s
2024-01-01 22:11:23,402	44k	INFO	====> Epoch: 649, cost 22.17 s
2024-01-01 22:11:45,716	44k	INFO	====> Epoch: 650, cost 22.31 s
2024-01-01 22:12:08,111	44k	INFO	====> Epoch: 651, cost 22.40 s
2024-01-01 22:12:30,499	44k	INFO	====> Epoch: 652, cost 22.39 s
2024-01-01 22:12:52,910	44k	INFO	====> Epoch: 653, cost 22.41 s
2024-01-01 22:13:15,301	44k	INFO	====> Epoch: 654, cost 22.39 s
2024-01-01 22:13:37,550	44k	INFO	====> Epoch: 655, cost 22.25 s
2024-01-01 22:13:59,952	44k	INFO	Train Epoch: 656 [96%]
2024-01-01 22:13:59,954	44k	INFO	Losses: [2.3689754009246826, 2.1031200885772705, 4.737943172454834, 14.76807689666748, 0.5641777515411377], step: 16400, lr: 9.213824095973405e-05, reference_loss: 24.542293548583984
2024-01-01 22:14:00,341	44k	INFO	====> Epoch: 656, cost 22.79 s
2024-01-01 22:14:22,472	44k	INFO	====> Epoch: 657, cost 22.13 s
2024-01-01 22:14:44,656	44k	INFO	====> Epoch: 658, cost 22.18 s
2024-01-01 22:15:06,935	44k	INFO	====> Epoch: 659, cost 22.28 s
2024-01-01 22:15:29,277	44k	INFO	====> Epoch: 660, cost 22.34 s
2024-01-01 22:15:51,545	44k	INFO	====> Epoch: 661, cost 22.27 s
2024-01-01 22:16:13,869	44k	INFO	====> Epoch: 662, cost 22.32 s
2024-01-01 22:16:36,182	44k	INFO	====> Epoch: 663, cost 22.31 s
2024-01-01 22:16:58,362	44k	INFO	Train Epoch: 664 [96%]
2024-01-01 22:16:58,364	44k	INFO	Losses: [2.5531165599823, 2.301734447479248, 5.243257522583008, 16.696611404418945, 0.3725583553314209], step: 16600, lr: 9.204614301917867e-05, reference_loss: 27.167278289794922
2024-01-01 22:16:58,929	44k	INFO	====> Epoch: 664, cost 22.75 s
2024-01-01 22:17:21,202	44k	INFO	====> Epoch: 665, cost 22.27 s
2024-01-01 22:17:43,461	44k	INFO	====> Epoch: 666, cost 22.26 s
2024-01-01 22:18:05,686	44k	INFO	====> Epoch: 667, cost 22.22 s
2024-01-01 22:18:27,901	44k	INFO	====> Epoch: 668, cost 22.21 s
2024-01-01 22:18:50,074	44k	INFO	====> Epoch: 669, cost 22.17 s
2024-01-01 22:19:12,411	44k	INFO	====> Epoch: 670, cost 22.34 s
2024-01-01 22:19:34,619	44k	INFO	====> Epoch: 671, cost 22.21 s
2024-01-01 22:19:56,808	44k	INFO	Train Epoch: 672 [96%]
2024-01-01 22:19:56,810	44k	INFO	Losses: [2.444260835647583, 1.9956055879592896, 4.3645429611206055, 16.365934371948242, 0.2595413029193878], step: 16800, lr: 9.195413713628104e-05, reference_loss: 25.42988395690918
2024-01-01 22:20:02,761	44k	INFO	Saving model and optimizer state at iteration 672 to ./logs/44k/G_16800.pth
2024-01-01 22:20:03,873	44k	INFO	Saving model and optimizer state at iteration 672 to ./logs/44k/D_16800.pth
2024-01-01 22:20:04,371	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_14400.pth
2024-01-01 22:20:04,409	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_14400.pth
2024-01-01 22:20:04,409	44k	INFO	====> Epoch: 672, cost 29.79 s
2024-01-01 22:20:26,691	44k	INFO	====> Epoch: 673, cost 22.28 s
2024-01-01 22:20:49,016	44k	INFO	====> Epoch: 674, cost 22.32 s
2024-01-01 22:21:11,271	44k	INFO	====> Epoch: 675, cost 22.26 s
2024-01-01 22:21:33,531	44k	INFO	====> Epoch: 676, cost 22.26 s
2024-01-01 22:21:55,869	44k	INFO	====> Epoch: 677, cost 22.34 s
2024-01-01 22:22:18,294	44k	INFO	====> Epoch: 678, cost 22.42 s
2024-01-01 22:22:40,694	44k	INFO	====> Epoch: 679, cost 22.40 s
2024-01-01 22:23:03,052	44k	INFO	Train Epoch: 680 [96%]
2024-01-01 22:23:03,054	44k	INFO	Losses: [2.2796597480773926, 2.332965135574341, 6.369479656219482, 18.230268478393555, 0.3996005952358246], step: 17000, lr: 9.186222321902381e-05, reference_loss: 29.611974716186523
2024-01-01 22:23:03,454	44k	INFO	====> Epoch: 680, cost 22.76 s
2024-01-01 22:23:25,737	44k	INFO	====> Epoch: 681, cost 22.28 s
2024-01-01 22:23:47,954	44k	INFO	====> Epoch: 682, cost 22.22 s
2024-01-01 22:24:10,388	44k	INFO	====> Epoch: 683, cost 22.43 s
2024-01-01 22:24:32,684	44k	INFO	====> Epoch: 684, cost 22.30 s
2024-01-01 22:24:54,747	44k	INFO	====> Epoch: 685, cost 22.06 s
2024-01-01 22:25:16,961	44k	INFO	====> Epoch: 686, cost 22.21 s
2024-01-01 22:25:39,200	44k	INFO	====> Epoch: 687, cost 22.24 s
2024-01-01 22:26:01,376	44k	INFO	Train Epoch: 688 [96%]
2024-01-01 22:26:01,378	44k	INFO	Losses: [2.291238784790039, 2.3564393520355225, 5.566246032714844, 16.33327865600586, 0.4185519218444824], step: 17200, lr: 9.177040117548157e-05, reference_loss: 26.965755462646484
2024-01-01 22:26:01,772	44k	INFO	====> Epoch: 688, cost 22.57 s
2024-01-01 22:26:23,987	44k	INFO	====> Epoch: 689, cost 22.22 s
2024-01-01 22:26:46,216	44k	INFO	====> Epoch: 690, cost 22.23 s
2024-01-01 22:27:08,472	44k	INFO	====> Epoch: 691, cost 22.26 s
2024-01-01 22:27:30,677	44k	INFO	====> Epoch: 692, cost 22.20 s
2024-01-01 22:27:53,043	44k	INFO	====> Epoch: 693, cost 22.37 s
2024-01-01 22:28:15,079	44k	INFO	====> Epoch: 694, cost 22.04 s
2024-01-01 22:28:37,195	44k	INFO	====> Epoch: 695, cost 22.12 s
2024-01-01 22:28:59,372	44k	INFO	Train Epoch: 696 [96%]
2024-01-01 22:28:59,374	44k	INFO	Losses: [2.422266960144043, 2.292304754257202, 6.278801441192627, 17.915130615234375, 0.3564126491546631], step: 17400, lr: 9.167867091382074e-05, reference_loss: 29.264917373657227
2024-01-01 22:28:59,767	44k	INFO	====> Epoch: 696, cost 22.57 s
2024-01-01 22:29:21,901	44k	INFO	====> Epoch: 697, cost 22.13 s
2024-01-01 22:29:43,921	44k	INFO	====> Epoch: 698, cost 22.02 s
2024-01-01 22:30:06,015	44k	INFO	====> Epoch: 699, cost 22.09 s
2024-01-01 22:30:28,177	44k	INFO	====> Epoch: 700, cost 22.16 s
2024-01-01 22:30:50,140	44k	INFO	====> Epoch: 701, cost 21.96 s
2024-01-01 22:31:12,099	44k	INFO	====> Epoch: 702, cost 21.96 s
2024-01-01 22:31:34,449	44k	INFO	====> Epoch: 703, cost 22.35 s
2024-01-01 22:31:56,551	44k	INFO	Train Epoch: 704 [96%]
2024-01-01 22:31:56,553	44k	INFO	Losses: [2.446716785430908, 2.2490663528442383, 4.604043960571289, 15.585641860961914, 0.2764906585216522], step: 17600, lr: 9.158703234229962e-05, reference_loss: 25.16196060180664
2024-01-01 22:32:02,060	44k	INFO	Saving model and optimizer state at iteration 704 to ./logs/44k/G_17600.pth
2024-01-01 22:32:02,979	44k	INFO	Saving model and optimizer state at iteration 704 to ./logs/44k/D_17600.pth
2024-01-01 22:32:03,461	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_15200.pth
2024-01-01 22:32:03,500	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_15200.pth
2024-01-01 22:32:03,500	44k	INFO	====> Epoch: 704, cost 29.05 s
2024-01-01 22:32:25,460	44k	INFO	====> Epoch: 705, cost 21.96 s
2024-01-01 22:32:47,437	44k	INFO	====> Epoch: 706, cost 21.98 s
2024-01-01 22:33:09,636	44k	INFO	====> Epoch: 707, cost 22.20 s
2024-01-01 22:33:31,641	44k	INFO	====> Epoch: 708, cost 22.01 s
2024-01-01 22:33:53,614	44k	INFO	====> Epoch: 709, cost 21.97 s
2024-01-01 22:34:15,653	44k	INFO	====> Epoch: 710, cost 22.04 s
2024-01-01 22:34:37,966	44k	INFO	====> Epoch: 711, cost 22.31 s
2024-01-01 22:35:00,198	44k	INFO	Train Epoch: 712 [96%]
2024-01-01 22:35:00,201	44k	INFO	Losses: [2.4087469577789307, 2.2707910537719727, 5.959137916564941, 18.74213218688965, 0.34389427304267883], step: 17800, lr: 9.149548536926816e-05, reference_loss: 29.724702835083008
2024-01-01 22:35:00,686	44k	INFO	====> Epoch: 712, cost 22.72 s
2024-01-01 22:35:22,763	44k	INFO	====> Epoch: 713, cost 22.08 s
2024-01-01 22:35:44,880	44k	INFO	====> Epoch: 714, cost 22.12 s
2024-01-01 22:36:06,993	44k	INFO	====> Epoch: 715, cost 22.11 s
2024-01-01 22:36:29,180	44k	INFO	====> Epoch: 716, cost 22.19 s
2024-01-01 22:36:51,366	44k	INFO	====> Epoch: 717, cost 22.19 s
2024-01-01 22:37:13,336	44k	INFO	====> Epoch: 718, cost 21.97 s
2024-01-01 22:37:35,275	44k	INFO	====> Epoch: 719, cost 21.94 s
2024-01-01 22:37:57,492	44k	INFO	Train Epoch: 720 [96%]
2024-01-01 22:37:57,494	44k	INFO	Losses: [2.325556993484497, 2.2535390853881836, 4.846312046051025, 15.70959186553955, 0.41367873549461365], step: 18000, lr: 9.140402990316795e-05, reference_loss: 25.548677444458008
2024-01-01 22:37:58,071	44k	INFO	====> Epoch: 720, cost 22.80 s
2024-01-01 22:38:20,257	44k	INFO	====> Epoch: 721, cost 22.19 s
2024-01-01 22:38:42,260	44k	INFO	====> Epoch: 722, cost 22.00 s
2024-01-01 22:39:04,365	44k	INFO	====> Epoch: 723, cost 22.10 s
2024-01-01 22:39:26,556	44k	INFO	====> Epoch: 724, cost 22.19 s
2024-01-01 22:39:48,697	44k	INFO	====> Epoch: 725, cost 22.14 s
2024-01-01 22:40:10,817	44k	INFO	====> Epoch: 726, cost 22.12 s
2024-01-01 22:40:32,891	44k	INFO	====> Epoch: 727, cost 22.07 s
2024-01-01 22:40:54,947	44k	INFO	Train Epoch: 728 [96%]
2024-01-01 22:40:54,949	44k	INFO	Losses: [2.4426097869873047, 2.495901346206665, 6.602977275848389, 17.33472442626953, 0.2753230929374695], step: 18200, lr: 9.13126658525321e-05, reference_loss: 29.15153694152832
2024-01-01 22:40:55,336	44k	INFO	====> Epoch: 728, cost 22.45 s
2024-01-01 22:41:17,399	44k	INFO	====> Epoch: 729, cost 22.06 s
2024-01-01 22:41:39,695	44k	INFO	====> Epoch: 730, cost 22.30 s
2024-01-01 22:42:01,779	44k	INFO	====> Epoch: 731, cost 22.08 s
2024-01-01 22:42:23,860	44k	INFO	====> Epoch: 732, cost 22.08 s
2024-01-01 22:42:45,897	44k	INFO	====> Epoch: 733, cost 22.04 s
2024-01-01 22:43:08,045	44k	INFO	====> Epoch: 734, cost 22.15 s
2024-01-01 22:43:30,137	44k	INFO	====> Epoch: 735, cost 22.09 s
2024-01-01 22:43:52,194	44k	INFO	Train Epoch: 736 [96%]
2024-01-01 22:43:52,196	44k	INFO	Losses: [2.4941983222961426, 2.2313761711120605, 4.777737617492676, 16.871862411499023, 0.21397842466831207], step: 18400, lr: 9.122139312598508e-05, reference_loss: 26.589153289794922
2024-01-01 22:43:58,340	44k	INFO	Saving model and optimizer state at iteration 736 to ./logs/44k/G_18400.pth
2024-01-01 22:43:59,267	44k	INFO	Saving model and optimizer state at iteration 736 to ./logs/44k/D_18400.pth
2024-01-01 22:43:59,797	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_16000.pth
2024-01-01 22:43:59,836	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_16000.pth
2024-01-01 22:43:59,836	44k	INFO	====> Epoch: 736, cost 29.70 s
2024-01-01 22:44:21,853	44k	INFO	====> Epoch: 737, cost 22.02 s
2024-01-01 22:44:44,155	44k	INFO	====> Epoch: 738, cost 22.30 s
2024-01-01 22:45:06,268	44k	INFO	====> Epoch: 739, cost 22.11 s
2024-01-01 22:45:28,381	44k	INFO	====> Epoch: 740, cost 22.11 s
2024-01-01 22:45:50,484	44k	INFO	====> Epoch: 741, cost 22.10 s
2024-01-01 22:46:12,428	44k	INFO	====> Epoch: 742, cost 21.94 s
2024-01-01 22:46:34,435	44k	INFO	====> Epoch: 743, cost 22.01 s
2024-01-01 22:46:56,577	44k	INFO	Train Epoch: 744 [96%]
2024-01-01 22:46:56,579	44k	INFO	Losses: [2.417952060699463, 2.2197325229644775, 5.169571876525879, 16.812847137451172, 0.3073436915874481], step: 18600, lr: 9.113021163224278e-05, reference_loss: 26.927448272705078
2024-01-01 22:46:56,959	44k	INFO	====> Epoch: 744, cost 22.52 s
2024-01-01 22:47:19,215	44k	INFO	====> Epoch: 745, cost 22.26 s
2024-01-01 22:47:41,357	44k	INFO	====> Epoch: 746, cost 22.14 s
2024-01-01 22:48:03,532	44k	INFO	====> Epoch: 747, cost 22.18 s
2024-01-01 22:48:25,667	44k	INFO	====> Epoch: 748, cost 22.13 s
2024-01-01 22:48:47,673	44k	INFO	====> Epoch: 749, cost 22.01 s
2024-01-01 22:49:09,925	44k	INFO	====> Epoch: 750, cost 22.25 s
2024-01-01 22:49:32,004	44k	INFO	====> Epoch: 751, cost 22.08 s
2024-01-01 22:49:54,039	44k	INFO	Train Epoch: 752 [96%]
2024-01-01 22:49:54,041	44k	INFO	Losses: [2.1542961597442627, 2.413168430328369, 5.550180435180664, 15.430561065673828, 0.4055463671684265], step: 18800, lr: 9.103912128011228e-05, reference_loss: 25.953752517700195
2024-01-01 22:49:54,511	44k	INFO	====> Epoch: 752, cost 22.51 s
2024-01-01 22:50:16,692	44k	INFO	====> Epoch: 753, cost 22.18 s
2024-01-01 22:50:38,811	44k	INFO	====> Epoch: 754, cost 22.12 s
2024-01-01 22:51:00,803	44k	INFO	====> Epoch: 755, cost 21.99 s
2024-01-01 22:51:22,792	44k	INFO	====> Epoch: 756, cost 21.99 s
2024-01-01 22:51:44,788	44k	INFO	====> Epoch: 757, cost 22.00 s
2024-01-01 22:52:06,866	44k	INFO	====> Epoch: 758, cost 22.08 s
2024-01-01 22:52:28,912	44k	INFO	====> Epoch: 759, cost 22.05 s
2024-01-01 22:52:51,201	44k	INFO	Train Epoch: 760 [96%]
2024-01-01 22:52:51,204	44k	INFO	Losses: [2.369112014770508, 2.4317805767059326, 6.514947891235352, 16.845861434936523, 0.2976613938808441], step: 19000, lr: 9.094812197849185e-05, reference_loss: 28.459362030029297
2024-01-01 22:52:51,690	44k	INFO	====> Epoch: 760, cost 22.78 s
2024-01-01 22:53:13,794	44k	INFO	====> Epoch: 761, cost 22.10 s
2024-01-01 22:53:35,950	44k	INFO	====> Epoch: 762, cost 22.16 s
2024-01-01 22:53:58,186	44k	INFO	====> Epoch: 763, cost 22.24 s
2024-01-01 22:54:20,484	44k	INFO	====> Epoch: 764, cost 22.30 s
2024-01-01 22:54:42,805	44k	INFO	====> Epoch: 765, cost 22.32 s
2024-01-01 22:55:05,177	44k	INFO	====> Epoch: 766, cost 22.37 s
2024-01-01 22:55:27,418	44k	INFO	====> Epoch: 767, cost 22.24 s
2024-01-01 22:55:49,471	44k	INFO	Train Epoch: 768 [96%]
2024-01-01 22:55:49,474	44k	INFO	Losses: [2.273448944091797, 2.3952784538269043, 5.121946811676025, 15.133885383605957, 0.23691299557685852], step: 19200, lr: 9.085721363637077e-05, reference_loss: 25.161474227905273
2024-01-01 22:55:55,434	44k	INFO	Saving model and optimizer state at iteration 768 to ./logs/44k/G_19200.pth
2024-01-01 22:55:56,353	44k	INFO	Saving model and optimizer state at iteration 768 to ./logs/44k/D_19200.pth
2024-01-01 22:55:56,834	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_16800.pth
2024-01-01 22:55:56,873	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_16800.pth
2024-01-01 22:55:56,873	44k	INFO	====> Epoch: 768, cost 29.46 s
2024-01-01 22:56:18,983	44k	INFO	====> Epoch: 769, cost 22.11 s
2024-01-01 22:56:41,190	44k	INFO	====> Epoch: 770, cost 22.21 s
2024-01-01 22:57:03,513	44k	INFO	====> Epoch: 771, cost 22.32 s
2024-01-01 22:57:25,763	44k	INFO	====> Epoch: 772, cost 22.25 s
2024-01-01 22:57:47,862	44k	INFO	====> Epoch: 773, cost 22.10 s
2024-01-01 22:58:09,944	44k	INFO	====> Epoch: 774, cost 22.08 s
2024-01-01 22:58:32,024	44k	INFO	====> Epoch: 775, cost 22.08 s
2024-01-01 22:58:54,064	44k	INFO	Train Epoch: 776 [96%]
2024-01-01 22:58:54,066	44k	INFO	Losses: [2.3237104415893555, 2.2002673149108887, 5.6287150382995605, 16.552978515625, 0.2904358208179474], step: 19400, lr: 9.076639616282937e-05, reference_loss: 26.99610710144043
2024-01-01 22:58:54,535	44k	INFO	====> Epoch: 776, cost 22.51 s
2024-01-01 22:59:16,697	44k	INFO	====> Epoch: 777, cost 22.16 s
2024-01-01 22:59:38,768	44k	INFO	====> Epoch: 778, cost 22.07 s
2024-01-01 23:00:00,830	44k	INFO	====> Epoch: 779, cost 22.06 s
2024-01-01 23:00:22,876	44k	INFO	====> Epoch: 780, cost 22.05 s
2024-01-01 23:00:45,045	44k	INFO	====> Epoch: 781, cost 22.17 s
2024-01-01 23:01:07,134	44k	INFO	====> Epoch: 782, cost 22.09 s
2024-01-01 23:01:29,299	44k	INFO	====> Epoch: 783, cost 22.17 s
2024-01-01 23:01:51,446	44k	INFO	Train Epoch: 784 [96%]
2024-01-01 23:01:51,448	44k	INFO	Losses: [2.2138843536376953, 2.463881015777588, 5.4246439933776855, 15.290664672851562, 0.540771484375], step: 19600, lr: 9.067566946703881e-05, reference_loss: 25.93384552001953
2024-01-01 23:01:51,843	44k	INFO	====> Epoch: 784, cost 22.54 s
2024-01-01 23:02:13,983	44k	INFO	====> Epoch: 785, cost 22.14 s
2024-01-01 23:02:36,074	44k	INFO	====> Epoch: 786, cost 22.09 s
2024-01-01 23:02:58,282	44k	INFO	====> Epoch: 787, cost 22.21 s
2024-01-01 23:03:20,395	44k	INFO	====> Epoch: 788, cost 22.11 s
2024-01-01 23:03:42,541	44k	INFO	====> Epoch: 789, cost 22.15 s
2024-01-01 23:04:04,566	44k	INFO	====> Epoch: 790, cost 22.03 s
2024-01-01 23:04:26,576	44k	INFO	====> Epoch: 791, cost 22.01 s
2024-01-01 23:04:48,709	44k	INFO	Train Epoch: 792 [96%]
2024-01-01 23:04:48,711	44k	INFO	Losses: [2.398674249649048, 2.3294148445129395, 6.901942729949951, 17.610462188720703, 0.32038503885269165], step: 19800, lr: 9.058503345826105e-05, reference_loss: 29.56087875366211
2024-01-01 23:04:49,119	44k	INFO	====> Epoch: 792, cost 22.54 s
2024-01-01 23:05:11,382	44k	INFO	====> Epoch: 793, cost 22.26 s
2024-01-01 23:05:33,562	44k	INFO	====> Epoch: 794, cost 22.18 s
2024-01-01 23:05:55,615	44k	INFO	====> Epoch: 795, cost 22.05 s
2024-01-01 23:06:17,730	44k	INFO	====> Epoch: 796, cost 22.11 s
2024-01-01 23:06:39,935	44k	INFO	====> Epoch: 797, cost 22.21 s
2024-01-01 23:07:02,094	44k	INFO	====> Epoch: 798, cost 22.16 s
2024-01-01 23:07:24,122	44k	INFO	====> Epoch: 799, cost 22.03 s
2024-01-01 23:07:46,172	44k	INFO	Train Epoch: 800 [96%]
2024-01-01 23:07:46,173	44k	INFO	Losses: [2.4694976806640625, 2.130687952041626, 5.296977519989014, 16.407943725585938, 0.18043823540210724], step: 20000, lr: 9.049448804584871e-05, reference_loss: 26.485546112060547
2024-01-01 23:07:52,270	44k	INFO	Saving model and optimizer state at iteration 800 to ./logs/44k/G_20000.pth
2024-01-01 23:07:53,217	44k	INFO	Saving model and optimizer state at iteration 800 to ./logs/44k/D_20000.pth
2024-01-01 23:07:53,739	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_17600.pth
2024-01-01 23:07:53,778	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_17600.pth
2024-01-01 23:07:53,778	44k	INFO	====> Epoch: 800, cost 29.66 s
2024-01-01 23:08:15,805	44k	INFO	====> Epoch: 801, cost 22.03 s
2024-01-01 23:08:37,922	44k	INFO	====> Epoch: 802, cost 22.12 s
2024-01-01 23:09:00,011	44k	INFO	====> Epoch: 803, cost 22.09 s
2024-01-01 23:09:22,273	44k	INFO	====> Epoch: 804, cost 22.26 s
2024-01-01 23:09:44,365	44k	INFO	====> Epoch: 805, cost 22.09 s
2024-01-01 23:10:06,495	44k	INFO	====> Epoch: 806, cost 22.13 s
2024-01-01 23:10:28,619	44k	INFO	====> Epoch: 807, cost 22.12 s
2024-01-01 23:10:50,741	44k	INFO	Train Epoch: 808 [96%]
2024-01-01 23:10:50,743	44k	INFO	Losses: [2.69612717628479, 2.266695261001587, 5.7484588623046875, 18.227264404296875, 0.3600437045097351], step: 20200, lr: 9.040403313924505e-05, reference_loss: 29.2985897064209
2024-01-01 23:10:51,135	44k	INFO	====> Epoch: 808, cost 22.52 s
2024-01-01 23:11:13,231	44k	INFO	====> Epoch: 809, cost 22.10 s
2024-01-01 23:11:35,421	44k	INFO	====> Epoch: 810, cost 22.19 s
2024-01-01 23:11:57,439	44k	INFO	====> Epoch: 811, cost 22.02 s
2024-01-01 23:12:19,589	44k	INFO	====> Epoch: 812, cost 22.15 s
2024-01-01 23:12:41,700	44k	INFO	====> Epoch: 813, cost 22.11 s
2024-01-01 23:13:03,861	44k	INFO	====> Epoch: 814, cost 22.16 s
2024-01-01 23:13:25,971	44k	INFO	====> Epoch: 815, cost 22.11 s
2024-01-01 23:13:48,137	44k	INFO	Train Epoch: 816 [96%]
2024-01-01 23:13:48,139	44k	INFO	Losses: [2.145289897918701, 2.4742941856384277, 6.353755474090576, 15.347153663635254, 0.3106895387172699], step: 20400, lr: 9.031366864798387e-05, reference_loss: 26.631181716918945
2024-01-01 23:13:48,553	44k	INFO	====> Epoch: 816, cost 22.58 s
2024-01-01 23:14:10,623	44k	INFO	====> Epoch: 817, cost 22.07 s
2024-01-01 23:14:32,693	44k	INFO	====> Epoch: 818, cost 22.07 s
2024-01-01 23:14:54,814	44k	INFO	====> Epoch: 819, cost 22.12 s
2024-01-01 23:15:16,953	44k	INFO	====> Epoch: 820, cost 22.14 s
2024-01-01 23:15:39,058	44k	INFO	====> Epoch: 821, cost 22.10 s
2024-01-01 23:16:01,156	44k	INFO	====> Epoch: 822, cost 22.10 s
2024-01-01 23:16:23,293	44k	INFO	====> Epoch: 823, cost 22.14 s
2024-01-01 23:16:45,492	44k	INFO	Train Epoch: 824 [96%]
2024-01-01 23:16:45,493	44k	INFO	Losses: [2.4117119312286377, 2.2983758449554443, 6.248422145843506, 16.48992156982422, 0.12892179191112518], step: 20600, lr: 9.022339448168936e-05, reference_loss: 27.57735252380371
2024-01-01 23:16:46,093	44k	INFO	====> Epoch: 824, cost 22.80 s
2024-01-01 23:17:08,197	44k	INFO	====> Epoch: 825, cost 22.10 s
2024-01-01 23:17:30,280	44k	INFO	====> Epoch: 826, cost 22.08 s
2024-01-01 23:17:52,334	44k	INFO	====> Epoch: 827, cost 22.05 s
2024-01-01 23:18:14,417	44k	INFO	====> Epoch: 828, cost 22.08 s
2024-01-01 23:18:36,485	44k	INFO	====> Epoch: 829, cost 22.07 s
2024-01-01 23:18:58,573	44k	INFO	====> Epoch: 830, cost 22.09 s
2024-01-01 23:19:20,762	44k	INFO	====> Epoch: 831, cost 22.19 s
2024-01-01 23:19:42,898	44k	INFO	Train Epoch: 832 [96%]
2024-01-01 23:19:42,900	44k	INFO	Losses: [2.3363595008850098, 2.49592661857605, 5.519067764282227, 16.628131866455078, 0.2707427144050598], step: 20800, lr: 9.013321055007607e-05, reference_loss: 27.250226974487305
2024-01-01 23:19:48,455	44k	INFO	Saving model and optimizer state at iteration 832 to ./logs/44k/G_20800.pth
2024-01-01 23:19:49,525	44k	INFO	Saving model and optimizer state at iteration 832 to ./logs/44k/D_20800.pth
2024-01-01 23:19:50,005	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_18400.pth
2024-01-01 23:19:50,044	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_18400.pth
2024-01-01 23:19:50,044	44k	INFO	====> Epoch: 832, cost 29.28 s
2024-01-01 23:20:12,134	44k	INFO	====> Epoch: 833, cost 22.09 s
2024-01-01 23:20:34,257	44k	INFO	====> Epoch: 834, cost 22.12 s
2024-01-01 23:20:56,351	44k	INFO	====> Epoch: 835, cost 22.09 s
2024-01-01 23:21:18,565	44k	INFO	====> Epoch: 836, cost 22.21 s
2024-01-01 23:21:40,784	44k	INFO	====> Epoch: 837, cost 22.22 s
2024-01-01 23:22:02,923	44k	INFO	====> Epoch: 838, cost 22.14 s
2024-01-01 23:22:24,912	44k	INFO	====> Epoch: 839, cost 21.99 s
2024-01-01 23:22:47,101	44k	INFO	Train Epoch: 840 [96%]
2024-01-01 23:22:47,103	44k	INFO	Losses: [2.2816667556762695, 2.358112335205078, 6.582434177398682, 17.29183578491211, 0.2467973828315735], step: 21000, lr: 9.004311676294879e-05, reference_loss: 28.760847091674805
2024-01-01 23:22:47,499	44k	INFO	====> Epoch: 840, cost 22.59 s
2024-01-01 23:23:09,649	44k	INFO	====> Epoch: 841, cost 22.15 s
2024-01-01 23:23:31,608	44k	INFO	====> Epoch: 842, cost 21.96 s
2024-01-01 23:23:53,767	44k	INFO	====> Epoch: 843, cost 22.16 s
2024-01-01 23:24:15,857	44k	INFO	====> Epoch: 844, cost 22.09 s
2024-01-01 23:24:37,959	44k	INFO	====> Epoch: 845, cost 22.10 s
2024-01-01 23:25:00,088	44k	INFO	====> Epoch: 846, cost 22.13 s
2024-01-01 23:25:22,217	44k	INFO	====> Epoch: 847, cost 22.13 s
2024-01-01 23:25:44,313	44k	INFO	Train Epoch: 848 [96%]
2024-01-01 23:25:44,316	44k	INFO	Losses: [2.2688138484954834, 2.4066224098205566, 5.2285380363464355, 15.661377906799316, 0.31858089566230774], step: 21200, lr: 8.995311303020248e-05, reference_loss: 25.883934020996094
2024-01-01 23:25:44,690	44k	INFO	====> Epoch: 848, cost 22.47 s
2024-01-01 23:26:06,851	44k	INFO	====> Epoch: 849, cost 22.16 s
2024-01-01 23:26:29,016	44k	INFO	====> Epoch: 850, cost 22.16 s
2024-01-01 23:26:51,206	44k	INFO	====> Epoch: 851, cost 22.19 s
2024-01-01 23:27:13,283	44k	INFO	====> Epoch: 852, cost 22.08 s
2024-01-01 23:27:35,637	44k	INFO	====> Epoch: 853, cost 22.35 s
2024-01-01 23:27:57,897	44k	INFO	====> Epoch: 854, cost 22.26 s
2024-01-01 23:28:20,140	44k	INFO	====> Epoch: 855, cost 22.24 s
2024-01-01 23:28:42,339	44k	INFO	Train Epoch: 856 [96%]
2024-01-01 23:28:42,341	44k	INFO	Losses: [2.373821973800659, 2.627328395843506, 7.303128242492676, 16.944772720336914, 0.17014451324939728], step: 21400, lr: 8.98631992618221e-05, reference_loss: 29.4191951751709
2024-01-01 23:28:42,735	44k	INFO	====> Epoch: 856, cost 22.60 s
2024-01-01 23:29:04,991	44k	INFO	====> Epoch: 857, cost 22.26 s
2024-01-01 23:29:27,180	44k	INFO	====> Epoch: 858, cost 22.19 s
2024-01-01 23:29:49,380	44k	INFO	====> Epoch: 859, cost 22.20 s
2024-01-01 23:30:11,512	44k	INFO	====> Epoch: 860, cost 22.13 s
2024-01-01 23:30:33,604	44k	INFO	====> Epoch: 861, cost 22.09 s
2024-01-01 23:30:55,676	44k	INFO	====> Epoch: 862, cost 22.07 s
2024-01-01 23:31:17,942	44k	INFO	====> Epoch: 863, cost 22.27 s
2024-01-01 23:31:40,067	44k	INFO	Train Epoch: 864 [96%]
2024-01-01 23:31:40,070	44k	INFO	Losses: [2.2817916870117188, 2.7020373344421387, 6.074630260467529, 16.979223251342773, 0.1385638415813446], step: 21600, lr: 8.977337536788267e-05, reference_loss: 28.176244735717773
2024-01-01 23:31:45,529	44k	INFO	Saving model and optimizer state at iteration 864 to ./logs/44k/G_21600.pth
2024-01-01 23:31:46,434	44k	INFO	Saving model and optimizer state at iteration 864 to ./logs/44k/D_21600.pth
2024-01-01 23:31:46,916	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_19200.pth
2024-01-01 23:31:46,955	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_19200.pth
2024-01-01 23:31:46,955	44k	INFO	====> Epoch: 864, cost 29.01 s
2024-01-01 23:32:09,016	44k	INFO	====> Epoch: 865, cost 22.06 s
2024-01-01 23:32:31,042	44k	INFO	====> Epoch: 866, cost 22.03 s
2024-01-01 23:32:53,121	44k	INFO	====> Epoch: 867, cost 22.08 s
2024-01-01 23:33:15,153	44k	INFO	====> Epoch: 868, cost 22.03 s
2024-01-01 23:33:37,169	44k	INFO	====> Epoch: 869, cost 22.02 s
2024-01-01 23:33:59,287	44k	INFO	====> Epoch: 870, cost 22.12 s
2024-01-01 23:34:21,603	44k	INFO	====> Epoch: 871, cost 22.32 s
2024-01-01 23:34:43,729	44k	INFO	Train Epoch: 872 [96%]
2024-01-01 23:34:43,731	44k	INFO	Losses: [2.310791254043579, 2.5356736183166504, 6.352319240570068, 16.943370819091797, 0.17651739716529846], step: 21800, lr: 8.968364125854907e-05, reference_loss: 28.31867218017578
2024-01-01 23:34:44,120	44k	INFO	====> Epoch: 872, cost 22.52 s
2024-01-01 23:35:06,235	44k	INFO	====> Epoch: 873, cost 22.11 s
2024-01-01 23:35:28,327	44k	INFO	====> Epoch: 874, cost 22.09 s
2024-01-01 23:35:50,511	44k	INFO	====> Epoch: 875, cost 22.18 s
2024-01-01 23:36:12,664	44k	INFO	====> Epoch: 876, cost 22.15 s
2024-01-01 23:36:34,888	44k	INFO	====> Epoch: 877, cost 22.22 s
2024-01-01 23:36:57,274	44k	INFO	====> Epoch: 878, cost 22.39 s
2024-01-01 23:37:19,574	44k	INFO	====> Epoch: 879, cost 22.30 s
2024-01-01 23:37:41,749	44k	INFO	Train Epoch: 880 [96%]
2024-01-01 23:37:41,750	44k	INFO	Losses: [2.180748462677002, 2.478759527206421, 5.897624969482422, 14.831130981445312, 0.42323610186576843], step: 22000, lr: 8.959399684407593e-05, reference_loss: 25.811500549316406
2024-01-01 23:37:42,319	44k	INFO	====> Epoch: 880, cost 22.75 s
2024-01-01 23:38:04,476	44k	INFO	====> Epoch: 881, cost 22.16 s
2024-01-01 23:38:26,784	44k	INFO	====> Epoch: 882, cost 22.31 s
2024-01-01 23:38:49,051	44k	INFO	====> Epoch: 883, cost 22.27 s
2024-01-01 23:39:11,349	44k	INFO	====> Epoch: 884, cost 22.30 s
2024-01-01 23:39:33,604	44k	INFO	====> Epoch: 885, cost 22.26 s
2024-01-01 23:39:55,911	44k	INFO	====> Epoch: 886, cost 22.31 s
2024-01-01 23:40:18,289	44k	INFO	====> Epoch: 887, cost 22.38 s
2024-01-01 23:40:40,602	44k	INFO	Train Epoch: 888 [96%]
2024-01-01 23:40:40,604	44k	INFO	Losses: [2.188119649887085, 2.4959094524383545, 6.904232978820801, 15.904592514038086, 0.08991825580596924], step: 22200, lr: 8.950444203480763e-05, reference_loss: 27.582773208618164
2024-01-01 23:40:41,094	44k	INFO	====> Epoch: 888, cost 22.81 s
2024-01-01 23:41:03,403	44k	INFO	====> Epoch: 889, cost 22.31 s
2024-01-01 23:41:25,880	44k	INFO	====> Epoch: 890, cost 22.48 s
2024-01-01 23:41:48,107	44k	INFO	====> Epoch: 891, cost 22.23 s
2024-01-01 23:42:10,342	44k	INFO	====> Epoch: 892, cost 22.24 s
2024-01-01 23:42:32,625	44k	INFO	====> Epoch: 893, cost 22.28 s
2024-01-01 23:42:54,916	44k	INFO	====> Epoch: 894, cost 22.29 s
2024-01-01 23:43:17,256	44k	INFO	====> Epoch: 895, cost 22.34 s
2024-01-01 23:43:39,577	44k	INFO	Train Epoch: 896 [96%]
2024-01-01 23:43:39,579	44k	INFO	Losses: [2.4735302925109863, 2.2041492462158203, 4.9310078620910645, 15.286901473999023, 0.16292524337768555], step: 22400, lr: 8.941497674117817e-05, reference_loss: 25.058513641357422
2024-01-01 23:43:45,528	44k	INFO	Saving model and optimizer state at iteration 896 to ./logs/44k/G_22400.pth
2024-01-01 23:43:46,440	44k	INFO	Saving model and optimizer state at iteration 896 to ./logs/44k/D_22400.pth
2024-01-01 23:43:46,944	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_20000.pth
2024-01-01 23:43:46,983	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_20000.pth
2024-01-01 23:43:46,983	44k	INFO	====> Epoch: 896, cost 29.73 s
2024-01-01 23:44:09,230	44k	INFO	====> Epoch: 897, cost 22.25 s
2024-01-01 23:44:31,786	44k	INFO	====> Epoch: 898, cost 22.56 s
2024-01-01 23:44:54,057	44k	INFO	====> Epoch: 899, cost 22.27 s
2024-01-01 23:45:16,247	44k	INFO	====> Epoch: 900, cost 22.19 s
2024-01-01 23:45:38,463	44k	INFO	====> Epoch: 901, cost 22.22 s
2024-01-01 23:46:00,786	44k	INFO	====> Epoch: 902, cost 22.32 s
2024-01-01 23:46:23,175	44k	INFO	====> Epoch: 903, cost 22.39 s
2024-01-01 23:46:45,485	44k	INFO	Train Epoch: 904 [96%]
2024-01-01 23:46:45,487	44k	INFO	Losses: [2.2890357971191406, 2.4751808643341064, 6.630181789398193, 17.235328674316406, 0.21199996769428253], step: 22600, lr: 8.932560087371105e-05, reference_loss: 28.841726303100586
2024-01-01 23:46:45,879	44k	INFO	====> Epoch: 904, cost 22.70 s
2024-01-01 23:47:08,090	44k	INFO	====> Epoch: 905, cost 22.21 s
2024-01-01 23:47:30,192	44k	INFO	====> Epoch: 906, cost 22.10 s
2024-01-01 23:47:52,279	44k	INFO	====> Epoch: 907, cost 22.09 s
2024-01-01 23:48:14,473	44k	INFO	====> Epoch: 908, cost 22.19 s
2024-01-01 23:48:36,686	44k	INFO	====> Epoch: 909, cost 22.21 s
2024-01-01 23:48:59,033	44k	INFO	====> Epoch: 910, cost 22.35 s
2024-01-01 23:49:21,264	44k	INFO	====> Epoch: 911, cost 22.23 s
2024-01-01 23:49:43,506	44k	INFO	Train Epoch: 912 [96%]
2024-01-01 23:49:43,508	44k	INFO	Losses: [2.1718924045562744, 2.481158494949341, 5.32340669631958, 14.099464416503906, 0.2262663096189499], step: 22800, lr: 8.923631434301922e-05, reference_loss: 24.302188873291016
2024-01-01 23:49:43,884	44k	INFO	====> Epoch: 912, cost 22.62 s
2024-01-01 23:50:06,254	44k	INFO	====> Epoch: 913, cost 22.37 s
2024-01-01 23:50:28,602	44k	INFO	====> Epoch: 914, cost 22.35 s
2024-01-01 23:50:50,716	44k	INFO	====> Epoch: 915, cost 22.11 s
2024-01-01 23:51:12,842	44k	INFO	====> Epoch: 916, cost 22.13 s
2024-01-01 23:51:34,990	44k	INFO	====> Epoch: 917, cost 22.15 s
2024-01-01 23:51:57,089	44k	INFO	====> Epoch: 918, cost 22.10 s
2024-01-01 23:52:19,297	44k	INFO	====> Epoch: 919, cost 22.21 s
2024-01-01 23:52:41,609	44k	INFO	Train Epoch: 920 [96%]
2024-01-01 23:52:41,611	44k	INFO	Losses: [2.2194793224334717, 2.360426902770996, 6.720308303833008, 16.245004653930664, 0.08834222704172134], step: 23000, lr: 8.9147117059805e-05, reference_loss: 27.633562088012695
2024-01-01 23:52:41,983	44k	INFO	====> Epoch: 920, cost 22.69 s
2024-01-01 23:53:04,222	44k	INFO	====> Epoch: 921, cost 22.24 s
2024-01-01 23:53:26,657	44k	INFO	====> Epoch: 922, cost 22.44 s
2024-01-01 23:53:49,062	44k	INFO	====> Epoch: 923, cost 22.41 s
2024-01-01 23:54:11,346	44k	INFO	====> Epoch: 924, cost 22.28 s
2024-01-01 23:54:33,610	44k	INFO	====> Epoch: 925, cost 22.26 s
2024-01-01 23:54:55,971	44k	INFO	====> Epoch: 926, cost 22.36 s
2024-01-01 23:55:18,101	44k	INFO	====> Epoch: 927, cost 22.13 s
2024-01-01 23:55:40,177	44k	INFO	Train Epoch: 928 [96%]
2024-01-01 23:55:40,179	44k	INFO	Losses: [2.408449411392212, 2.1903774738311768, 5.117640972137451, 15.312409400939941, 0.11601155251264572], step: 23200, lr: 8.90580089348599e-05, reference_loss: 25.144887924194336
2024-01-01 23:55:45,844	44k	INFO	Saving model and optimizer state at iteration 928 to ./logs/44k/G_23200.pth
2024-01-01 23:55:46,753	44k	INFO	Saving model and optimizer state at iteration 928 to ./logs/44k/D_23200.pth
2024-01-01 23:55:47,242	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_20800.pth
2024-01-01 23:55:47,282	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_20800.pth
2024-01-01 23:55:47,282	44k	INFO	====> Epoch: 928, cost 29.18 s
2024-01-01 23:56:09,383	44k	INFO	====> Epoch: 929, cost 22.10 s
2024-01-01 23:56:31,634	44k	INFO	====> Epoch: 930, cost 22.25 s
2024-01-01 23:56:53,844	44k	INFO	====> Epoch: 931, cost 22.21 s
2024-01-01 23:57:16,074	44k	INFO	====> Epoch: 932, cost 22.23 s
2024-01-01 23:57:38,254	44k	INFO	====> Epoch: 933, cost 22.18 s
2024-01-01 23:58:00,403	44k	INFO	====> Epoch: 934, cost 22.15 s
2024-01-01 23:58:22,518	44k	INFO	====> Epoch: 935, cost 22.12 s
2024-01-01 23:58:44,576	44k	INFO	Train Epoch: 936 [96%]
2024-01-01 23:58:44,578	44k	INFO	Losses: [2.4776389598846436, 2.383575916290283, 5.700579643249512, 15.923868179321289, 0.17180560529232025], step: 23400, lr: 8.896898987906474e-05, reference_loss: 26.657468795776367
2024-01-01 23:58:44,953	44k	INFO	====> Epoch: 936, cost 22.43 s
2024-01-01 23:59:07,130	44k	INFO	====> Epoch: 937, cost 22.18 s
2024-01-01 23:59:29,439	44k	INFO	====> Epoch: 938, cost 22.31 s
2024-01-01 23:59:51,651	44k	INFO	====> Epoch: 939, cost 22.21 s
2024-01-02 00:00:14,021	44k	INFO	====> Epoch: 940, cost 22.37 s
2024-01-02 00:00:36,202	44k	INFO	====> Epoch: 941, cost 22.18 s
2024-01-02 00:00:58,496	44k	INFO	====> Epoch: 942, cost 22.29 s
2024-01-02 00:01:20,748	44k	INFO	====> Epoch: 943, cost 22.25 s
2024-01-02 00:01:42,932	44k	INFO	Train Epoch: 944 [96%]
2024-01-02 00:01:42,934	44k	INFO	Losses: [2.327805280685425, 2.32635760307312, 4.9923624992370605, 14.01427936553955, 0.26382333040237427], step: 23600, lr: 8.888005980338925e-05, reference_loss: 23.92462730407715
2024-01-02 00:01:43,323	44k	INFO	====> Epoch: 944, cost 22.58 s
2024-01-02 00:02:05,564	44k	INFO	====> Epoch: 945, cost 22.24 s
2024-01-02 00:02:27,741	44k	INFO	====> Epoch: 946, cost 22.18 s
2024-01-02 00:02:49,928	44k	INFO	====> Epoch: 947, cost 22.19 s
2024-01-02 00:03:12,091	44k	INFO	====> Epoch: 948, cost 22.16 s
2024-01-02 00:03:34,318	44k	INFO	====> Epoch: 949, cost 22.23 s
2024-01-02 00:03:56,623	44k	INFO	====> Epoch: 950, cost 22.30 s
2024-01-02 00:04:18,805	44k	INFO	====> Epoch: 951, cost 22.18 s
2024-01-02 00:04:40,909	44k	INFO	Train Epoch: 952 [96%]
2024-01-02 00:04:40,911	44k	INFO	Losses: [2.2400619983673096, 2.4093127250671387, 7.026684284210205, 16.566987991333008, 0.05982968583703041], step: 23800, lr: 8.879121861889226e-05, reference_loss: 28.30287742614746
2024-01-02 00:04:41,303	44k	INFO	====> Epoch: 952, cost 22.50 s
2024-01-02 00:05:03,432	44k	INFO	====> Epoch: 953, cost 22.13 s
2024-01-02 00:05:25,686	44k	INFO	====> Epoch: 954, cost 22.25 s
2024-01-02 00:05:47,971	44k	INFO	====> Epoch: 955, cost 22.28 s
2024-01-02 00:06:10,154	44k	INFO	====> Epoch: 956, cost 22.18 s
2024-01-02 00:06:32,352	44k	INFO	====> Epoch: 957, cost 22.20 s
2024-01-02 00:06:54,476	44k	INFO	====> Epoch: 958, cost 22.12 s
2024-01-02 00:07:16,671	44k	INFO	====> Epoch: 959, cost 22.20 s
2024-01-02 00:07:38,959	44k	INFO	Train Epoch: 960 [96%]
2024-01-02 00:07:38,960	44k	INFO	Losses: [2.425055742263794, 2.299665689468384, 5.340066909790039, 15.092315673828125, 0.08830680698156357], step: 24000, lr: 8.870246623672146e-05, reference_loss: 25.245410919189453
2024-01-02 00:07:44,942	44k	INFO	Saving model and optimizer state at iteration 960 to ./logs/44k/G_24000.pth
2024-01-02 00:07:45,846	44k	INFO	Saving model and optimizer state at iteration 960 to ./logs/44k/D_24000.pth
2024-01-02 00:07:46,344	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_21600.pth
2024-01-02 00:07:46,383	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_21600.pth
2024-01-02 00:07:46,384	44k	INFO	====> Epoch: 960, cost 29.71 s
2024-01-02 00:08:08,533	44k	INFO	====> Epoch: 961, cost 22.15 s
2024-01-02 00:08:30,753	44k	INFO	====> Epoch: 962, cost 22.22 s
2024-01-02 00:08:52,835	44k	INFO	====> Epoch: 963, cost 22.08 s
2024-01-02 00:09:14,933	44k	INFO	====> Epoch: 964, cost 22.10 s
2024-01-02 00:09:37,131	44k	INFO	====> Epoch: 965, cost 22.20 s
2024-01-02 00:09:59,206	44k	INFO	====> Epoch: 966, cost 22.08 s
2024-01-02 00:10:21,539	44k	INFO	====> Epoch: 967, cost 22.33 s
2024-01-02 00:10:43,583	44k	INFO	Train Epoch: 968 [96%]
2024-01-02 00:10:43,585	44k	INFO	Losses: [2.2544963359832764, 2.5126800537109375, 7.014040946960449, 17.750606536865234, 0.14340968430042267], step: 24200, lr: 8.861380256811337e-05, reference_loss: 29.675233840942383
2024-01-02 00:10:43,969	44k	INFO	====> Epoch: 968, cost 22.43 s
2024-01-02 00:11:06,066	44k	INFO	====> Epoch: 969, cost 22.10 s
2024-01-02 00:11:28,263	44k	INFO	====> Epoch: 970, cost 22.20 s
2024-01-02 00:11:50,440	44k	INFO	====> Epoch: 971, cost 22.18 s
2024-01-02 00:12:12,565	44k	INFO	====> Epoch: 972, cost 22.13 s
2024-01-02 00:12:34,682	44k	INFO	====> Epoch: 973, cost 22.12 s
2024-01-02 00:12:56,927	44k	INFO	====> Epoch: 974, cost 22.25 s
2024-01-02 00:13:19,156	44k	INFO	====> Epoch: 975, cost 22.23 s
2024-01-02 00:13:41,392	44k	INFO	Train Epoch: 976 [96%]
2024-01-02 00:13:41,393	44k	INFO	Losses: [2.2746191024780273, 2.4619534015655518, 5.30783224105835, 14.26296329498291, 0.13793475925922394], step: 24400, lr: 8.852522752439323e-05, reference_loss: 24.44530487060547
2024-01-02 00:13:41,981	44k	INFO	====> Epoch: 976, cost 22.82 s
2024-01-02 00:14:04,147	44k	INFO	====> Epoch: 977, cost 22.17 s
2024-01-02 00:14:26,388	44k	INFO	====> Epoch: 978, cost 22.24 s
2024-01-02 00:14:48,617	44k	INFO	====> Epoch: 979, cost 22.23 s
2024-01-02 00:15:10,837	44k	INFO	====> Epoch: 980, cost 22.22 s
2024-01-02 00:15:33,054	44k	INFO	====> Epoch: 981, cost 22.22 s
2024-01-02 00:15:55,258	44k	INFO	====> Epoch: 982, cost 22.20 s
2024-01-02 00:16:17,493	44k	INFO	====> Epoch: 983, cost 22.24 s
2024-01-02 00:16:39,776	44k	INFO	Train Epoch: 984 [96%]
2024-01-02 00:16:39,777	44k	INFO	Losses: [2.4471499919891357, 2.5217349529266357, 6.344234943389893, 16.07097053527832, 0.11531568318605423], step: 24600, lr: 8.843674101697492e-05, reference_loss: 27.499406814575195
2024-01-02 00:16:40,183	44k	INFO	====> Epoch: 984, cost 22.69 s
2024-01-02 00:17:02,464	44k	INFO	====> Epoch: 985, cost 22.28 s
2024-01-02 00:17:24,904	44k	INFO	====> Epoch: 986, cost 22.44 s
2024-01-02 00:17:47,154	44k	INFO	====> Epoch: 987, cost 22.25 s
2024-01-02 00:18:09,382	44k	INFO	====> Epoch: 988, cost 22.23 s
2024-01-02 00:18:31,604	44k	INFO	====> Epoch: 989, cost 22.22 s
2024-01-02 00:18:53,972	44k	INFO	====> Epoch: 990, cost 22.37 s
2024-01-02 00:19:16,309	44k	INFO	====> Epoch: 991, cost 22.34 s
2024-01-02 00:19:38,618	44k	INFO	Train Epoch: 992 [96%]
2024-01-02 00:19:38,619	44k	INFO	Losses: [2.3082005977630615, 2.567392110824585, 5.2989325523376465, 14.770318984985352, 0.020751507952809334], step: 24800, lr: 8.834834295736085e-05, reference_loss: 24.965595245361328
2024-01-02 00:19:44,680	44k	INFO	Saving model and optimizer state at iteration 992 to ./logs/44k/G_24800.pth
2024-01-02 00:19:45,603	44k	INFO	Saving model and optimizer state at iteration 992 to ./logs/44k/D_24800.pth
2024-01-02 00:19:46,105	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_22400.pth
2024-01-02 00:19:46,144	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_22400.pth
2024-01-02 00:19:46,144	44k	INFO	====> Epoch: 992, cost 29.84 s
2024-01-02 00:20:08,321	44k	INFO	====> Epoch: 993, cost 22.18 s
2024-01-02 00:20:30,738	44k	INFO	====> Epoch: 994, cost 22.42 s
2024-01-02 00:20:52,922	44k	INFO	====> Epoch: 995, cost 22.18 s
2024-01-02 00:21:15,146	44k	INFO	====> Epoch: 996, cost 22.22 s
2024-01-02 00:21:37,319	44k	INFO	====> Epoch: 997, cost 22.17 s
2024-01-02 00:21:59,532	44k	INFO	====> Epoch: 998, cost 22.21 s
2024-01-02 00:22:21,783	44k	INFO	====> Epoch: 999, cost 22.25 s
2024-01-02 00:22:44,027	44k	INFO	Train Epoch: 1000 [96%]
2024-01-02 00:22:44,029	44k	INFO	Losses: [2.2927095890045166, 2.407649517059326, 6.046139240264893, 15.672412872314453, 0.12831582129001617], step: 25000, lr: 8.82600332571419e-05, reference_loss: 26.547225952148438
2024-01-02 00:22:44,515	44k	INFO	====> Epoch: 1000, cost 22.73 s
2024-01-02 00:23:06,778	44k	INFO	====> Epoch: 1001, cost 22.26 s
2024-01-02 00:23:29,042	44k	INFO	====> Epoch: 1002, cost 22.26 s
2024-01-02 00:23:51,172	44k	INFO	====> Epoch: 1003, cost 22.13 s
2024-01-02 00:24:13,282	44k	INFO	====> Epoch: 1004, cost 22.11 s
2024-01-02 00:24:35,382	44k	INFO	====> Epoch: 1005, cost 22.10 s
2024-01-02 00:24:57,752	44k	INFO	====> Epoch: 1006, cost 22.37 s
2024-01-02 00:25:20,001	44k	INFO	====> Epoch: 1007, cost 22.25 s
2024-01-02 00:25:42,367	44k	INFO	Train Epoch: 1008 [96%]
2024-01-02 00:25:42,369	44k	INFO	Losses: [2.119110107421875, 2.582958459854126, 6.198240280151367, 15.037500381469727, 0.17745935916900635], step: 25200, lr: 8.817181182799734e-05, reference_loss: 26.11526870727539
2024-01-02 00:25:42,762	44k	INFO	====> Epoch: 1008, cost 22.76 s
2024-01-02 00:26:04,961	44k	INFO	====> Epoch: 1009, cost 22.20 s
2024-01-02 00:26:27,266	44k	INFO	====> Epoch: 1010, cost 22.30 s
2024-01-02 00:26:49,497	44k	INFO	====> Epoch: 1011, cost 22.23 s
2024-01-02 00:27:11,760	44k	INFO	====> Epoch: 1012, cost 22.26 s
2024-01-02 00:27:34,002	44k	INFO	====> Epoch: 1013, cost 22.24 s
2024-01-02 00:27:56,281	44k	INFO	====> Epoch: 1014, cost 22.28 s
2024-01-02 00:28:18,534	44k	INFO	====> Epoch: 1015, cost 22.25 s
2024-01-02 00:28:40,965	44k	INFO	Train Epoch: 1016 [96%]
2024-01-02 00:28:40,967	44k	INFO	Losses: [2.357103109359741, 2.4386112689971924, 6.769644260406494, 15.573129653930664, 0.06462419033050537], step: 25400, lr: 8.808367858169472e-05, reference_loss: 27.203113555908203
2024-01-02 00:28:41,366	44k	INFO	====> Epoch: 1016, cost 22.83 s
2024-01-02 00:29:03,672	44k	INFO	====> Epoch: 1017, cost 22.31 s
2024-01-02 00:29:26,033	44k	INFO	====> Epoch: 1018, cost 22.36 s
2024-01-02 00:29:48,257	44k	INFO	====> Epoch: 1019, cost 22.22 s
2024-01-02 00:30:10,431	44k	INFO	====> Epoch: 1020, cost 22.17 s
2024-01-02 00:30:32,634	44k	INFO	====> Epoch: 1021, cost 22.20 s
2024-01-02 00:30:54,780	44k	INFO	====> Epoch: 1022, cost 22.15 s
2024-01-02 00:31:16,977	44k	INFO	====> Epoch: 1023, cost 22.20 s
2024-01-02 00:31:39,191	44k	INFO	Train Epoch: 1024 [96%]
2024-01-02 00:31:39,193	44k	INFO	Losses: [2.4175949096679688, 2.1719682216644287, 5.383475303649902, 14.482362747192383, 0.026804663240909576], step: 25600, lr: 8.799563343008971e-05, reference_loss: 24.482206344604492
2024-01-02 00:31:45,218	44k	INFO	Saving model and optimizer state at iteration 1024 to ./logs/44k/G_25600.pth
2024-01-02 00:31:46,146	44k	INFO	Saving model and optimizer state at iteration 1024 to ./logs/44k/D_25600.pth
2024-01-02 00:31:46,653	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_23200.pth
2024-01-02 00:31:46,692	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_23200.pth
2024-01-02 00:31:46,692	44k	INFO	====> Epoch: 1024, cost 29.72 s
2024-01-02 00:32:08,892	44k	INFO	====> Epoch: 1025, cost 22.20 s
2024-01-02 00:32:31,085	44k	INFO	====> Epoch: 1026, cost 22.19 s
2024-01-02 00:32:53,258	44k	INFO	====> Epoch: 1027, cost 22.17 s
2024-01-02 00:33:15,504	44k	INFO	====> Epoch: 1028, cost 22.25 s
2024-01-02 00:33:37,697	44k	INFO	====> Epoch: 1029, cost 22.19 s
2024-01-02 00:33:59,904	44k	INFO	====> Epoch: 1030, cost 22.21 s
2024-01-02 00:34:22,132	44k	INFO	====> Epoch: 1031, cost 22.23 s
2024-01-02 00:34:44,317	44k	INFO	Train Epoch: 1032 [96%]
2024-01-02 00:34:44,319	44k	INFO	Losses: [2.270282745361328, 2.7648544311523438, 6.9657087326049805, 16.559898376464844, 0.06357550621032715], step: 25800, lr: 8.79076762851262e-05, reference_loss: 28.62432098388672
2024-01-02 00:34:44,707	44k	INFO	====> Epoch: 1032, cost 22.58 s
2024-01-02 00:35:06,966	44k	INFO	====> Epoch: 1033, cost 22.26 s
2024-01-02 00:35:29,235	44k	INFO	====> Epoch: 1034, cost 22.27 s
2024-01-02 00:35:51,535	44k	INFO	====> Epoch: 1035, cost 22.30 s
2024-01-02 00:36:13,786	44k	INFO	====> Epoch: 1036, cost 22.25 s
2024-01-02 00:36:35,968	44k	INFO	====> Epoch: 1037, cost 22.18 s
2024-01-02 00:36:58,203	44k	INFO	====> Epoch: 1038, cost 22.24 s
2024-01-02 00:37:20,494	44k	INFO	====> Epoch: 1039, cost 22.29 s
2024-01-02 00:37:42,716	44k	INFO	Train Epoch: 1040 [96%]
2024-01-02 00:37:42,719	44k	INFO	Losses: [2.3007559776306152, 2.4990789890289307, 5.304399013519287, 14.066554069519043, 0.12410274147987366], step: 26000, lr: 8.781980705883603e-05, reference_loss: 24.294891357421875
2024-01-02 00:37:43,101	44k	INFO	====> Epoch: 1040, cost 22.61 s
2024-01-02 00:38:05,349	44k	INFO	====> Epoch: 1041, cost 22.25 s
2024-01-02 00:38:27,656	44k	INFO	====> Epoch: 1042, cost 22.31 s
2024-01-02 00:38:49,944	44k	INFO	====> Epoch: 1043, cost 22.29 s
2024-01-02 00:39:12,212	44k	INFO	====> Epoch: 1044, cost 22.27 s
2024-01-02 00:39:34,469	44k	INFO	====> Epoch: 1045, cost 22.26 s
2024-01-02 00:39:56,703	44k	INFO	====> Epoch: 1046, cost 22.23 s
2024-01-02 00:40:18,887	44k	INFO	====> Epoch: 1047, cost 22.18 s
2024-01-02 00:40:41,029	44k	INFO	Train Epoch: 1048 [96%]
2024-01-02 00:40:41,031	44k	INFO	Losses: [2.369011878967285, 2.652219295501709, 7.638265609741211, 16.757829666137695, -0.03965887054800987], step: 26200, lr: 8.773202566333896e-05, reference_loss: 29.377666473388672
2024-01-02 00:40:41,423	44k	INFO	====> Epoch: 1048, cost 22.54 s
2024-01-02 00:41:03,598	44k	INFO	====> Epoch: 1049, cost 22.17 s
2024-01-02 00:41:25,806	44k	INFO	====> Epoch: 1050, cost 22.21 s
2024-01-02 00:41:47,956	44k	INFO	====> Epoch: 1051, cost 22.15 s
2024-01-02 00:42:10,194	44k	INFO	====> Epoch: 1052, cost 22.24 s
2024-01-02 00:42:32,484	44k	INFO	====> Epoch: 1053, cost 22.29 s
2024-01-02 00:42:54,777	44k	INFO	====> Epoch: 1054, cost 22.29 s
2024-01-02 00:43:17,090	44k	INFO	====> Epoch: 1055, cost 22.31 s
2024-01-02 00:43:39,401	44k	INFO	Train Epoch: 1056 [96%]
2024-01-02 00:43:39,403	44k	INFO	Losses: [2.3757176399230957, 2.394472122192383, 5.744699001312256, 15.45205020904541, 0.03406481444835663], step: 26400, lr: 8.764433201084264e-05, reference_loss: 26.00100326538086
2024-01-02 00:43:45,226	44k	INFO	Saving model and optimizer state at iteration 1056 to ./logs/44k/G_26400.pth
2024-01-02 00:43:46,144	44k	INFO	Saving model and optimizer state at iteration 1056 to ./logs/44k/D_26400.pth
2024-01-02 00:43:46,638	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_24000.pth
2024-01-02 00:43:46,677	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_24000.pth
2024-01-02 00:43:46,677	44k	INFO	====> Epoch: 1056, cost 29.59 s
2024-01-02 00:44:08,826	44k	INFO	====> Epoch: 1057, cost 22.15 s
2024-01-02 00:44:31,034	44k	INFO	====> Epoch: 1058, cost 22.21 s
2024-01-02 00:44:53,254	44k	INFO	====> Epoch: 1059, cost 22.22 s
2024-01-02 00:45:15,494	44k	INFO	====> Epoch: 1060, cost 22.24 s
2024-01-02 00:45:37,711	44k	INFO	====> Epoch: 1061, cost 22.22 s
2024-01-02 00:45:59,984	44k	INFO	====> Epoch: 1062, cost 22.27 s
2024-01-02 00:46:22,485	44k	INFO	====> Epoch: 1063, cost 22.50 s
2024-01-02 00:46:44,738	44k	INFO	Train Epoch: 1064 [96%]
2024-01-02 00:46:44,740	44k	INFO	Losses: [2.282224655151367, 2.4422056674957275, 6.335212230682373, 15.657010078430176, 0.1322859227657318], step: 26600, lr: 8.75567260136424e-05, reference_loss: 26.84893798828125
2024-01-02 00:46:45,125	44k	INFO	====> Epoch: 1064, cost 22.64 s
2024-01-02 00:47:07,269	44k	INFO	====> Epoch: 1065, cost 22.14 s
2024-01-02 00:47:29,397	44k	INFO	====> Epoch: 1066, cost 22.13 s
2024-01-02 00:47:51,506	44k	INFO	====> Epoch: 1067, cost 22.11 s
2024-01-02 00:48:13,761	44k	INFO	====> Epoch: 1068, cost 22.26 s
2024-01-02 00:48:36,033	44k	INFO	====> Epoch: 1069, cost 22.27 s
2024-01-02 00:48:58,297	44k	INFO	====> Epoch: 1070, cost 22.26 s
2024-01-02 00:49:20,410	44k	INFO	====> Epoch: 1071, cost 22.11 s
2024-01-02 00:49:42,542	44k	INFO	Train Epoch: 1072 [96%]
2024-01-02 00:49:42,543	44k	INFO	Losses: [2.430568218231201, 2.3629729747772217, 5.083134174346924, 13.179502487182617, 0.07601740211248398], step: 26800, lr: 8.746920758412135e-05, reference_loss: 23.13219451904297
2024-01-02 00:49:43,224	44k	INFO	====> Epoch: 1072, cost 22.81 s
2024-01-02 00:50:05,386	44k	INFO	====> Epoch: 1073, cost 22.16 s
2024-01-02 00:50:27,652	44k	INFO	====> Epoch: 1074, cost 22.27 s
2024-01-02 00:50:49,877	44k	INFO	====> Epoch: 1075, cost 22.23 s
2024-01-02 00:51:12,012	44k	INFO	====> Epoch: 1076, cost 22.14 s
2024-01-02 00:51:34,184	44k	INFO	====> Epoch: 1077, cost 22.17 s
2024-01-02 00:51:56,491	44k	INFO	====> Epoch: 1078, cost 22.31 s
2024-01-02 00:52:18,784	44k	INFO	====> Epoch: 1079, cost 22.29 s
2024-01-02 00:52:41,010	44k	INFO	Train Epoch: 1080 [96%]
2024-01-02 00:52:41,012	44k	INFO	Losses: [2.354370594024658, 2.716881036758423, 7.388131141662598, 16.311017990112305, 0.012256483547389507], step: 27000, lr: 8.738177663475008e-05, reference_loss: 28.782657623291016
2024-01-02 00:52:41,499	44k	INFO	====> Epoch: 1080, cost 22.72 s
2024-01-02 00:53:03,706	44k	INFO	====> Epoch: 1081, cost 22.21 s
2024-01-02 00:53:26,059	44k	INFO	====> Epoch: 1082, cost 22.35 s
2024-01-02 00:53:48,197	44k	INFO	====> Epoch: 1083, cost 22.14 s
2024-01-02 00:54:10,461	44k	INFO	====> Epoch: 1084, cost 22.26 s
2024-01-02 00:54:32,766	44k	INFO	====> Epoch: 1085, cost 22.30 s
2024-01-02 00:54:55,069	44k	INFO	====> Epoch: 1086, cost 22.30 s
2024-01-02 00:55:17,345	44k	INFO	====> Epoch: 1087, cost 22.28 s
2024-01-02 00:55:39,634	44k	INFO	Train Epoch: 1088 [96%]
2024-01-02 00:55:39,635	44k	INFO	Losses: [2.3884265422821045, 2.2152962684631348, 5.113567352294922, 14.40018367767334, -0.07956799864768982], step: 27200, lr: 8.729443307808668e-05, reference_loss: 24.037904739379883
2024-01-02 00:55:45,555	44k	INFO	Saving model and optimizer state at iteration 1088 to ./logs/44k/G_27200.pth
2024-01-02 00:55:46,477	44k	INFO	Saving model and optimizer state at iteration 1088 to ./logs/44k/D_27200.pth
2024-01-02 00:55:46,976	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_24800.pth
2024-01-02 00:55:47,014	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_24800.pth
2024-01-02 00:55:47,015	44k	INFO	====> Epoch: 1088, cost 29.67 s
2024-01-02 00:56:09,225	44k	INFO	====> Epoch: 1089, cost 22.21 s
2024-01-02 00:56:31,630	44k	INFO	====> Epoch: 1090, cost 22.40 s
2024-01-02 00:56:53,792	44k	INFO	====> Epoch: 1091, cost 22.16 s
2024-01-02 00:57:15,876	44k	INFO	====> Epoch: 1092, cost 22.08 s
2024-01-02 00:57:37,981	44k	INFO	====> Epoch: 1093, cost 22.10 s
2024-01-02 00:58:00,200	44k	INFO	====> Epoch: 1094, cost 22.22 s
2024-01-02 00:58:22,485	44k	INFO	====> Epoch: 1095, cost 22.28 s
2024-01-02 00:58:44,685	44k	INFO	Train Epoch: 1096 [96%]
2024-01-02 00:58:44,688	44k	INFO	Losses: [2.2530899047851562, 2.6414296627044678, 7.417397499084473, 16.24454116821289, 0.12037436664104462], step: 27400, lr: 8.72071768267767e-05, reference_loss: 28.67683219909668
2024-01-02 00:58:45,082	44k	INFO	====> Epoch: 1096, cost 22.60 s
2024-01-02 00:59:07,280	44k	INFO	====> Epoch: 1097, cost 22.20 s
2024-01-02 00:59:29,494	44k	INFO	====> Epoch: 1098, cost 22.21 s
2024-01-02 00:59:51,706	44k	INFO	====> Epoch: 1099, cost 22.21 s
2024-01-02 01:00:13,985	44k	INFO	====> Epoch: 1100, cost 22.28 s
2024-01-02 01:00:36,271	44k	INFO	====> Epoch: 1101, cost 22.29 s
2024-01-02 01:00:58,767	44k	INFO	====> Epoch: 1102, cost 22.50 s
2024-01-02 01:01:20,991	44k	INFO	====> Epoch: 1103, cost 22.22 s
2024-01-02 01:01:43,240	44k	INFO	Train Epoch: 1104 [96%]
2024-01-02 01:01:43,242	44k	INFO	Losses: [2.294409990310669, 2.3694355487823486, 5.339160442352295, 12.29969596862793, 0.07329503446817398], step: 27600, lr: 8.712000779355297e-05, reference_loss: 22.37599754333496
2024-01-02 01:01:43,635	44k	INFO	====> Epoch: 1104, cost 22.64 s
2024-01-02 01:02:05,759	44k	INFO	====> Epoch: 1105, cost 22.12 s
2024-01-02 01:02:28,015	44k	INFO	====> Epoch: 1106, cost 22.26 s
2024-01-02 01:02:50,462	44k	INFO	====> Epoch: 1107, cost 22.45 s
2024-01-02 01:03:12,828	44k	INFO	====> Epoch: 1108, cost 22.37 s
2024-01-02 01:03:35,170	44k	INFO	====> Epoch: 1109, cost 22.34 s
2024-01-02 01:03:57,494	44k	INFO	====> Epoch: 1110, cost 22.32 s
2024-01-02 01:04:19,779	44k	INFO	====> Epoch: 1111, cost 22.29 s
2024-01-02 01:04:42,046	44k	INFO	Train Epoch: 1112 [96%]
2024-01-02 01:04:42,048	44k	INFO	Losses: [2.260647773742676, 2.6323070526123047, 7.8326239585876465, 15.594461441040039, 0.03493451327085495], step: 27800, lr: 8.703292589123555e-05, reference_loss: 28.3549747467041
2024-01-02 01:04:42,610	44k	INFO	====> Epoch: 1112, cost 22.83 s
2024-01-02 01:05:04,861	44k	INFO	====> Epoch: 1113, cost 22.25 s
2024-01-02 01:05:27,128	44k	INFO	====> Epoch: 1114, cost 22.27 s
2024-01-02 01:05:49,409	44k	INFO	====> Epoch: 1115, cost 22.28 s
2024-01-02 01:06:11,696	44k	INFO	====> Epoch: 1116, cost 22.29 s
2024-01-02 01:06:33,967	44k	INFO	====> Epoch: 1117, cost 22.27 s
2024-01-02 01:06:56,181	44k	INFO	====> Epoch: 1118, cost 22.21 s
2024-01-02 01:07:18,351	44k	INFO	====> Epoch: 1119, cost 22.17 s
2024-01-02 01:07:40,560	44k	INFO	Train Epoch: 1120 [96%]
2024-01-02 01:07:40,561	44k	INFO	Losses: [2.1909232139587402, 2.5019874572753906, 6.875568866729736, 15.243605613708496, -0.08656613528728485], step: 28000, lr: 8.694593103273164e-05, reference_loss: 26.72551727294922
2024-01-02 01:07:46,570	44k	INFO	Saving model and optimizer state at iteration 1120 to ./logs/44k/G_28000.pth
2024-01-02 01:07:47,472	44k	INFO	Saving model and optimizer state at iteration 1120 to ./logs/44k/D_28000.pth
2024-01-02 01:07:47,971	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_25600.pth
2024-01-02 01:07:48,009	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_25600.pth
2024-01-02 01:07:48,010	44k	INFO	====> Epoch: 1120, cost 29.66 s
2024-01-02 01:08:10,205	44k	INFO	====> Epoch: 1121, cost 22.20 s
2024-01-02 01:08:32,456	44k	INFO	====> Epoch: 1122, cost 22.25 s
2024-01-02 01:08:54,704	44k	INFO	====> Epoch: 1123, cost 22.25 s
2024-01-02 01:09:16,845	44k	INFO	====> Epoch: 1124, cost 22.14 s
2024-01-02 01:09:39,091	44k	INFO	====> Epoch: 1125, cost 22.25 s
2024-01-02 01:10:01,310	44k	INFO	====> Epoch: 1126, cost 22.22 s
2024-01-02 01:10:23,479	44k	INFO	====> Epoch: 1127, cost 22.17 s
2024-01-02 01:10:45,719	44k	INFO	Train Epoch: 1128 [96%]
2024-01-02 01:10:45,721	44k	INFO	Losses: [2.4388184547424316, 2.4467055797576904, 6.282156944274902, 15.341484069824219, 0.0767059251666069], step: 28200, lr: 8.68590231310355e-05, reference_loss: 26.58587074279785
2024-01-02 01:10:46,109	44k	INFO	====> Epoch: 1128, cost 22.63 s
2024-01-02 01:11:08,412	44k	INFO	====> Epoch: 1129, cost 22.30 s
2024-01-02 01:11:30,677	44k	INFO	====> Epoch: 1130, cost 22.26 s
2024-01-02 01:11:52,892	44k	INFO	====> Epoch: 1131, cost 22.21 s
2024-01-02 01:12:15,406	44k	INFO	====> Epoch: 1132, cost 22.51 s
2024-01-02 01:12:37,727	44k	INFO	====> Epoch: 1133, cost 22.32 s
2024-01-02 01:12:59,965	44k	INFO	====> Epoch: 1134, cost 22.24 s
2024-01-02 01:13:22,281	44k	INFO	====> Epoch: 1135, cost 22.32 s
2024-01-02 01:13:44,477	44k	INFO	Train Epoch: 1136 [96%]
2024-01-02 01:13:44,479	44k	INFO	Losses: [2.3062615394592285, 2.1925461292266846, 5.4383978843688965, 12.248144149780273, 0.030893735587596893], step: 28400, lr: 8.677220209922833e-05, reference_loss: 22.216243743896484
2024-01-02 01:13:44,951	44k	INFO	====> Epoch: 1136, cost 22.67 s
2024-01-02 01:14:07,155	44k	INFO	====> Epoch: 1137, cost 22.20 s
2024-01-02 01:14:29,240	44k	INFO	====> Epoch: 1138, cost 22.09 s
2024-01-02 01:14:51,296	44k	INFO	====> Epoch: 1139, cost 22.06 s
2024-01-02 01:15:13,370	44k	INFO	====> Epoch: 1140, cost 22.07 s
2024-01-02 01:15:35,422	44k	INFO	====> Epoch: 1141, cost 22.05 s
2024-01-02 01:15:57,637	44k	INFO	====> Epoch: 1142, cost 22.22 s
2024-01-02 01:16:19,862	44k	INFO	====> Epoch: 1143, cost 22.22 s
2024-01-02 01:16:41,993	44k	INFO	Train Epoch: 1144 [96%]
2024-01-02 01:16:41,995	44k	INFO	Losses: [2.3264060020446777, 2.6674752235412598, 7.842709541320801, 15.56420612335205, -0.07677924633026123], step: 28600, lr: 8.668546785047828e-05, reference_loss: 28.324018478393555
2024-01-02 01:16:42,490	44k	INFO	====> Epoch: 1144, cost 22.63 s
2024-01-02 01:17:04,677	44k	INFO	====> Epoch: 1145, cost 22.19 s
2024-01-02 01:17:26,952	44k	INFO	====> Epoch: 1146, cost 22.28 s
2024-01-02 01:17:49,277	44k	INFO	====> Epoch: 1147, cost 22.32 s
2024-01-02 01:18:11,560	44k	INFO	====> Epoch: 1148, cost 22.28 s
2024-01-02 01:18:33,691	44k	INFO	====> Epoch: 1149, cost 22.13 s
2024-01-02 01:18:55,779	44k	INFO	====> Epoch: 1150, cost 22.09 s
2024-01-02 01:19:17,920	44k	INFO	====> Epoch: 1151, cost 22.14 s
2024-01-02 01:19:40,132	44k	INFO	Train Epoch: 1152 [96%]
2024-01-02 01:19:40,134	44k	INFO	Losses: [2.3109748363494873, 2.3444066047668457, 5.699524879455566, 14.955912590026855, -0.13414910435676575], step: 28800, lr: 8.659882029804021e-05, reference_loss: 25.176668167114258
2024-01-02 01:19:46,059	44k	INFO	Saving model and optimizer state at iteration 1152 to ./logs/44k/G_28800.pth
2024-01-02 01:19:46,963	44k	INFO	Saving model and optimizer state at iteration 1152 to ./logs/44k/D_28800.pth
2024-01-02 01:19:47,464	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_26400.pth
2024-01-02 01:19:47,502	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_26400.pth
2024-01-02 01:19:47,503	44k	INFO	====> Epoch: 1152, cost 29.58 s
2024-01-02 01:20:09,692	44k	INFO	====> Epoch: 1153, cost 22.19 s
2024-01-02 01:20:31,744	44k	INFO	====> Epoch: 1154, cost 22.05 s
2024-01-02 01:20:53,844	44k	INFO	====> Epoch: 1155, cost 22.10 s
2024-01-02 01:21:16,069	44k	INFO	====> Epoch: 1156, cost 22.22 s
2024-01-02 01:21:38,274	44k	INFO	====> Epoch: 1157, cost 22.21 s
2024-01-02 01:22:00,485	44k	INFO	====> Epoch: 1158, cost 22.21 s
2024-01-02 01:22:22,895	44k	INFO	====> Epoch: 1159, cost 22.41 s
2024-01-02 01:22:45,142	44k	INFO	Train Epoch: 1160 [96%]
2024-01-02 01:22:45,144	44k	INFO	Losses: [2.415947914123535, 2.4682421684265137, 6.3148698806762695, 15.739219665527344, -0.026178011670708656], step: 29000, lr: 8.651225935525575e-05, reference_loss: 26.91210174560547
2024-01-02 01:22:45,529	44k	INFO	====> Epoch: 1160, cost 22.63 s
2024-01-02 01:23:07,615	44k	INFO	====> Epoch: 1161, cost 22.09 s
2024-01-02 01:23:29,691	44k	INFO	====> Epoch: 1162, cost 22.08 s
2024-01-02 01:23:51,896	44k	INFO	====> Epoch: 1163, cost 22.20 s
2024-01-02 01:24:14,067	44k	INFO	====> Epoch: 1164, cost 22.17 s
2024-01-02 01:24:36,235	44k	INFO	====> Epoch: 1165, cost 22.17 s
2024-01-02 01:24:58,434	44k	INFO	====> Epoch: 1166, cost 22.20 s
2024-01-02 01:25:20,657	44k	INFO	====> Epoch: 1167, cost 22.22 s
2024-01-02 01:25:42,802	44k	INFO	Train Epoch: 1168 [96%]
2024-01-02 01:25:42,804	44k	INFO	Losses: [2.2348310947418213, 2.4179673194885254, 5.348137855529785, 12.840091705322266, 0.07812224328517914], step: 29200, lr: 8.642578493555313e-05, reference_loss: 22.919151306152344
2024-01-02 01:25:43,376	44k	INFO	====> Epoch: 1168, cost 22.72 s
2024-01-02 01:26:05,460	44k	INFO	====> Epoch: 1169, cost 22.08 s
2024-01-02 01:26:27,593	44k	INFO	====> Epoch: 1170, cost 22.13 s
2024-01-02 01:26:49,765	44k	INFO	====> Epoch: 1171, cost 22.17 s
2024-01-02 01:27:11,854	44k	INFO	====> Epoch: 1172, cost 22.09 s
2024-01-02 01:27:33,948	44k	INFO	====> Epoch: 1173, cost 22.09 s
2024-01-02 01:27:56,045	44k	INFO	====> Epoch: 1174, cost 22.10 s
2024-01-02 01:28:18,153	44k	INFO	====> Epoch: 1175, cost 22.11 s
2024-01-02 01:28:40,252	44k	INFO	Train Epoch: 1176 [96%]
2024-01-02 01:28:40,254	44k	INFO	Losses: [2.0784730911254883, 2.5475270748138428, 7.298972129821777, 14.627649307250977, -0.14825530350208282], step: 29400, lr: 8.633939695244714e-05, reference_loss: 26.404367446899414
2024-01-02 01:28:40,644	44k	INFO	====> Epoch: 1176, cost 22.49 s
2024-01-02 01:29:02,746	44k	INFO	====> Epoch: 1177, cost 22.10 s
2024-01-02 01:29:25,055	44k	INFO	====> Epoch: 1178, cost 22.31 s
2024-01-02 01:29:47,190	44k	INFO	====> Epoch: 1179, cost 22.14 s
2024-01-02 01:30:09,324	44k	INFO	====> Epoch: 1180, cost 22.13 s
2024-01-02 01:30:31,535	44k	INFO	====> Epoch: 1181, cost 22.21 s
2024-01-02 01:30:53,766	44k	INFO	====> Epoch: 1182, cost 22.23 s
2024-01-02 01:31:15,890	44k	INFO	====> Epoch: 1183, cost 22.12 s
2024-01-02 01:31:38,050	44k	INFO	Train Epoch: 1184 [96%]
2024-01-02 01:31:38,052	44k	INFO	Losses: [2.275089740753174, 2.6777257919311523, 6.045589447021484, 14.110871315002441, -0.0944722592830658], step: 29600, lr: 8.625309531953894e-05, reference_loss: 25.014802932739258
2024-01-02 01:31:43,991	44k	INFO	Saving model and optimizer state at iteration 1184 to ./logs/44k/G_29600.pth
2024-01-02 01:31:44,910	44k	INFO	Saving model and optimizer state at iteration 1184 to ./logs/44k/D_29600.pth
2024-01-02 01:31:45,418	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_27200.pth
2024-01-02 01:31:45,457	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_27200.pth
2024-01-02 01:31:45,457	44k	INFO	====> Epoch: 1184, cost 29.57 s
2024-01-02 01:32:07,664	44k	INFO	====> Epoch: 1185, cost 22.21 s
2024-01-02 01:32:30,083	44k	INFO	====> Epoch: 1186, cost 22.42 s
2024-01-02 01:32:52,275	44k	INFO	====> Epoch: 1187, cost 22.19 s
2024-01-02 01:33:14,444	44k	INFO	====> Epoch: 1188, cost 22.17 s
2024-01-02 01:33:36,516	44k	INFO	====> Epoch: 1189, cost 22.07 s
2024-01-02 01:33:58,595	44k	INFO	====> Epoch: 1190, cost 22.08 s
2024-01-02 01:34:20,686	44k	INFO	====> Epoch: 1191, cost 22.09 s
2024-01-02 01:34:42,777	44k	INFO	Train Epoch: 1192 [96%]
2024-01-02 01:34:42,779	44k	INFO	Losses: [2.138792037963867, 2.8255510330200195, 7.959780216217041, 16.16680335998535, -0.06196305528283119], step: 29800, lr: 8.616687995051611e-05, reference_loss: 29.02896499633789
2024-01-02 01:34:43,261	44k	INFO	====> Epoch: 1192, cost 22.58 s
2024-01-02 01:35:05,379	44k	INFO	====> Epoch: 1193, cost 22.12 s
2024-01-02 01:35:27,563	44k	INFO	====> Epoch: 1194, cost 22.18 s
2024-01-02 01:35:49,689	44k	INFO	====> Epoch: 1195, cost 22.13 s
2024-01-02 01:36:11,838	44k	INFO	====> Epoch: 1196, cost 22.15 s
2024-01-02 01:36:33,957	44k	INFO	====> Epoch: 1197, cost 22.12 s
2024-01-02 01:36:56,256	44k	INFO	====> Epoch: 1198, cost 22.30 s
2024-01-02 01:37:18,365	44k	INFO	====> Epoch: 1199, cost 22.11 s
2024-01-02 01:37:40,432	44k	INFO	Train Epoch: 1200 [96%]
2024-01-02 01:37:40,434	44k	INFO	Losses: [2.3112895488739014, 2.671860933303833, 5.398702621459961, 13.732272148132324, -0.007474921643733978], step: 30000, lr: 8.608075075915251e-05, reference_loss: 24.10664939880371
2024-01-02 01:37:40,911	44k	INFO	====> Epoch: 1200, cost 22.55 s
2024-01-02 01:38:02,996	44k	INFO	====> Epoch: 1201, cost 22.08 s
2024-01-02 01:38:25,159	44k	INFO	====> Epoch: 1202, cost 22.16 s
2024-01-02 01:38:47,374	44k	INFO	====> Epoch: 1203, cost 22.22 s
2024-01-02 01:39:09,632	44k	INFO	====> Epoch: 1204, cost 22.26 s
2024-01-02 01:39:31,939	44k	INFO	====> Epoch: 1205, cost 22.31 s
2024-01-02 01:39:54,233	44k	INFO	====> Epoch: 1206, cost 22.29 s
2024-01-02 01:40:16,453	44k	INFO	====> Epoch: 1207, cost 22.22 s
2024-01-02 01:40:38,619	44k	INFO	Train Epoch: 1208 [96%]
2024-01-02 01:40:38,621	44k	INFO	Losses: [2.2908148765563965, 2.6960904598236084, 6.9886345863342285, 14.886117935180664, -0.13449299335479736], step: 30200, lr: 8.599470765930816e-05, reference_loss: 26.72716522216797
2024-01-02 01:40:39,277	44k	INFO	====> Epoch: 1208, cost 22.82 s
2024-01-02 01:41:01,521	44k	INFO	====> Epoch: 1209, cost 22.24 s
2024-01-02 01:41:23,742	44k	INFO	====> Epoch: 1210, cost 22.22 s
2024-01-02 01:41:45,969	44k	INFO	====> Epoch: 1211, cost 22.23 s
2024-01-02 01:42:08,183	44k	INFO	====> Epoch: 1212, cost 22.21 s
2024-01-02 01:42:30,345	44k	INFO	====> Epoch: 1213, cost 22.16 s
2024-01-02 01:42:52,525	44k	INFO	====> Epoch: 1214, cost 22.18 s
2024-01-02 01:43:14,787	44k	INFO	====> Epoch: 1215, cost 22.26 s
2024-01-02 01:43:37,025	44k	INFO	Train Epoch: 1216 [96%]
2024-01-02 01:43:37,027	44k	INFO	Losses: [2.4249958992004395, 2.1971030235290527, 6.22315788269043, 15.009048461914062, -0.17619670927524567], step: 30400, lr: 8.590875056492924e-05, reference_loss: 25.67810821533203
2024-01-02 01:43:43,099	44k	INFO	Saving model and optimizer state at iteration 1216 to ./logs/44k/G_30400.pth
2024-01-02 01:43:43,999	44k	INFO	Saving model and optimizer state at iteration 1216 to ./logs/44k/D_30400.pth
2024-01-02 01:43:44,500	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_28000.pth
2024-01-02 01:43:44,539	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_28000.pth
2024-01-02 01:43:44,539	44k	INFO	====> Epoch: 1216, cost 29.75 s
2024-01-02 01:44:06,665	44k	INFO	====> Epoch: 1217, cost 22.13 s
2024-01-02 01:44:28,855	44k	INFO	====> Epoch: 1218, cost 22.19 s
2024-01-02 01:44:51,058	44k	INFO	====> Epoch: 1219, cost 22.20 s
2024-01-02 01:45:13,307	44k	INFO	====> Epoch: 1220, cost 22.25 s
2024-01-02 01:45:35,469	44k	INFO	====> Epoch: 1221, cost 22.16 s
2024-01-02 01:45:57,661	44k	INFO	====> Epoch: 1222, cost 22.19 s
2024-01-02 01:46:19,863	44k	INFO	====> Epoch: 1223, cost 22.20 s
2024-01-02 01:46:42,073	44k	INFO	Train Epoch: 1224 [96%]
2024-01-02 01:46:42,075	44k	INFO	Losses: [2.2814371585845947, 2.5649607181549072, 7.347782135009766, 16.28094482421875, -0.020067069679498672], step: 30600, lr: 8.582287939004785e-05, reference_loss: 28.45505714416504
2024-01-02 01:46:42,553	44k	INFO	====> Epoch: 1224, cost 22.69 s
2024-01-02 01:47:04,771	44k	INFO	====> Epoch: 1225, cost 22.22 s
2024-01-02 01:47:26,925	44k	INFO	====> Epoch: 1226, cost 22.15 s
2024-01-02 01:47:49,187	44k	INFO	====> Epoch: 1227, cost 22.26 s
2024-01-02 01:48:11,578	44k	INFO	====> Epoch: 1228, cost 22.39 s
2024-01-02 01:48:33,819	44k	INFO	====> Epoch: 1229, cost 22.24 s
2024-01-02 01:48:56,004	44k	INFO	====> Epoch: 1230, cost 22.19 s
2024-01-02 01:49:18,089	44k	INFO	====> Epoch: 1231, cost 22.08 s
2024-01-02 01:49:40,199	44k	INFO	Train Epoch: 1232 [96%]
2024-01-02 01:49:40,201	44k	INFO	Losses: [2.1891720294952393, 2.3843283653259277, 5.74537467956543, 13.196669578552246, -0.012719319202005863], step: 30800, lr: 8.573709404878208e-05, reference_loss: 23.502824783325195
2024-01-02 01:49:40,673	44k	INFO	====> Epoch: 1232, cost 22.58 s
2024-01-02 01:50:02,787	44k	INFO	====> Epoch: 1233, cost 22.11 s
2024-01-02 01:50:24,890	44k	INFO	====> Epoch: 1234, cost 22.10 s
2024-01-02 01:50:47,120	44k	INFO	====> Epoch: 1235, cost 22.23 s
2024-01-02 01:51:09,413	44k	INFO	====> Epoch: 1236, cost 22.29 s
2024-01-02 01:51:31,652	44k	INFO	====> Epoch: 1237, cost 22.24 s
2024-01-02 01:51:53,981	44k	INFO	====> Epoch: 1238, cost 22.33 s
2024-01-02 01:52:16,275	44k	INFO	====> Epoch: 1239, cost 22.29 s
2024-01-02 01:52:38,596	44k	INFO	Train Epoch: 1240 [96%]
2024-01-02 01:52:38,598	44k	INFO	Losses: [2.253628969192505, 2.5029029846191406, 8.270574569702148, 15.522242546081543, -0.051589347422122955], step: 31000, lr: 8.565139445533588e-05, reference_loss: 28.497758865356445
2024-01-02 01:52:38,986	44k	INFO	====> Epoch: 1240, cost 22.71 s
2024-01-02 01:53:01,149	44k	INFO	====> Epoch: 1241, cost 22.16 s
2024-01-02 01:53:23,296	44k	INFO	====> Epoch: 1242, cost 22.15 s
2024-01-02 01:53:45,428	44k	INFO	====> Epoch: 1243, cost 22.13 s
2024-01-02 01:54:07,575	44k	INFO	====> Epoch: 1244, cost 22.15 s
2024-01-02 01:54:29,702	44k	INFO	====> Epoch: 1245, cost 22.13 s
2024-01-02 01:54:51,800	44k	INFO	====> Epoch: 1246, cost 22.10 s
2024-01-02 01:55:13,890	44k	INFO	====> Epoch: 1247, cost 22.09 s
2024-01-02 01:55:36,169	44k	INFO	Train Epoch: 1248 [96%]
2024-01-02 01:55:36,171	44k	INFO	Losses: [2.2661631107330322, 2.4015088081359863, 5.8661208152771, 13.939177513122559, -0.1855139136314392], step: 31200, lr: 8.556578052399892e-05, reference_loss: 24.28745460510254
2024-01-02 01:55:41,999	44k	INFO	Saving model and optimizer state at iteration 1248 to ./logs/44k/G_31200.pth
2024-01-02 01:55:42,918	44k	INFO	Saving model and optimizer state at iteration 1248 to ./logs/44k/D_31200.pth
2024-01-02 01:55:43,419	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_28800.pth
2024-01-02 01:55:43,458	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_28800.pth
2024-01-02 01:55:43,459	44k	INFO	====> Epoch: 1248, cost 29.57 s
2024-01-02 01:56:05,765	44k	INFO	====> Epoch: 1249, cost 22.31 s
2024-01-02 01:56:28,019	44k	INFO	====> Epoch: 1250, cost 22.25 s
2024-01-02 01:56:50,147	44k	INFO	====> Epoch: 1251, cost 22.13 s
2024-01-02 01:57:12,231	44k	INFO	====> Epoch: 1252, cost 22.08 s
2024-01-02 01:57:34,313	44k	INFO	====> Epoch: 1253, cost 22.08 s
2024-01-02 01:57:56,387	44k	INFO	====> Epoch: 1254, cost 22.07 s
2024-01-02 01:58:18,701	44k	INFO	====> Epoch: 1255, cost 22.31 s
2024-01-02 01:58:40,909	44k	INFO	Train Epoch: 1256 [96%]
2024-01-02 01:58:40,912	44k	INFO	Losses: [2.354144811630249, 2.611079216003418, 7.186385154724121, 16.566255569458008, -0.11359624564647675], step: 31400, lr: 8.548025216914657e-05, reference_loss: 28.60426902770996
2024-01-02 01:58:41,303	44k	INFO	====> Epoch: 1256, cost 22.60 s
2024-01-02 01:59:03,401	44k	INFO	====> Epoch: 1257, cost 22.10 s
2024-01-02 01:59:25,520	44k	INFO	====> Epoch: 1258, cost 22.12 s
2024-01-02 01:59:47,785	44k	INFO	====> Epoch: 1259, cost 22.26 s
2024-01-02 02:00:09,926	44k	INFO	====> Epoch: 1260, cost 22.14 s
2024-01-02 02:00:32,076	44k	INFO	====> Epoch: 1261, cost 22.15 s
2024-01-02 02:00:54,234	44k	INFO	====> Epoch: 1262, cost 22.16 s
2024-01-02 02:01:16,493	44k	INFO	====> Epoch: 1263, cost 22.26 s
2024-01-02 02:01:38,734	44k	INFO	Train Epoch: 1264 [96%]
2024-01-02 02:01:38,736	44k	INFO	Losses: [2.134958267211914, 2.582702159881592, 6.45656681060791, 14.115314483642578, -0.06416177749633789], step: 31600, lr: 8.539480930523977e-05, reference_loss: 25.225379943847656
2024-01-02 02:01:39,313	44k	INFO	====> Epoch: 1264, cost 22.82 s
2024-01-02 02:02:01,481	44k	INFO	====> Epoch: 1265, cost 22.17 s
2024-01-02 02:02:23,685	44k	INFO	====> Epoch: 1266, cost 22.20 s
2024-01-02 02:02:45,902	44k	INFO	====> Epoch: 1267, cost 22.22 s
2024-01-02 02:03:07,992	44k	INFO	====> Epoch: 1268, cost 22.09 s
2024-01-02 02:03:30,096	44k	INFO	====> Epoch: 1269, cost 22.10 s
2024-01-02 02:03:52,302	44k	INFO	====> Epoch: 1270, cost 22.21 s
2024-01-02 02:04:14,478	44k	INFO	====> Epoch: 1271, cost 22.18 s
2024-01-02 02:04:36,564	44k	INFO	Train Epoch: 1272 [96%]
2024-01-02 02:04:36,566	44k	INFO	Losses: [2.2641866207122803, 2.7169406414031982, 8.22113037109375, 16.145610809326172, -0.21956080198287964], step: 31800, lr: 8.530945184682498e-05, reference_loss: 29.128307342529297
2024-01-02 02:04:36,953	44k	INFO	====> Epoch: 1272, cost 22.47 s
2024-01-02 02:04:59,053	44k	INFO	====> Epoch: 1273, cost 22.10 s
2024-01-02 02:05:21,453	44k	INFO	====> Epoch: 1274, cost 22.40 s
2024-01-02 02:05:43,619	44k	INFO	====> Epoch: 1275, cost 22.17 s
2024-01-02 02:06:05,865	44k	INFO	====> Epoch: 1276, cost 22.25 s
2024-01-02 02:06:28,184	44k	INFO	====> Epoch: 1277, cost 22.32 s
2024-01-02 02:06:50,500	44k	INFO	====> Epoch: 1278, cost 22.32 s
2024-01-02 02:07:12,822	44k	INFO	====> Epoch: 1279, cost 22.32 s
2024-01-02 02:07:35,107	44k	INFO	Train Epoch: 1280 [96%]
2024-01-02 02:07:35,109	44k	INFO	Losses: [2.4079108238220215, 2.3099782466888428, 5.193291187286377, 13.431218147277832, -0.23210620880126953], step: 32000, lr: 8.522417970853403e-05, reference_loss: 23.110294342041016
2024-01-02 02:07:40,924	44k	INFO	Saving model and optimizer state at iteration 1280 to ./logs/44k/G_32000.pth
2024-01-02 02:07:41,845	44k	INFO	Saving model and optimizer state at iteration 1280 to ./logs/44k/D_32000.pth
2024-01-02 02:07:42,344	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_29600.pth
2024-01-02 02:07:42,383	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_29600.pth
2024-01-02 02:07:42,384	44k	INFO	====> Epoch: 1280, cost 29.56 s
2024-01-02 02:08:04,546	44k	INFO	====> Epoch: 1281, cost 22.16 s
2024-01-02 02:08:26,953	44k	INFO	====> Epoch: 1282, cost 22.41 s
2024-01-02 02:08:49,170	44k	INFO	====> Epoch: 1283, cost 22.22 s
2024-01-02 02:09:11,389	44k	INFO	====> Epoch: 1284, cost 22.22 s
2024-01-02 02:09:33,627	44k	INFO	====> Epoch: 1285, cost 22.24 s
2024-01-02 02:09:55,887	44k	INFO	====> Epoch: 1286, cost 22.26 s
2024-01-02 02:10:18,181	44k	INFO	====> Epoch: 1287, cost 22.29 s
2024-01-02 02:10:40,480	44k	INFO	Train Epoch: 1288 [96%]
2024-01-02 02:10:40,482	44k	INFO	Losses: [2.2799124717712402, 2.5760130882263184, 7.053501605987549, 15.729764938354492, -0.06655246019363403], step: 32200, lr: 8.513899280508415e-05, reference_loss: 27.57263946533203
2024-01-02 02:10:40,872	44k	INFO	====> Epoch: 1288, cost 22.69 s
2024-01-02 02:11:03,127	44k	INFO	====> Epoch: 1289, cost 22.26 s
2024-01-02 02:11:25,273	44k	INFO	====> Epoch: 1290, cost 22.15 s
2024-01-02 02:11:47,390	44k	INFO	====> Epoch: 1291, cost 22.12 s
2024-01-02 02:12:09,518	44k	INFO	====> Epoch: 1292, cost 22.13 s
2024-01-02 02:12:31,574	44k	INFO	====> Epoch: 1293, cost 22.06 s
2024-01-02 02:12:53,816	44k	INFO	====> Epoch: 1294, cost 22.24 s
2024-01-02 02:13:15,891	44k	INFO	====> Epoch: 1295, cost 22.08 s
2024-01-02 02:13:37,968	44k	INFO	Train Epoch: 1296 [96%]
2024-01-02 02:13:37,970	44k	INFO	Losses: [2.189337730407715, 2.705230236053467, 5.738959312438965, 13.403366088867188, -0.06140657514333725], step: 32400, lr: 8.505389105127777e-05, reference_loss: 23.975486755371094
2024-01-02 02:13:38,457	44k	INFO	====> Epoch: 1296, cost 22.57 s
2024-01-02 02:14:00,555	44k	INFO	====> Epoch: 1297, cost 22.10 s
2024-01-02 02:14:22,654	44k	INFO	====> Epoch: 1298, cost 22.10 s
2024-01-02 02:14:44,727	44k	INFO	====> Epoch: 1299, cost 22.07 s
2024-01-02 02:15:06,829	44k	INFO	====> Epoch: 1300, cost 22.10 s
2024-01-02 02:15:28,904	44k	INFO	====> Epoch: 1301, cost 22.08 s
2024-01-02 02:15:50,975	44k	INFO	====> Epoch: 1302, cost 22.07 s
2024-01-02 02:16:13,174	44k	INFO	====> Epoch: 1303, cost 22.20 s
2024-01-02 02:16:35,537	44k	INFO	Train Epoch: 1304 [96%]
2024-01-02 02:16:35,539	44k	INFO	Losses: [2.330566167831421, 2.549192428588867, 7.266494274139404, 14.580452919006348, -0.19802984595298767], step: 32600, lr: 8.49688743620025e-05, reference_loss: 26.528676986694336
2024-01-02 02:16:35,917	44k	INFO	====> Epoch: 1304, cost 22.74 s
2024-01-02 02:16:58,136	44k	INFO	====> Epoch: 1305, cost 22.22 s
2024-01-02 02:17:20,394	44k	INFO	====> Epoch: 1306, cost 22.26 s
2024-01-02 02:17:42,651	44k	INFO	====> Epoch: 1307, cost 22.26 s
2024-01-02 02:18:04,919	44k	INFO	====> Epoch: 1308, cost 22.27 s
2024-01-02 02:18:27,130	44k	INFO	====> Epoch: 1309, cost 22.21 s
2024-01-02 02:18:49,280	44k	INFO	====> Epoch: 1310, cost 22.15 s
2024-01-02 02:19:11,437	44k	INFO	====> Epoch: 1311, cost 22.16 s
2024-01-02 02:19:33,636	44k	INFO	Train Epoch: 1312 [96%]
2024-01-02 02:19:33,637	44k	INFO	Losses: [2.295692205429077, 2.3130898475646973, 6.4608540534973145, 14.512635231018066, -0.2304227650165558], step: 32800, lr: 8.488394265223098e-05, reference_loss: 25.351848602294922
2024-01-02 02:19:39,800	44k	INFO	Saving model and optimizer state at iteration 1312 to ./logs/44k/G_32800.pth
2024-01-02 02:19:40,705	44k	INFO	Saving model and optimizer state at iteration 1312 to ./logs/44k/D_32800.pth
2024-01-02 02:19:41,216	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_30400.pth
2024-01-02 02:19:41,255	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_30400.pth
2024-01-02 02:19:41,255	44k	INFO	====> Epoch: 1312, cost 29.82 s
2024-01-02 02:20:03,402	44k	INFO	====> Epoch: 1313, cost 22.15 s
2024-01-02 02:20:25,603	44k	INFO	====> Epoch: 1314, cost 22.20 s
2024-01-02 02:20:47,800	44k	INFO	====> Epoch: 1315, cost 22.20 s
2024-01-02 02:21:09,961	44k	INFO	====> Epoch: 1316, cost 22.16 s
2024-01-02 02:21:32,162	44k	INFO	====> Epoch: 1317, cost 22.20 s
2024-01-02 02:21:54,413	44k	INFO	====> Epoch: 1318, cost 22.25 s
2024-01-02 02:22:16,679	44k	INFO	====> Epoch: 1319, cost 22.27 s
2024-01-02 02:22:38,975	44k	INFO	Train Epoch: 1320 [96%]
2024-01-02 02:22:38,977	44k	INFO	Losses: [2.279475688934326, 2.685194492340088, 7.369451999664307, 15.609410285949707, -0.12372477352619171], step: 33000, lr: 8.479909583702088e-05, reference_loss: 27.819807052612305
2024-01-02 02:22:39,461	44k	INFO	====> Epoch: 1320, cost 22.78 s
2024-01-02 02:23:01,724	44k	INFO	====> Epoch: 1321, cost 22.26 s
2024-01-02 02:23:23,982	44k	INFO	====> Epoch: 1322, cost 22.26 s
2024-01-02 02:23:46,279	44k	INFO	====> Epoch: 1323, cost 22.30 s
2024-01-02 02:24:08,688	44k	INFO	====> Epoch: 1324, cost 22.41 s
2024-01-02 02:24:30,981	44k	INFO	====> Epoch: 1325, cost 22.29 s
2024-01-02 02:24:53,173	44k	INFO	====> Epoch: 1326, cost 22.19 s
2024-01-02 02:25:15,321	44k	INFO	====> Epoch: 1327, cost 22.15 s
2024-01-02 02:25:37,473	44k	INFO	Train Epoch: 1328 [96%]
2024-01-02 02:25:37,475	44k	INFO	Losses: [2.46514892578125, 2.4238080978393555, 6.210042476654053, 14.447269439697266, -0.13807065784931183], step: 33200, lr: 8.47143338315148e-05, reference_loss: 25.4081974029541
2024-01-02 02:25:37,950	44k	INFO	====> Epoch: 1328, cost 22.63 s
2024-01-02 02:26:00,165	44k	INFO	====> Epoch: 1329, cost 22.22 s
2024-01-02 02:26:22,448	44k	INFO	====> Epoch: 1330, cost 22.28 s
2024-01-02 02:26:44,631	44k	INFO	====> Epoch: 1331, cost 22.18 s
2024-01-02 02:27:06,857	44k	INFO	====> Epoch: 1332, cost 22.23 s
2024-01-02 02:27:29,080	44k	INFO	====> Epoch: 1333, cost 22.22 s
2024-01-02 02:27:51,461	44k	INFO	====> Epoch: 1334, cost 22.38 s
2024-01-02 02:28:13,553	44k	INFO	====> Epoch: 1335, cost 22.09 s
2024-01-02 02:28:35,634	44k	INFO	Train Epoch: 1336 [96%]
2024-01-02 02:28:35,636	44k	INFO	Losses: [2.139819383621216, 2.602120876312256, 7.419651031494141, 14.56498908996582, -0.24723480641841888], step: 33400, lr: 8.462965655094014e-05, reference_loss: 26.479347229003906
2024-01-02 02:28:36,105	44k	INFO	====> Epoch: 1336, cost 22.55 s
2024-01-02 02:28:58,245	44k	INFO	====> Epoch: 1337, cost 22.14 s
2024-01-02 02:29:20,368	44k	INFO	====> Epoch: 1338, cost 22.12 s
2024-01-02 02:29:42,519	44k	INFO	====> Epoch: 1339, cost 22.15 s
2024-01-02 02:30:04,738	44k	INFO	====> Epoch: 1340, cost 22.22 s
2024-01-02 02:30:26,961	44k	INFO	====> Epoch: 1341, cost 22.22 s
2024-01-02 02:30:49,196	44k	INFO	====> Epoch: 1342, cost 22.24 s
2024-01-02 02:31:11,405	44k	INFO	====> Epoch: 1343, cost 22.21 s
2024-01-02 02:31:33,784	44k	INFO	Train Epoch: 1344 [96%]
2024-01-02 02:31:33,786	44k	INFO	Losses: [2.3302786350250244, 2.410452365875244, 6.23328971862793, 14.442340850830078, -0.21897652745246887], step: 33600, lr: 8.454506391060898e-05, reference_loss: 25.197385787963867
2024-01-02 02:31:39,825	44k	INFO	Saving model and optimizer state at iteration 1344 to ./logs/44k/G_33600.pth
2024-01-02 02:31:40,756	44k	INFO	Saving model and optimizer state at iteration 1344 to ./logs/44k/D_33600.pth
2024-01-02 02:31:41,257	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_31200.pth
2024-01-02 02:31:41,297	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_31200.pth
2024-01-02 02:31:41,297	44k	INFO	====> Epoch: 1344, cost 29.89 s
2024-01-02 02:32:03,411	44k	INFO	====> Epoch: 1345, cost 22.11 s
2024-01-02 02:32:25,615	44k	INFO	====> Epoch: 1346, cost 22.20 s
2024-01-02 02:32:47,796	44k	INFO	====> Epoch: 1347, cost 22.18 s
2024-01-02 02:33:09,997	44k	INFO	====> Epoch: 1348, cost 22.20 s
2024-01-02 02:33:32,207	44k	INFO	====> Epoch: 1349, cost 22.21 s
2024-01-02 02:33:54,335	44k	INFO	====> Epoch: 1350, cost 22.13 s
2024-01-02 02:34:16,739	44k	INFO	====> Epoch: 1351, cost 22.40 s
2024-01-02 02:34:38,858	44k	INFO	Train Epoch: 1352 [96%]
2024-01-02 02:34:38,860	44k	INFO	Losses: [2.0645902156829834, 2.7181875705718994, 8.15857982635498, 16.085254669189453, -0.1969984918832779], step: 33800, lr: 8.446055582591813e-05, reference_loss: 28.829612731933594
2024-01-02 02:34:39,250	44k	INFO	====> Epoch: 1352, cost 22.51 s
2024-01-02 02:35:01,530	44k	INFO	====> Epoch: 1353, cost 22.28 s
2024-01-02 02:35:23,805	44k	INFO	====> Epoch: 1354, cost 22.28 s
2024-01-02 02:35:46,069	44k	INFO	====> Epoch: 1355, cost 22.26 s
2024-01-02 02:36:08,327	44k	INFO	====> Epoch: 1356, cost 22.26 s
2024-01-02 02:36:30,593	44k	INFO	====> Epoch: 1357, cost 22.27 s
2024-01-02 02:36:52,833	44k	INFO	====> Epoch: 1358, cost 22.24 s
2024-01-02 02:37:14,958	44k	INFO	====> Epoch: 1359, cost 22.12 s
2024-01-02 02:37:37,158	44k	INFO	Train Epoch: 1360 [96%]
2024-01-02 02:37:37,159	44k	INFO	Losses: [2.2844252586364746, 2.4943575859069824, 5.390321254730225, 12.875131607055664, -0.1754850596189499], step: 34000, lr: 8.437613221234893e-05, reference_loss: 22.868749618530273
2024-01-02 02:37:37,726	44k	INFO	====> Epoch: 1360, cost 22.77 s
2024-01-02 02:37:59,964	44k	INFO	====> Epoch: 1361, cost 22.24 s
2024-01-02 02:38:22,174	44k	INFO	====> Epoch: 1362, cost 22.21 s
2024-01-02 02:38:44,309	44k	INFO	====> Epoch: 1363, cost 22.13 s
2024-01-02 02:39:06,467	44k	INFO	====> Epoch: 1364, cost 22.16 s
2024-01-02 02:39:28,591	44k	INFO	====> Epoch: 1365, cost 22.12 s
2024-01-02 02:39:50,750	44k	INFO	====> Epoch: 1366, cost 22.16 s
2024-01-02 02:40:12,938	44k	INFO	====> Epoch: 1367, cost 22.19 s
2024-01-02 02:40:35,207	44k	INFO	Train Epoch: 1368 [96%]
2024-01-02 02:40:35,209	44k	INFO	Losses: [2.0511832237243652, 2.6930768489837646, 7.8708696365356445, 14.486969947814941, -0.24681317806243896], step: 34200, lr: 8.429179298546718e-05, reference_loss: 26.855287551879883
2024-01-02 02:40:35,607	44k	INFO	====> Epoch: 1368, cost 22.67 s
2024-01-02 02:40:57,933	44k	INFO	====> Epoch: 1369, cost 22.33 s
2024-01-02 02:41:20,341	44k	INFO	====> Epoch: 1370, cost 22.41 s
2024-01-02 02:41:42,575	44k	INFO	====> Epoch: 1371, cost 22.23 s
2024-01-02 02:42:04,728	44k	INFO	====> Epoch: 1372, cost 22.15 s
2024-01-02 02:42:26,985	44k	INFO	====> Epoch: 1373, cost 22.26 s
2024-01-02 02:42:49,233	44k	INFO	====> Epoch: 1374, cost 22.25 s
2024-01-02 02:43:11,489	44k	INFO	====> Epoch: 1375, cost 22.26 s
2024-01-02 02:43:33,743	44k	INFO	Train Epoch: 1376 [96%]
2024-01-02 02:43:33,745	44k	INFO	Losses: [2.2808268070220947, 2.4760563373565674, 6.976574897766113, 14.432759284973145, -0.28728264570236206], step: 34400, lr: 8.420753806092313e-05, reference_loss: 25.878934860229492
2024-01-02 02:43:39,794	44k	INFO	Saving model and optimizer state at iteration 1376 to ./logs/44k/G_34400.pth
2024-01-02 02:43:40,691	44k	INFO	Saving model and optimizer state at iteration 1376 to ./logs/44k/D_34400.pth
2024-01-02 02:43:41,192	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_32000.pth
2024-01-02 02:43:41,232	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_32000.pth
2024-01-02 02:43:41,232	44k	INFO	====> Epoch: 1376, cost 29.74 s
2024-01-02 02:44:03,499	44k	INFO	====> Epoch: 1377, cost 22.27 s
2024-01-02 02:44:25,897	44k	INFO	====> Epoch: 1378, cost 22.40 s
2024-01-02 02:44:48,005	44k	INFO	====> Epoch: 1379, cost 22.11 s
2024-01-02 02:45:10,211	44k	INFO	====> Epoch: 1380, cost 22.21 s
2024-01-02 02:45:32,482	44k	INFO	====> Epoch: 1381, cost 22.27 s
2024-01-02 02:45:54,719	44k	INFO	====> Epoch: 1382, cost 22.24 s
2024-01-02 02:46:16,841	44k	INFO	====> Epoch: 1383, cost 22.12 s
2024-01-02 02:46:38,958	44k	INFO	Train Epoch: 1384 [96%]
2024-01-02 02:46:38,960	44k	INFO	Losses: [2.035285472869873, 2.852412700653076, 8.918587684631348, 15.684595108032227, -0.18757522106170654], step: 34600, lr: 8.412336735445132e-05, reference_loss: 29.303306579589844
2024-01-02 02:46:39,351	44k	INFO	====> Epoch: 1384, cost 22.51 s
2024-01-02 02:47:01,582	44k	INFO	====> Epoch: 1385, cost 22.23 s
2024-01-02 02:47:23,712	44k	INFO	====> Epoch: 1386, cost 22.13 s
2024-01-02 02:47:45,839	44k	INFO	====> Epoch: 1387, cost 22.13 s
2024-01-02 02:48:07,978	44k	INFO	====> Epoch: 1388, cost 22.14 s
2024-01-02 02:48:30,248	44k	INFO	====> Epoch: 1389, cost 22.27 s
2024-01-02 02:48:52,695	44k	INFO	====> Epoch: 1390, cost 22.45 s
2024-01-02 02:49:14,947	44k	INFO	====> Epoch: 1391, cost 22.25 s
2024-01-02 02:49:37,198	44k	INFO	Train Epoch: 1392 [96%]
2024-01-02 02:49:37,200	44k	INFO	Losses: [2.2727818489074707, 2.3602664470672607, 5.564819812774658, 12.879133224487305, -0.19390513002872467], step: 34800, lr: 8.403928078187053e-05, reference_loss: 22.88309669494629
2024-01-02 02:49:37,588	44k	INFO	====> Epoch: 1392, cost 22.64 s
2024-01-02 02:49:59,859	44k	INFO	====> Epoch: 1393, cost 22.27 s
2024-01-02 02:50:22,100	44k	INFO	====> Epoch: 1394, cost 22.24 s
2024-01-02 02:50:44,314	44k	INFO	====> Epoch: 1395, cost 22.21 s
2024-01-02 02:51:06,552	44k	INFO	====> Epoch: 1396, cost 22.24 s
2024-01-02 02:51:28,820	44k	INFO	====> Epoch: 1397, cost 22.27 s
2024-01-02 02:51:51,111	44k	INFO	====> Epoch: 1398, cost 22.29 s
2024-01-02 02:52:13,373	44k	INFO	====> Epoch: 1399, cost 22.26 s
2024-01-02 02:52:35,630	44k	INFO	Train Epoch: 1400 [96%]
2024-01-02 02:52:35,632	44k	INFO	Losses: [2.0188426971435547, 2.8898355960845947, 8.096964836120605, 15.071511268615723, -0.37421613931655884], step: 35000, lr: 8.395527825908361e-05, reference_loss: 27.702938079833984
2024-01-02 02:52:36,198	44k	INFO	====> Epoch: 1400, cost 22.83 s
2024-01-02 02:52:58,483	44k	INFO	====> Epoch: 1401, cost 22.28 s
2024-01-02 02:53:20,683	44k	INFO	====> Epoch: 1402, cost 22.20 s
2024-01-02 02:53:42,881	44k	INFO	====> Epoch: 1403, cost 22.20 s
2024-01-02 02:54:05,202	44k	INFO	====> Epoch: 1404, cost 22.32 s
2024-01-02 02:54:27,403	44k	INFO	====> Epoch: 1405, cost 22.20 s
2024-01-02 02:54:49,728	44k	INFO	====> Epoch: 1406, cost 22.33 s
2024-01-02 02:55:11,971	44k	INFO	====> Epoch: 1407, cost 22.24 s
2024-01-02 02:55:34,302	44k	INFO	Train Epoch: 1408 [96%]
2024-01-02 02:55:34,304	44k	INFO	Losses: [2.2734808921813965, 2.351151704788208, 6.073922634124756, 13.906051635742188, -0.36580270528793335], step: 35200, lr: 8.387135970207758e-05, reference_loss: 24.23880386352539
2024-01-02 02:55:40,645	44k	INFO	Saving model and optimizer state at iteration 1408 to ./logs/44k/G_35200.pth
2024-01-02 02:55:41,564	44k	INFO	Saving model and optimizer state at iteration 1408 to ./logs/44k/D_35200.pth
2024-01-02 02:55:42,077	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_32800.pth
2024-01-02 02:55:42,115	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_32800.pth
2024-01-02 02:55:42,116	44k	INFO	====> Epoch: 1408, cost 30.14 s
2024-01-02 02:56:04,381	44k	INFO	====> Epoch: 1409, cost 22.26 s
2024-01-02 02:56:26,527	44k	INFO	====> Epoch: 1410, cost 22.15 s
2024-01-02 02:56:48,679	44k	INFO	====> Epoch: 1411, cost 22.15 s
2024-01-02 02:57:10,923	44k	INFO	====> Epoch: 1412, cost 22.24 s
2024-01-02 02:57:33,316	44k	INFO	====> Epoch: 1413, cost 22.39 s
2024-01-02 02:57:55,696	44k	INFO	====> Epoch: 1414, cost 22.38 s
2024-01-02 02:58:18,069	44k	INFO	====> Epoch: 1415, cost 22.37 s
2024-01-02 02:58:40,330	44k	INFO	Train Epoch: 1416 [96%]
2024-01-02 02:58:40,332	44k	INFO	Losses: [2.1103734970092773, 2.7843880653381348, 8.244241714477539, 16.076416015625, -0.18771886825561523], step: 35400, lr: 8.378752502692335e-05, reference_loss: 29.027700424194336
2024-01-02 02:58:40,731	44k	INFO	====> Epoch: 1416, cost 22.66 s
2024-01-02 02:59:02,995	44k	INFO	====> Epoch: 1417, cost 22.26 s
2024-01-02 02:59:25,231	44k	INFO	====> Epoch: 1418, cost 22.24 s
2024-01-02 02:59:47,439	44k	INFO	====> Epoch: 1419, cost 22.21 s
2024-01-02 03:00:09,793	44k	INFO	====> Epoch: 1420, cost 22.35 s
2024-01-02 03:00:32,026	44k	INFO	====> Epoch: 1421, cost 22.23 s
2024-01-02 03:00:54,314	44k	INFO	====> Epoch: 1422, cost 22.29 s
2024-01-02 03:01:16,519	44k	INFO	====> Epoch: 1423, cost 22.21 s
2024-01-02 03:01:38,620	44k	INFO	Train Epoch: 1424 [96%]
2024-01-02 03:01:38,622	44k	INFO	Losses: [2.2085769176483154, 2.4501123428344727, 6.161001205444336, 11.834454536437988, -0.1664903312921524], step: 35600, lr: 8.370377414977579e-05, reference_loss: 22.487653732299805
2024-01-02 03:01:39,007	44k	INFO	====> Epoch: 1424, cost 22.49 s
2024-01-02 03:02:01,141	44k	INFO	====> Epoch: 1425, cost 22.13 s
2024-01-02 03:02:23,234	44k	INFO	====> Epoch: 1426, cost 22.09 s
2024-01-02 03:02:45,364	44k	INFO	====> Epoch: 1427, cost 22.13 s
2024-01-02 03:03:07,634	44k	INFO	====> Epoch: 1428, cost 22.27 s
2024-01-02 03:03:29,879	44k	INFO	====> Epoch: 1429, cost 22.24 s
2024-01-02 03:03:52,276	44k	INFO	====> Epoch: 1430, cost 22.40 s
2024-01-02 03:04:14,508	44k	INFO	====> Epoch: 1431, cost 22.23 s
2024-01-02 03:04:36,742	44k	INFO	Train Epoch: 1432 [96%]
2024-01-02 03:04:36,744	44k	INFO	Losses: [2.240007162094116, 2.6280088424682617, 7.73726749420166, 14.52088451385498, -0.3378598093986511], step: 35800, lr: 8.36201069868735e-05, reference_loss: 26.788307189941406
2024-01-02 03:04:37,129	44k	INFO	====> Epoch: 1432, cost 22.62 s
2024-01-02 03:04:59,381	44k	INFO	====> Epoch: 1433, cost 22.25 s
2024-01-02 03:05:21,588	44k	INFO	====> Epoch: 1434, cost 22.21 s
2024-01-02 03:05:43,767	44k	INFO	====> Epoch: 1435, cost 22.18 s
2024-01-02 03:06:05,986	44k	INFO	====> Epoch: 1436, cost 22.22 s
2024-01-02 03:06:28,209	44k	INFO	====> Epoch: 1437, cost 22.22 s
2024-01-02 03:06:50,317	44k	INFO	====> Epoch: 1438, cost 22.11 s
2024-01-02 03:07:12,560	44k	INFO	====> Epoch: 1439, cost 22.24 s
2024-01-02 03:07:34,946	44k	INFO	Train Epoch: 1440 [96%]
2024-01-02 03:07:34,948	44k	INFO	Losses: [2.3389554023742676, 2.217899799346924, 5.763124465942383, 13.603012084960938, -0.3723388910293579], step: 36000, lr: 8.353652345453889e-05, reference_loss: 23.5506534576416
2024-01-02 03:07:40,738	44k	INFO	Saving model and optimizer state at iteration 1440 to ./logs/44k/G_36000.pth
2024-01-02 03:07:41,659	44k	INFO	Saving model and optimizer state at iteration 1440 to ./logs/44k/D_36000.pth
2024-01-02 03:07:42,149	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_33600.pth
2024-01-02 03:07:42,187	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_33600.pth
2024-01-02 03:07:42,187	44k	INFO	====> Epoch: 1440, cost 29.63 s
2024-01-02 03:08:04,447	44k	INFO	====> Epoch: 1441, cost 22.26 s
2024-01-02 03:08:26,759	44k	INFO	====> Epoch: 1442, cost 22.31 s
2024-01-02 03:08:49,015	44k	INFO	====> Epoch: 1443, cost 22.26 s
2024-01-02 03:09:11,270	44k	INFO	====> Epoch: 1444, cost 22.25 s
2024-01-02 03:09:33,511	44k	INFO	====> Epoch: 1445, cost 22.24 s
2024-01-02 03:09:55,713	44k	INFO	====> Epoch: 1446, cost 22.20 s
2024-01-02 03:10:18,111	44k	INFO	====> Epoch: 1447, cost 22.40 s
2024-01-02 03:10:40,309	44k	INFO	Train Epoch: 1448 [96%]
2024-01-02 03:10:40,312	44k	INFO	Losses: [2.1300625801086426, 2.733517646789551, 7.363519668579102, 14.548324584960938, -0.23302572965621948], step: 36200, lr: 8.345302346917795e-05, reference_loss: 26.54239845275879
2024-01-02 03:10:40,693	44k	INFO	====> Epoch: 1448, cost 22.58 s
2024-01-02 03:11:02,782	44k	INFO	====> Epoch: 1449, cost 22.09 s
2024-01-02 03:11:24,874	44k	INFO	====> Epoch: 1450, cost 22.09 s
2024-01-02 03:11:46,957	44k	INFO	====> Epoch: 1451, cost 22.08 s
2024-01-02 03:12:09,047	44k	INFO	====> Epoch: 1452, cost 22.09 s
2024-01-02 03:12:31,168	44k	INFO	====> Epoch: 1453, cost 22.12 s
2024-01-02 03:12:53,361	44k	INFO	====> Epoch: 1454, cost 22.19 s
2024-01-02 03:13:15,515	44k	INFO	====> Epoch: 1455, cost 22.15 s
2024-01-02 03:13:37,619	44k	INFO	Train Epoch: 1456 [96%]
2024-01-02 03:13:37,621	44k	INFO	Losses: [2.1745004653930664, 2.6163885593414307, 5.9066314697265625, 12.77580451965332, -0.24596820771694183], step: 36400, lr: 8.336960694728028e-05, reference_loss: 23.22735595703125
2024-01-02 03:13:38,196	44k	INFO	====> Epoch: 1456, cost 22.68 s
2024-01-02 03:14:00,390	44k	INFO	====> Epoch: 1457, cost 22.19 s
2024-01-02 03:14:22,558	44k	INFO	====> Epoch: 1458, cost 22.17 s
2024-01-02 03:14:44,775	44k	INFO	====> Epoch: 1459, cost 22.22 s
2024-01-02 03:15:06,999	44k	INFO	====> Epoch: 1460, cost 22.22 s
2024-01-02 03:15:29,221	44k	INFO	====> Epoch: 1461, cost 22.22 s
2024-01-02 03:15:51,433	44k	INFO	====> Epoch: 1462, cost 22.21 s
2024-01-02 03:16:13,660	44k	INFO	====> Epoch: 1463, cost 22.23 s
2024-01-02 03:16:35,893	44k	INFO	Train Epoch: 1464 [96%]
2024-01-02 03:16:35,895	44k	INFO	Losses: [2.1091620922088623, 2.797363519668579, 8.649480819702148, 15.241678237915039, -0.32798582315444946], step: 36600, lr: 8.328627380541889e-05, reference_loss: 28.469697952270508
2024-01-02 03:16:36,282	44k	INFO	====> Epoch: 1464, cost 22.62 s
2024-01-02 03:16:58,489	44k	INFO	====> Epoch: 1465, cost 22.21 s
2024-01-02 03:17:20,890	44k	INFO	====> Epoch: 1466, cost 22.40 s
2024-01-02 03:17:43,034	44k	INFO	====> Epoch: 1467, cost 22.14 s
2024-01-02 03:18:05,128	44k	INFO	====> Epoch: 1468, cost 22.09 s
2024-01-02 03:18:27,329	44k	INFO	====> Epoch: 1469, cost 22.20 s
2024-01-02 03:18:49,529	44k	INFO	====> Epoch: 1470, cost 22.20 s
2024-01-02 03:19:11,746	44k	INFO	====> Epoch: 1471, cost 22.22 s
2024-01-02 03:19:33,955	44k	INFO	Train Epoch: 1472 [96%]
2024-01-02 03:19:33,957	44k	INFO	Losses: [2.2653634548187256, 2.4806571006774902, 6.756094932556152, 14.156269073486328, -0.42048588395118713], step: 36800, lr: 8.32030239602502e-05, reference_loss: 25.237897872924805
2024-01-02 03:19:39,786	44k	INFO	Saving model and optimizer state at iteration 1472 to ./logs/44k/G_36800.pth
2024-01-02 03:19:40,705	44k	INFO	Saving model and optimizer state at iteration 1472 to ./logs/44k/D_36800.pth
2024-01-02 03:19:41,202	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_34400.pth
2024-01-02 03:19:41,241	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_34400.pth
2024-01-02 03:19:41,241	44k	INFO	====> Epoch: 1472, cost 29.50 s
2024-01-02 03:20:03,246	44k	INFO	====> Epoch: 1473, cost 22.00 s
2024-01-02 03:20:25,480	44k	INFO	====> Epoch: 1474, cost 22.23 s
2024-01-02 03:20:47,535	44k	INFO	====> Epoch: 1475, cost 22.06 s
2024-01-02 03:21:09,710	44k	INFO	====> Epoch: 1476, cost 22.17 s
2024-01-02 03:21:31,866	44k	INFO	====> Epoch: 1477, cost 22.16 s
2024-01-02 03:21:53,946	44k	INFO	====> Epoch: 1478, cost 22.08 s
2024-01-02 03:22:16,016	44k	INFO	====> Epoch: 1479, cost 22.07 s
2024-01-02 03:22:38,130	44k	INFO	Train Epoch: 1480 [96%]
2024-01-02 03:22:38,132	44k	INFO	Losses: [2.1115567684173584, 2.8092334270477295, 8.293758392333984, 15.41618824005127, -0.3054034411907196], step: 37000, lr: 8.3119857328514e-05, reference_loss: 28.325334548950195
2024-01-02 03:22:38,517	44k	INFO	====> Epoch: 1480, cost 22.50 s
2024-01-02 03:23:00,677	44k	INFO	====> Epoch: 1481, cost 22.16 s
2024-01-02 03:23:22,840	44k	INFO	====> Epoch: 1482, cost 22.16 s
2024-01-02 03:23:44,938	44k	INFO	====> Epoch: 1483, cost 22.10 s
2024-01-02 03:24:07,022	44k	INFO	====> Epoch: 1484, cost 22.08 s
2024-01-02 03:24:29,232	44k	INFO	====> Epoch: 1485, cost 22.21 s
2024-01-02 03:24:51,540	44k	INFO	====> Epoch: 1486, cost 22.31 s
2024-01-02 03:25:13,705	44k	INFO	====> Epoch: 1487, cost 22.16 s
2024-01-02 03:25:35,837	44k	INFO	Train Epoch: 1488 [96%]
2024-01-02 03:25:35,839	44k	INFO	Losses: [2.104551076889038, 2.807204008102417, 7.171075344085693, 14.067330360412598, -0.2803983986377716], step: 37200, lr: 8.303677382703322e-05, reference_loss: 25.869762420654297
2024-01-02 03:25:36,315	44k	INFO	====> Epoch: 1488, cost 22.61 s
2024-01-02 03:25:58,487	44k	INFO	====> Epoch: 1489, cost 22.17 s
2024-01-02 03:26:20,623	44k	INFO	====> Epoch: 1490, cost 22.14 s
2024-01-02 03:26:42,769	44k	INFO	====> Epoch: 1491, cost 22.15 s
2024-01-02 03:27:04,898	44k	INFO	====> Epoch: 1492, cost 22.13 s
2024-01-02 03:27:27,089	44k	INFO	====> Epoch: 1493, cost 22.19 s
2024-01-02 03:27:49,334	44k	INFO	====> Epoch: 1494, cost 22.25 s
2024-01-02 03:28:11,589	44k	INFO	====> Epoch: 1495, cost 22.25 s
2024-01-02 03:28:33,936	44k	INFO	Train Epoch: 1496 [96%]
2024-01-02 03:28:33,938	44k	INFO	Losses: [2.012753486633301, 2.861182928085327, 9.114699363708496, 14.838947296142578, -0.3776561915874481], step: 37400, lr: 8.295377337271398e-05, reference_loss: 28.449926376342773
2024-01-02 03:28:34,416	44k	INFO	====> Epoch: 1496, cost 22.83 s
2024-01-02 03:28:56,535	44k	INFO	====> Epoch: 1497, cost 22.12 s
2024-01-02 03:29:18,632	44k	INFO	====> Epoch: 1498, cost 22.10 s
2024-01-02 03:29:40,748	44k	INFO	====> Epoch: 1499, cost 22.12 s
2024-01-02 03:30:03,020	44k	INFO	====> Epoch: 1500, cost 22.27 s
2024-01-02 03:30:25,294	44k	INFO	====> Epoch: 1501, cost 22.27 s
2024-01-02 03:30:47,538	44k	INFO	====> Epoch: 1502, cost 22.24 s
2024-01-02 03:31:09,744	44k	INFO	====> Epoch: 1503, cost 22.21 s
2024-01-02 03:31:32,011	44k	INFO	Train Epoch: 1504 [96%]
2024-01-02 03:31:32,013	44k	INFO	Losses: [2.2888882160186768, 2.4022765159606934, 7.095193862915039, 14.398603439331055, -0.47248345613479614], step: 37600, lr: 8.287085588254543e-05, reference_loss: 25.712480545043945
2024-01-02 03:31:38,152	44k	INFO	Saving model and optimizer state at iteration 1504 to ./logs/44k/G_37600.pth
2024-01-02 03:31:39,076	44k	INFO	Saving model and optimizer state at iteration 1504 to ./logs/44k/D_37600.pth
2024-01-02 03:31:39,584	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_35200.pth
2024-01-02 03:31:39,622	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_35200.pth
2024-01-02 03:31:39,623	44k	INFO	====> Epoch: 1504, cost 29.88 s
2024-01-02 03:32:01,848	44k	INFO	====> Epoch: 1505, cost 22.23 s
2024-01-02 03:32:24,118	44k	INFO	====> Epoch: 1506, cost 22.27 s
2024-01-02 03:32:46,377	44k	INFO	====> Epoch: 1507, cost 22.26 s
2024-01-02 03:33:08,623	44k	INFO	====> Epoch: 1508, cost 22.25 s
2024-01-02 03:33:30,864	44k	INFO	====> Epoch: 1509, cost 22.24 s
2024-01-02 03:33:53,097	44k	INFO	====> Epoch: 1510, cost 22.23 s
2024-01-02 03:34:15,346	44k	INFO	====> Epoch: 1511, cost 22.25 s
2024-01-02 03:34:37,487	44k	INFO	Train Epoch: 1512 [96%]
2024-01-02 03:34:37,489	44k	INFO	Losses: [2.0124917030334473, 2.967637777328491, 8.392720222473145, 15.0075101852417, -0.3543306589126587], step: 37800, lr: 8.278802127359971e-05, reference_loss: 28.026029586791992
2024-01-02 03:34:37,887	44k	INFO	====> Epoch: 1512, cost 22.54 s
2024-01-02 03:35:00,085	44k	INFO	====> Epoch: 1513, cost 22.20 s
2024-01-02 03:35:22,277	44k	INFO	====> Epoch: 1514, cost 22.19 s
2024-01-02 03:35:44,447	44k	INFO	====> Epoch: 1515, cost 22.17 s
2024-01-02 03:36:06,863	44k	INFO	====> Epoch: 1516, cost 22.42 s
2024-01-02 03:36:29,118	44k	INFO	====> Epoch: 1517, cost 22.25 s
2024-01-02 03:36:51,393	44k	INFO	====> Epoch: 1518, cost 22.28 s
2024-01-02 03:37:13,670	44k	INFO	====> Epoch: 1519, cost 22.28 s
2024-01-02 03:37:35,938	44k	INFO	Train Epoch: 1520 [96%]
2024-01-02 03:37:35,940	44k	INFO	Losses: [2.194368362426758, 2.4146640300750732, 5.776591777801514, 12.743703842163086, -0.3564615547657013], step: 38000, lr: 8.270526946303185e-05, reference_loss: 22.772865295410156
2024-01-02 03:37:36,323	44k	INFO	====> Epoch: 1520, cost 22.65 s
2024-01-02 03:37:58,623	44k	INFO	====> Epoch: 1521, cost 22.30 s
2024-01-02 03:38:20,892	44k	INFO	====> Epoch: 1522, cost 22.27 s
2024-01-02 03:38:43,122	44k	INFO	====> Epoch: 1523, cost 22.23 s
2024-01-02 03:39:05,352	44k	INFO	====> Epoch: 1524, cost 22.23 s
2024-01-02 03:39:27,671	44k	INFO	====> Epoch: 1525, cost 22.32 s
2024-01-02 03:39:50,083	44k	INFO	====> Epoch: 1526, cost 22.41 s
2024-01-02 03:40:12,386	44k	INFO	====> Epoch: 1527, cost 22.30 s
2024-01-02 03:40:34,693	44k	INFO	Train Epoch: 1528 [96%]
2024-01-02 03:40:34,695	44k	INFO	Losses: [2.092135190963745, 2.8500912189483643, 8.46985912322998, 14.884345054626465, -0.41027721762657166], step: 38200, lr: 8.26226003680797e-05, reference_loss: 27.886154174804688
2024-01-02 03:40:35,083	44k	INFO	====> Epoch: 1528, cost 22.70 s
2024-01-02 03:40:57,391	44k	INFO	====> Epoch: 1529, cost 22.31 s
2024-01-02 03:41:19,730	44k	INFO	====> Epoch: 1530, cost 22.34 s
2024-01-02 03:41:42,061	44k	INFO	====> Epoch: 1531, cost 22.33 s
2024-01-02 03:42:04,341	44k	INFO	====> Epoch: 1532, cost 22.28 s
2024-01-02 03:42:26,572	44k	INFO	====> Epoch: 1533, cost 22.23 s
2024-01-02 03:42:48,817	44k	INFO	====> Epoch: 1534, cost 22.24 s
2024-01-02 03:43:11,065	44k	INFO	====> Epoch: 1535, cost 22.25 s
2024-01-02 03:43:33,450	44k	INFO	Train Epoch: 1536 [96%]
2024-01-02 03:43:33,452	44k	INFO	Losses: [2.160351514816284, 2.57106614112854, 7.5171332359313965, 14.219385147094727, -0.4536542594432831], step: 38400, lr: 8.25400139060638e-05, reference_loss: 26.0142822265625
2024-01-02 03:43:39,304	44k	INFO	Saving model and optimizer state at iteration 1536 to ./logs/44k/G_38400.pth
2024-01-02 03:43:40,231	44k	INFO	Saving model and optimizer state at iteration 1536 to ./logs/44k/D_38400.pth
2024-01-02 03:43:40,732	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_36000.pth
2024-01-02 03:43:40,771	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_36000.pth
2024-01-02 03:43:40,771	44k	INFO	====> Epoch: 1536, cost 29.71 s
2024-01-02 03:44:02,824	44k	INFO	====> Epoch: 1537, cost 22.05 s
2024-01-02 03:44:24,912	44k	INFO	====> Epoch: 1538, cost 22.09 s
2024-01-02 03:44:47,082	44k	INFO	====> Epoch: 1539, cost 22.17 s
2024-01-02 03:45:09,338	44k	INFO	====> Epoch: 1540, cost 22.26 s
2024-01-02 03:45:31,720	44k	INFO	====> Epoch: 1541, cost 22.38 s
2024-01-02 03:45:54,053	44k	INFO	====> Epoch: 1542, cost 22.33 s
2024-01-02 03:46:16,472	44k	INFO	====> Epoch: 1543, cost 22.42 s
2024-01-02 03:46:38,609	44k	INFO	Train Epoch: 1544 [96%]
2024-01-02 03:46:38,612	44k	INFO	Losses: [2.077176094055176, 3.109513759613037, 8.857573509216309, 15.759068489074707, -0.31399208307266235], step: 38600, lr: 8.245750999438739e-05, reference_loss: 29.489341735839844
2024-01-02 03:46:39,011	44k	INFO	====> Epoch: 1544, cost 22.54 s
2024-01-02 03:47:01,364	44k	INFO	====> Epoch: 1545, cost 22.35 s
2024-01-02 03:47:23,735	44k	INFO	====> Epoch: 1546, cost 22.37 s
2024-01-02 03:47:46,073	44k	INFO	====> Epoch: 1547, cost 22.34 s
2024-01-02 03:48:08,366	44k	INFO	====> Epoch: 1548, cost 22.29 s
2024-01-02 03:48:30,566	44k	INFO	====> Epoch: 1549, cost 22.20 s
2024-01-02 03:48:52,694	44k	INFO	====> Epoch: 1550, cost 22.13 s
2024-01-02 03:49:14,782	44k	INFO	====> Epoch: 1551, cost 22.09 s
2024-01-02 03:49:36,880	44k	INFO	Train Epoch: 1552 [96%]
2024-01-02 03:49:36,882	44k	INFO	Losses: [2.1229090690612793, 2.4831202030181885, 5.9392852783203125, 12.730596542358398, -0.2657005786895752], step: 38800, lr: 8.23750885505362e-05, reference_loss: 23.010210037231445
2024-01-02 03:49:37,442	44k	INFO	====> Epoch: 1552, cost 22.66 s
2024-01-02 03:49:59,575	44k	INFO	====> Epoch: 1553, cost 22.13 s
2024-01-02 03:50:21,728	44k	INFO	====> Epoch: 1554, cost 22.15 s
2024-01-02 03:50:43,922	44k	INFO	====> Epoch: 1555, cost 22.19 s
2024-01-02 03:51:06,108	44k	INFO	====> Epoch: 1556, cost 22.19 s
2024-01-02 03:51:28,305	44k	INFO	====> Epoch: 1557, cost 22.20 s
2024-01-02 03:51:50,579	44k	INFO	====> Epoch: 1558, cost 22.27 s
2024-01-02 03:52:12,873	44k	INFO	====> Epoch: 1559, cost 22.29 s
2024-01-02 03:52:35,042	44k	INFO	Train Epoch: 1560 [96%]
2024-01-02 03:52:35,044	44k	INFO	Losses: [2.0990653038024902, 2.7980592250823975, 8.202131271362305, 14.106878280639648, -0.43488559126853943], step: 39000, lr: 8.22927494920785e-05, reference_loss: 26.771249771118164
2024-01-02 03:52:35,431	44k	INFO	====> Epoch: 1560, cost 22.56 s
2024-01-02 03:52:57,644	44k	INFO	====> Epoch: 1561, cost 22.21 s
2024-01-02 03:53:20,157	44k	INFO	====> Epoch: 1562, cost 22.51 s
2024-01-02 03:53:42,491	44k	INFO	====> Epoch: 1563, cost 22.33 s
2024-01-02 03:54:04,827	44k	INFO	====> Epoch: 1564, cost 22.34 s
2024-01-02 03:54:27,164	44k	INFO	====> Epoch: 1565, cost 22.34 s
2024-01-02 03:54:49,423	44k	INFO	====> Epoch: 1566, cost 22.26 s
2024-01-02 03:55:11,654	44k	INFO	====> Epoch: 1567, cost 22.23 s
2024-01-02 03:55:33,923	44k	INFO	Train Epoch: 1568 [96%]
2024-01-02 03:55:33,925	44k	INFO	Losses: [2.1337080001831055, 2.522707462310791, 6.5152587890625, 13.830304145812988, -0.4891025125980377], step: 39200, lr: 8.221049273666493e-05, reference_loss: 24.512876510620117
2024-01-02 03:55:39,739	44k	INFO	Saving model and optimizer state at iteration 1568 to ./logs/44k/G_39200.pth
2024-01-02 03:55:40,654	44k	INFO	Saving model and optimizer state at iteration 1568 to ./logs/44k/D_39200.pth
2024-01-02 03:55:41,149	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_36800.pth
2024-01-02 03:55:41,188	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_36800.pth
2024-01-02 03:55:41,188	44k	INFO	====> Epoch: 1568, cost 29.53 s
2024-01-02 03:56:03,419	44k	INFO	====> Epoch: 1569, cost 22.23 s
2024-01-02 03:56:25,757	44k	INFO	====> Epoch: 1570, cost 22.34 s
2024-01-02 03:56:47,874	44k	INFO	====> Epoch: 1571, cost 22.12 s
2024-01-02 03:57:10,081	44k	INFO	====> Epoch: 1572, cost 22.21 s
2024-01-02 03:57:32,292	44k	INFO	====> Epoch: 1573, cost 22.21 s
2024-01-02 03:57:54,516	44k	INFO	====> Epoch: 1574, cost 22.22 s
2024-01-02 03:58:16,741	44k	INFO	====> Epoch: 1575, cost 22.22 s
2024-01-02 03:58:38,956	44k	INFO	Train Epoch: 1576 [96%]
2024-01-02 03:58:38,958	44k	INFO	Losses: [2.1621408462524414, 2.8444299697875977, 7.8104352951049805, 15.579312324523926, -0.37973088026046753], step: 39400, lr: 8.212831820202844e-05, reference_loss: 28.01658821105957
2024-01-02 03:58:39,353	44k	INFO	====> Epoch: 1576, cost 22.61 s
2024-01-02 03:59:01,566	44k	INFO	====> Epoch: 1577, cost 22.21 s
2024-01-02 03:59:23,708	44k	INFO	====> Epoch: 1578, cost 22.14 s
2024-01-02 03:59:45,897	44k	INFO	====> Epoch: 1579, cost 22.19 s
2024-01-02 04:00:08,025	44k	INFO	====> Epoch: 1580, cost 22.13 s
2024-01-02 04:00:30,119	44k	INFO	====> Epoch: 1581, cost 22.09 s
2024-01-02 04:00:52,382	44k	INFO	====> Epoch: 1582, cost 22.26 s
2024-01-02 04:01:14,485	44k	INFO	====> Epoch: 1583, cost 22.10 s
2024-01-02 04:01:36,674	44k	INFO	Train Epoch: 1584 [96%]
2024-01-02 04:01:36,676	44k	INFO	Losses: [2.148225784301758, 2.7679367065429688, 6.193587779998779, 11.676833152770996, -0.3965054750442505], step: 39600, lr: 8.204622580598422e-05, reference_loss: 22.390077590942383
2024-01-02 04:01:37,156	44k	INFO	====> Epoch: 1584, cost 22.67 s
2024-01-02 04:01:59,230	44k	INFO	====> Epoch: 1585, cost 22.07 s
2024-01-02 04:02:21,367	44k	INFO	====> Epoch: 1586, cost 22.14 s
2024-01-02 04:02:43,555	44k	INFO	====> Epoch: 1587, cost 22.19 s
2024-01-02 04:03:05,705	44k	INFO	====> Epoch: 1588, cost 22.15 s
2024-01-02 04:03:27,790	44k	INFO	====> Epoch: 1589, cost 22.09 s
2024-01-02 04:03:49,972	44k	INFO	====> Epoch: 1590, cost 22.18 s
2024-01-02 04:04:12,202	44k	INFO	====> Epoch: 1591, cost 22.23 s
2024-01-02 04:04:34,469	44k	INFO	Train Epoch: 1592 [96%]
2024-01-02 04:04:34,471	44k	INFO	Losses: [1.9986766576766968, 2.8427724838256836, 9.123246192932129, 15.228126525878906, -0.43446657061576843], step: 39800, lr: 8.196421546642959e-05, reference_loss: 28.75835418701172
2024-01-02 04:04:35,126	44k	INFO	====> Epoch: 1592, cost 22.92 s
2024-01-02 04:04:57,333	44k	INFO	====> Epoch: 1593, cost 22.21 s
2024-01-02 04:05:19,569	44k	INFO	====> Epoch: 1594, cost 22.24 s
2024-01-02 04:05:41,873	44k	INFO	====> Epoch: 1595, cost 22.30 s
2024-01-02 04:06:04,091	44k	INFO	====> Epoch: 1596, cost 22.22 s
2024-01-02 04:06:26,183	44k	INFO	====> Epoch: 1597, cost 22.09 s
2024-01-02 04:06:48,278	44k	INFO	====> Epoch: 1598, cost 22.10 s
2024-01-02 04:07:10,355	44k	INFO	====> Epoch: 1599, cost 22.08 s
2024-01-02 04:07:32,442	44k	INFO	Train Epoch: 1600 [96%]
2024-01-02 04:07:32,443	44k	INFO	Losses: [2.1426234245300293, 2.616743564605713, 7.570058345794678, 14.32227897644043, -0.5125049948692322], step: 40000, lr: 8.188228710134397e-05, reference_loss: 26.13920021057129
2024-01-02 04:07:38,603	44k	INFO	Saving model and optimizer state at iteration 1600 to ./logs/44k/G_40000.pth
2024-01-02 04:07:39,494	44k	INFO	Saving model and optimizer state at iteration 1600 to ./logs/44k/D_40000.pth
2024-01-02 04:07:39,989	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_37600.pth
2024-01-02 04:07:40,028	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_37600.pth
2024-01-02 04:07:40,028	44k	INFO	====> Epoch: 1600, cost 29.67 s
2024-01-02 04:08:02,066	44k	INFO	====> Epoch: 1601, cost 22.04 s
2024-01-02 04:08:24,109	44k	INFO	====> Epoch: 1602, cost 22.04 s
2024-01-02 04:08:46,306	44k	INFO	====> Epoch: 1603, cost 22.20 s
2024-01-02 04:09:08,387	44k	INFO	====> Epoch: 1604, cost 22.08 s
2024-01-02 04:09:30,486	44k	INFO	====> Epoch: 1605, cost 22.10 s
2024-01-02 04:09:52,607	44k	INFO	====> Epoch: 1606, cost 22.12 s
2024-01-02 04:10:14,820	44k	INFO	====> Epoch: 1607, cost 22.21 s
2024-01-02 04:10:37,001	44k	INFO	Train Epoch: 1608 [96%]
2024-01-02 04:10:37,003	44k	INFO	Losses: [2.067068099975586, 2.9079363346099854, 8.56639575958252, 15.647587776184082, -0.39932382106781006], step: 40200, lr: 8.180044062878873e-05, reference_loss: 28.789663314819336
2024-01-02 04:10:37,400	44k	INFO	====> Epoch: 1608, cost 22.58 s
2024-01-02 04:10:59,625	44k	INFO	====> Epoch: 1609, cost 22.22 s
2024-01-02 04:11:21,886	44k	INFO	====> Epoch: 1610, cost 22.26 s
2024-01-02 04:11:44,152	44k	INFO	====> Epoch: 1611, cost 22.27 s
2024-01-02 04:12:06,577	44k	INFO	====> Epoch: 1612, cost 22.42 s
2024-01-02 04:12:28,882	44k	INFO	====> Epoch: 1613, cost 22.30 s
2024-01-02 04:12:51,131	44k	INFO	====> Epoch: 1614, cost 22.25 s
2024-01-02 04:13:13,398	44k	INFO	====> Epoch: 1615, cost 22.27 s
2024-01-02 04:13:35,658	44k	INFO	Train Epoch: 1616 [96%]
2024-01-02 04:13:35,661	44k	INFO	Losses: [2.1568715572357178, 2.566527843475342, 6.570216655731201, 14.216598510742188, -0.43018844723701477], step: 40400, lr: 8.171867596690716e-05, reference_loss: 25.08002471923828
2024-01-02 04:13:36,055	44k	INFO	====> Epoch: 1616, cost 22.66 s
2024-01-02 04:13:58,288	44k	INFO	====> Epoch: 1617, cost 22.23 s
2024-01-02 04:14:20,569	44k	INFO	====> Epoch: 1618, cost 22.28 s
2024-01-02 04:14:42,853	44k	INFO	====> Epoch: 1619, cost 22.28 s
2024-01-02 04:15:05,115	44k	INFO	====> Epoch: 1620, cost 22.26 s
2024-01-02 04:15:27,359	44k	INFO	====> Epoch: 1621, cost 22.24 s
2024-01-02 04:15:49,750	44k	INFO	====> Epoch: 1622, cost 22.39 s
2024-01-02 04:16:12,034	44k	INFO	====> Epoch: 1623, cost 22.28 s
2024-01-02 04:16:34,353	44k	INFO	Train Epoch: 1624 [96%]
2024-01-02 04:16:34,355	44k	INFO	Losses: [2.0819931030273438, 2.8115010261535645, 8.237197875976562, 14.308489799499512, -0.5573636293411255], step: 40600, lr: 8.16369930339244e-05, reference_loss: 26.881818771362305
2024-01-02 04:16:34,743	44k	INFO	====> Epoch: 1624, cost 22.71 s
2024-01-02 04:16:57,012	44k	INFO	====> Epoch: 1625, cost 22.27 s
2024-01-02 04:17:19,252	44k	INFO	====> Epoch: 1626, cost 22.24 s
2024-01-02 04:17:41,479	44k	INFO	====> Epoch: 1627, cost 22.23 s
2024-01-02 04:18:03,690	44k	INFO	====> Epoch: 1628, cost 22.21 s
2024-01-02 04:18:25,777	44k	INFO	====> Epoch: 1629, cost 22.09 s
2024-01-02 04:18:47,871	44k	INFO	====> Epoch: 1630, cost 22.09 s
2024-01-02 04:19:09,980	44k	INFO	====> Epoch: 1631, cost 22.11 s
2024-01-02 04:19:32,410	44k	INFO	Train Epoch: 1632 [96%]
2024-01-02 04:19:32,412	44k	INFO	Losses: [2.1051039695739746, 2.5528876781463623, 7.473319053649902, 14.293951988220215, -0.5656214356422424], step: 40800, lr: 8.155539174814723e-05, reference_loss: 25.85964012145996
2024-01-02 04:19:38,130	44k	INFO	Saving model and optimizer state at iteration 1632 to ./logs/44k/G_40800.pth
2024-01-02 04:19:39,035	44k	INFO	Saving model and optimizer state at iteration 1632 to ./logs/44k/D_40800.pth
2024-01-02 04:19:39,534	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_38400.pth
2024-01-02 04:19:39,572	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_38400.pth
2024-01-02 04:19:39,572	44k	INFO	====> Epoch: 1632, cost 29.59 s
2024-01-02 04:20:01,869	44k	INFO	====> Epoch: 1633, cost 22.30 s
2024-01-02 04:20:24,156	44k	INFO	====> Epoch: 1634, cost 22.29 s
2024-01-02 04:20:46,324	44k	INFO	====> Epoch: 1635, cost 22.17 s
2024-01-02 04:21:08,436	44k	INFO	====> Epoch: 1636, cost 22.11 s
2024-01-02 04:21:30,639	44k	INFO	====> Epoch: 1637, cost 22.20 s
2024-01-02 04:21:53,065	44k	INFO	====> Epoch: 1638, cost 22.43 s
2024-01-02 04:22:15,528	44k	INFO	====> Epoch: 1639, cost 22.46 s
2024-01-02 04:22:37,749	44k	INFO	Train Epoch: 1640 [96%]
2024-01-02 04:22:37,751	44k	INFO	Losses: [2.180262565612793, 3.0057594776153564, 8.413984298706055, 15.196455001831055, -0.37624168395996094], step: 41000, lr: 8.147387202796423e-05, reference_loss: 28.42021942138672
2024-01-02 04:22:38,140	44k	INFO	====> Epoch: 1640, cost 22.61 s
2024-01-02 04:23:00,402	44k	INFO	====> Epoch: 1641, cost 22.26 s
2024-01-02 04:23:22,575	44k	INFO	====> Epoch: 1642, cost 22.17 s
2024-01-02 04:23:44,772	44k	INFO	====> Epoch: 1643, cost 22.20 s
2024-01-02 04:24:07,064	44k	INFO	====> Epoch: 1644, cost 22.29 s
2024-01-02 04:24:29,208	44k	INFO	====> Epoch: 1645, cost 22.14 s
2024-01-02 04:24:51,354	44k	INFO	====> Epoch: 1646, cost 22.15 s
2024-01-02 04:25:13,526	44k	INFO	====> Epoch: 1647, cost 22.17 s
2024-01-02 04:25:35,852	44k	INFO	Train Epoch: 1648 [96%]
2024-01-02 04:25:35,854	44k	INFO	Losses: [2.088654041290283, 2.603407382965088, 6.2360029220581055, 13.101367950439453, -0.3190978765487671], step: 41200, lr: 8.139243379184544e-05, reference_loss: 23.71033477783203
2024-01-02 04:25:36,521	44k	INFO	====> Epoch: 1648, cost 22.99 s
2024-01-02 04:25:58,733	44k	INFO	====> Epoch: 1649, cost 22.21 s
2024-01-02 04:26:21,012	44k	INFO	====> Epoch: 1650, cost 22.28 s
2024-01-02 04:26:43,185	44k	INFO	====> Epoch: 1651, cost 22.17 s
2024-01-02 04:27:05,341	44k	INFO	====> Epoch: 1652, cost 22.16 s
2024-01-02 04:27:27,618	44k	INFO	====> Epoch: 1653, cost 22.28 s
2024-01-02 04:27:49,876	44k	INFO	====> Epoch: 1654, cost 22.26 s
2024-01-02 04:28:12,015	44k	INFO	====> Epoch: 1655, cost 22.14 s
2024-01-02 04:28:34,148	44k	INFO	Train Epoch: 1656 [96%]
2024-01-02 04:28:34,149	44k	INFO	Losses: [2.0911598205566406, 2.698071241378784, 8.40264892578125, 13.786785125732422, -0.5288488268852234], step: 41400, lr: 8.131107695834244e-05, reference_loss: 26.44981575012207
2024-01-02 04:28:34,621	44k	INFO	====> Epoch: 1656, cost 22.61 s
2024-01-02 04:28:56,835	44k	INFO	====> Epoch: 1657, cost 22.21 s
2024-01-02 04:29:19,274	44k	INFO	====> Epoch: 1658, cost 22.44 s
2024-01-02 04:29:41,604	44k	INFO	====> Epoch: 1659, cost 22.33 s
2024-01-02 04:30:03,965	44k	INFO	====> Epoch: 1660, cost 22.36 s
2024-01-02 04:30:26,216	44k	INFO	====> Epoch: 1661, cost 22.25 s
2024-01-02 04:30:48,467	44k	INFO	====> Epoch: 1662, cost 22.25 s
2024-01-02 04:31:10,746	44k	INFO	====> Epoch: 1663, cost 22.28 s
2024-01-02 04:31:32,986	44k	INFO	Train Epoch: 1664 [96%]
2024-01-02 04:31:32,988	44k	INFO	Losses: [2.2428488731384277, 2.5146265029907227, 6.563773155212402, 13.64168643951416, -0.615839421749115], step: 41600, lr: 8.122980144608825e-05, reference_loss: 24.347097396850586
2024-01-02 04:31:38,954	44k	INFO	Saving model and optimizer state at iteration 1664 to ./logs/44k/G_41600.pth
2024-01-02 04:31:39,874	44k	INFO	Saving model and optimizer state at iteration 1664 to ./logs/44k/D_41600.pth
2024-01-02 04:31:40,379	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_39200.pth
2024-01-02 04:31:40,418	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_39200.pth
2024-01-02 04:31:40,418	44k	INFO	====> Epoch: 1664, cost 29.67 s
2024-01-02 04:32:02,643	44k	INFO	====> Epoch: 1665, cost 22.22 s
2024-01-02 04:32:25,166	44k	INFO	====> Epoch: 1666, cost 22.52 s
2024-01-02 04:32:47,361	44k	INFO	====> Epoch: 1667, cost 22.19 s
2024-01-02 04:33:09,497	44k	INFO	====> Epoch: 1668, cost 22.14 s
2024-01-02 04:33:31,680	44k	INFO	====> Epoch: 1669, cost 22.18 s
2024-01-02 04:33:53,907	44k	INFO	====> Epoch: 1670, cost 22.23 s
2024-01-02 04:34:16,086	44k	INFO	====> Epoch: 1671, cost 22.18 s
2024-01-02 04:34:38,222	44k	INFO	Train Epoch: 1672 [96%]
2024-01-02 04:34:38,224	44k	INFO	Losses: [1.9030687808990479, 3.197175979614258, 8.545509338378906, 14.983443260192871, -0.4587242007255554], step: 41800, lr: 8.114860717379715e-05, reference_loss: 28.17047119140625
2024-01-02 04:34:38,621	44k	INFO	====> Epoch: 1672, cost 22.54 s
2024-01-02 04:35:00,904	44k	INFO	====> Epoch: 1673, cost 22.28 s
2024-01-02 04:35:23,261	44k	INFO	====> Epoch: 1674, cost 22.36 s
2024-01-02 04:35:45,634	44k	INFO	====> Epoch: 1675, cost 22.37 s
2024-01-02 04:36:08,007	44k	INFO	====> Epoch: 1676, cost 22.37 s
2024-01-02 04:36:30,305	44k	INFO	====> Epoch: 1677, cost 22.30 s
2024-01-02 04:36:52,746	44k	INFO	====> Epoch: 1678, cost 22.44 s
2024-01-02 04:37:15,050	44k	INFO	====> Epoch: 1679, cost 22.30 s
2024-01-02 04:37:37,363	44k	INFO	Train Epoch: 1680 [96%]
2024-01-02 04:37:37,365	44k	INFO	Losses: [2.0920639038085938, 2.736236810684204, 6.6987385749816895, 13.004356384277344, -0.4794510006904602], step: 42000, lr: 8.106749406026473e-05, reference_loss: 24.051944732666016
2024-01-02 04:37:37,756	44k	INFO	====> Epoch: 1680, cost 22.71 s
2024-01-02 04:38:00,016	44k	INFO	====> Epoch: 1681, cost 22.26 s
2024-01-02 04:38:22,246	44k	INFO	====> Epoch: 1682, cost 22.23 s
2024-01-02 04:38:44,524	44k	INFO	====> Epoch: 1683, cost 22.28 s
2024-01-02 04:39:06,827	44k	INFO	====> Epoch: 1684, cost 22.30 s
2024-01-02 04:39:29,143	44k	INFO	====> Epoch: 1685, cost 22.32 s
2024-01-02 04:39:51,438	44k	INFO	====> Epoch: 1686, cost 22.30 s
2024-01-02 04:40:13,727	44k	INFO	====> Epoch: 1687, cost 22.29 s
2024-01-02 04:40:36,112	44k	INFO	Train Epoch: 1688 [96%]
2024-01-02 04:40:36,114	44k	INFO	Losses: [1.927886724472046, 2.9064908027648926, 9.435295104980469, 15.169800758361816, -0.6187911629676819], step: 42200, lr: 8.098646202436773e-05, reference_loss: 28.820680618286133
2024-01-02 04:40:36,598	44k	INFO	====> Epoch: 1688, cost 22.87 s
2024-01-02 04:40:58,719	44k	INFO	====> Epoch: 1689, cost 22.12 s
2024-01-02 04:41:20,829	44k	INFO	====> Epoch: 1690, cost 22.11 s
2024-01-02 04:41:42,951	44k	INFO	====> Epoch: 1691, cost 22.12 s
2024-01-02 04:42:05,104	44k	INFO	====> Epoch: 1692, cost 22.15 s
2024-01-02 04:42:27,350	44k	INFO	====> Epoch: 1693, cost 22.25 s
2024-01-02 04:42:49,582	44k	INFO	====> Epoch: 1694, cost 22.23 s
2024-01-02 04:43:11,815	44k	INFO	====> Epoch: 1695, cost 22.23 s
2024-01-02 04:43:34,037	44k	INFO	Train Epoch: 1696 [96%]
2024-01-02 04:43:34,038	44k	INFO	Losses: [2.11599063873291, 2.587430477142334, 6.8344011306762695, 13.581396102905273, -0.6312900185585022], step: 42400, lr: 8.090551098506395e-05, reference_loss: 24.48792839050293
2024-01-02 04:43:40,135	44k	INFO	Saving model and optimizer state at iteration 1696 to ./logs/44k/G_42400.pth
2024-01-02 04:43:41,044	44k	INFO	Saving model and optimizer state at iteration 1696 to ./logs/44k/D_42400.pth
2024-01-02 04:43:41,548	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_40000.pth
2024-01-02 04:43:41,587	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_40000.pth
2024-01-02 04:43:41,588	44k	INFO	====> Epoch: 1696, cost 29.77 s
2024-01-02 04:44:03,750	44k	INFO	====> Epoch: 1697, cost 22.16 s
2024-01-02 04:44:25,830	44k	INFO	====> Epoch: 1698, cost 22.08 s
2024-01-02 04:44:47,964	44k	INFO	====> Epoch: 1699, cost 22.13 s
2024-01-02 04:45:10,231	44k	INFO	====> Epoch: 1700, cost 22.27 s
2024-01-02 04:45:32,482	44k	INFO	====> Epoch: 1701, cost 22.25 s
2024-01-02 04:45:54,736	44k	INFO	====> Epoch: 1702, cost 22.25 s
2024-01-02 04:46:17,029	44k	INFO	====> Epoch: 1703, cost 22.29 s
2024-01-02 04:46:39,345	44k	INFO	Train Epoch: 1704 [96%]
2024-01-02 04:46:39,347	44k	INFO	Losses: [2.006432294845581, 2.9973342418670654, 8.929733276367188, 15.23496150970459, -0.5388742089271545], step: 42600, lr: 8.082464086139226e-05, reference_loss: 28.629587173461914
2024-01-02 04:46:39,749	44k	INFO	====> Epoch: 1704, cost 22.72 s
2024-01-02 04:47:02,062	44k	INFO	====> Epoch: 1705, cost 22.31 s
2024-01-02 04:47:24,375	44k	INFO	====> Epoch: 1706, cost 22.31 s
2024-01-02 04:47:46,693	44k	INFO	====> Epoch: 1707, cost 22.32 s
2024-01-02 04:48:09,119	44k	INFO	====> Epoch: 1708, cost 22.43 s
2024-01-02 04:48:31,254	44k	INFO	====> Epoch: 1709, cost 22.13 s
2024-01-02 04:48:53,517	44k	INFO	====> Epoch: 1710, cost 22.26 s
2024-01-02 04:49:15,728	44k	INFO	====> Epoch: 1711, cost 22.21 s
2024-01-02 04:49:37,828	44k	INFO	Train Epoch: 1712 [96%]
2024-01-02 04:49:37,830	44k	INFO	Losses: [2.1529347896575928, 2.6785597801208496, 6.219026565551758, 11.989401817321777, -0.5143431425094604], step: 42800, lr: 8.074385157247243e-05, reference_loss: 22.52557945251465
2024-01-02 04:49:38,224	44k	INFO	====> Epoch: 1712, cost 22.50 s
2024-01-02 04:50:00,350	44k	INFO	====> Epoch: 1713, cost 22.13 s
2024-01-02 04:50:22,492	44k	INFO	====> Epoch: 1714, cost 22.14 s
2024-01-02 04:50:44,692	44k	INFO	====> Epoch: 1715, cost 22.20 s
2024-01-02 04:51:06,854	44k	INFO	====> Epoch: 1716, cost 22.16 s
2024-01-02 04:51:28,962	44k	INFO	====> Epoch: 1717, cost 22.11 s
2024-01-02 04:51:51,227	44k	INFO	====> Epoch: 1718, cost 22.26 s
2024-01-02 04:52:13,417	44k	INFO	====> Epoch: 1719, cost 22.19 s
2024-01-02 04:52:35,700	44k	INFO	Train Epoch: 1720 [96%]
2024-01-02 04:52:35,702	44k	INFO	Losses: [1.9452979564666748, 3.0098443031311035, 8.865519523620605, 14.37723159790039, -0.6360076665878296], step: 43000, lr: 8.066314303750501e-05, reference_loss: 27.561885833740234
2024-01-02 04:52:36,098	44k	INFO	====> Epoch: 1720, cost 22.68 s
2024-01-02 04:52:58,396	44k	INFO	====> Epoch: 1721, cost 22.30 s
2024-01-02 04:53:20,661	44k	INFO	====> Epoch: 1722, cost 22.26 s
2024-01-02 04:53:42,900	44k	INFO	====> Epoch: 1723, cost 22.24 s
2024-01-02 04:54:05,124	44k	INFO	====> Epoch: 1724, cost 22.22 s
2024-01-02 04:54:27,345	44k	INFO	====> Epoch: 1725, cost 22.22 s
2024-01-02 04:54:49,463	44k	INFO	====> Epoch: 1726, cost 22.12 s
2024-01-02 04:55:11,561	44k	INFO	====> Epoch: 1727, cost 22.10 s
2024-01-02 04:55:33,783	44k	INFO	Train Epoch: 1728 [96%]
2024-01-02 04:55:33,785	44k	INFO	Losses: [2.178419351577759, 2.8322784900665283, 7.973470687866211, 13.605768203735352, -0.6871386766433716], step: 43200, lr: 8.058251517577144e-05, reference_loss: 25.90279769897461
2024-01-02 04:55:39,610	44k	INFO	Saving model and optimizer state at iteration 1728 to ./logs/44k/G_43200.pth
2024-01-02 04:55:40,520	44k	INFO	Saving model and optimizer state at iteration 1728 to ./logs/44k/D_43200.pth
2024-01-02 04:55:41,019	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_40800.pth
2024-01-02 04:55:41,057	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_40800.pth
2024-01-02 04:55:41,058	44k	INFO	====> Epoch: 1728, cost 29.50 s
2024-01-02 04:56:03,062	44k	INFO	====> Epoch: 1729, cost 22.00 s
2024-01-02 04:56:25,160	44k	INFO	====> Epoch: 1730, cost 22.10 s
2024-01-02 04:56:47,280	44k	INFO	====> Epoch: 1731, cost 22.12 s
2024-01-02 04:57:09,397	44k	INFO	====> Epoch: 1732, cost 22.12 s
2024-01-02 04:57:31,483	44k	INFO	====> Epoch: 1733, cost 22.09 s
2024-01-02 04:57:53,582	44k	INFO	====> Epoch: 1734, cost 22.10 s
2024-01-02 04:58:15,855	44k	INFO	====> Epoch: 1735, cost 22.27 s
2024-01-02 04:58:38,068	44k	INFO	Train Epoch: 1736 [96%]
2024-01-02 04:58:38,070	44k	INFO	Losses: [2.100123882293701, 2.9362332820892334, 7.564298152923584, 13.813712120056152, -0.5270237922668457], step: 43400, lr: 8.05019679066337e-05, reference_loss: 25.887344360351562
2024-01-02 04:58:38,455	44k	INFO	====> Epoch: 1736, cost 22.60 s
2024-01-02 04:59:00,658	44k	INFO	====> Epoch: 1737, cost 22.20 s
2024-01-02 04:59:22,871	44k	INFO	====> Epoch: 1738, cost 22.21 s
2024-01-02 04:59:45,098	44k	INFO	====> Epoch: 1739, cost 22.23 s
2024-01-02 05:00:07,358	44k	INFO	====> Epoch: 1740, cost 22.26 s
2024-01-02 05:00:29,523	44k	INFO	====> Epoch: 1741, cost 22.16 s
2024-01-02 05:00:51,801	44k	INFO	====> Epoch: 1742, cost 22.28 s
2024-01-02 05:01:14,069	44k	INFO	====> Epoch: 1743, cost 22.27 s
2024-01-02 05:01:36,322	44k	INFO	Train Epoch: 1744 [96%]
2024-01-02 05:01:36,324	44k	INFO	Losses: [2.043031692504883, 2.7685532569885254, 7.475341796875, 13.680675506591797, -0.5149752497673035], step: 43600, lr: 8.042150114953448e-05, reference_loss: 25.452627182006836
2024-01-02 05:01:36,899	44k	INFO	====> Epoch: 1744, cost 22.83 s
2024-01-02 05:01:59,078	44k	INFO	====> Epoch: 1745, cost 22.18 s
2024-01-02 05:02:21,320	44k	INFO	====> Epoch: 1746, cost 22.24 s
2024-01-02 05:02:43,474	44k	INFO	====> Epoch: 1747, cost 22.15 s
2024-01-02 05:03:05,623	44k	INFO	====> Epoch: 1748, cost 22.15 s
2024-01-02 05:03:27,766	44k	INFO	====> Epoch: 1749, cost 22.14 s
2024-01-02 05:03:49,933	44k	INFO	====> Epoch: 1750, cost 22.17 s
2024-01-02 05:04:12,102	44k	INFO	====> Epoch: 1751, cost 22.17 s
2024-01-02 05:04:34,419	44k	INFO	Train Epoch: 1752 [96%]
2024-01-02 05:04:34,421	44k	INFO	Losses: [1.9744621515274048, 2.8702056407928467, 8.857147216796875, 14.067676544189453, -0.6767380833625793], step: 43800, lr: 8.034111482399694e-05, reference_loss: 27.09275245666504
2024-01-02 05:04:34,903	44k	INFO	====> Epoch: 1752, cost 22.80 s
2024-01-02 05:04:57,266	44k	INFO	====> Epoch: 1753, cost 22.36 s
2024-01-02 05:05:19,816	44k	INFO	====> Epoch: 1754, cost 22.55 s
2024-01-02 05:05:42,183	44k	INFO	====> Epoch: 1755, cost 22.37 s
2024-01-02 05:06:04,395	44k	INFO	====> Epoch: 1756, cost 22.21 s
2024-01-02 05:06:26,519	44k	INFO	====> Epoch: 1757, cost 22.12 s
2024-01-02 05:06:48,664	44k	INFO	====> Epoch: 1758, cost 22.14 s
2024-01-02 05:07:10,805	44k	INFO	====> Epoch: 1759, cost 22.14 s
2024-01-02 05:07:32,941	44k	INFO	Train Epoch: 1760 [96%]
2024-01-02 05:07:32,943	44k	INFO	Losses: [2.1987674236297607, 2.629284620285034, 6.444092273712158, 13.351690292358398, -0.7189896106719971], step: 44000, lr: 8.026080884962472e-05, reference_loss: 23.904844284057617
2024-01-02 05:07:38,707	44k	INFO	Saving model and optimizer state at iteration 1760 to ./logs/44k/G_44000.pth
2024-01-02 05:07:39,638	44k	INFO	Saving model and optimizer state at iteration 1760 to ./logs/44k/D_44000.pth
2024-01-02 05:07:40,135	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_41600.pth
2024-01-02 05:07:40,174	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_41600.pth
2024-01-02 05:07:40,174	44k	INFO	====> Epoch: 1760, cost 29.37 s
2024-01-02 05:08:02,269	44k	INFO	====> Epoch: 1761, cost 22.09 s
2024-01-02 05:08:24,644	44k	INFO	====> Epoch: 1762, cost 22.38 s
2024-01-02 05:08:46,916	44k	INFO	====> Epoch: 1763, cost 22.27 s
2024-01-02 05:09:09,207	44k	INFO	====> Epoch: 1764, cost 22.29 s
2024-01-02 05:09:31,521	44k	INFO	====> Epoch: 1765, cost 22.31 s
2024-01-02 05:09:53,823	44k	INFO	====> Epoch: 1766, cost 22.30 s
2024-01-02 05:10:16,171	44k	INFO	====> Epoch: 1767, cost 22.35 s
2024-01-02 05:10:38,555	44k	INFO	Train Epoch: 1768 [96%]
2024-01-02 05:10:38,557	44k	INFO	Losses: [1.9639458656311035, 2.930022954940796, 8.315122604370117, 15.097379684448242, -0.6118534207344055], step: 44200, lr: 8.01805831461018e-05, reference_loss: 27.694618225097656
2024-01-02 05:10:38,941	44k	INFO	====> Epoch: 1768, cost 22.77 s
2024-01-02 05:11:01,102	44k	INFO	====> Epoch: 1769, cost 22.16 s
2024-01-02 05:11:23,300	44k	INFO	====> Epoch: 1770, cost 22.20 s
2024-01-02 05:11:45,522	44k	INFO	====> Epoch: 1771, cost 22.22 s
2024-01-02 05:12:07,801	44k	INFO	====> Epoch: 1772, cost 22.28 s
2024-01-02 05:12:30,087	44k	INFO	====> Epoch: 1773, cost 22.29 s
2024-01-02 05:12:52,401	44k	INFO	====> Epoch: 1774, cost 22.31 s
2024-01-02 05:13:14,618	44k	INFO	====> Epoch: 1775, cost 22.22 s
2024-01-02 05:13:36,954	44k	INFO	Train Epoch: 1776 [96%]
2024-01-02 05:13:36,956	44k	INFO	Losses: [2.0149717330932617, 2.6151223182678223, 7.391304016113281, 13.664962768554688, -0.47245872020721436], step: 44400, lr: 8.010043763319242e-05, reference_loss: 25.213903427124023
2024-01-02 05:13:37,436	44k	INFO	====> Epoch: 1776, cost 22.82 s
2024-01-02 05:13:59,748	44k	INFO	====> Epoch: 1777, cost 22.31 s
2024-01-02 05:14:22,019	44k	INFO	====> Epoch: 1778, cost 22.27 s
2024-01-02 05:14:44,203	44k	INFO	====> Epoch: 1779, cost 22.18 s
2024-01-02 05:15:06,514	44k	INFO	====> Epoch: 1780, cost 22.31 s
2024-01-02 05:15:28,868	44k	INFO	====> Epoch: 1781, cost 22.35 s
2024-01-02 05:15:51,156	44k	INFO	====> Epoch: 1782, cost 22.29 s
2024-01-02 05:16:13,360	44k	INFO	====> Epoch: 1783, cost 22.20 s
2024-01-02 05:16:35,547	44k	INFO	Train Epoch: 1784 [96%]
2024-01-02 05:16:35,548	44k	INFO	Losses: [1.941399335861206, 2.9327549934387207, 9.202741622924805, 14.816990852355957, -0.7168447375297546], step: 44600, lr: 8.002037223074105e-05, reference_loss: 28.17704200744629
2024-01-02 05:16:36,115	44k	INFO	====> Epoch: 1784, cost 22.76 s
2024-01-02 05:16:58,318	44k	INFO	====> Epoch: 1785, cost 22.20 s
2024-01-02 05:17:20,560	44k	INFO	====> Epoch: 1786, cost 22.24 s
2024-01-02 05:17:42,815	44k	INFO	====> Epoch: 1787, cost 22.25 s
2024-01-02 05:18:05,077	44k	INFO	====> Epoch: 1788, cost 22.26 s
2024-01-02 05:18:27,344	44k	INFO	====> Epoch: 1789, cost 22.27 s
2024-01-02 05:18:49,593	44k	INFO	====> Epoch: 1790, cost 22.25 s
2024-01-02 05:19:11,722	44k	INFO	====> Epoch: 1791, cost 22.13 s
2024-01-02 05:19:33,860	44k	INFO	Train Epoch: 1792 [96%]
2024-01-02 05:19:33,861	44k	INFO	Losses: [2.288198709487915, 2.3831958770751953, 6.368560791015625, 12.837713241577148, -0.7491910457611084], step: 44800, lr: 7.994038685867228e-05, reference_loss: 23.128477096557617
2024-01-02 05:19:39,936	44k	INFO	Saving model and optimizer state at iteration 1792 to ./logs/44k/G_44800.pth
2024-01-02 05:19:40,848	44k	INFO	Saving model and optimizer state at iteration 1792 to ./logs/44k/D_44800.pth
2024-01-02 05:19:41,342	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_42400.pth
2024-01-02 05:19:41,381	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_42400.pth
2024-01-02 05:19:41,381	44k	INFO	====> Epoch: 1792, cost 29.66 s
2024-01-02 05:20:03,496	44k	INFO	====> Epoch: 1793, cost 22.12 s
2024-01-02 05:20:25,819	44k	INFO	====> Epoch: 1794, cost 22.32 s
2024-01-02 05:20:48,132	44k	INFO	====> Epoch: 1795, cost 22.31 s
2024-01-02 05:21:10,396	44k	INFO	====> Epoch: 1796, cost 22.26 s
2024-01-02 05:21:32,505	44k	INFO	====> Epoch: 1797, cost 22.11 s
2024-01-02 05:21:54,637	44k	INFO	====> Epoch: 1798, cost 22.13 s
2024-01-02 05:22:16,776	44k	INFO	====> Epoch: 1799, cost 22.14 s
2024-01-02 05:22:38,957	44k	INFO	Train Epoch: 1800 [96%]
2024-01-02 05:22:38,958	44k	INFO	Losses: [1.8505977392196655, 3.3345868587493896, 9.42653751373291, 15.378597259521484, -0.5828086137771606], step: 45000, lr: 7.986048143699072e-05, reference_loss: 29.407508850097656
2024-01-02 05:22:39,354	44k	INFO	====> Epoch: 1800, cost 22.58 s
2024-01-02 05:23:01,584	44k	INFO	====> Epoch: 1801, cost 22.23 s
2024-01-02 05:23:23,902	44k	INFO	====> Epoch: 1802, cost 22.32 s
2024-01-02 05:23:46,188	44k	INFO	====> Epoch: 1803, cost 22.29 s
2024-01-02 05:24:08,519	44k	INFO	====> Epoch: 1804, cost 22.33 s
2024-01-02 05:24:30,637	44k	INFO	====> Epoch: 1805, cost 22.12 s
2024-01-02 05:24:52,779	44k	INFO	====> Epoch: 1806, cost 22.14 s
2024-01-02 05:25:14,916	44k	INFO	====> Epoch: 1807, cost 22.14 s
2024-01-02 05:25:37,033	44k	INFO	Train Epoch: 1808 [96%]
2024-01-02 05:25:37,035	44k	INFO	Losses: [2.033238172531128, 2.7536067962646484, 7.55269718170166, 13.826603889465332, -0.5533116459846497], step: 45200, lr: 7.978065588578095e-05, reference_loss: 25.61283302307129
2024-01-02 05:25:37,421	44k	INFO	====> Epoch: 1808, cost 22.50 s
2024-01-02 05:25:59,657	44k	INFO	====> Epoch: 1809, cost 22.24 s
2024-01-02 05:26:21,964	44k	INFO	====> Epoch: 1810, cost 22.31 s
2024-01-02 05:26:44,250	44k	INFO	====> Epoch: 1811, cost 22.29 s
2024-01-02 05:27:06,521	44k	INFO	====> Epoch: 1812, cost 22.27 s
2024-01-02 05:27:28,813	44k	INFO	====> Epoch: 1813, cost 22.29 s
2024-01-02 05:27:51,160	44k	INFO	====> Epoch: 1814, cost 22.35 s
2024-01-02 05:28:13,289	44k	INFO	====> Epoch: 1815, cost 22.13 s
2024-01-02 05:28:35,404	44k	INFO	Train Epoch: 1816 [96%]
2024-01-02 05:28:35,406	44k	INFO	Losses: [1.9346826076507568, 2.8090808391571045, 8.485401153564453, 13.645318984985352, -0.7182512879371643], step: 45400, lr: 7.970091012520744e-05, reference_loss: 26.156230926513672
2024-01-02 05:28:35,793	44k	INFO	====> Epoch: 1816, cost 22.50 s
2024-01-02 05:28:57,909	44k	INFO	====> Epoch: 1817, cost 22.12 s
2024-01-02 05:29:20,134	44k	INFO	====> Epoch: 1818, cost 22.22 s
2024-01-02 05:29:42,311	44k	INFO	====> Epoch: 1819, cost 22.18 s
2024-01-02 05:30:04,423	44k	INFO	====> Epoch: 1820, cost 22.11 s
2024-01-02 05:30:26,625	44k	INFO	====> Epoch: 1821, cost 22.20 s
2024-01-02 05:30:48,901	44k	INFO	====> Epoch: 1822, cost 22.28 s
2024-01-02 05:31:11,172	44k	INFO	====> Epoch: 1823, cost 22.27 s
2024-01-02 05:31:33,590	44k	INFO	Train Epoch: 1824 [96%]
2024-01-02 05:31:33,592	44k	INFO	Losses: [2.1120564937591553, 2.639577865600586, 6.992373466491699, 13.141818046569824, -0.7257211208343506], step: 45600, lr: 7.962124407551444e-05, reference_loss: 24.160104751586914
2024-01-02 05:31:39,391	44k	INFO	Saving model and optimizer state at iteration 1824 to ./logs/44k/G_45600.pth
2024-01-02 05:31:40,312	44k	INFO	Saving model and optimizer state at iteration 1824 to ./logs/44k/D_45600.pth
2024-01-02 05:31:40,811	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_43200.pth
2024-01-02 05:31:40,850	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_43200.pth
2024-01-02 05:31:40,850	44k	INFO	====> Epoch: 1824, cost 29.68 s
2024-01-02 05:32:02,931	44k	INFO	====> Epoch: 1825, cost 22.08 s
2024-01-02 05:32:24,998	44k	INFO	====> Epoch: 1826, cost 22.07 s
2024-01-02 05:32:47,142	44k	INFO	====> Epoch: 1827, cost 22.14 s
2024-01-02 05:33:09,362	44k	INFO	====> Epoch: 1828, cost 22.22 s
2024-01-02 05:33:31,588	44k	INFO	====> Epoch: 1829, cost 22.23 s
2024-01-02 05:33:53,843	44k	INFO	====> Epoch: 1830, cost 22.25 s
2024-01-02 05:34:16,270	44k	INFO	====> Epoch: 1831, cost 22.43 s
2024-01-02 05:34:38,508	44k	INFO	Train Epoch: 1832 [96%]
2024-01-02 05:34:38,510	44k	INFO	Losses: [2.0050406455993652, 2.9257631301879883, 8.256980895996094, 14.143791198730469, -0.6266894936561584], step: 45800, lr: 7.954165765702597e-05, reference_loss: 26.704885482788086
2024-01-02 05:34:38,905	44k	INFO	====> Epoch: 1832, cost 22.64 s
2024-01-02 05:35:01,141	44k	INFO	====> Epoch: 1833, cost 22.24 s
2024-01-02 05:35:23,273	44k	INFO	====> Epoch: 1834, cost 22.13 s
2024-01-02 05:35:45,450	44k	INFO	====> Epoch: 1835, cost 22.18 s
2024-01-02 05:36:07,558	44k	INFO	====> Epoch: 1836, cost 22.11 s
2024-01-02 05:36:29,773	44k	INFO	====> Epoch: 1837, cost 22.21 s
2024-01-02 05:36:51,963	44k	INFO	====> Epoch: 1838, cost 22.19 s
2024-01-02 05:37:14,180	44k	INFO	====> Epoch: 1839, cost 22.22 s
2024-01-02 05:37:36,397	44k	INFO	Train Epoch: 1840 [96%]
2024-01-02 05:37:36,398	44k	INFO	Losses: [2.048487663269043, 2.7649028301239014, 7.665260314941406, 13.590438842773438, -0.5921423435211182], step: 46000, lr: 7.946215079014563e-05, reference_loss: 25.476947784423828
2024-01-02 05:37:36,978	44k	INFO	====> Epoch: 1840, cost 22.80 s
2024-01-02 05:37:59,216	44k	INFO	====> Epoch: 1841, cost 22.24 s
2024-01-02 05:38:21,495	44k	INFO	====> Epoch: 1842, cost 22.28 s
2024-01-02 05:38:43,835	44k	INFO	====> Epoch: 1843, cost 22.34 s
2024-01-02 05:39:06,154	44k	INFO	====> Epoch: 1844, cost 22.32 s
2024-01-02 05:39:28,411	44k	INFO	====> Epoch: 1845, cost 22.26 s
2024-01-02 05:39:50,669	44k	INFO	====> Epoch: 1846, cost 22.26 s
2024-01-02 05:40:12,944	44k	INFO	====> Epoch: 1847, cost 22.27 s
2024-01-02 05:40:35,166	44k	INFO	Train Epoch: 1848 [96%]
2024-01-02 05:40:35,167	44k	INFO	Losses: [2.0155630111694336, 2.8210105895996094, 9.506807327270508, 14.661802291870117, -0.7226929664611816], step: 46200, lr: 7.938272339535662e-05, reference_loss: 28.28249168395996
2024-01-02 05:40:35,569	44k	INFO	====> Epoch: 1848, cost 22.62 s
2024-01-02 05:40:57,747	44k	INFO	====> Epoch: 1849, cost 22.18 s
2024-01-02 05:41:19,981	44k	INFO	====> Epoch: 1850, cost 22.23 s
2024-01-02 05:41:42,198	44k	INFO	====> Epoch: 1851, cost 22.22 s
2024-01-02 05:42:04,347	44k	INFO	====> Epoch: 1852, cost 22.15 s
2024-01-02 05:42:26,438	44k	INFO	====> Epoch: 1853, cost 22.09 s
2024-01-02 05:42:48,540	44k	INFO	====> Epoch: 1854, cost 22.10 s
2024-01-02 05:43:10,681	44k	INFO	====> Epoch: 1855, cost 22.14 s
2024-01-02 05:43:32,870	44k	INFO	Train Epoch: 1856 [96%]
2024-01-02 05:43:32,872	44k	INFO	Losses: [2.077888250350952, 2.6543033123016357, 6.7454915046691895, 12.906518936157227, -0.7876545190811157], step: 46400, lr: 7.93033753932216e-05, reference_loss: 23.596546173095703
2024-01-02 05:43:38,855	44k	INFO	Saving model and optimizer state at iteration 1856 to ./logs/44k/G_46400.pth
2024-01-02 05:43:39,761	44k	INFO	Saving model and optimizer state at iteration 1856 to ./logs/44k/D_46400.pth
2024-01-02 05:43:40,267	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_44000.pth
2024-01-02 05:43:40,306	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_44000.pth
2024-01-02 05:43:40,306	44k	INFO	====> Epoch: 1856, cost 29.63 s
2024-01-02 05:44:02,518	44k	INFO	====> Epoch: 1857, cost 22.21 s
2024-01-02 05:44:24,912	44k	INFO	====> Epoch: 1858, cost 22.39 s
2024-01-02 05:44:47,099	44k	INFO	====> Epoch: 1859, cost 22.19 s
2024-01-02 05:45:09,336	44k	INFO	====> Epoch: 1860, cost 22.24 s
2024-01-02 05:45:31,593	44k	INFO	====> Epoch: 1861, cost 22.26 s
2024-01-02 05:45:53,844	44k	INFO	====> Epoch: 1862, cost 22.25 s
2024-01-02 05:46:16,100	44k	INFO	====> Epoch: 1863, cost 22.26 s
2024-01-02 05:46:38,280	44k	INFO	Train Epoch: 1864 [96%]
2024-01-02 05:46:38,282	44k	INFO	Losses: [2.0301756858825684, 3.1425087451934814, 8.480387687683105, 14.615754127502441, -0.6670589447021484], step: 46600, lr: 7.922410670438265e-05, reference_loss: 27.60176658630371
2024-01-02 05:46:38,679	44k	INFO	====> Epoch: 1864, cost 22.58 s
2024-01-02 05:47:00,812	44k	INFO	====> Epoch: 1865, cost 22.13 s
2024-01-02 05:47:22,978	44k	INFO	====> Epoch: 1866, cost 22.17 s
2024-01-02 05:47:45,291	44k	INFO	====> Epoch: 1867, cost 22.31 s
2024-01-02 05:48:07,589	44k	INFO	====> Epoch: 1868, cost 22.30 s
2024-01-02 05:48:29,826	44k	INFO	====> Epoch: 1869, cost 22.24 s
2024-01-02 05:48:52,108	44k	INFO	====> Epoch: 1870, cost 22.28 s
2024-01-02 05:49:14,300	44k	INFO	====> Epoch: 1871, cost 22.19 s
2024-01-02 05:49:36,517	44k	INFO	Train Epoch: 1872 [96%]
2024-01-02 05:49:36,519	44k	INFO	Losses: [2.0623042583465576, 2.6940155029296875, 7.559694766998291, 13.413000106811523, -0.6489851474761963], step: 46800, lr: 7.914491724956114e-05, reference_loss: 25.08003044128418
2024-01-02 05:49:36,919	44k	INFO	====> Epoch: 1872, cost 22.62 s
2024-01-02 05:49:59,200	44k	INFO	====> Epoch: 1873, cost 22.28 s
2024-01-02 05:50:21,466	44k	INFO	====> Epoch: 1874, cost 22.27 s
2024-01-02 05:50:43,770	44k	INFO	====> Epoch: 1875, cost 22.30 s
2024-01-02 05:51:06,053	44k	INFO	====> Epoch: 1876, cost 22.28 s
2024-01-02 05:51:28,210	44k	INFO	====> Epoch: 1877, cost 22.16 s
2024-01-02 05:51:50,516	44k	INFO	====> Epoch: 1878, cost 22.31 s
2024-01-02 05:52:12,815	44k	INFO	====> Epoch: 1879, cost 22.30 s
2024-01-02 05:52:35,218	44k	INFO	Train Epoch: 1880 [96%]
2024-01-02 05:52:35,220	44k	INFO	Losses: [1.8771021366119385, 2.8100366592407227, 8.649544715881348, 14.036605834960938, -0.7327709794044495], step: 47000, lr: 7.906580694955773e-05, reference_loss: 26.640518188476562
2024-01-02 05:52:35,604	44k	INFO	====> Epoch: 1880, cost 22.79 s
2024-01-02 05:52:57,739	44k	INFO	====> Epoch: 1881, cost 22.14 s
2024-01-02 05:53:19,877	44k	INFO	====> Epoch: 1882, cost 22.14 s
2024-01-02 05:53:42,020	44k	INFO	====> Epoch: 1883, cost 22.14 s
2024-01-02 05:54:04,171	44k	INFO	====> Epoch: 1884, cost 22.15 s
2024-01-02 05:54:26,443	44k	INFO	====> Epoch: 1885, cost 22.27 s
2024-01-02 05:54:48,723	44k	INFO	====> Epoch: 1886, cost 22.28 s
2024-01-02 05:55:11,005	44k	INFO	====> Epoch: 1887, cost 22.28 s
2024-01-02 05:55:33,273	44k	INFO	Train Epoch: 1888 [96%]
2024-01-02 05:55:33,274	44k	INFO	Losses: [2.1028270721435547, 2.713472604751587, 7.777655124664307, 13.395380973815918, -0.8162776231765747], step: 47200, lr: 7.89867757252522e-05, reference_loss: 25.17305564880371
2024-01-02 05:55:39,286	44k	INFO	Saving model and optimizer state at iteration 1888 to ./logs/44k/G_47200.pth
2024-01-02 05:55:40,190	44k	INFO	Saving model and optimizer state at iteration 1888 to ./logs/44k/D_47200.pth
2024-01-02 05:55:40,687	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_44800.pth
2024-01-02 05:55:40,726	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_44800.pth
2024-01-02 05:55:40,726	44k	INFO	====> Epoch: 1888, cost 29.72 s
2024-01-02 05:56:02,786	44k	INFO	====> Epoch: 1889, cost 22.06 s
2024-01-02 05:56:25,058	44k	INFO	====> Epoch: 1890, cost 22.27 s
2024-01-02 05:56:47,333	44k	INFO	====> Epoch: 1891, cost 22.27 s
2024-01-02 05:57:09,599	44k	INFO	====> Epoch: 1892, cost 22.27 s
2024-01-02 05:57:31,859	44k	INFO	====> Epoch: 1893, cost 22.26 s
2024-01-02 05:57:54,153	44k	INFO	====> Epoch: 1894, cost 22.29 s
2024-01-02 05:58:16,541	44k	INFO	====> Epoch: 1895, cost 22.39 s
2024-01-02 05:58:38,796	44k	INFO	Train Epoch: 1896 [96%]
2024-01-02 05:58:38,798	44k	INFO	Losses: [1.9486002922058105, 3.1066970825195312, 7.867796421051025, 13.738795280456543, -0.7045710682868958], step: 47400, lr: 7.890782349760348e-05, reference_loss: 25.957317352294922
2024-01-02 05:58:39,181	44k	INFO	====> Epoch: 1896, cost 22.64 s
2024-01-02 05:59:01,433	44k	INFO	====> Epoch: 1897, cost 22.25 s
2024-01-02 05:59:23,719	44k	INFO	====> Epoch: 1898, cost 22.29 s
2024-01-02 05:59:45,918	44k	INFO	====> Epoch: 1899, cost 22.20 s
2024-01-02 06:00:08,206	44k	INFO	====> Epoch: 1900, cost 22.29 s
2024-01-02 06:00:30,403	44k	INFO	====> Epoch: 1901, cost 22.20 s
2024-01-02 06:00:52,545	44k	INFO	====> Epoch: 1902, cost 22.14 s
2024-01-02 06:01:14,743	44k	INFO	====> Epoch: 1903, cost 22.20 s
2024-01-02 06:01:36,865	44k	INFO	Train Epoch: 1904 [96%]
2024-01-02 06:01:36,867	44k	INFO	Losses: [2.0974414348602295, 2.5079073905944824, 6.728122711181641, 12.6076078414917, -0.7156453728675842], step: 47600, lr: 7.882895018764944e-05, reference_loss: 23.225433349609375
2024-01-02 06:01:37,257	44k	INFO	====> Epoch: 1904, cost 22.51 s
2024-01-02 06:01:59,367	44k	INFO	====> Epoch: 1905, cost 22.11 s
2024-01-02 06:02:21,495	44k	INFO	====> Epoch: 1906, cost 22.13 s
2024-01-02 06:02:43,622	44k	INFO	====> Epoch: 1907, cost 22.13 s
2024-01-02 06:03:05,816	44k	INFO	====> Epoch: 1908, cost 22.19 s
2024-01-02 06:03:28,176	44k	INFO	====> Epoch: 1909, cost 22.36 s
2024-01-02 06:03:50,683	44k	INFO	====> Epoch: 1910, cost 22.51 s
2024-01-02 06:04:12,886	44k	INFO	====> Epoch: 1911, cost 22.20 s
2024-01-02 06:04:35,153	44k	INFO	Train Epoch: 1912 [96%]
2024-01-02 06:04:35,155	44k	INFO	Losses: [1.9212968349456787, 2.840494394302368, 8.668506622314453, 13.471110343933105, -0.8412030339241028], step: 47800, lr: 7.87501557165069e-05, reference_loss: 26.060205459594727
2024-01-02 06:04:35,542	44k	INFO	====> Epoch: 1912, cost 22.66 s
2024-01-02 06:04:57,815	44k	INFO	====> Epoch: 1913, cost 22.27 s
2024-01-02 06:05:20,097	44k	INFO	====> Epoch: 1914, cost 22.28 s
2024-01-02 06:05:42,369	44k	INFO	====> Epoch: 1915, cost 22.27 s
2024-01-02 06:06:04,637	44k	INFO	====> Epoch: 1916, cost 22.27 s
2024-01-02 06:06:26,889	44k	INFO	====> Epoch: 1917, cost 22.25 s
2024-01-02 06:06:49,158	44k	INFO	====> Epoch: 1918, cost 22.27 s
2024-01-02 06:07:11,380	44k	INFO	====> Epoch: 1919, cost 22.22 s
2024-01-02 06:07:33,644	44k	INFO	Train Epoch: 1920 [96%]
2024-01-02 06:07:33,645	44k	INFO	Losses: [1.9520196914672852, 2.9579670429229736, 8.138810157775879, 13.865155220031738, -0.8698672652244568], step: 48000, lr: 7.867144000537153e-05, reference_loss: 26.044084548950195
2024-01-02 06:07:39,494	44k	INFO	Saving model and optimizer state at iteration 1920 to ./logs/44k/G_48000.pth
2024-01-02 06:07:40,392	44k	INFO	Saving model and optimizer state at iteration 1920 to ./logs/44k/D_48000.pth
2024-01-02 06:07:40,893	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_45600.pth
2024-01-02 06:07:40,933	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_45600.pth
2024-01-02 06:07:40,933	44k	INFO	====> Epoch: 1920, cost 29.55 s
2024-01-02 06:08:03,124	44k	INFO	====> Epoch: 1921, cost 22.19 s
2024-01-02 06:08:25,281	44k	INFO	====> Epoch: 1922, cost 22.16 s
2024-01-02 06:08:47,413	44k	INFO	====> Epoch: 1923, cost 22.13 s
2024-01-02 06:09:09,669	44k	INFO	====> Epoch: 1924, cost 22.26 s
2024-01-02 06:09:31,910	44k	INFO	====> Epoch: 1925, cost 22.24 s
2024-01-02 06:09:54,164	44k	INFO	====> Epoch: 1926, cost 22.25 s
2024-01-02 06:10:16,614	44k	INFO	====> Epoch: 1927, cost 22.45 s
2024-01-02 06:10:38,885	44k	INFO	Train Epoch: 1928 [96%]
2024-01-02 06:10:38,887	44k	INFO	Losses: [1.9378300905227661, 3.2047181129455566, 9.037257194519043, 14.336271286010742, -0.7281841039657593], step: 48200, lr: 7.859280297551778e-05, reference_loss: 27.787893295288086
2024-01-02 06:10:39,275	44k	INFO	====> Epoch: 1928, cost 22.66 s
2024-01-02 06:11:01,551	44k	INFO	====> Epoch: 1929, cost 22.28 s
2024-01-02 06:11:23,824	44k	INFO	====> Epoch: 1930, cost 22.27 s
2024-01-02 06:11:46,029	44k	INFO	====> Epoch: 1931, cost 22.20 s
2024-01-02 06:12:08,279	44k	INFO	====> Epoch: 1932, cost 22.25 s
2024-01-02 06:12:30,515	44k	INFO	====> Epoch: 1933, cost 22.24 s
2024-01-02 06:12:52,714	44k	INFO	====> Epoch: 1934, cost 22.20 s
2024-01-02 06:13:14,992	44k	INFO	====> Epoch: 1935, cost 22.28 s
2024-01-02 06:13:37,307	44k	INFO	Train Epoch: 1936 [96%]
2024-01-02 06:13:37,309	44k	INFO	Losses: [1.946487307548523, 2.845263719558716, 6.830264091491699, 11.402789115905762, -0.7249067425727844], step: 48400, lr: 7.851424454829878e-05, reference_loss: 22.299896240234375
2024-01-02 06:13:37,879	44k	INFO	====> Epoch: 1936, cost 22.89 s
2024-01-02 06:14:00,162	44k	INFO	====> Epoch: 1937, cost 22.28 s
2024-01-02 06:14:22,443	44k	INFO	====> Epoch: 1938, cost 22.28 s
2024-01-02 06:14:44,721	44k	INFO	====> Epoch: 1939, cost 22.28 s
2024-01-02 06:15:07,033	44k	INFO	====> Epoch: 1940, cost 22.31 s
2024-01-02 06:15:29,302	44k	INFO	====> Epoch: 1941, cost 22.27 s
2024-01-02 06:15:51,600	44k	INFO	====> Epoch: 1942, cost 22.30 s
2024-01-02 06:16:13,806	44k	INFO	====> Epoch: 1943, cost 22.21 s
2024-01-02 06:16:35,908	44k	INFO	Train Epoch: 1944 [96%]
2024-01-02 06:16:35,910	44k	INFO	Losses: [1.8064533472061157, 2.9452950954437256, 9.20035171508789, 13.489418983459473, -0.8375948071479797], step: 48600, lr: 7.843576464514628e-05, reference_loss: 26.603925704956055
2024-01-02 06:16:36,293	44k	INFO	====> Epoch: 1944, cost 22.49 s
2024-01-02 06:16:58,372	44k	INFO	====> Epoch: 1945, cost 22.08 s
2024-01-02 06:17:20,708	44k	INFO	====> Epoch: 1946, cost 22.34 s
2024-01-02 06:17:42,872	44k	INFO	====> Epoch: 1947, cost 22.16 s
2024-01-02 06:18:04,974	44k	INFO	====> Epoch: 1948, cost 22.10 s
2024-01-02 06:18:27,076	44k	INFO	====> Epoch: 1949, cost 22.10 s
2024-01-02 06:18:49,178	44k	INFO	====> Epoch: 1950, cost 22.10 s
2024-01-02 06:19:11,289	44k	INFO	====> Epoch: 1951, cost 22.11 s
2024-01-02 06:19:33,392	44k	INFO	Train Epoch: 1952 [96%]
2024-01-02 06:19:33,394	44k	INFO	Losses: [2.0354602336883545, 2.7764029502868652, 7.575582504272461, 13.149822235107422, -0.8746320605278015], step: 48800, lr: 7.835736318757056e-05, reference_loss: 24.662635803222656
2024-01-02 06:19:39,203	44k	INFO	Saving model and optimizer state at iteration 1952 to ./logs/44k/G_48800.pth
2024-01-02 06:19:40,126	44k	INFO	Saving model and optimizer state at iteration 1952 to ./logs/44k/D_48800.pth
2024-01-02 06:19:40,622	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_46400.pth
2024-01-02 06:19:40,660	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_46400.pth
2024-01-02 06:19:40,661	44k	INFO	====> Epoch: 1952, cost 29.37 s
2024-01-02 06:20:02,695	44k	INFO	====> Epoch: 1953, cost 22.03 s
2024-01-02 06:20:24,965	44k	INFO	====> Epoch: 1954, cost 22.27 s
2024-01-02 06:20:47,104	44k	INFO	====> Epoch: 1955, cost 22.14 s
2024-01-02 06:21:09,262	44k	INFO	====> Epoch: 1956, cost 22.16 s
2024-01-02 06:21:31,373	44k	INFO	====> Epoch: 1957, cost 22.11 s
2024-01-02 06:21:53,498	44k	INFO	====> Epoch: 1958, cost 22.12 s
2024-01-02 06:22:15,791	44k	INFO	====> Epoch: 1959, cost 22.29 s
2024-01-02 06:22:38,154	44k	INFO	Train Epoch: 1960 [96%]
2024-01-02 06:22:38,156	44k	INFO	Losses: [2.035743236541748, 3.3530921936035156, 8.816073417663574, 14.584303855895996, -0.7593173980712891], step: 49000, lr: 7.827904009716035e-05, reference_loss: 28.02989387512207
2024-01-02 06:22:38,555	44k	INFO	====> Epoch: 1960, cost 22.76 s
2024-01-02 06:23:00,873	44k	INFO	====> Epoch: 1961, cost 22.32 s
2024-01-02 06:23:23,135	44k	INFO	====> Epoch: 1962, cost 22.26 s
2024-01-02 06:23:45,302	44k	INFO	====> Epoch: 1963, cost 22.17 s
2024-01-02 06:24:07,464	44k	INFO	====> Epoch: 1964, cost 22.16 s
2024-01-02 06:24:29,590	44k	INFO	====> Epoch: 1965, cost 22.13 s
2024-01-02 06:24:51,857	44k	INFO	====> Epoch: 1966, cost 22.27 s
2024-01-02 06:25:14,094	44k	INFO	====> Epoch: 1967, cost 22.24 s
2024-01-02 06:25:36,279	44k	INFO	Train Epoch: 1968 [96%]
2024-01-02 06:25:36,281	44k	INFO	Losses: [2.0118799209594727, 2.6825151443481445, 6.973690986633301, 11.686677932739258, -0.7870340943336487], step: 49200, lr: 7.820079529558277e-05, reference_loss: 22.56772804260254
2024-01-02 06:25:36,662	44k	INFO	====> Epoch: 1968, cost 22.57 s
2024-01-02 06:25:58,877	44k	INFO	====> Epoch: 1969, cost 22.22 s
2024-01-02 06:26:21,180	44k	INFO	====> Epoch: 1970, cost 22.30 s
2024-01-02 06:26:43,469	44k	INFO	====> Epoch: 1971, cost 22.29 s
2024-01-02 06:27:05,690	44k	INFO	====> Epoch: 1972, cost 22.22 s
2024-01-02 06:27:27,959	44k	INFO	====> Epoch: 1973, cost 22.27 s
2024-01-02 06:27:50,260	44k	INFO	====> Epoch: 1974, cost 22.30 s
2024-01-02 06:28:12,558	44k	INFO	====> Epoch: 1975, cost 22.30 s
2024-01-02 06:28:34,798	44k	INFO	Train Epoch: 1976 [96%]
2024-01-02 06:28:34,800	44k	INFO	Losses: [1.9170626401901245, 3.0505735874176025, 9.973546028137207, 14.284064292907715, -0.918643593788147], step: 49400, lr: 7.812262870458322e-05, reference_loss: 28.306602478027344
2024-01-02 06:28:35,372	44k	INFO	====> Epoch: 1976, cost 22.81 s
2024-01-02 06:28:57,652	44k	INFO	====> Epoch: 1977, cost 22.28 s
2024-01-02 06:29:19,981	44k	INFO	====> Epoch: 1978, cost 22.33 s
2024-01-02 06:29:42,234	44k	INFO	====> Epoch: 1979, cost 22.25 s
2024-01-02 06:30:04,457	44k	INFO	====> Epoch: 1980, cost 22.22 s
2024-01-02 06:30:26,692	44k	INFO	====> Epoch: 1981, cost 22.24 s
2024-01-02 06:30:48,938	44k	INFO	====> Epoch: 1982, cost 22.25 s
2024-01-02 06:31:11,198	44k	INFO	====> Epoch: 1983, cost 22.26 s
2024-01-02 06:31:33,450	44k	INFO	Train Epoch: 1984 [96%]
2024-01-02 06:31:33,451	44k	INFO	Losses: [2.144991636276245, 2.563051462173462, 7.181083679199219, 12.522047996520996, -0.9733822345733643], step: 49600, lr: 7.804454024598534e-05, reference_loss: 23.43779182434082
2024-01-02 06:31:39,436	44k	INFO	Saving model and optimizer state at iteration 1984 to ./logs/44k/G_49600.pth
2024-01-02 06:31:40,331	44k	INFO	Saving model and optimizer state at iteration 1984 to ./logs/44k/D_49600.pth
2024-01-02 06:31:40,835	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_47200.pth
2024-01-02 06:31:40,873	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_47200.pth
2024-01-02 06:31:40,874	44k	INFO	====> Epoch: 1984, cost 29.68 s
2024-01-02 06:32:02,928	44k	INFO	====> Epoch: 1985, cost 22.05 s
2024-01-02 06:32:25,021	44k	INFO	====> Epoch: 1986, cost 22.09 s
2024-01-02 06:32:47,227	44k	INFO	====> Epoch: 1987, cost 22.21 s
2024-01-02 06:33:09,465	44k	INFO	====> Epoch: 1988, cost 22.24 s
2024-01-02 06:33:31,711	44k	INFO	====> Epoch: 1989, cost 22.25 s
2024-01-02 06:33:54,015	44k	INFO	====> Epoch: 1990, cost 22.30 s
2024-01-02 06:34:16,334	44k	INFO	====> Epoch: 1991, cost 22.32 s
2024-01-02 06:34:38,640	44k	INFO	Train Epoch: 1992 [96%]
2024-01-02 06:34:38,642	44k	INFO	Losses: [2.0294954776763916, 3.220325231552124, 8.915926933288574, 14.50119400024414, -0.7573538422584534], step: 49800, lr: 7.796652984169091e-05, reference_loss: 27.909587860107422
2024-01-02 06:34:39,034	44k	INFO	====> Epoch: 1992, cost 22.70 s
2024-01-02 06:35:01,214	44k	INFO	====> Epoch: 1993, cost 22.18 s
2024-01-02 06:35:23,467	44k	INFO	====> Epoch: 1994, cost 22.25 s
2024-01-02 06:35:45,764	44k	INFO	====> Epoch: 1995, cost 22.30 s
2024-01-02 06:36:08,273	44k	INFO	====> Epoch: 1996, cost 22.51 s
2024-01-02 06:36:30,522	44k	INFO	====> Epoch: 1997, cost 22.25 s
2024-01-02 06:36:52,750	44k	INFO	====> Epoch: 1998, cost 22.23 s
2024-01-02 06:37:14,869	44k	INFO	====> Epoch: 1999, cost 22.12 s
2024-01-02 06:37:37,007	44k	INFO	Train Epoch: 2000 [96%]
2024-01-02 06:37:37,009	44k	INFO	Losses: [2.098602294921875, 2.555154323577881, 7.07633638381958, 13.260059356689453, -0.8200953602790833], step: 50000, lr: 7.788859741367973e-05, reference_loss: 24.17005729675293
2024-01-02 06:37:37,416	44k	INFO	====> Epoch: 2000, cost 22.55 s
2024-01-02 06:37:59,583	44k	INFO	====> Epoch: 2001, cost 22.17 s
2024-01-02 06:38:21,714	44k	INFO	====> Epoch: 2002, cost 22.13 s
2024-01-02 06:38:43,917	44k	INFO	====> Epoch: 2003, cost 22.20 s
2024-01-02 06:39:06,154	44k	INFO	====> Epoch: 2004, cost 22.24 s
2024-01-02 06:39:28,377	44k	INFO	====> Epoch: 2005, cost 22.22 s
2024-01-02 06:39:50,819	44k	INFO	====> Epoch: 2006, cost 22.44 s
2024-01-02 06:40:13,092	44k	INFO	====> Epoch: 2007, cost 22.27 s
2024-01-02 06:40:35,373	44k	INFO	Train Epoch: 2008 [96%]
2024-01-02 06:40:35,375	44k	INFO	Losses: [1.783880591392517, 2.8444089889526367, 8.835978507995605, 13.236639976501465, -0.9466435313224792], step: 50200, lr: 7.781074288400968e-05, reference_loss: 25.75426483154297
2024-01-02 06:40:35,775	44k	INFO	====> Epoch: 2008, cost 22.68 s
2024-01-02 06:40:58,035	44k	INFO	====> Epoch: 2009, cost 22.26 s
2024-01-02 06:41:20,302	44k	INFO	====> Epoch: 2010, cost 22.27 s
2024-01-02 06:41:42,551	44k	INFO	====> Epoch: 2011, cost 22.25 s
2024-01-02 06:42:04,833	44k	INFO	====> Epoch: 2012, cost 22.28 s
2024-01-02 06:42:27,086	44k	INFO	====> Epoch: 2013, cost 22.25 s
2024-01-02 06:42:49,305	44k	INFO	====> Epoch: 2014, cost 22.22 s
2024-01-02 06:43:11,415	44k	INFO	====> Epoch: 2015, cost 22.11 s
2024-01-02 06:43:33,717	44k	INFO	Train Epoch: 2016 [96%]
2024-01-02 06:43:33,719	44k	INFO	Losses: [2.283132791519165, 2.4945406913757324, 6.737569808959961, 13.208465576171875, -0.9623944759368896], step: 50400, lr: 7.773296617481642e-05, reference_loss: 23.761314392089844
2024-01-02 06:43:39,476	44k	INFO	Saving model and optimizer state at iteration 2016 to ./logs/44k/G_50400.pth
2024-01-02 06:43:40,390	44k	INFO	Saving model and optimizer state at iteration 2016 to ./logs/44k/D_50400.pth
2024-01-02 06:43:40,888	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_48000.pth
2024-01-02 06:43:40,926	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_48000.pth
2024-01-02 06:43:40,926	44k	INFO	====> Epoch: 2016, cost 29.51 s
2024-01-02 06:44:03,123	44k	INFO	====> Epoch: 2017, cost 22.20 s
2024-01-02 06:44:25,437	44k	INFO	====> Epoch: 2018, cost 22.31 s
2024-01-02 06:44:47,645	44k	INFO	====> Epoch: 2019, cost 22.21 s
2024-01-02 06:45:09,706	44k	INFO	====> Epoch: 2020, cost 22.06 s
2024-01-02 06:45:31,916	44k	INFO	====> Epoch: 2021, cost 22.21 s
2024-01-02 06:45:54,123	44k	INFO	====> Epoch: 2022, cost 22.21 s
2024-01-02 06:46:16,505	44k	INFO	====> Epoch: 2023, cost 22.38 s
2024-01-02 06:46:38,665	44k	INFO	Train Epoch: 2024 [96%]
2024-01-02 06:46:38,667	44k	INFO	Losses: [2.0028274059295654, 3.0592987537384033, 7.860799312591553, 13.358715057373047, -0.8220454454421997], step: 50600, lr: 7.765526720831357e-05, reference_loss: 25.4595947265625
2024-01-02 06:46:39,051	44k	INFO	====> Epoch: 2024, cost 22.55 s
2024-01-02 06:47:01,182	44k	INFO	====> Epoch: 2025, cost 22.13 s
2024-01-02 06:47:23,403	44k	INFO	====> Epoch: 2026, cost 22.22 s
2024-01-02 06:47:45,665	44k	INFO	====> Epoch: 2027, cost 22.26 s
2024-01-02 06:48:07,885	44k	INFO	====> Epoch: 2028, cost 22.22 s
2024-01-02 06:48:30,033	44k	INFO	====> Epoch: 2029, cost 22.15 s
2024-01-02 06:48:52,132	44k	INFO	====> Epoch: 2030, cost 22.10 s
2024-01-02 06:49:14,208	44k	INFO	====> Epoch: 2031, cost 22.08 s
2024-01-02 06:49:36,290	44k	INFO	Train Epoch: 2032 [96%]
2024-01-02 06:49:36,292	44k	INFO	Losses: [1.9783320426940918, 2.578134059906006, 6.763751983642578, 12.303204536437988, -0.8126731514930725], step: 50800, lr: 7.757764590679243e-05, reference_loss: 22.810749053955078
2024-01-02 06:49:36,886	44k	INFO	====> Epoch: 2032, cost 22.68 s
2024-01-02 06:49:58,939	44k	INFO	====> Epoch: 2033, cost 22.05 s
2024-01-02 06:50:20,947	44k	INFO	====> Epoch: 2034, cost 22.01 s
2024-01-02 06:50:43,018	44k	INFO	====> Epoch: 2035, cost 22.07 s
2024-01-02 06:51:05,066	44k	INFO	====> Epoch: 2036, cost 22.05 s
2024-01-02 06:51:27,088	44k	INFO	====> Epoch: 2037, cost 22.02 s
2024-01-02 06:51:49,146	44k	INFO	====> Epoch: 2038, cost 22.06 s
2024-01-02 06:52:11,245	44k	INFO	====> Epoch: 2039, cost 22.10 s
2024-01-02 06:52:33,320	44k	INFO	Train Epoch: 2040 [96%]
2024-01-02 06:52:33,322	44k	INFO	Losses: [1.8310269117355347, 2.8967466354370117, 8.664615631103516, 12.888293266296387, -0.985995352268219], step: 51000, lr: 7.750010219262196e-05, reference_loss: 25.29468536376953
2024-01-02 06:52:33,706	44k	INFO	====> Epoch: 2040, cost 22.46 s
2024-01-02 06:52:55,837	44k	INFO	====> Epoch: 2041, cost 22.13 s
2024-01-02 06:53:18,189	44k	INFO	====> Epoch: 2042, cost 22.35 s
2024-01-02 06:53:40,359	44k	INFO	====> Epoch: 2043, cost 22.17 s
2024-01-02 06:54:02,415	44k	INFO	====> Epoch: 2044, cost 22.06 s
2024-01-02 06:54:24,495	44k	INFO	====> Epoch: 2045, cost 22.08 s
2024-01-02 06:54:46,599	44k	INFO	====> Epoch: 2046, cost 22.10 s
2024-01-02 06:55:08,758	44k	INFO	====> Epoch: 2047, cost 22.16 s
2024-01-02 06:55:31,048	44k	INFO	Train Epoch: 2048 [96%]
2024-01-02 06:55:31,050	44k	INFO	Losses: [2.1481096744537354, 2.509559154510498, 6.595533847808838, 12.620619773864746, -0.9913799166679382], step: 51200, lr: 7.742263598824878e-05, reference_loss: 22.8824405670166
2024-01-02 06:55:36,936	44k	INFO	Saving model and optimizer state at iteration 2048 to ./logs/44k/G_51200.pth
2024-01-02 06:55:37,845	44k	INFO	Saving model and optimizer state at iteration 2048 to ./logs/44k/D_51200.pth
2024-01-02 06:55:38,343	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_48800.pth
2024-01-02 06:55:38,382	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_48800.pth
2024-01-02 06:55:38,382	44k	INFO	====> Epoch: 2048, cost 29.62 s
2024-01-02 06:56:00,475	44k	INFO	====> Epoch: 2049, cost 22.09 s
2024-01-02 06:56:22,770	44k	INFO	====> Epoch: 2050, cost 22.29 s
2024-01-02 06:56:44,983	44k	INFO	====> Epoch: 2051, cost 22.21 s
2024-01-02 06:57:07,273	44k	INFO	====> Epoch: 2052, cost 22.29 s
2024-01-02 06:57:29,512	44k	INFO	====> Epoch: 2053, cost 22.24 s
2024-01-02 06:57:51,816	44k	INFO	====> Epoch: 2054, cost 22.30 s
2024-01-02 06:58:14,111	44k	INFO	====> Epoch: 2055, cost 22.30 s
2024-01-02 06:58:36,354	44k	INFO	Train Epoch: 2056 [96%]
2024-01-02 06:58:36,355	44k	INFO	Losses: [1.8419655561447144, 3.284475326538086, 9.577001571655273, 14.629419326782227, -0.8554583191871643], step: 51400, lr: 7.734524721619695e-05, reference_loss: 28.47740364074707
2024-01-02 06:58:36,755	44k	INFO	====> Epoch: 2056, cost 22.64 s
2024-01-02 06:58:58,943	44k	INFO	====> Epoch: 2057, cost 22.19 s
2024-01-02 06:59:21,208	44k	INFO	====> Epoch: 2058, cost 22.26 s
2024-01-02 06:59:43,434	44k	INFO	====> Epoch: 2059, cost 22.23 s
2024-01-02 07:00:05,663	44k	INFO	====> Epoch: 2060, cost 22.23 s
2024-01-02 07:00:27,906	44k	INFO	====> Epoch: 2061, cost 22.24 s
2024-01-02 07:00:50,352	44k	INFO	====> Epoch: 2062, cost 22.45 s
2024-01-02 07:01:12,640	44k	INFO	====> Epoch: 2063, cost 22.29 s
2024-01-02 07:01:34,918	44k	INFO	Train Epoch: 2064 [96%]
2024-01-02 07:01:34,920	44k	INFO	Losses: [2.1130990982055664, 2.6731910705566406, 6.923346996307373, 12.268048286437988, -0.9031217694282532], step: 51600, lr: 7.726793579906805e-05, reference_loss: 23.074562072753906
2024-01-02 07:01:35,397	44k	INFO	====> Epoch: 2064, cost 22.76 s
2024-01-02 07:01:57,658	44k	INFO	====> Epoch: 2065, cost 22.26 s
2024-01-02 07:02:19,881	44k	INFO	====> Epoch: 2066, cost 22.22 s
2024-01-02 07:02:42,145	44k	INFO	====> Epoch: 2067, cost 22.26 s
2024-01-02 07:03:04,403	44k	INFO	====> Epoch: 2068, cost 22.26 s
2024-01-02 07:03:26,677	44k	INFO	====> Epoch: 2069, cost 22.27 s
2024-01-02 07:03:48,990	44k	INFO	====> Epoch: 2070, cost 22.31 s
2024-01-02 07:04:11,264	44k	INFO	====> Epoch: 2071, cost 22.27 s
2024-01-02 07:04:33,455	44k	INFO	Train Epoch: 2072 [96%]
2024-01-02 07:04:33,457	44k	INFO	Losses: [1.8343477249145508, 3.146526575088501, 10.062002182006836, 14.338155746459961, -0.9654024839401245], step: 51800, lr: 7.7190701659541e-05, reference_loss: 28.41562843322754
2024-01-02 07:04:34,133	44k	INFO	====> Epoch: 2072, cost 22.87 s
2024-01-02 07:04:56,388	44k	INFO	====> Epoch: 2073, cost 22.25 s
2024-01-02 07:05:18,661	44k	INFO	====> Epoch: 2074, cost 22.27 s
2024-01-02 07:05:41,010	44k	INFO	====> Epoch: 2075, cost 22.35 s
2024-01-02 07:06:03,376	44k	INFO	====> Epoch: 2076, cost 22.37 s
2024-01-02 07:06:25,723	44k	INFO	====> Epoch: 2077, cost 22.35 s
2024-01-02 07:06:48,128	44k	INFO	====> Epoch: 2078, cost 22.40 s
2024-01-02 07:07:10,465	44k	INFO	====> Epoch: 2079, cost 22.34 s
2024-01-02 07:07:32,752	44k	INFO	Train Epoch: 2080 [96%]
2024-01-02 07:07:32,753	44k	INFO	Losses: [2.113356351852417, 2.714931011199951, 7.331512451171875, 13.196818351745605, -1.0704220533370972], step: 52000, lr: 7.7113544720372e-05, reference_loss: 24.286195755004883
2024-01-02 07:07:39,169	44k	INFO	Saving model and optimizer state at iteration 2080 to ./logs/44k/G_52000.pth
2024-01-02 07:07:40,103	44k	INFO	Saving model and optimizer state at iteration 2080 to ./logs/44k/D_52000.pth
2024-01-02 07:07:40,636	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_49600.pth
2024-01-02 07:07:40,676	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_49600.pth
2024-01-02 07:07:40,676	44k	INFO	====> Epoch: 2080, cost 30.21 s
2024-01-02 07:08:02,866	44k	INFO	====> Epoch: 2081, cost 22.19 s
2024-01-02 07:08:25,044	44k	INFO	====> Epoch: 2082, cost 22.18 s
2024-01-02 07:08:47,254	44k	INFO	====> Epoch: 2083, cost 22.21 s
2024-01-02 07:09:09,400	44k	INFO	====> Epoch: 2084, cost 22.15 s
2024-01-02 07:09:31,616	44k	INFO	====> Epoch: 2085, cost 22.22 s
2024-01-02 07:09:53,749	44k	INFO	====> Epoch: 2086, cost 22.13 s
2024-01-02 07:10:15,852	44k	INFO	====> Epoch: 2087, cost 22.10 s
2024-01-02 07:10:37,953	44k	INFO	Train Epoch: 2088 [96%]
2024-01-02 07:10:37,955	44k	INFO	Losses: [1.8507390022277832, 3.302708148956299, 9.890458106994629, 14.49237060546875, -0.9087346792221069], step: 52200, lr: 7.703646490439444e-05, reference_loss: 28.627540588378906
2024-01-02 07:10:38,346	44k	INFO	====> Epoch: 2088, cost 22.49 s
2024-01-02 07:11:00,468	44k	INFO	====> Epoch: 2089, cost 22.12 s
2024-01-02 07:11:22,596	44k	INFO	====> Epoch: 2090, cost 22.13 s
2024-01-02 07:11:44,681	44k	INFO	====> Epoch: 2091, cost 22.09 s
2024-01-02 07:12:06,932	44k	INFO	====> Epoch: 2092, cost 22.25 s
2024-01-02 07:12:29,051	44k	INFO	====> Epoch: 2093, cost 22.12 s
2024-01-02 07:12:51,303	44k	INFO	====> Epoch: 2094, cost 22.25 s
2024-01-02 07:13:13,535	44k	INFO	====> Epoch: 2095, cost 22.23 s
2024-01-02 07:13:35,602	44k	INFO	Train Epoch: 2096 [96%]
2024-01-02 07:13:35,605	44k	INFO	Losses: [1.9800688028335571, 2.658444881439209, 6.646046161651611, 11.93339729309082, -0.904724657535553], step: 52400, lr: 7.695946213451885e-05, reference_loss: 22.313232421875
2024-01-02 07:13:36,081	44k	INFO	====> Epoch: 2096, cost 22.55 s
2024-01-02 07:13:58,163	44k	INFO	====> Epoch: 2097, cost 22.08 s
2024-01-02 07:14:20,264	44k	INFO	====> Epoch: 2098, cost 22.10 s
2024-01-02 07:14:42,403	44k	INFO	====> Epoch: 2099, cost 22.14 s
2024-01-02 07:15:04,578	44k	INFO	====> Epoch: 2100, cost 22.17 s
2024-01-02 07:15:26,754	44k	INFO	====> Epoch: 2101, cost 22.18 s
2024-01-02 07:15:49,067	44k	INFO	====> Epoch: 2102, cost 22.31 s
2024-01-02 07:16:11,127	44k	INFO	====> Epoch: 2103, cost 22.06 s
2024-01-02 07:16:33,214	44k	INFO	Train Epoch: 2104 [96%]
2024-01-02 07:16:33,216	44k	INFO	Losses: [1.9279451370239258, 2.8903560638427734, 8.885406494140625, 14.093530654907227, -1.0065343379974365], step: 52600, lr: 7.688253633373288e-05, reference_loss: 26.79070281982422
2024-01-02 07:16:33,695	44k	INFO	====> Epoch: 2104, cost 22.57 s
2024-01-02 07:16:55,810	44k	INFO	====> Epoch: 2105, cost 22.11 s
2024-01-02 07:17:17,897	44k	INFO	====> Epoch: 2106, cost 22.09 s
2024-01-02 07:17:39,969	44k	INFO	====> Epoch: 2107, cost 22.07 s
2024-01-02 07:18:02,204	44k	INFO	====> Epoch: 2108, cost 22.24 s
2024-01-02 07:18:24,332	44k	INFO	====> Epoch: 2109, cost 22.13 s
2024-01-02 07:18:46,424	44k	INFO	====> Epoch: 2110, cost 22.09 s
2024-01-02 07:19:08,503	44k	INFO	====> Epoch: 2111, cost 22.08 s
2024-01-02 07:19:30,800	44k	INFO	Train Epoch: 2112 [96%]
2024-01-02 07:19:30,802	44k	INFO	Losses: [2.143301010131836, 2.631850242614746, 8.07944393157959, 13.51507568359375, -1.062290906906128], step: 52800, lr: 7.680568742510108e-05, reference_loss: 25.30738067626953
2024-01-02 07:19:36,662	44k	INFO	Saving model and optimizer state at iteration 2112 to ./logs/44k/G_52800.pth
2024-01-02 07:19:37,576	44k	INFO	Saving model and optimizer state at iteration 2112 to ./logs/44k/D_52800.pth
2024-01-02 07:19:38,077	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_50400.pth
2024-01-02 07:19:38,116	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_50400.pth
2024-01-02 07:19:38,116	44k	INFO	====> Epoch: 2112, cost 29.61 s
2024-01-02 07:20:00,316	44k	INFO	====> Epoch: 2113, cost 22.20 s
2024-01-02 07:20:22,455	44k	INFO	====> Epoch: 2114, cost 22.14 s
2024-01-02 07:20:44,572	44k	INFO	====> Epoch: 2115, cost 22.12 s
2024-01-02 07:21:06,694	44k	INFO	====> Epoch: 2116, cost 22.12 s
2024-01-02 07:21:28,969	44k	INFO	====> Epoch: 2117, cost 22.28 s
2024-01-02 07:21:51,253	44k	INFO	====> Epoch: 2118, cost 22.28 s
2024-01-02 07:22:13,733	44k	INFO	====> Epoch: 2119, cost 22.48 s
2024-01-02 07:22:36,008	44k	INFO	Train Epoch: 2120 [96%]
2024-01-02 07:22:36,011	44k	INFO	Losses: [2.1398351192474365, 3.161334991455078, 9.531440734863281, 14.435441017150879, -0.9850609302520752], step: 53000, lr: 7.67289153317649e-05, reference_loss: 28.282989501953125
2024-01-02 07:22:36,406	44k	INFO	====> Epoch: 2120, cost 22.67 s
2024-01-02 07:22:58,699	44k	INFO	====> Epoch: 2121, cost 22.29 s
2024-01-02 07:23:20,997	44k	INFO	====> Epoch: 2122, cost 22.30 s
2024-01-02 07:23:43,333	44k	INFO	====> Epoch: 2123, cost 22.34 s
2024-01-02 07:24:05,595	44k	INFO	====> Epoch: 2124, cost 22.26 s
2024-01-02 07:24:27,860	44k	INFO	====> Epoch: 2125, cost 22.26 s
2024-01-02 07:24:50,152	44k	INFO	====> Epoch: 2126, cost 22.29 s
2024-01-02 07:25:12,417	44k	INFO	====> Epoch: 2127, cost 22.27 s
2024-01-02 07:25:34,710	44k	INFO	Train Epoch: 2128 [96%]
2024-01-02 07:25:34,712	44k	INFO	Losses: [1.985994577407837, 2.767246723175049, 8.01271915435791, 13.231610298156738, -0.9420643448829651], step: 53200, lr: 7.665221997694265e-05, reference_loss: 25.055505752563477
2024-01-02 07:25:35,280	44k	INFO	====> Epoch: 2128, cost 22.86 s
2024-01-02 07:25:57,622	44k	INFO	====> Epoch: 2129, cost 22.34 s
2024-01-02 07:26:19,947	44k	INFO	====> Epoch: 2130, cost 22.33 s
2024-01-02 07:26:42,247	44k	INFO	====> Epoch: 2131, cost 22.30 s
2024-01-02 07:27:04,510	44k	INFO	====> Epoch: 2132, cost 22.26 s
2024-01-02 07:27:26,698	44k	INFO	====> Epoch: 2133, cost 22.19 s
2024-01-02 07:27:48,950	44k	INFO	====> Epoch: 2134, cost 22.25 s
2024-01-02 07:28:11,262	44k	INFO	====> Epoch: 2135, cost 22.31 s
2024-01-02 07:28:33,537	44k	INFO	Train Epoch: 2136 [96%]
2024-01-02 07:28:33,539	44k	INFO	Losses: [1.8640081882476807, 2.995601177215576, 8.804045677185059, 13.451735496520996, -1.0185978412628174], step: 53400, lr: 7.65756012839294e-05, reference_loss: 26.096792221069336
2024-01-02 07:28:33,922	44k	INFO	====> Epoch: 2136, cost 22.66 s
2024-01-02 07:28:56,203	44k	INFO	====> Epoch: 2137, cost 22.28 s
2024-01-02 07:29:18,618	44k	INFO	====> Epoch: 2138, cost 22.41 s
2024-01-02 07:29:40,793	44k	INFO	====> Epoch: 2139, cost 22.18 s
2024-01-02 07:30:03,031	44k	INFO	====> Epoch: 2140, cost 22.24 s
2024-01-02 07:30:25,310	44k	INFO	====> Epoch: 2141, cost 22.28 s
2024-01-02 07:30:47,528	44k	INFO	====> Epoch: 2142, cost 22.22 s
2024-01-02 07:31:09,705	44k	INFO	====> Epoch: 2143, cost 22.18 s
2024-01-02 07:31:31,868	44k	INFO	Train Epoch: 2144 [96%]
2024-01-02 07:31:31,870	44k	INFO	Losses: [2.0497853755950928, 2.8855645656585693, 8.168429374694824, 13.691110610961914, -1.0920833349227905], step: 53600, lr: 7.649905917609686e-05, reference_loss: 25.70280647277832
2024-01-02 07:31:37,901	44k	INFO	Saving model and optimizer state at iteration 2144 to ./logs/44k/G_53600.pth
2024-01-02 07:31:38,827	44k	INFO	Saving model and optimizer state at iteration 2144 to ./logs/44k/D_53600.pth
2024-01-02 07:31:39,331	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_51200.pth
2024-01-02 07:31:39,370	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_51200.pth
2024-01-02 07:31:39,371	44k	INFO	====> Epoch: 2144, cost 29.67 s
2024-01-02 07:32:01,550	44k	INFO	====> Epoch: 2145, cost 22.18 s
2024-01-02 07:32:23,924	44k	INFO	====> Epoch: 2146, cost 22.37 s
2024-01-02 07:32:46,113	44k	INFO	====> Epoch: 2147, cost 22.19 s
2024-01-02 07:33:08,185	44k	INFO	====> Epoch: 2148, cost 22.07 s
2024-01-02 07:33:30,303	44k	INFO	====> Epoch: 2149, cost 22.12 s
2024-01-02 07:33:52,523	44k	INFO	====> Epoch: 2150, cost 22.22 s
2024-01-02 07:34:14,778	44k	INFO	====> Epoch: 2151, cost 22.26 s
2024-01-02 07:34:37,046	44k	INFO	Train Epoch: 2152 [96%]
2024-01-02 07:34:37,048	44k	INFO	Losses: [1.8986506462097168, 3.255934715270996, 9.046533584594727, 13.84133529663086, -1.0100555419921875], step: 53800, lr: 7.642259357689333e-05, reference_loss: 27.032398223876953
2024-01-02 07:34:37,432	44k	INFO	====> Epoch: 2152, cost 22.65 s
2024-01-02 07:34:59,563	44k	INFO	====> Epoch: 2153, cost 22.13 s
2024-01-02 07:35:21,687	44k	INFO	====> Epoch: 2154, cost 22.12 s
2024-01-02 07:35:43,864	44k	INFO	====> Epoch: 2155, cost 22.18 s
2024-01-02 07:36:06,155	44k	INFO	====> Epoch: 2156, cost 22.29 s
2024-01-02 07:36:28,447	44k	INFO	====> Epoch: 2157, cost 22.29 s
2024-01-02 07:36:50,966	44k	INFO	====> Epoch: 2158, cost 22.52 s
2024-01-02 07:37:13,261	44k	INFO	====> Epoch: 2159, cost 22.30 s
2024-01-02 07:37:35,597	44k	INFO	Train Epoch: 2160 [96%]
2024-01-02 07:37:35,599	44k	INFO	Losses: [2.0138425827026367, 2.5696070194244385, 6.675682067871094, 12.073429107666016, -0.9714635610580444], step: 54000, lr: 7.63462044098437e-05, reference_loss: 22.36109733581543
2024-01-02 07:37:35,987	44k	INFO	====> Epoch: 2160, cost 22.73 s
2024-01-02 07:37:58,279	44k	INFO	====> Epoch: 2161, cost 22.29 s
2024-01-02 07:38:20,563	44k	INFO	====> Epoch: 2162, cost 22.28 s
2024-01-02 07:38:42,876	44k	INFO	====> Epoch: 2163, cost 22.31 s
2024-01-02 07:39:05,198	44k	INFO	====> Epoch: 2164, cost 22.32 s
2024-01-02 07:39:27,516	44k	INFO	====> Epoch: 2165, cost 22.32 s
2024-01-02 07:39:49,811	44k	INFO	====> Epoch: 2166, cost 22.29 s
2024-01-02 07:40:12,101	44k	INFO	====> Epoch: 2167, cost 22.29 s
2024-01-02 07:40:34,445	44k	INFO	Train Epoch: 2168 [96%]
2024-01-02 07:40:34,447	44k	INFO	Losses: [1.7700071334838867, 3.2074718475341797, 10.58629322052002, 14.004950523376465, -1.0956298112869263], step: 54200, lr: 7.62698915985492e-05, reference_loss: 28.47309112548828
2024-01-02 07:40:35,121	44k	INFO	====> Epoch: 2168, cost 23.02 s
2024-01-02 07:40:57,469	44k	INFO	====> Epoch: 2169, cost 22.35 s
2024-01-02 07:41:19,772	44k	INFO	====> Epoch: 2170, cost 22.30 s
2024-01-02 07:41:42,098	44k	INFO	====> Epoch: 2171, cost 22.33 s
2024-01-02 07:42:04,455	44k	INFO	====> Epoch: 2172, cost 22.36 s
2024-01-02 07:42:26,833	44k	INFO	====> Epoch: 2173, cost 22.38 s
2024-01-02 07:42:49,137	44k	INFO	====> Epoch: 2174, cost 22.30 s
2024-01-02 07:43:11,432	44k	INFO	====> Epoch: 2175, cost 22.30 s
2024-01-02 07:43:33,608	44k	INFO	Train Epoch: 2176 [96%]
2024-01-02 07:43:33,610	44k	INFO	Losses: [2.087879180908203, 2.676853895187378, 7.040933609008789, 12.994951248168945, -1.1402841806411743], step: 54400, lr: 7.619365506668749e-05, reference_loss: 23.66033363342285
2024-01-02 07:43:39,720	44k	INFO	Saving model and optimizer state at iteration 2176 to ./logs/44k/G_54400.pth
2024-01-02 07:43:40,628	44k	INFO	Saving model and optimizer state at iteration 2176 to ./logs/44k/D_54400.pth
2024-01-02 07:43:41,125	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_52000.pth
2024-01-02 07:43:41,164	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_52000.pth
2024-01-02 07:43:41,165	44k	INFO	====> Epoch: 2176, cost 29.73 s
2024-01-02 07:44:03,270	44k	INFO	====> Epoch: 2177, cost 22.11 s
2024-01-02 07:44:25,372	44k	INFO	====> Epoch: 2178, cost 22.10 s
2024-01-02 07:44:47,484	44k	INFO	====> Epoch: 2179, cost 22.11 s
2024-01-02 07:45:09,618	44k	INFO	====> Epoch: 2180, cost 22.13 s
2024-01-02 07:45:31,761	44k	INFO	====> Epoch: 2181, cost 22.14 s
2024-01-02 07:45:53,839	44k	INFO	====> Epoch: 2182, cost 22.08 s
2024-01-02 07:46:16,056	44k	INFO	====> Epoch: 2183, cost 22.22 s
2024-01-02 07:46:38,269	44k	INFO	Train Epoch: 2184 [96%]
2024-01-02 07:46:38,271	44k	INFO	Losses: [1.9683101177215576, 3.183936834335327, 8.615105628967285, 13.903898239135742, -1.0153696537017822], step: 54600, lr: 7.611749473801248e-05, reference_loss: 26.655881881713867
2024-01-02 07:46:38,663	44k	INFO	====> Epoch: 2184, cost 22.61 s
2024-01-02 07:47:01,014	44k	INFO	====> Epoch: 2185, cost 22.35 s
2024-01-02 07:47:23,398	44k	INFO	====> Epoch: 2186, cost 22.38 s
2024-01-02 07:47:45,688	44k	INFO	====> Epoch: 2187, cost 22.29 s
2024-01-02 07:48:08,128	44k	INFO	====> Epoch: 2188, cost 22.44 s
2024-01-02 07:48:30,407	44k	INFO	====> Epoch: 2189, cost 22.28 s
2024-01-02 07:48:52,712	44k	INFO	====> Epoch: 2190, cost 22.30 s
2024-01-02 07:49:15,036	44k	INFO	====> Epoch: 2191, cost 22.32 s
2024-01-02 07:49:37,343	44k	INFO	Train Epoch: 2192 [96%]
2024-01-02 07:49:37,345	44k	INFO	Losses: [2.0533409118652344, 2.683899402618408, 6.972017765045166, 11.141690254211426, -1.0505626201629639], step: 54800, lr: 7.604141053635433e-05, reference_loss: 21.800386428833008
2024-01-02 07:49:37,734	44k	INFO	====> Epoch: 2192, cost 22.70 s
2024-01-02 07:49:59,882	44k	INFO	====> Epoch: 2193, cost 22.15 s
2024-01-02 07:50:22,163	44k	INFO	====> Epoch: 2194, cost 22.28 s
2024-01-02 07:50:44,374	44k	INFO	====> Epoch: 2195, cost 22.21 s
2024-01-02 07:51:06,665	44k	INFO	====> Epoch: 2196, cost 22.29 s
2024-01-02 07:51:28,872	44k	INFO	====> Epoch: 2197, cost 22.21 s
2024-01-02 07:51:51,235	44k	INFO	====> Epoch: 2198, cost 22.36 s
2024-01-02 07:52:13,464	44k	INFO	====> Epoch: 2199, cost 22.23 s
2024-01-02 07:52:35,721	44k	INFO	Train Epoch: 2200 [96%]
2024-01-02 07:52:35,723	44k	INFO	Losses: [1.763117790222168, 3.01655912399292, 9.198906898498535, 13.32932186126709, -1.1258772611618042], step: 55000, lr: 7.596540238561933e-05, reference_loss: 26.182029724121094
2024-01-02 07:52:36,113	44k	INFO	====> Epoch: 2200, cost 22.65 s
2024-01-02 07:52:58,369	44k	INFO	====> Epoch: 2201, cost 22.26 s
2024-01-02 07:53:20,610	44k	INFO	====> Epoch: 2202, cost 22.24 s
2024-01-02 07:53:42,826	44k	INFO	====> Epoch: 2203, cost 22.22 s
2024-01-02 07:54:05,114	44k	INFO	====> Epoch: 2204, cost 22.29 s
2024-01-02 07:54:27,319	44k	INFO	====> Epoch: 2205, cost 22.20 s
2024-01-02 07:54:49,455	44k	INFO	====> Epoch: 2206, cost 22.14 s
2024-01-02 07:55:11,706	44k	INFO	====> Epoch: 2207, cost 22.25 s
2024-01-02 07:55:34,104	44k	INFO	Train Epoch: 2208 [96%]
2024-01-02 07:55:34,106	44k	INFO	Losses: [2.183283805847168, 2.7315759658813477, 7.404411792755127, 12.904060363769531, -1.191287636756897], step: 55200, lr: 7.588947020978982e-05, reference_loss: 24.03204345703125
2024-01-02 07:55:40,070	44k	INFO	Saving model and optimizer state at iteration 2208 to ./logs/44k/G_55200.pth
2024-01-02 07:55:40,982	44k	INFO	Saving model and optimizer state at iteration 2208 to ./logs/44k/D_55200.pth
2024-01-02 07:55:41,480	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_52800.pth
2024-01-02 07:55:41,518	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_52800.pth
2024-01-02 07:55:41,518	44k	INFO	====> Epoch: 2208, cost 29.81 s
2024-01-02 07:56:03,623	44k	INFO	====> Epoch: 2209, cost 22.10 s
2024-01-02 07:56:25,810	44k	INFO	====> Epoch: 2210, cost 22.19 s
2024-01-02 07:56:48,041	44k	INFO	====> Epoch: 2211, cost 22.23 s
2024-01-02 07:57:10,273	44k	INFO	====> Epoch: 2212, cost 22.23 s
2024-01-02 07:57:32,418	44k	INFO	====> Epoch: 2213, cost 22.15 s
2024-01-02 07:57:54,544	44k	INFO	====> Epoch: 2214, cost 22.13 s
2024-01-02 07:58:16,999	44k	INFO	====> Epoch: 2215, cost 22.45 s
2024-01-02 07:58:39,229	44k	INFO	Train Epoch: 2216 [96%]
2024-01-02 07:58:39,230	44k	INFO	Losses: [1.8821043968200684, 3.2775750160217285, 9.303686141967773, 14.385916709899902, -1.0487467050552368], step: 55400, lr: 7.58136139329241e-05, reference_loss: 27.800535202026367
2024-01-02 07:58:39,631	44k	INFO	====> Epoch: 2216, cost 22.63 s
2024-01-02 07:59:01,801	44k	INFO	====> Epoch: 2217, cost 22.17 s
2024-01-02 07:59:24,078	44k	INFO	====> Epoch: 2218, cost 22.28 s
2024-01-02 07:59:46,360	44k	INFO	====> Epoch: 2219, cost 22.28 s
2024-01-02 08:00:08,640	44k	INFO	====> Epoch: 2220, cost 22.28 s
2024-01-02 08:00:30,917	44k	INFO	====> Epoch: 2221, cost 22.28 s
2024-01-02 08:00:53,192	44k	INFO	====> Epoch: 2222, cost 22.28 s
2024-01-02 08:01:15,471	44k	INFO	====> Epoch: 2223, cost 22.28 s
2024-01-02 08:01:37,728	44k	INFO	Train Epoch: 2224 [96%]
2024-01-02 08:01:37,730	44k	INFO	Losses: [2.0607659816741943, 2.7012603282928467, 6.7844648361206055, 12.315650939941406, -1.0155447721481323], step: 55600, lr: 7.573783347915643e-05, reference_loss: 22.84659767150879
2024-01-02 08:01:38,318	44k	INFO	====> Epoch: 2224, cost 22.85 s
2024-01-02 08:02:00,527	44k	INFO	====> Epoch: 2225, cost 22.21 s
2024-01-02 08:02:22,754	44k	INFO	====> Epoch: 2226, cost 22.23 s
2024-01-02 08:02:44,949	44k	INFO	====> Epoch: 2227, cost 22.20 s
2024-01-02 08:03:07,177	44k	INFO	====> Epoch: 2228, cost 22.23 s
2024-01-02 08:03:29,407	44k	INFO	====> Epoch: 2229, cost 22.23 s
2024-01-02 08:03:51,635	44k	INFO	====> Epoch: 2230, cost 22.23 s
2024-01-02 08:04:13,931	44k	INFO	====> Epoch: 2231, cost 22.30 s
2024-01-02 08:04:36,015	44k	INFO	Train Epoch: 2232 [96%]
2024-01-02 08:04:36,017	44k	INFO	Losses: [1.766139030456543, 3.3648929595947266, 10.76786994934082, 13.486777305603027, -1.14043128490448], step: 55800, lr: 7.566212877269685e-05, reference_loss: 28.245248794555664
2024-01-02 08:04:36,408	44k	INFO	====> Epoch: 2232, cost 22.48 s
2024-01-02 08:04:58,466	44k	INFO	====> Epoch: 2233, cost 22.06 s
2024-01-02 08:05:20,825	44k	INFO	====> Epoch: 2234, cost 22.36 s
2024-01-02 08:05:43,011	44k	INFO	====> Epoch: 2235, cost 22.19 s
2024-01-02 08:06:05,142	44k	INFO	====> Epoch: 2236, cost 22.13 s
2024-01-02 08:06:27,187	44k	INFO	====> Epoch: 2237, cost 22.04 s
2024-01-02 08:06:49,282	44k	INFO	====> Epoch: 2238, cost 22.10 s
2024-01-02 08:07:11,448	44k	INFO	====> Epoch: 2239, cost 22.17 s
2024-01-02 08:07:33,617	44k	INFO	Train Epoch: 2240 [96%]
2024-01-02 08:07:33,619	44k	INFO	Losses: [2.025531053543091, 2.811337471008301, 7.123541831970215, 12.292512893676758, -1.1788040399551392], step: 56000, lr: 7.558649973783121e-05, reference_loss: 23.07411766052246
2024-01-02 08:07:39,459	44k	INFO	Saving model and optimizer state at iteration 2240 to ./logs/44k/G_56000.pth
2024-01-02 08:07:40,343	44k	INFO	Saving model and optimizer state at iteration 2240 to ./logs/44k/D_56000.pth
2024-01-02 08:07:40,844	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_53600.pth
2024-01-02 08:07:40,882	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_53600.pth
2024-01-02 08:07:40,883	44k	INFO	====> Epoch: 2240, cost 29.44 s
2024-01-02 08:08:03,048	44k	INFO	====> Epoch: 2241, cost 22.17 s
2024-01-02 08:08:25,547	44k	INFO	====> Epoch: 2242, cost 22.50 s
2024-01-02 08:08:47,896	44k	INFO	====> Epoch: 2243, cost 22.35 s
2024-01-02 08:09:10,216	44k	INFO	====> Epoch: 2244, cost 22.32 s
2024-01-02 08:09:32,381	44k	INFO	====> Epoch: 2245, cost 22.16 s
2024-01-02 08:09:54,533	44k	INFO	====> Epoch: 2246, cost 22.15 s
2024-01-02 08:10:16,869	44k	INFO	====> Epoch: 2247, cost 22.34 s
2024-01-02 08:10:38,997	44k	INFO	Train Epoch: 2248 [96%]
2024-01-02 08:10:38,999	44k	INFO	Losses: [2.008842945098877, 2.9764204025268555, 8.071433067321777, 12.784808158874512, -1.103843331336975], step: 56200, lr: 7.5510946298921e-05, reference_loss: 24.737659454345703
2024-01-02 08:10:39,387	44k	INFO	====> Epoch: 2248, cost 22.52 s
2024-01-02 08:11:01,554	44k	INFO	====> Epoch: 2249, cost 22.17 s
2024-01-02 08:11:23,718	44k	INFO	====> Epoch: 2250, cost 22.16 s
2024-01-02 08:11:45,812	44k	INFO	====> Epoch: 2251, cost 22.09 s
2024-01-02 08:12:08,108	44k	INFO	====> Epoch: 2252, cost 22.30 s
2024-01-02 08:12:30,439	44k	INFO	====> Epoch: 2253, cost 22.33 s
2024-01-02 08:12:52,834	44k	INFO	====> Epoch: 2254, cost 22.40 s
2024-01-02 08:13:14,913	44k	INFO	====> Epoch: 2255, cost 22.08 s
2024-01-02 08:13:36,979	44k	INFO	Train Epoch: 2256 [96%]
2024-01-02 08:13:36,982	44k	INFO	Losses: [2.017782211303711, 2.580552101135254, 6.839109420776367, 11.765118598937988, -1.008675456047058], step: 56400, lr: 7.543546838040335e-05, reference_loss: 22.19388771057129
2024-01-02 08:13:37,365	44k	INFO	====> Epoch: 2256, cost 22.45 s
2024-01-02 08:13:59,456	44k	INFO	====> Epoch: 2257, cost 22.09 s
2024-01-02 08:14:21,566	44k	INFO	====> Epoch: 2258, cost 22.11 s
2024-01-02 08:14:43,690	44k	INFO	====> Epoch: 2259, cost 22.12 s
2024-01-02 08:15:06,018	44k	INFO	====> Epoch: 2260, cost 22.33 s
2024-01-02 08:15:28,363	44k	INFO	====> Epoch: 2261, cost 22.35 s
2024-01-02 08:15:50,696	44k	INFO	====> Epoch: 2262, cost 22.33 s
2024-01-02 08:16:13,085	44k	INFO	====> Epoch: 2263, cost 22.39 s
2024-01-02 08:16:35,516	44k	INFO	Train Epoch: 2264 [96%]
2024-01-02 08:16:35,518	44k	INFO	Losses: [1.807147741317749, 2.9509902000427246, 9.081513404846191, 12.960176467895508, -1.184389352798462], step: 56600, lr: 7.536006590679087e-05, reference_loss: 25.61543846130371
2024-01-02 08:16:35,913	44k	INFO	====> Epoch: 2264, cost 22.83 s
2024-01-02 08:16:58,048	44k	INFO	====> Epoch: 2265, cost 22.13 s
2024-01-02 08:17:20,141	44k	INFO	====> Epoch: 2266, cost 22.09 s
2024-01-02 08:17:42,210	44k	INFO	====> Epoch: 2267, cost 22.07 s
2024-01-02 08:18:04,269	44k	INFO	====> Epoch: 2268, cost 22.06 s
2024-01-02 08:18:26,360	44k	INFO	====> Epoch: 2269, cost 22.09 s
2024-01-02 08:18:48,428	44k	INFO	====> Epoch: 2270, cost 22.07 s
2024-01-02 08:19:10,579	44k	INFO	====> Epoch: 2271, cost 22.15 s
2024-01-02 08:19:32,817	44k	INFO	Train Epoch: 2272 [96%]
2024-01-02 08:19:32,818	44k	INFO	Losses: [2.0800976753234863, 2.5866010189056396, 7.178006649017334, 12.161245346069336, -1.2147588729858398], step: 56800, lr: 7.528473880267168e-05, reference_loss: 22.79119110107422
2024-01-02 08:19:39,109	44k	INFO	Saving model and optimizer state at iteration 2272 to ./logs/44k/G_56800.pth
2024-01-02 08:19:40,034	44k	INFO	Saving model and optimizer state at iteration 2272 to ./logs/44k/D_56800.pth
2024-01-02 08:19:40,547	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_54400.pth
2024-01-02 08:19:40,586	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_54400.pth
2024-01-02 08:19:40,587	44k	INFO	====> Epoch: 2272, cost 30.01 s
2024-01-02 08:20:02,775	44k	INFO	====> Epoch: 2273, cost 22.19 s
2024-01-02 08:20:24,860	44k	INFO	====> Epoch: 2274, cost 22.08 s
2024-01-02 08:20:46,845	44k	INFO	====> Epoch: 2275, cost 21.98 s
2024-01-02 08:21:08,882	44k	INFO	====> Epoch: 2276, cost 22.04 s
2024-01-02 08:21:30,924	44k	INFO	====> Epoch: 2277, cost 22.04 s
2024-01-02 08:21:53,059	44k	INFO	====> Epoch: 2278, cost 22.13 s
2024-01-02 08:22:15,420	44k	INFO	====> Epoch: 2279, cost 22.36 s
2024-01-02 08:22:37,558	44k	INFO	Train Epoch: 2280 [96%]
2024-01-02 08:22:37,560	44k	INFO	Losses: [2.005126953125, 3.2506308555603027, 9.3818359375, 14.231341361999512, -1.118378758430481], step: 57000, lr: 7.520948699270922e-05, reference_loss: 27.75055503845215
2024-01-02 08:22:38,048	44k	INFO	====> Epoch: 2280, cost 22.63 s
2024-01-02 08:23:00,098	44k	INFO	====> Epoch: 2281, cost 22.05 s
2024-01-02 08:23:22,215	44k	INFO	====> Epoch: 2282, cost 22.12 s
2024-01-02 08:23:44,280	44k	INFO	====> Epoch: 2283, cost 22.07 s
2024-01-02 08:24:06,647	44k	INFO	====> Epoch: 2284, cost 22.37 s
2024-01-02 08:24:28,912	44k	INFO	====> Epoch: 2285, cost 22.26 s
2024-01-02 08:24:51,028	44k	INFO	====> Epoch: 2286, cost 22.12 s
2024-01-02 08:25:13,104	44k	INFO	====> Epoch: 2287, cost 22.08 s
2024-01-02 08:25:35,315	44k	INFO	Train Epoch: 2288 [96%]
2024-01-02 08:25:35,317	44k	INFO	Losses: [2.0355072021484375, 2.7586472034454346, 8.253868103027344, 12.732179641723633, -1.095736026763916], step: 57200, lr: 7.51343104016423e-05, reference_loss: 24.684465408325195
2024-01-02 08:25:35,703	44k	INFO	====> Epoch: 2288, cost 22.60 s
2024-01-02 08:25:57,959	44k	INFO	====> Epoch: 2289, cost 22.26 s
2024-01-02 08:26:20,225	44k	INFO	====> Epoch: 2290, cost 22.27 s
2024-01-02 08:26:42,408	44k	INFO	====> Epoch: 2291, cost 22.18 s
2024-01-02 08:27:04,562	44k	INFO	====> Epoch: 2292, cost 22.15 s
2024-01-02 08:27:26,706	44k	INFO	====> Epoch: 2293, cost 22.14 s
2024-01-02 08:27:49,059	44k	INFO	====> Epoch: 2294, cost 22.35 s
2024-01-02 08:28:11,285	44k	INFO	====> Epoch: 2295, cost 22.23 s
2024-01-02 08:28:33,477	44k	INFO	Train Epoch: 2296 [96%]
2024-01-02 08:28:33,479	44k	INFO	Losses: [1.7993223667144775, 3.0292670726776123, 9.209327697753906, 12.718270301818848, -1.2013040781021118], step: 57400, lr: 7.505920895428489e-05, reference_loss: 25.55488395690918
2024-01-02 08:28:33,864	44k	INFO	====> Epoch: 2296, cost 22.58 s
2024-01-02 08:28:56,045	44k	INFO	====> Epoch: 2297, cost 22.18 s
2024-01-02 08:29:18,342	44k	INFO	====> Epoch: 2298, cost 22.30 s
2024-01-02 08:29:40,638	44k	INFO	====> Epoch: 2299, cost 22.30 s
2024-01-02 08:30:02,827	44k	INFO	====> Epoch: 2300, cost 22.19 s
2024-01-02 08:30:25,174	44k	INFO	====> Epoch: 2301, cost 22.35 s
2024-01-02 08:30:47,427	44k	INFO	====> Epoch: 2302, cost 22.25 s
2024-01-02 08:31:09,524	44k	INFO	====> Epoch: 2303, cost 22.10 s
2024-01-02 08:31:31,897	44k	INFO	Train Epoch: 2304 [96%]
2024-01-02 08:31:31,899	44k	INFO	Losses: [2.028385639190674, 2.8334593772888184, 7.427946090698242, 12.395567893981934, -1.2683557271957397], step: 57600, lr: 7.498418257552619e-05, reference_loss: 23.417003631591797
2024-01-02 08:31:37,961	44k	INFO	Saving model and optimizer state at iteration 2304 to ./logs/44k/G_57600.pth
2024-01-02 08:31:38,880	44k	INFO	Saving model and optimizer state at iteration 2304 to ./logs/44k/D_57600.pth
2024-01-02 08:31:39,394	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_55200.pth
2024-01-02 08:31:39,433	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_55200.pth
2024-01-02 08:31:39,434	44k	INFO	====> Epoch: 2304, cost 29.91 s
2024-01-02 08:32:01,595	44k	INFO	====> Epoch: 2305, cost 22.16 s
2024-01-02 08:32:23,758	44k	INFO	====> Epoch: 2306, cost 22.16 s
2024-01-02 08:32:45,850	44k	INFO	====> Epoch: 2307, cost 22.09 s
2024-01-02 08:33:07,944	44k	INFO	====> Epoch: 2308, cost 22.09 s
2024-01-02 08:33:30,051	44k	INFO	====> Epoch: 2309, cost 22.11 s
2024-01-02 08:33:52,225	44k	INFO	====> Epoch: 2310, cost 22.17 s
2024-01-02 08:34:14,672	44k	INFO	====> Epoch: 2311, cost 22.45 s
2024-01-02 08:34:36,912	44k	INFO	Train Epoch: 2312 [96%]
2024-01-02 08:34:36,914	44k	INFO	Losses: [1.9595528841018677, 3.0971713066101074, 9.370028495788574, 13.806543350219727, -1.1821469068527222], step: 57800, lr: 7.490923119033039e-05, reference_loss: 27.051149368286133
2024-01-02 08:34:37,309	44k	INFO	====> Epoch: 2312, cost 22.64 s
2024-01-02 08:34:59,512	44k	INFO	====> Epoch: 2313, cost 22.20 s
2024-01-02 08:35:21,609	44k	INFO	====> Epoch: 2314, cost 22.10 s
2024-01-02 08:35:43,732	44k	INFO	====> Epoch: 2315, cost 22.12 s
2024-01-02 08:36:06,005	44k	INFO	====> Epoch: 2316, cost 22.27 s
2024-01-02 08:36:28,304	44k	INFO	====> Epoch: 2317, cost 22.30 s
2024-01-02 08:36:50,666	44k	INFO	====> Epoch: 2318, cost 22.36 s
2024-01-02 08:37:12,994	44k	INFO	====> Epoch: 2319, cost 22.33 s
2024-01-02 08:37:35,253	44k	INFO	Train Epoch: 2320 [96%]
2024-01-02 08:37:35,254	44k	INFO	Losses: [1.9757790565490723, 2.691746950149536, 7.688957691192627, 12.95450210571289, -1.1107728481292725], step: 58000, lr: 7.483435472373676e-05, reference_loss: 24.200212478637695
2024-01-02 08:37:35,847	44k	INFO	====> Epoch: 2320, cost 22.85 s
2024-01-02 08:37:57,968	44k	INFO	====> Epoch: 2321, cost 22.12 s
2024-01-02 08:38:20,086	44k	INFO	====> Epoch: 2322, cost 22.12 s
2024-01-02 08:38:42,206	44k	INFO	====> Epoch: 2323, cost 22.12 s
2024-01-02 08:39:04,371	44k	INFO	====> Epoch: 2324, cost 22.17 s
2024-01-02 08:39:26,561	44k	INFO	====> Epoch: 2325, cost 22.19 s
2024-01-02 08:39:48,793	44k	INFO	====> Epoch: 2326, cost 22.23 s
2024-01-02 08:40:11,070	44k	INFO	====> Epoch: 2327, cost 22.28 s
2024-01-02 08:40:33,306	44k	INFO	Train Epoch: 2328 [96%]
2024-01-02 08:40:33,308	44k	INFO	Losses: [1.9004614353179932, 3.0372655391693115, 10.259923934936523, 13.7645263671875, -1.2953882217407227], step: 58200, lr: 7.475955310085947e-05, reference_loss: 27.666790008544922
2024-01-02 08:40:33,717	44k	INFO	====> Epoch: 2328, cost 22.65 s
2024-01-02 08:40:55,916	44k	INFO	====> Epoch: 2329, cost 22.20 s
2024-01-02 08:41:18,338	44k	INFO	====> Epoch: 2330, cost 22.42 s
2024-01-02 08:41:40,600	44k	INFO	====> Epoch: 2331, cost 22.26 s
2024-01-02 08:42:02,846	44k	INFO	====> Epoch: 2332, cost 22.25 s
2024-01-02 08:42:25,154	44k	INFO	====> Epoch: 2333, cost 22.31 s
2024-01-02 08:42:47,414	44k	INFO	====> Epoch: 2334, cost 22.26 s
2024-01-02 08:43:09,674	44k	INFO	====> Epoch: 2335, cost 22.26 s
2024-01-02 08:43:31,942	44k	INFO	Train Epoch: 2336 [96%]
2024-01-02 08:43:31,944	44k	INFO	Losses: [2.0811679363250732, 2.657038688659668, 6.919877529144287, 12.475547790527344, -1.3078913688659668], step: 58400, lr: 7.468482624688751e-05, reference_loss: 22.825740814208984
2024-01-02 08:43:37,935	44k	INFO	Saving model and optimizer state at iteration 2336 to ./logs/44k/G_58400.pth
2024-01-02 08:43:38,855	44k	INFO	Saving model and optimizer state at iteration 2336 to ./logs/44k/D_58400.pth
2024-01-02 08:43:39,362	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_56000.pth
2024-01-02 08:43:39,402	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_56000.pth
2024-01-02 08:43:39,403	44k	INFO	====> Epoch: 2336, cost 29.73 s
2024-01-02 08:44:01,534	44k	INFO	====> Epoch: 2337, cost 22.13 s
2024-01-02 08:44:23,896	44k	INFO	====> Epoch: 2338, cost 22.36 s
2024-01-02 08:44:46,105	44k	INFO	====> Epoch: 2339, cost 22.21 s
2024-01-02 08:45:08,224	44k	INFO	====> Epoch: 2340, cost 22.12 s
2024-01-02 08:45:30,338	44k	INFO	====> Epoch: 2341, cost 22.11 s
2024-01-02 08:45:52,398	44k	INFO	====> Epoch: 2342, cost 22.06 s
2024-01-02 08:46:14,439	44k	INFO	====> Epoch: 2343, cost 22.04 s
2024-01-02 08:46:36,496	44k	INFO	Train Epoch: 2344 [96%]
2024-01-02 08:46:36,498	44k	INFO	Losses: [1.947369933128357, 3.3612449169158936, 8.998444557189941, 13.728216171264648, -1.1312628984451294], step: 58600, lr: 7.461017408708469e-05, reference_loss: 26.904010772705078
2024-01-02 08:46:36,903	44k	INFO	====> Epoch: 2344, cost 22.46 s
2024-01-02 08:46:58,959	44k	INFO	====> Epoch: 2345, cost 22.06 s
2024-01-02 08:47:21,128	44k	INFO	====> Epoch: 2346, cost 22.17 s
2024-01-02 08:47:43,161	44k	INFO	====> Epoch: 2347, cost 22.03 s
2024-01-02 08:48:05,337	44k	INFO	====> Epoch: 2348, cost 22.18 s
2024-01-02 08:48:27,436	44k	INFO	====> Epoch: 2349, cost 22.10 s
2024-01-02 08:48:49,579	44k	INFO	====> Epoch: 2350, cost 22.14 s
2024-01-02 08:49:11,572	44k	INFO	====> Epoch: 2351, cost 21.99 s
2024-01-02 08:49:33,555	44k	INFO	Train Epoch: 2352 [96%]
2024-01-02 08:49:33,557	44k	INFO	Losses: [1.8602633476257324, 2.7808029651641846, 7.2051873207092285, 11.901833534240723, -1.1514980792999268], step: 58800, lr: 7.453559654678954e-05, reference_loss: 22.596590042114258
2024-01-02 08:49:33,951	44k	INFO	====> Epoch: 2352, cost 22.38 s
2024-01-02 08:49:55,965	44k	INFO	====> Epoch: 2353, cost 22.01 s
2024-01-02 08:50:17,968	44k	INFO	====> Epoch: 2354, cost 22.00 s
2024-01-02 08:50:39,934	44k	INFO	====> Epoch: 2355, cost 21.97 s
2024-01-02 08:51:02,055	44k	INFO	====> Epoch: 2356, cost 22.12 s
2024-01-02 08:51:24,204	44k	INFO	====> Epoch: 2357, cost 22.15 s
2024-01-02 08:51:46,257	44k	INFO	====> Epoch: 2358, cost 22.05 s
2024-01-02 08:52:08,263	44k	INFO	====> Epoch: 2359, cost 22.01 s
2024-01-02 08:52:30,244	44k	INFO	Train Epoch: 2360 [96%]
2024-01-02 08:52:30,246	44k	INFO	Losses: [1.690190315246582, 3.248594284057617, 10.342041969299316, 13.98050594329834, -1.3454442024230957], step: 59000, lr: 7.446109355141515e-05, reference_loss: 27.915889739990234
2024-01-02 08:52:30,908	44k	INFO	====> Epoch: 2360, cost 22.64 s
2024-01-02 08:52:52,878	44k	INFO	====> Epoch: 2361, cost 21.97 s
2024-01-02 08:53:14,841	44k	INFO	====> Epoch: 2362, cost 21.96 s
2024-01-02 08:53:36,824	44k	INFO	====> Epoch: 2363, cost 21.98 s
2024-01-02 08:53:58,790	44k	INFO	====> Epoch: 2364, cost 21.97 s
2024-01-02 08:54:20,904	44k	INFO	====> Epoch: 2365, cost 22.11 s
2024-01-02 08:54:42,980	44k	INFO	====> Epoch: 2366, cost 22.08 s
2024-01-02 08:55:05,076	44k	INFO	====> Epoch: 2367, cost 22.10 s
2024-01-02 08:55:27,155	44k	INFO	Train Epoch: 2368 [96%]
2024-01-02 08:55:27,157	44k	INFO	Losses: [2.001085042953491, 2.681488513946533, 7.33452033996582, 12.13691520690918, -1.3477048873901367], step: 59200, lr: 7.438666502644924e-05, reference_loss: 22.806304931640625
2024-01-02 08:55:33,310	44k	INFO	Saving model and optimizer state at iteration 2368 to ./logs/44k/G_59200.pth
2024-01-02 08:55:34,220	44k	INFO	Saving model and optimizer state at iteration 2368 to ./logs/44k/D_59200.pth
2024-01-02 08:55:34,721	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_56800.pth
2024-01-02 08:55:34,760	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_56800.pth
2024-01-02 08:55:34,760	44k	INFO	====> Epoch: 2368, cost 29.68 s
2024-01-02 08:55:56,728	44k	INFO	====> Epoch: 2369, cost 21.97 s
2024-01-02 08:56:18,862	44k	INFO	====> Epoch: 2370, cost 22.13 s
2024-01-02 08:56:41,055	44k	INFO	====> Epoch: 2371, cost 22.19 s
2024-01-02 08:57:03,199	44k	INFO	====> Epoch: 2372, cost 22.14 s
2024-01-02 08:57:25,456	44k	INFO	====> Epoch: 2373, cost 22.26 s
2024-01-02 08:57:47,671	44k	INFO	====> Epoch: 2374, cost 22.22 s
2024-01-02 08:58:09,922	44k	INFO	====> Epoch: 2375, cost 22.25 s
2024-01-02 08:58:32,128	44k	INFO	Train Epoch: 2376 [96%]
2024-01-02 08:58:32,129	44k	INFO	Losses: [2.0429704189300537, 3.3685598373413086, 9.241769790649414, 13.967501640319824, -1.2704384326934814], step: 59400, lr: 7.431231089745396e-05, reference_loss: 27.35036277770996
2024-01-02 08:58:32,533	44k	INFO	====> Epoch: 2376, cost 22.61 s
2024-01-02 08:58:54,771	44k	INFO	====> Epoch: 2377, cost 22.24 s
2024-01-02 08:59:17,074	44k	INFO	====> Epoch: 2378, cost 22.30 s
2024-01-02 08:59:39,318	44k	INFO	====> Epoch: 2379, cost 22.24 s
2024-01-02 09:00:01,495	44k	INFO	====> Epoch: 2380, cost 22.18 s
2024-01-02 09:00:23,512	44k	INFO	====> Epoch: 2381, cost 22.02 s
2024-01-02 09:00:45,533	44k	INFO	====> Epoch: 2382, cost 22.02 s
2024-01-02 09:01:07,616	44k	INFO	====> Epoch: 2383, cost 22.08 s
2024-01-02 09:01:29,695	44k	INFO	Train Epoch: 2384 [96%]
2024-01-02 09:01:29,697	44k	INFO	Losses: [1.991586685180664, 2.852895498275757, 7.717759132385254, 12.794615745544434, -1.1551412343978882], step: 59600, lr: 7.423803109006585e-05, reference_loss: 24.20171546936035
2024-01-02 09:01:30,097	44k	INFO	====> Epoch: 2384, cost 22.48 s
2024-01-02 09:01:52,188	44k	INFO	====> Epoch: 2385, cost 22.09 s
2024-01-02 09:02:14,418	44k	INFO	====> Epoch: 2386, cost 22.23 s
2024-01-02 09:02:36,649	44k	INFO	====> Epoch: 2387, cost 22.23 s
2024-01-02 09:02:58,948	44k	INFO	====> Epoch: 2388, cost 22.30 s
2024-01-02 09:03:21,206	44k	INFO	====> Epoch: 2389, cost 22.26 s
2024-01-02 09:03:43,695	44k	INFO	====> Epoch: 2390, cost 22.49 s
2024-01-02 09:04:05,886	44k	INFO	====> Epoch: 2391, cost 22.19 s
2024-01-02 09:04:28,029	44k	INFO	Train Epoch: 2392 [96%]
2024-01-02 09:04:28,032	44k	INFO	Losses: [1.645392656326294, 3.404360294342041, 10.576930046081543, 13.677945137023926, -1.2720272541046143], step: 59800, lr: 7.416382552999586e-05, reference_loss: 28.03260040283203
2024-01-02 09:04:28,429	44k	INFO	====> Epoch: 2392, cost 22.54 s
2024-01-02 09:04:50,533	44k	INFO	====> Epoch: 2393, cost 22.10 s
2024-01-02 09:05:12,757	44k	INFO	====> Epoch: 2394, cost 22.22 s
2024-01-02 09:05:34,973	44k	INFO	====> Epoch: 2395, cost 22.22 s
2024-01-02 09:05:57,109	44k	INFO	====> Epoch: 2396, cost 22.14 s
2024-01-02 09:06:19,243	44k	INFO	====> Epoch: 2397, cost 22.13 s
2024-01-02 09:06:41,271	44k	INFO	====> Epoch: 2398, cost 22.03 s
2024-01-02 09:07:03,347	44k	INFO	====> Epoch: 2399, cost 22.08 s
2024-01-02 09:07:25,541	44k	INFO	Train Epoch: 2400 [96%]
2024-01-02 09:07:25,544	44k	INFO	Losses: [1.8791697025299072, 2.9284305572509766, 8.676253318786621, 13.111621856689453, -1.4094643592834473], step: 60000, lr: 7.408969414302911e-05, reference_loss: 25.186010360717773
2024-01-02 09:07:31,255	44k	INFO	Saving model and optimizer state at iteration 2400 to ./logs/44k/G_60000.pth
2024-01-02 09:07:32,146	44k	INFO	Saving model and optimizer state at iteration 2400 to ./logs/44k/D_60000.pth
2024-01-02 09:07:32,642	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_57600.pth
2024-01-02 09:07:32,681	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_57600.pth
2024-01-02 09:07:32,681	44k	INFO	====> Epoch: 2400, cost 29.33 s
2024-01-02 09:07:54,857	44k	INFO	====> Epoch: 2401, cost 22.18 s
2024-01-02 09:08:17,116	44k	INFO	====> Epoch: 2402, cost 22.26 s
2024-01-02 09:08:39,267	44k	INFO	====> Epoch: 2403, cost 22.15 s
2024-01-02 09:09:01,487	44k	INFO	====> Epoch: 2404, cost 22.22 s
2024-01-02 09:09:23,770	44k	INFO	====> Epoch: 2405, cost 22.28 s
2024-01-02 09:09:45,969	44k	INFO	====> Epoch: 2406, cost 22.20 s
2024-01-02 09:10:08,271	44k	INFO	====> Epoch: 2407, cost 22.30 s
2024-01-02 09:10:30,463	44k	INFO	Train Epoch: 2408 [96%]
2024-01-02 09:10:30,465	44k	INFO	Losses: [1.7904398441314697, 3.2347240447998047, 9.742290496826172, 14.022189140319824, -1.2584662437438965], step: 60200, lr: 7.401563685502496e-05, reference_loss: 27.53117561340332
2024-01-02 09:10:30,868	44k	INFO	====> Epoch: 2408, cost 22.60 s
2024-01-02 09:10:53,248	44k	INFO	====> Epoch: 2409, cost 22.38 s
2024-01-02 09:11:15,633	44k	INFO	====> Epoch: 2410, cost 22.38 s
2024-01-02 09:11:37,917	44k	INFO	====> Epoch: 2411, cost 22.28 s
2024-01-02 09:12:00,088	44k	INFO	====> Epoch: 2412, cost 22.17 s
2024-01-02 09:12:22,381	44k	INFO	====> Epoch: 2413, cost 22.29 s
2024-01-02 09:12:44,613	44k	INFO	====> Epoch: 2414, cost 22.23 s
2024-01-02 09:13:06,874	44k	INFO	====> Epoch: 2415, cost 22.26 s
2024-01-02 09:13:29,117	44k	INFO	Train Epoch: 2416 [96%]
2024-01-02 09:13:29,119	44k	INFO	Losses: [2.096238613128662, 2.8941445350646973, 9.026638984680176, 12.885916709899902, -1.2357064485549927], step: 60400, lr: 7.394165359191684e-05, reference_loss: 25.667232513427734
2024-01-02 09:13:29,720	44k	INFO	====> Epoch: 2416, cost 22.85 s
2024-01-02 09:13:52,000	44k	INFO	====> Epoch: 2417, cost 22.28 s
2024-01-02 09:14:14,291	44k	INFO	====> Epoch: 2418, cost 22.29 s
2024-01-02 09:14:36,581	44k	INFO	====> Epoch: 2419, cost 22.29 s
2024-01-02 09:14:58,903	44k	INFO	====> Epoch: 2420, cost 22.32 s
2024-01-02 09:15:20,923	44k	INFO	====> Epoch: 2421, cost 22.02 s
2024-01-02 09:15:43,279	44k	INFO	====> Epoch: 2422, cost 22.36 s
2024-01-02 09:16:05,608	44k	INFO	====> Epoch: 2423, cost 22.33 s
2024-01-02 09:16:27,888	44k	INFO	Train Epoch: 2424 [96%]
2024-01-02 09:16:27,890	44k	INFO	Losses: [1.8082568645477295, 3.2094614505767822, 10.549307823181152, 13.35289478302002, -1.391439437866211], step: 60600, lr: 7.386774427971223e-05, reference_loss: 27.52848243713379
2024-01-02 09:16:28,284	44k	INFO	====> Epoch: 2424, cost 22.68 s
2024-01-02 09:16:50,601	44k	INFO	====> Epoch: 2425, cost 22.32 s
2024-01-02 09:17:13,050	44k	INFO	====> Epoch: 2426, cost 22.45 s
2024-01-02 09:17:35,271	44k	INFO	====> Epoch: 2427, cost 22.22 s
2024-01-02 09:17:57,554	44k	INFO	====> Epoch: 2428, cost 22.28 s
2024-01-02 09:18:19,955	44k	INFO	====> Epoch: 2429, cost 22.40 s
2024-01-02 09:18:42,357	44k	INFO	====> Epoch: 2430, cost 22.40 s
2024-01-02 09:19:04,697	44k	INFO	====> Epoch: 2431, cost 22.34 s
2024-01-02 09:19:26,989	44k	INFO	Train Epoch: 2432 [96%]
2024-01-02 09:19:26,991	44k	INFO	Losses: [2.04652738571167, 2.769711494445801, 8.325559616088867, 13.148432731628418, -1.4011212587356567], step: 60800, lr: 7.379390884449261e-05, reference_loss: 24.889108657836914
2024-01-02 09:19:32,830	44k	INFO	Saving model and optimizer state at iteration 2432 to ./logs/44k/G_60800.pth
2024-01-02 09:19:33,739	44k	INFO	Saving model and optimizer state at iteration 2432 to ./logs/44k/D_60800.pth
2024-01-02 09:19:34,225	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_58400.pth
2024-01-02 09:19:34,264	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_58400.pth
2024-01-02 09:19:34,265	44k	INFO	====> Epoch: 2432, cost 29.57 s
2024-01-02 09:19:56,469	44k	INFO	====> Epoch: 2433, cost 22.20 s
2024-01-02 09:20:18,965	44k	INFO	====> Epoch: 2434, cost 22.50 s
2024-01-02 09:20:41,275	44k	INFO	====> Epoch: 2435, cost 22.31 s
2024-01-02 09:21:03,583	44k	INFO	====> Epoch: 2436, cost 22.31 s
2024-01-02 09:21:25,950	44k	INFO	====> Epoch: 2437, cost 22.37 s
2024-01-02 09:21:48,130	44k	INFO	====> Epoch: 2438, cost 22.18 s
2024-01-02 09:22:10,299	44k	INFO	====> Epoch: 2439, cost 22.17 s
2024-01-02 09:22:32,523	44k	INFO	Train Epoch: 2440 [96%]
2024-01-02 09:22:32,524	44k	INFO	Losses: [1.9749798774719238, 3.1810991764068604, 9.50275707244873, 13.641407012939453, -1.2785001993179321], step: 61000, lr: 7.372014721241325e-05, reference_loss: 27.021743774414062
2024-01-02 09:22:32,931	44k	INFO	====> Epoch: 2440, cost 22.63 s
2024-01-02 09:22:55,147	44k	INFO	====> Epoch: 2441, cost 22.22 s
2024-01-02 09:23:17,475	44k	INFO	====> Epoch: 2442, cost 22.33 s
2024-01-02 09:23:39,673	44k	INFO	====> Epoch: 2443, cost 22.20 s
2024-01-02 09:24:02,053	44k	INFO	====> Epoch: 2444, cost 22.38 s
2024-01-02 09:24:24,464	44k	INFO	====> Epoch: 2445, cost 22.41 s
2024-01-02 09:24:47,101	44k	INFO	====> Epoch: 2446, cost 22.64 s
2024-01-02 09:25:09,567	44k	INFO	====> Epoch: 2447, cost 22.47 s
2024-01-02 09:25:32,096	44k	INFO	Train Epoch: 2448 [96%]
2024-01-02 09:25:32,098	44k	INFO	Losses: [2.052182674407959, 2.927165985107422, 7.61455774307251, 12.549720764160156, -1.2856829166412354], step: 61200, lr: 7.364645930970334e-05, reference_loss: 23.85794448852539
2024-01-02 09:25:32,501	44k	INFO	====> Epoch: 2448, cost 22.93 s
2024-01-02 09:25:54,913	44k	INFO	====> Epoch: 2449, cost 22.41 s
2024-01-02 09:26:17,453	44k	INFO	====> Epoch: 2450, cost 22.54 s
2024-01-02 09:26:39,986	44k	INFO	====> Epoch: 2451, cost 22.53 s
2024-01-02 09:27:02,470	44k	INFO	====> Epoch: 2452, cost 22.48 s
2024-01-02 09:27:25,093	44k	INFO	====> Epoch: 2453, cost 22.62 s
2024-01-02 09:27:47,639	44k	INFO	====> Epoch: 2454, cost 22.55 s
2024-01-02 09:28:10,036	44k	INFO	====> Epoch: 2455, cost 22.40 s
2024-01-02 09:28:32,659	44k	INFO	Train Epoch: 2456 [96%]
2024-01-02 09:28:32,661	44k	INFO	Losses: [1.8075273036956787, 3.0499489307403564, 9.578155517578125, 13.086825370788574, -1.3711403608322144], step: 61400, lr: 7.357284506266572e-05, reference_loss: 26.151317596435547
2024-01-02 09:28:33,075	44k	INFO	====> Epoch: 2456, cost 23.04 s
2024-01-02 09:28:55,371	44k	INFO	====> Epoch: 2457, cost 22.30 s
2024-01-02 09:29:17,882	44k	INFO	====> Epoch: 2458, cost 22.51 s
2024-01-02 09:29:40,394	44k	INFO	====> Epoch: 2459, cost 22.51 s
2024-01-02 09:30:02,827	44k	INFO	====> Epoch: 2460, cost 22.43 s
2024-01-02 09:30:25,233	44k	INFO	====> Epoch: 2461, cost 22.41 s
2024-01-02 09:30:47,622	44k	INFO	====> Epoch: 2462, cost 22.39 s
2024-01-02 09:31:09,973	44k	INFO	====> Epoch: 2463, cost 22.35 s
2024-01-02 09:31:32,323	44k	INFO	Train Epoch: 2464 [96%]
2024-01-02 09:31:32,324	44k	INFO	Losses: [2.133208990097046, 2.6704909801483154, 7.35467529296875, 12.310145378112793, -1.478244662284851], step: 61600, lr: 7.349930439767697e-05, reference_loss: 22.990276336669922
2024-01-02 09:31:38,493	44k	INFO	Saving model and optimizer state at iteration 2464 to ./logs/44k/G_61600.pth
2024-01-02 09:31:39,386	44k	INFO	Saving model and optimizer state at iteration 2464 to ./logs/44k/D_61600.pth
2024-01-02 09:31:39,892	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_59200.pth
2024-01-02 09:31:39,931	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_59200.pth
2024-01-02 09:31:39,931	44k	INFO	====> Epoch: 2464, cost 29.96 s
2024-01-02 09:32:02,123	44k	INFO	====> Epoch: 2465, cost 22.19 s
2024-01-02 09:32:24,428	44k	INFO	====> Epoch: 2466, cost 22.30 s
2024-01-02 09:32:46,707	44k	INFO	====> Epoch: 2467, cost 22.28 s
2024-01-02 09:33:08,961	44k	INFO	====> Epoch: 2468, cost 22.25 s
2024-01-02 09:33:31,227	44k	INFO	====> Epoch: 2469, cost 22.27 s
2024-01-02 09:33:53,563	44k	INFO	====> Epoch: 2470, cost 22.34 s
2024-01-02 09:34:15,691	44k	INFO	====> Epoch: 2471, cost 22.13 s
2024-01-02 09:34:37,836	44k	INFO	Train Epoch: 2472 [96%]
2024-01-02 09:34:37,838	44k	INFO	Losses: [1.8598225116729736, 3.0971875190734863, 9.512984275817871, 13.913726806640625, -1.3328046798706055], step: 61800, lr: 7.342583724118724e-05, reference_loss: 27.050914764404297
2024-01-02 09:34:38,213	44k	INFO	====> Epoch: 2472, cost 22.52 s
2024-01-02 09:35:00,411	44k	INFO	====> Epoch: 2473, cost 22.20 s
2024-01-02 09:35:22,579	44k	INFO	====> Epoch: 2474, cost 22.17 s
2024-01-02 09:35:44,774	44k	INFO	====> Epoch: 2475, cost 22.20 s
2024-01-02 09:36:07,168	44k	INFO	====> Epoch: 2476, cost 22.39 s
2024-01-02 09:36:29,294	44k	INFO	====> Epoch: 2477, cost 22.13 s
2024-01-02 09:36:51,479	44k	INFO	====> Epoch: 2478, cost 22.19 s
2024-01-02 09:37:13,756	44k	INFO	====> Epoch: 2479, cost 22.28 s
2024-01-02 09:37:36,094	44k	INFO	Train Epoch: 2480 [96%]
2024-01-02 09:37:36,096	44k	INFO	Losses: [2.034064531326294, 2.9093730449676514, 8.030457496643066, 12.71738052368164, -1.357643961906433], step: 62000, lr: 7.335244351972012e-05, reference_loss: 24.333633422851562
2024-01-02 09:37:36,483	44k	INFO	====> Epoch: 2480, cost 22.73 s
2024-01-02 09:37:58,800	44k	INFO	====> Epoch: 2481, cost 22.32 s
2024-01-02 09:38:21,126	44k	INFO	====> Epoch: 2482, cost 22.33 s
2024-01-02 09:38:43,334	44k	INFO	====> Epoch: 2483, cost 22.21 s
2024-01-02 09:39:05,506	44k	INFO	====> Epoch: 2484, cost 22.17 s
2024-01-02 09:39:27,758	44k	INFO	====> Epoch: 2485, cost 22.25 s
2024-01-02 09:39:50,164	44k	INFO	====> Epoch: 2486, cost 22.41 s
2024-01-02 09:40:12,406	44k	INFO	====> Epoch: 2487, cost 22.24 s
2024-01-02 09:40:34,595	44k	INFO	Train Epoch: 2488 [96%]
2024-01-02 09:40:34,597	44k	INFO	Losses: [1.818157434463501, 3.3044536113739014, 10.399635314941406, 13.471308708190918, -1.387208342552185], step: 62200, lr: 7.327912315987275e-05, reference_loss: 27.606346130371094
2024-01-02 09:40:35,088	44k	INFO	====> Epoch: 2488, cost 22.68 s
2024-01-02 09:40:57,309	44k	INFO	====> Epoch: 2489, cost 22.22 s
2024-01-02 09:41:19,539	44k	INFO	====> Epoch: 2490, cost 22.23 s
2024-01-02 09:41:41,706	44k	INFO	====> Epoch: 2491, cost 22.17 s
2024-01-02 09:42:03,843	44k	INFO	====> Epoch: 2492, cost 22.14 s
2024-01-02 09:42:26,055	44k	INFO	====> Epoch: 2493, cost 22.21 s
2024-01-02 09:42:48,333	44k	INFO	====> Epoch: 2494, cost 22.28 s
2024-01-02 09:43:10,463	44k	INFO	====> Epoch: 2495, cost 22.13 s
2024-01-02 09:43:32,742	44k	INFO	Train Epoch: 2496 [96%]
2024-01-02 09:43:32,744	44k	INFO	Losses: [2.012449264526367, 3.125743865966797, 8.728513717651367, 12.740290641784668, -1.4543280601501465], step: 62400, lr: 7.320587608831558e-05, reference_loss: 25.15266990661621
2024-01-02 09:43:38,550	44k	INFO	Saving model and optimizer state at iteration 2496 to ./logs/44k/G_62400.pth
2024-01-02 09:43:39,492	44k	INFO	Saving model and optimizer state at iteration 2496 to ./logs/44k/D_62400.pth
2024-01-02 09:43:39,996	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_60000.pth
2024-01-02 09:43:40,035	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_60000.pth
2024-01-02 09:43:40,035	44k	INFO	====> Epoch: 2496, cost 29.57 s
2024-01-02 09:44:02,307	44k	INFO	====> Epoch: 2497, cost 22.27 s
2024-01-02 09:44:24,682	44k	INFO	====> Epoch: 2498, cost 22.37 s
2024-01-02 09:44:46,937	44k	INFO	====> Epoch: 2499, cost 22.25 s
2024-01-02 09:45:09,200	44k	INFO	====> Epoch: 2500, cost 22.26 s
2024-01-02 09:45:31,480	44k	INFO	====> Epoch: 2501, cost 22.28 s
2024-01-02 09:45:53,854	44k	INFO	====> Epoch: 2502, cost 22.37 s
2024-01-02 09:46:16,380	44k	INFO	====> Epoch: 2503, cost 22.53 s
2024-01-02 09:46:38,720	44k	INFO	Train Epoch: 2504 [96%]
2024-01-02 09:46:38,722	44k	INFO	Losses: [1.8404264450073242, 3.195869207382202, 9.176443099975586, 13.423222541809082, -1.4046872854232788], step: 62600, lr: 7.313270223179237e-05, reference_loss: 26.231273651123047
2024-01-02 09:46:39,117	44k	INFO	====> Epoch: 2504, cost 22.74 s
2024-01-02 09:47:01,442	44k	INFO	====> Epoch: 2505, cost 22.33 s
2024-01-02 09:47:23,789	44k	INFO	====> Epoch: 2506, cost 22.35 s
2024-01-02 09:47:46,163	44k	INFO	====> Epoch: 2507, cost 22.37 s
2024-01-02 09:48:08,516	44k	INFO	====> Epoch: 2508, cost 22.35 s
2024-01-02 09:48:30,775	44k	INFO	====> Epoch: 2509, cost 22.26 s
2024-01-02 09:48:53,017	44k	INFO	====> Epoch: 2510, cost 22.24 s
2024-01-02 09:49:15,254	44k	INFO	====> Epoch: 2511, cost 22.24 s
2024-01-02 09:49:37,552	44k	INFO	Train Epoch: 2512 [96%]
2024-01-02 09:49:37,554	44k	INFO	Losses: [1.9945430755615234, 2.865960121154785, 8.39653205871582, 12.675383567810059, -1.3698703050613403], step: 62800, lr: 7.305960151712014e-05, reference_loss: 24.56254768371582
2024-01-02 09:49:38,131	44k	INFO	====> Epoch: 2512, cost 22.88 s
2024-01-02 09:50:00,410	44k	INFO	====> Epoch: 2513, cost 22.28 s
2024-01-02 09:50:22,599	44k	INFO	====> Epoch: 2514, cost 22.19 s
2024-01-02 09:50:44,785	44k	INFO	====> Epoch: 2515, cost 22.19 s
2024-01-02 09:51:06,899	44k	INFO	====> Epoch: 2516, cost 22.11 s
2024-01-02 09:51:28,975	44k	INFO	====> Epoch: 2517, cost 22.08 s
2024-01-02 09:51:51,184	44k	INFO	====> Epoch: 2518, cost 22.21 s
2024-01-02 09:52:13,464	44k	INFO	====> Epoch: 2519, cost 22.28 s
2024-01-02 09:52:35,603	44k	INFO	Train Epoch: 2520 [96%]
2024-01-02 09:52:35,605	44k	INFO	Losses: [1.8766734600067139, 3.1767256259918213, 9.87944507598877, 13.22546672821045, -1.476454734802246], step: 63000, lr: 7.298657387118901e-05, reference_loss: 26.681854248046875
2024-01-02 09:52:36,078	44k	INFO	====> Epoch: 2520, cost 22.61 s
2024-01-02 09:52:58,325	44k	INFO	====> Epoch: 2521, cost 22.25 s
2024-01-02 09:53:20,729	44k	INFO	====> Epoch: 2522, cost 22.40 s
2024-01-02 09:53:42,966	44k	INFO	====> Epoch: 2523, cost 22.24 s
2024-01-02 09:54:05,244	44k	INFO	====> Epoch: 2524, cost 22.28 s
2024-01-02 09:54:27,573	44k	INFO	====> Epoch: 2525, cost 22.33 s
2024-01-02 09:54:49,954	44k	INFO	====> Epoch: 2526, cost 22.38 s
2024-01-02 09:55:12,256	44k	INFO	====> Epoch: 2527, cost 22.30 s
2024-01-02 09:55:34,526	44k	INFO	Train Epoch: 2528 [96%]
2024-01-02 09:55:34,528	44k	INFO	Losses: [2.062824249267578, 2.7658612728118896, 7.126705646514893, 12.099374771118164, -1.523011326789856], step: 63200, lr: 7.29136192209622e-05, reference_loss: 22.531753540039062
2024-01-02 09:55:40,055	44k	INFO	Saving model and optimizer state at iteration 2528 to ./logs/44k/G_63200.pth
2024-01-02 09:55:40,963	44k	INFO	Saving model and optimizer state at iteration 2528 to ./logs/44k/D_63200.pth
2024-01-02 09:55:41,447	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_60800.pth
2024-01-02 09:55:41,486	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_60800.pth
2024-01-02 09:55:41,486	44k	INFO	====> Epoch: 2528, cost 29.23 s
2024-01-02 09:56:03,729	44k	INFO	====> Epoch: 2529, cost 22.24 s
2024-01-02 09:56:26,192	44k	INFO	====> Epoch: 2530, cost 22.46 s
2024-01-02 09:56:48,457	44k	INFO	====> Epoch: 2531, cost 22.27 s
2024-01-02 09:57:10,743	44k	INFO	====> Epoch: 2532, cost 22.29 s
2024-01-02 09:57:33,018	44k	INFO	====> Epoch: 2533, cost 22.27 s
2024-01-02 09:57:55,171	44k	INFO	====> Epoch: 2534, cost 22.15 s
2024-01-02 09:58:17,403	44k	INFO	====> Epoch: 2535, cost 22.23 s
2024-01-02 09:58:39,633	44k	INFO	Train Epoch: 2536 [96%]
2024-01-02 09:58:39,635	44k	INFO	Losses: [1.948047161102295, 3.0843567848205566, 9.426538467407227, 13.692586898803711, -1.4180445671081543], step: 63400, lr: 7.284073749347593e-05, reference_loss: 26.733484268188477
2024-01-02 09:58:40,013	44k	INFO	====> Epoch: 2536, cost 22.61 s
2024-01-02 09:59:02,279	44k	INFO	====> Epoch: 2537, cost 22.27 s
2024-01-02 09:59:24,561	44k	INFO	====> Epoch: 2538, cost 22.28 s
2024-01-02 09:59:46,892	44k	INFO	====> Epoch: 2539, cost 22.33 s
2024-01-02 10:00:09,170	44k	INFO	====> Epoch: 2540, cost 22.28 s
2024-01-02 10:00:31,397	44k	INFO	====> Epoch: 2541, cost 22.23 s
2024-01-02 10:00:53,885	44k	INFO	====> Epoch: 2542, cost 22.49 s
2024-01-02 10:01:16,214	44k	INFO	====> Epoch: 2543, cost 22.33 s
2024-01-02 10:01:38,478	44k	INFO	Train Epoch: 2544 [96%]
2024-01-02 10:01:38,480	44k	INFO	Losses: [2.078634023666382, 2.8643083572387695, 8.56173324584961, 12.439194679260254, -1.4093133211135864], step: 63600, lr: 7.276792861583938e-05, reference_loss: 24.534557342529297
2024-01-02 10:01:38,871	44k	INFO	====> Epoch: 2544, cost 22.66 s
2024-01-02 10:02:01,303	44k	INFO	====> Epoch: 2545, cost 22.43 s
2024-01-02 10:02:23,737	44k	INFO	====> Epoch: 2546, cost 22.43 s
2024-01-02 10:02:46,166	44k	INFO	====> Epoch: 2547, cost 22.43 s
2024-01-02 10:03:08,666	44k	INFO	====> Epoch: 2548, cost 22.50 s
2024-01-02 10:03:30,969	44k	INFO	====> Epoch: 2549, cost 22.30 s
2024-01-02 10:03:53,280	44k	INFO	====> Epoch: 2550, cost 22.31 s
2024-01-02 10:04:15,625	44k	INFO	====> Epoch: 2551, cost 22.34 s
2024-01-02 10:04:37,977	44k	INFO	Train Epoch: 2552 [96%]
2024-01-02 10:04:37,978	44k	INFO	Losses: [1.6692347526550293, 3.2272024154663086, 9.874534606933594, 12.698317527770996, -1.500465989112854], step: 63800, lr: 7.269519251523453e-05, reference_loss: 25.968822479248047
2024-01-02 10:04:38,581	44k	INFO	====> Epoch: 2552, cost 22.96 s
2024-01-02 10:05:00,923	44k	INFO	====> Epoch: 2553, cost 22.34 s
2024-01-02 10:05:23,372	44k	INFO	====> Epoch: 2554, cost 22.45 s
2024-01-02 10:05:45,772	44k	INFO	====> Epoch: 2555, cost 22.40 s
2024-01-02 10:06:08,127	44k	INFO	====> Epoch: 2556, cost 22.35 s
2024-01-02 10:06:30,459	44k	INFO	====> Epoch: 2557, cost 22.33 s
2024-01-02 10:06:52,809	44k	INFO	====> Epoch: 2558, cost 22.35 s
2024-01-02 10:07:15,282	44k	INFO	====> Epoch: 2559, cost 22.47 s
2024-01-02 10:07:37,772	44k	INFO	Train Epoch: 2560 [96%]
2024-01-02 10:07:37,773	44k	INFO	Losses: [2.0398409366607666, 2.9821720123291016, 8.454401016235352, 13.115714073181152, -1.5336226224899292], step: 64000, lr: 7.26225291189162e-05, reference_loss: 25.05850601196289
2024-01-02 10:07:44,487	44k	INFO	Saving model and optimizer state at iteration 2560 to ./logs/44k/G_64000.pth
2024-01-02 10:07:45,428	44k	INFO	Saving model and optimizer state at iteration 2560 to ./logs/44k/D_64000.pth
2024-01-02 10:07:45,951	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_61600.pth
2024-01-02 10:07:45,991	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_61600.pth
2024-01-02 10:07:45,991	44k	INFO	====> Epoch: 2560, cost 30.71 s
2024-01-02 10:08:08,300	44k	INFO	====> Epoch: 2561, cost 22.31 s
2024-01-02 10:08:30,675	44k	INFO	====> Epoch: 2562, cost 22.38 s
2024-01-02 10:08:52,968	44k	INFO	====> Epoch: 2563, cost 22.29 s
2024-01-02 10:09:15,210	44k	INFO	====> Epoch: 2564, cost 22.24 s
2024-01-02 10:09:37,488	44k	INFO	====> Epoch: 2565, cost 22.28 s
2024-01-02 10:09:59,914	44k	INFO	====> Epoch: 2566, cost 22.43 s
2024-01-02 10:10:22,276	44k	INFO	====> Epoch: 2567, cost 22.36 s
2024-01-02 10:10:44,590	44k	INFO	Train Epoch: 2568 [96%]
2024-01-02 10:10:44,592	44k	INFO	Losses: [1.962921142578125, 3.305934429168701, 9.541446685791016, 13.57998275756836, -1.4541891813278198], step: 64200, lr: 7.25499383542119e-05, reference_loss: 26.93609619140625
2024-01-02 10:10:44,981	44k	INFO	====> Epoch: 2568, cost 22.70 s
2024-01-02 10:11:07,224	44k	INFO	====> Epoch: 2569, cost 22.24 s
2024-01-02 10:11:29,552	44k	INFO	====> Epoch: 2570, cost 22.33 s
2024-01-02 10:11:51,917	44k	INFO	====> Epoch: 2571, cost 22.36 s
2024-01-02 10:12:14,406	44k	INFO	====> Epoch: 2572, cost 22.49 s
2024-01-02 10:12:36,673	44k	INFO	====> Epoch: 2573, cost 22.27 s
2024-01-02 10:12:58,929	44k	INFO	====> Epoch: 2574, cost 22.26 s
2024-01-02 10:13:21,308	44k	INFO	====> Epoch: 2575, cost 22.38 s
2024-01-02 10:13:43,560	44k	INFO	Train Epoch: 2576 [96%]
2024-01-02 10:13:43,562	44k	INFO	Losses: [2.003246784210205, 2.9219930171966553, 8.328130722045898, 12.921041488647461, -1.4391577243804932], step: 64400, lr: 7.247742014852179e-05, reference_loss: 24.735254287719727
2024-01-02 10:13:44,027	44k	INFO	====> Epoch: 2576, cost 22.72 s
2024-01-02 10:14:06,338	44k	INFO	====> Epoch: 2577, cost 22.31 s
2024-01-02 10:14:28,674	44k	INFO	====> Epoch: 2578, cost 22.34 s
2024-01-02 10:14:51,040	44k	INFO	====> Epoch: 2579, cost 22.37 s
2024-01-02 10:15:13,378	44k	INFO	====> Epoch: 2580, cost 22.34 s
2024-01-02 10:15:35,799	44k	INFO	====> Epoch: 2581, cost 22.42 s
2024-01-02 10:15:58,385	44k	INFO	====> Epoch: 2582, cost 22.59 s
2024-01-02 10:16:20,864	44k	INFO	====> Epoch: 2583, cost 22.48 s
2024-01-02 10:16:43,339	44k	INFO	Train Epoch: 2584 [96%]
2024-01-02 10:16:43,340	44k	INFO	Losses: [1.7381813526153564, 3.0950002670288086, 9.301443099975586, 12.499858856201172, -1.540065884590149], step: 64600, lr: 7.240497442931857e-05, reference_loss: 25.094417572021484
2024-01-02 10:16:43,741	44k	INFO	====> Epoch: 2584, cost 22.88 s
2024-01-02 10:17:06,273	44k	INFO	====> Epoch: 2585, cost 22.53 s
2024-01-02 10:17:28,646	44k	INFO	====> Epoch: 2586, cost 22.37 s
2024-01-02 10:17:51,148	44k	INFO	====> Epoch: 2587, cost 22.50 s
2024-01-02 10:18:13,558	44k	INFO	====> Epoch: 2588, cost 22.41 s
2024-01-02 10:18:35,941	44k	INFO	====> Epoch: 2589, cost 22.38 s
2024-01-02 10:18:58,408	44k	INFO	====> Epoch: 2590, cost 22.47 s
2024-01-02 10:19:20,850	44k	INFO	====> Epoch: 2591, cost 22.44 s
2024-01-02 10:19:43,278	44k	INFO	Train Epoch: 2592 [96%]
2024-01-02 10:19:43,279	44k	INFO	Losses: [2.029313802719116, 2.7772531509399414, 7.341311454772949, 12.362190246582031, -1.5962443351745605], step: 64800, lr: 7.233260112414749e-05, reference_loss: 22.9138240814209
2024-01-02 10:19:49,403	44k	INFO	Saving model and optimizer state at iteration 2592 to ./logs/44k/G_64800.pth
2024-01-02 10:19:50,341	44k	INFO	Saving model and optimizer state at iteration 2592 to ./logs/44k/D_64800.pth
2024-01-02 10:19:50,851	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_62400.pth
2024-01-02 10:19:50,890	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_62400.pth
2024-01-02 10:19:50,890	44k	INFO	====> Epoch: 2592, cost 30.04 s
2024-01-02 10:20:13,116	44k	INFO	====> Epoch: 2593, cost 22.23 s
2024-01-02 10:20:35,484	44k	INFO	====> Epoch: 2594, cost 22.37 s
2024-01-02 10:20:57,911	44k	INFO	====> Epoch: 2595, cost 22.43 s
2024-01-02 10:21:20,233	44k	INFO	====> Epoch: 2596, cost 22.32 s
2024-01-02 10:21:42,570	44k	INFO	====> Epoch: 2597, cost 22.34 s
2024-01-02 10:22:04,861	44k	INFO	====> Epoch: 2598, cost 22.29 s
2024-01-02 10:22:27,277	44k	INFO	====> Epoch: 2599, cost 22.42 s
2024-01-02 10:22:49,597	44k	INFO	Train Epoch: 2600 [96%]
2024-01-02 10:22:49,599	44k	INFO	Losses: [2.127323865890503, 3.6521711349487305, 9.386969566345215, 13.466899871826172, -1.5113664865493774], step: 65000, lr: 7.226030016062616e-05, reference_loss: 27.121999740600586
2024-01-02 10:22:49,998	44k	INFO	====> Epoch: 2600, cost 22.72 s
2024-01-02 10:23:12,383	44k	INFO	====> Epoch: 2601, cost 22.38 s
2024-01-02 10:23:34,520	44k	INFO	====> Epoch: 2602, cost 22.14 s
2024-01-02 10:23:56,675	44k	INFO	====> Epoch: 2603, cost 22.16 s
2024-01-02 10:24:18,997	44k	INFO	====> Epoch: 2604, cost 22.32 s
2024-01-02 10:24:41,340	44k	INFO	====> Epoch: 2605, cost 22.34 s
2024-01-02 10:25:03,709	44k	INFO	====> Epoch: 2606, cost 22.37 s
2024-01-02 10:25:26,056	44k	INFO	====> Epoch: 2607, cost 22.35 s
2024-01-02 10:25:48,382	44k	INFO	Train Epoch: 2608 [96%]
2024-01-02 10:25:48,383	44k	INFO	Losses: [2.0914978981018066, 2.8525147438049316, 8.611199378967285, 12.459710121154785, -1.4861994981765747], step: 65200, lr: 7.21880714664446e-05, reference_loss: 24.528722763061523
2024-01-02 10:25:48,987	44k	INFO	====> Epoch: 2608, cost 22.93 s
2024-01-02 10:26:11,205	44k	INFO	====> Epoch: 2609, cost 22.22 s
2024-01-02 10:26:33,470	44k	INFO	====> Epoch: 2610, cost 22.27 s
2024-01-02 10:26:55,760	44k	INFO	====> Epoch: 2611, cost 22.29 s
2024-01-02 10:27:18,205	44k	INFO	====> Epoch: 2612, cost 22.44 s
2024-01-02 10:27:40,549	44k	INFO	====> Epoch: 2613, cost 22.34 s
2024-01-02 10:28:02,743	44k	INFO	====> Epoch: 2614, cost 22.19 s
2024-01-02 10:28:25,049	44k	INFO	====> Epoch: 2615, cost 22.31 s
2024-01-02 10:28:47,439	44k	INFO	Train Epoch: 2616 [96%]
2024-01-02 10:28:47,440	44k	INFO	Losses: [1.7360907793045044, 3.133176326751709, 10.111352920532227, 12.916550636291504, -1.613804578781128], step: 65400, lr: 7.211591496936508e-05, reference_loss: 26.283367156982422
2024-01-02 10:28:47,840	44k	INFO	====> Epoch: 2616, cost 22.79 s
2024-01-02 10:29:10,263	44k	INFO	====> Epoch: 2617, cost 22.42 s
2024-01-02 10:29:32,738	44k	INFO	====> Epoch: 2618, cost 22.47 s
2024-01-02 10:29:55,096	44k	INFO	====> Epoch: 2619, cost 22.36 s
2024-01-02 10:30:17,366	44k	INFO	====> Epoch: 2620, cost 22.27 s
2024-01-02 10:30:39,668	44k	INFO	====> Epoch: 2621, cost 22.30 s
2024-01-02 10:31:02,019	44k	INFO	====> Epoch: 2622, cost 22.35 s
2024-01-02 10:31:24,368	44k	INFO	====> Epoch: 2623, cost 22.35 s
2024-01-02 10:31:46,621	44k	INFO	Train Epoch: 2624 [96%]
2024-01-02 10:31:46,623	44k	INFO	Losses: [1.983102798461914, 2.8967480659484863, 7.2237091064453125, 12.2432222366333, -1.6046525239944458], step: 65600, lr: 7.204383059722204e-05, reference_loss: 22.742130279541016
2024-01-02 10:31:52,524	44k	INFO	Saving model and optimizer state at iteration 2624 to ./logs/44k/G_65600.pth
2024-01-02 10:31:53,445	44k	INFO	Saving model and optimizer state at iteration 2624 to ./logs/44k/D_65600.pth
2024-01-02 10:31:53,934	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_63200.pth
2024-01-02 10:31:53,973	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_63200.pth
2024-01-02 10:31:53,973	44k	INFO	====> Epoch: 2624, cost 29.61 s
2024-01-02 10:32:16,242	44k	INFO	====> Epoch: 2625, cost 22.27 s
2024-01-02 10:32:38,870	44k	INFO	====> Epoch: 2626, cost 22.63 s
2024-01-02 10:33:01,304	44k	INFO	====> Epoch: 2627, cost 22.43 s
2024-01-02 10:33:23,651	44k	INFO	====> Epoch: 2628, cost 22.35 s
2024-01-02 10:33:46,024	44k	INFO	====> Epoch: 2629, cost 22.37 s
2024-01-02 10:34:08,448	44k	INFO	====> Epoch: 2630, cost 22.42 s
2024-01-02 10:34:30,860	44k	INFO	====> Epoch: 2631, cost 22.41 s
2024-01-02 10:34:53,258	44k	INFO	Train Epoch: 2632 [96%]
2024-01-02 10:34:53,259	44k	INFO	Losses: [1.8651220798492432, 3.100546360015869, 9.678887367248535, 13.528595924377441, -1.556053876876831], step: 65800, lr: 7.197181827792211e-05, reference_loss: 26.61709976196289
2024-01-02 10:34:53,660	44k	INFO	====> Epoch: 2632, cost 22.80 s
2024-01-02 10:35:16,133	44k	INFO	====> Epoch: 2633, cost 22.47 s
2024-01-02 10:35:38,530	44k	INFO	====> Epoch: 2634, cost 22.40 s
2024-01-02 10:36:00,965	44k	INFO	====> Epoch: 2635, cost 22.43 s
2024-01-02 10:36:23,377	44k	INFO	====> Epoch: 2636, cost 22.41 s
2024-01-02 10:36:45,670	44k	INFO	====> Epoch: 2637, cost 22.29 s
2024-01-02 10:37:08,123	44k	INFO	====> Epoch: 2638, cost 22.45 s
2024-01-02 10:37:30,430	44k	INFO	====> Epoch: 2639, cost 22.31 s
2024-01-02 10:37:52,695	44k	INFO	Train Epoch: 2640 [96%]
2024-01-02 10:37:52,698	44k	INFO	Losses: [1.9304364919662476, 2.859180450439453, 6.922727108001709, 11.77180004119873, -1.4703834056854248], step: 66000, lr: 7.189987793944396e-05, reference_loss: 22.013761520385742
2024-01-02 10:37:53,091	44k	INFO	====> Epoch: 2640, cost 22.66 s
2024-01-02 10:38:15,620	44k	INFO	====> Epoch: 2641, cost 22.53 s
2024-01-02 10:38:38,058	44k	INFO	====> Epoch: 2642, cost 22.44 s
2024-01-02 10:39:00,436	44k	INFO	====> Epoch: 2643, cost 22.38 s
2024-01-02 10:39:22,763	44k	INFO	====> Epoch: 2644, cost 22.33 s
2024-01-02 10:39:45,129	44k	INFO	====> Epoch: 2645, cost 22.37 s
2024-01-02 10:40:07,382	44k	INFO	====> Epoch: 2646, cost 22.25 s
2024-01-02 10:40:29,671	44k	INFO	====> Epoch: 2647, cost 22.29 s
2024-01-02 10:40:52,155	44k	INFO	Train Epoch: 2648 [96%]
2024-01-02 10:40:52,156	44k	INFO	Losses: [1.730247974395752, 3.1896767616271973, 9.645976066589355, 13.031783103942871, -1.668190598487854], step: 66200, lr: 7.182800950983827e-05, reference_loss: 25.929492950439453
2024-01-02 10:40:52,549	44k	INFO	====> Epoch: 2648, cost 22.88 s
2024-01-02 10:41:14,934	44k	INFO	====> Epoch: 2649, cost 22.39 s
2024-01-02 10:41:37,502	44k	INFO	====> Epoch: 2650, cost 22.57 s
2024-01-02 10:41:59,868	44k	INFO	====> Epoch: 2651, cost 22.37 s
2024-01-02 10:42:22,101	44k	INFO	====> Epoch: 2652, cost 22.23 s
2024-01-02 10:42:44,305	44k	INFO	====> Epoch: 2653, cost 22.20 s
2024-01-02 10:43:06,549	44k	INFO	====> Epoch: 2654, cost 22.24 s
2024-01-02 10:43:28,944	44k	INFO	====> Epoch: 2655, cost 22.40 s
2024-01-02 10:43:51,340	44k	INFO	Train Epoch: 2656 [96%]
2024-01-02 10:43:51,341	44k	INFO	Losses: [2.043268918991089, 2.7410902976989746, 7.65666389465332, 12.33004093170166, -1.6527327299118042], step: 66400, lr: 7.175621291722763e-05, reference_loss: 23.118331909179688
2024-01-02 10:43:58,229	44k	INFO	Saving model and optimizer state at iteration 2656 to ./logs/44k/G_66400.pth
2024-01-02 10:43:59,151	44k	INFO	Saving model and optimizer state at iteration 2656 to ./logs/44k/D_66400.pth
2024-01-02 10:43:59,675	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_64000.pth
2024-01-02 10:43:59,714	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_64000.pth
2024-01-02 10:43:59,715	44k	INFO	====> Epoch: 2656, cost 30.77 s
2024-01-02 10:44:21,866	44k	INFO	====> Epoch: 2657, cost 22.15 s
2024-01-02 10:44:44,096	44k	INFO	====> Epoch: 2658, cost 22.23 s
2024-01-02 10:45:06,521	44k	INFO	====> Epoch: 2659, cost 22.42 s
2024-01-02 10:45:28,823	44k	INFO	====> Epoch: 2660, cost 22.30 s
2024-01-02 10:45:51,068	44k	INFO	====> Epoch: 2661, cost 22.24 s
2024-01-02 10:46:13,462	44k	INFO	====> Epoch: 2662, cost 22.39 s
2024-01-02 10:46:35,831	44k	INFO	====> Epoch: 2663, cost 22.37 s
2024-01-02 10:46:58,142	44k	INFO	Train Epoch: 2664 [96%]
2024-01-02 10:46:58,144	44k	INFO	Losses: [1.906449317932129, 2.8999311923980713, 8.16889476776123, 12.580053329467773, -1.5306107997894287], step: 66600, lr: 7.16844880898064e-05, reference_loss: 24.024717330932617
2024-01-02 10:46:58,537	44k	INFO	====> Epoch: 2664, cost 22.71 s
2024-01-02 10:47:20,842	44k	INFO	====> Epoch: 2665, cost 22.31 s
2024-01-02 10:47:43,058	44k	INFO	====> Epoch: 2666, cost 22.22 s
2024-01-02 10:48:05,326	44k	INFO	====> Epoch: 2667, cost 22.27 s
2024-01-02 10:48:27,753	44k	INFO	====> Epoch: 2668, cost 22.43 s
2024-01-02 10:48:50,165	44k	INFO	====> Epoch: 2669, cost 22.41 s
2024-01-02 10:49:12,600	44k	INFO	====> Epoch: 2670, cost 22.43 s
2024-01-02 10:49:35,044	44k	INFO	====> Epoch: 2671, cost 22.44 s
2024-01-02 10:49:57,450	44k	INFO	Train Epoch: 2672 [96%]
2024-01-02 10:49:57,451	44k	INFO	Losses: [1.9273802042007446, 2.916483163833618, 7.371495246887207, 11.475098609924316, -1.4772169589996338], step: 66800, lr: 7.161283495584085e-05, reference_loss: 22.213239669799805
2024-01-02 10:49:57,845	44k	INFO	====> Epoch: 2672, cost 22.80 s
2024-01-02 10:50:20,227	44k	INFO	====> Epoch: 2673, cost 22.38 s
2024-01-02 10:50:42,564	44k	INFO	====> Epoch: 2674, cost 22.34 s
2024-01-02 10:51:04,925	44k	INFO	====> Epoch: 2675, cost 22.36 s
2024-01-02 10:51:27,349	44k	INFO	====> Epoch: 2676, cost 22.42 s
2024-01-02 10:51:49,786	44k	INFO	====> Epoch: 2677, cost 22.44 s
2024-01-02 10:52:12,260	44k	INFO	====> Epoch: 2678, cost 22.47 s
2024-01-02 10:52:34,542	44k	INFO	====> Epoch: 2679, cost 22.28 s
2024-01-02 10:52:56,766	44k	INFO	Train Epoch: 2680 [96%]
2024-01-02 10:52:56,769	44k	INFO	Losses: [1.6560325622558594, 3.398822784423828, 10.617497444152832, 13.373491287231445, -1.7004281282424927], step: 67000, lr: 7.154125344366885e-05, reference_loss: 27.345417022705078
2024-01-02 10:52:57,150	44k	INFO	====> Epoch: 2680, cost 22.61 s
2024-01-02 10:53:19,400	44k	INFO	====> Epoch: 2681, cost 22.25 s
2024-01-02 10:53:41,611	44k	INFO	====> Epoch: 2682, cost 22.21 s
2024-01-02 10:54:03,856	44k	INFO	====> Epoch: 2683, cost 22.24 s
2024-01-02 10:54:26,194	44k	INFO	====> Epoch: 2684, cost 22.34 s
2024-01-02 10:54:48,383	44k	INFO	====> Epoch: 2685, cost 22.19 s
2024-01-02 10:55:10,563	44k	INFO	====> Epoch: 2686, cost 22.18 s
2024-01-02 10:55:32,759	44k	INFO	====> Epoch: 2687, cost 22.20 s
2024-01-02 10:55:55,084	44k	INFO	Train Epoch: 2688 [96%]
2024-01-02 10:55:55,086	44k	INFO	Losses: [1.9692811965942383, 2.9957995414733887, 8.465012550354004, 12.51952075958252, -1.6957933902740479], step: 67200, lr: 7.146974348169993e-05, reference_loss: 24.253822326660156
2024-01-02 10:56:01,166	44k	INFO	Saving model and optimizer state at iteration 2688 to ./logs/44k/G_67200.pth
2024-01-02 10:56:02,067	44k	INFO	Saving model and optimizer state at iteration 2688 to ./logs/44k/D_67200.pth
2024-01-02 10:56:02,565	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_64800.pth
2024-01-02 10:56:02,604	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_64800.pth
2024-01-02 10:56:02,604	44k	INFO	====> Epoch: 2688, cost 29.85 s
2024-01-02 10:56:24,816	44k	INFO	====> Epoch: 2689, cost 22.21 s
2024-01-02 10:56:47,230	44k	INFO	====> Epoch: 2690, cost 22.41 s
2024-01-02 10:57:09,704	44k	INFO	====> Epoch: 2691, cost 22.47 s
2024-01-02 10:57:32,109	44k	INFO	====> Epoch: 2692, cost 22.40 s
2024-01-02 10:57:54,560	44k	INFO	====> Epoch: 2693, cost 22.45 s
2024-01-02 10:58:16,935	44k	INFO	====> Epoch: 2694, cost 22.37 s
2024-01-02 10:58:39,434	44k	INFO	====> Epoch: 2695, cost 22.50 s
2024-01-02 10:59:01,795	44k	INFO	Train Epoch: 2696 [96%]
2024-01-02 10:59:01,797	44k	INFO	Losses: [1.8421454429626465, 3.0564708709716797, 8.922870635986328, 12.309646606445312, -1.6157937049865723], step: 67400, lr: 7.139830499841519e-05, reference_loss: 24.51534080505371
2024-01-02 10:59:02,176	44k	INFO	====> Epoch: 2696, cost 22.74 s
2024-01-02 10:59:24,545	44k	INFO	====> Epoch: 2697, cost 22.37 s
2024-01-02 10:59:46,934	44k	INFO	====> Epoch: 2698, cost 22.39 s
2024-01-02 11:00:09,301	44k	INFO	====> Epoch: 2699, cost 22.37 s
2024-01-02 11:00:31,621	44k	INFO	====> Epoch: 2700, cost 22.32 s
2024-01-02 11:00:53,887	44k	INFO	====> Epoch: 2701, cost 22.27 s
2024-01-02 11:01:16,423	44k	INFO	====> Epoch: 2702, cost 22.54 s
2024-01-02 11:01:38,946	44k	INFO	====> Epoch: 2703, cost 22.52 s
2024-01-02 11:02:01,387	44k	INFO	Train Epoch: 2704 [96%]
2024-01-02 11:02:01,388	44k	INFO	Losses: [2.053772211074829, 2.8004579544067383, 7.073122024536133, 12.027216911315918, -1.556141972541809], step: 67600, lr: 7.132693792236723e-05, reference_loss: 22.398426055908203
2024-01-02 11:02:02,024	44k	INFO	====> Epoch: 2704, cost 23.08 s
2024-01-02 11:02:24,421	44k	INFO	====> Epoch: 2705, cost 22.40 s
2024-01-02 11:02:46,848	44k	INFO	====> Epoch: 2706, cost 22.43 s
2024-01-02 11:03:09,335	44k	INFO	====> Epoch: 2707, cost 22.49 s
2024-01-02 11:03:31,826	44k	INFO	====> Epoch: 2708, cost 22.49 s
2024-01-02 11:03:54,306	44k	INFO	====> Epoch: 2709, cost 22.48 s
2024-01-02 11:04:16,834	44k	INFO	====> Epoch: 2710, cost 22.53 s
2024-01-02 11:04:39,265	44k	INFO	====> Epoch: 2711, cost 22.43 s
2024-01-02 11:05:01,918	44k	INFO	Train Epoch: 2712 [96%]
2024-01-02 11:05:01,919	44k	INFO	Losses: [1.5832042694091797, 3.5272774696350098, 11.323970794677734, 13.331219673156738, -1.7171320915222168], step: 67800, lr: 7.125564218218001e-05, reference_loss: 28.048538208007812
2024-01-02 11:05:02,343	44k	INFO	====> Epoch: 2712, cost 23.08 s
2024-01-02 11:05:24,799	44k	INFO	====> Epoch: 2713, cost 22.46 s
2024-01-02 11:05:47,403	44k	INFO	====> Epoch: 2714, cost 22.60 s
2024-01-02 11:06:09,853	44k	INFO	====> Epoch: 2715, cost 22.45 s
2024-01-02 11:06:32,248	44k	INFO	====> Epoch: 2716, cost 22.39 s
2024-01-02 11:06:54,659	44k	INFO	====> Epoch: 2717, cost 22.41 s
2024-01-02 11:07:17,112	44k	INFO	====> Epoch: 2718, cost 22.45 s
2024-01-02 11:07:39,443	44k	INFO	====> Epoch: 2719, cost 22.33 s
2024-01-02 11:08:01,774	44k	INFO	Train Epoch: 2720 [96%]
2024-01-02 11:08:01,775	44k	INFO	Losses: [1.882406234741211, 2.7178397178649902, 8.981527328491211, 12.868128776550293, -1.6798076629638672], step: 68000, lr: 7.118441770654889e-05, reference_loss: 24.77009391784668
2024-01-02 11:08:08,125	44k	INFO	Saving model and optimizer state at iteration 2720 to ./logs/44k/G_68000.pth
2024-01-02 11:08:09,066	44k	INFO	Saving model and optimizer state at iteration 2720 to ./logs/44k/D_68000.pth
2024-01-02 11:08:09,588	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_65600.pth
2024-01-02 11:08:09,628	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_65600.pth
2024-01-02 11:08:09,629	44k	INFO	====> Epoch: 2720, cost 30.19 s
2024-01-02 11:08:32,028	44k	INFO	====> Epoch: 2721, cost 22.40 s
2024-01-02 11:08:54,611	44k	INFO	====> Epoch: 2722, cost 22.58 s
2024-01-02 11:09:16,977	44k	INFO	====> Epoch: 2723, cost 22.37 s
2024-01-02 11:09:39,495	44k	INFO	====> Epoch: 2724, cost 22.52 s
2024-01-02 11:10:01,921	44k	INFO	====> Epoch: 2725, cost 22.43 s
2024-01-02 11:10:24,246	44k	INFO	====> Epoch: 2726, cost 22.33 s
2024-01-02 11:10:46,515	44k	INFO	====> Epoch: 2727, cost 22.27 s
2024-01-02 11:11:08,827	44k	INFO	Train Epoch: 2728 [96%]
2024-01-02 11:11:08,829	44k	INFO	Losses: [1.9825258255004883, 3.329310894012451, 9.489452362060547, 13.298807144165039, -1.6634941101074219], step: 68200, lr: 7.111326442424049e-05, reference_loss: 26.436601638793945
2024-01-02 11:11:09,219	44k	INFO	====> Epoch: 2728, cost 22.70 s
2024-01-02 11:11:31,457	44k	INFO	====> Epoch: 2729, cost 22.24 s
2024-01-02 11:11:53,531	44k	INFO	====> Epoch: 2730, cost 22.07 s
2024-01-02 11:12:15,559	44k	INFO	====> Epoch: 2731, cost 22.03 s
2024-01-02 11:12:37,643	44k	INFO	====> Epoch: 2732, cost 22.08 s
2024-01-02 11:12:59,666	44k	INFO	====> Epoch: 2733, cost 22.02 s
2024-01-02 11:13:21,820	44k	INFO	====> Epoch: 2734, cost 22.15 s
2024-01-02 11:13:43,815	44k	INFO	====> Epoch: 2735, cost 22.00 s
2024-01-02 11:14:05,877	44k	INFO	Train Epoch: 2736 [96%]
2024-01-02 11:14:05,878	44k	INFO	Losses: [1.9409902095794678, 2.8917603492736816, 7.272450923919678, 10.179976463317871, -1.6070845127105713], step: 68400, lr: 7.104218226409263e-05, reference_loss: 20.6780948638916
2024-01-02 11:14:06,270	44k	INFO	====> Epoch: 2736, cost 22.46 s
2024-01-02 11:14:28,403	44k	INFO	====> Epoch: 2737, cost 22.13 s
2024-01-02 11:14:50,618	44k	INFO	====> Epoch: 2738, cost 22.21 s
2024-01-02 11:15:12,851	44k	INFO	====> Epoch: 2739, cost 22.23 s
2024-01-02 11:15:34,948	44k	INFO	====> Epoch: 2740, cost 22.10 s
2024-01-02 11:15:57,083	44k	INFO	====> Epoch: 2741, cost 22.13 s
2024-01-02 11:16:19,350	44k	INFO	====> Epoch: 2742, cost 22.27 s
2024-01-02 11:16:41,446	44k	INFO	====> Epoch: 2743, cost 22.10 s
2024-01-02 11:17:03,651	44k	INFO	Train Epoch: 2744 [96%]
2024-01-02 11:17:03,653	44k	INFO	Losses: [1.7241166830062866, 3.320774555206299, 9.520675659179688, 12.781051635742188, -1.7512972354888916], step: 68600, lr: 7.097117115501424e-05, reference_loss: 25.595321655273438
2024-01-02 11:17:04,329	44k	INFO	====> Epoch: 2744, cost 22.88 s
2024-01-02 11:17:26,507	44k	INFO	====> Epoch: 2745, cost 22.18 s
2024-01-02 11:17:48,633	44k	INFO	====> Epoch: 2746, cost 22.13 s
2024-01-02 11:18:10,799	44k	INFO	====> Epoch: 2747, cost 22.17 s
2024-01-02 11:18:32,979	44k	INFO	====> Epoch: 2748, cost 22.18 s
2024-01-02 11:18:55,163	44k	INFO	====> Epoch: 2749, cost 22.18 s
2024-01-02 11:19:17,262	44k	INFO	====> Epoch: 2750, cost 22.10 s
2024-01-02 11:19:39,404	44k	INFO	====> Epoch: 2751, cost 22.14 s
2024-01-02 11:20:01,552	44k	INFO	Train Epoch: 2752 [96%]
2024-01-02 11:20:01,553	44k	INFO	Losses: [1.9636491537094116, 3.046894073486328, 8.988072395324707, 12.601114273071289, -1.7627403736114502], step: 68800, lr: 7.090023102598532e-05, reference_loss: 24.83698844909668
2024-01-02 11:20:07,985	44k	INFO	Saving model and optimizer state at iteration 2752 to ./logs/44k/G_68800.pth
2024-01-02 11:20:08,923	44k	INFO	Saving model and optimizer state at iteration 2752 to ./logs/44k/D_68800.pth
2024-01-02 11:20:09,463	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_66400.pth
2024-01-02 11:20:09,503	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_66400.pth
2024-01-02 11:20:09,503	44k	INFO	====> Epoch: 2752, cost 30.10 s
2024-01-02 11:20:31,644	44k	INFO	====> Epoch: 2753, cost 22.14 s
2024-01-02 11:20:53,674	44k	INFO	====> Epoch: 2754, cost 22.03 s
2024-01-02 11:21:15,789	44k	INFO	====> Epoch: 2755, cost 22.12 s
2024-01-02 11:21:37,845	44k	INFO	====> Epoch: 2756, cost 22.06 s
2024-01-02 11:22:00,041	44k	INFO	====> Epoch: 2757, cost 22.20 s
2024-01-02 11:22:22,195	44k	INFO	====> Epoch: 2758, cost 22.15 s
2024-01-02 11:22:44,333	44k	INFO	====> Epoch: 2759, cost 22.14 s
2024-01-02 11:23:06,505	44k	INFO	Train Epoch: 2760 [96%]
2024-01-02 11:23:06,506	44k	INFO	Losses: [1.8904589414596558, 2.854668617248535, 8.562154769897461, 12.069927215576172, -1.6779234409332275], step: 69000, lr: 7.082936180605687e-05, reference_loss: 23.69928550720215
2024-01-02 11:23:06,900	44k	INFO	====> Epoch: 2760, cost 22.57 s
2024-01-02 11:23:29,098	44k	INFO	====> Epoch: 2761, cost 22.20 s
2024-01-02 11:23:51,325	44k	INFO	====> Epoch: 2762, cost 22.23 s
2024-01-02 11:24:13,543	44k	INFO	====> Epoch: 2763, cost 22.22 s
2024-01-02 11:24:36,040	44k	INFO	====> Epoch: 2764, cost 22.50 s
2024-01-02 11:24:58,308	44k	INFO	====> Epoch: 2765, cost 22.27 s
2024-01-02 11:25:20,616	44k	INFO	====> Epoch: 2766, cost 22.31 s
2024-01-02 11:25:43,060	44k	INFO	====> Epoch: 2767, cost 22.44 s
2024-01-02 11:26:05,388	44k	INFO	Train Epoch: 2768 [96%]
2024-01-02 11:26:05,390	44k	INFO	Losses: [2.081662893295288, 2.880821943283081, 8.27159309387207, 12.291119575500488, -1.647275447845459], step: 69200, lr: 7.075856342435085e-05, reference_loss: 23.877920150756836
2024-01-02 11:26:05,792	44k	INFO	====> Epoch: 2768, cost 22.73 s
2024-01-02 11:26:27,976	44k	INFO	====> Epoch: 2769, cost 22.18 s
2024-01-02 11:26:50,131	44k	INFO	====> Epoch: 2770, cost 22.16 s
2024-01-02 11:27:12,332	44k	INFO	====> Epoch: 2771, cost 22.20 s
2024-01-02 11:27:34,530	44k	INFO	====> Epoch: 2772, cost 22.20 s
2024-01-02 11:27:56,689	44k	INFO	====> Epoch: 2773, cost 22.16 s
2024-01-02 11:28:19,071	44k	INFO	====> Epoch: 2774, cost 22.38 s
2024-01-02 11:28:41,315	44k	INFO	====> Epoch: 2775, cost 22.24 s
2024-01-02 11:29:03,503	44k	INFO	Train Epoch: 2776 [96%]
2024-01-02 11:29:03,506	44k	INFO	Losses: [1.6226552724838257, 3.3097147941589355, 11.193443298339844, 13.441438674926758, -1.8170965909957886], step: 69400, lr: 7.068783581005998e-05, reference_loss: 27.750154495239258
2024-01-02 11:29:03,891	44k	INFO	====> Epoch: 2776, cost 22.58 s
2024-01-02 11:29:26,043	44k	INFO	====> Epoch: 2777, cost 22.15 s
2024-01-02 11:29:48,241	44k	INFO	====> Epoch: 2778, cost 22.20 s
2024-01-02 11:30:10,452	44k	INFO	====> Epoch: 2779, cost 22.21 s
2024-01-02 11:30:32,678	44k	INFO	====> Epoch: 2780, cost 22.23 s
2024-01-02 11:30:54,944	44k	INFO	====> Epoch: 2781, cost 22.27 s
2024-01-02 11:31:17,166	44k	INFO	====> Epoch: 2782, cost 22.22 s
2024-01-02 11:31:39,350	44k	INFO	====> Epoch: 2783, cost 22.18 s
2024-01-02 11:32:01,770	44k	INFO	Train Epoch: 2784 [96%]
2024-01-02 11:32:01,771	44k	INFO	Losses: [1.978714942932129, 3.071227550506592, 8.461800575256348, 12.48659896850586, -1.7269623279571533], step: 69600, lr: 7.061717889244778e-05, reference_loss: 24.271379470825195
2024-01-02 11:32:07,747	44k	INFO	Saving model and optimizer state at iteration 2784 to ./logs/44k/G_69600.pth
2024-01-02 11:32:08,671	44k	INFO	Saving model and optimizer state at iteration 2784 to ./logs/44k/D_69600.pth
2024-01-02 11:32:09,182	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_67200.pth
2024-01-02 11:32:09,221	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_67200.pth
2024-01-02 11:32:09,221	44k	INFO	====> Epoch: 2784, cost 29.87 s
2024-01-02 11:32:31,386	44k	INFO	====> Epoch: 2785, cost 22.17 s
2024-01-02 11:32:53,639	44k	INFO	====> Epoch: 2786, cost 22.25 s
2024-01-02 11:33:15,898	44k	INFO	====> Epoch: 2787, cost 22.26 s
2024-01-02 11:33:38,019	44k	INFO	====> Epoch: 2788, cost 22.12 s
2024-01-02 11:33:59,993	44k	INFO	====> Epoch: 2789, cost 21.97 s
2024-01-02 11:34:22,101	44k	INFO	====> Epoch: 2790, cost 22.11 s
2024-01-02 11:34:44,432	44k	INFO	====> Epoch: 2791, cost 22.33 s
2024-01-02 11:35:06,607	44k	INFO	Train Epoch: 2792 [96%]
2024-01-02 11:35:06,608	44k	INFO	Losses: [1.7405861616134644, 3.4278368949890137, 9.921527862548828, 13.498308181762695, -1.6893763542175293], step: 69800, lr: 7.054659260084853e-05, reference_loss: 26.898881912231445
2024-01-02 11:35:07,115	44k	INFO	====> Epoch: 2792, cost 22.68 s
2024-01-02 11:35:29,434	44k	INFO	====> Epoch: 2793, cost 22.32 s
2024-01-02 11:35:51,769	44k	INFO	====> Epoch: 2794, cost 22.33 s
2024-01-02 11:36:14,002	44k	INFO	====> Epoch: 2795, cost 22.23 s
2024-01-02 11:36:36,264	44k	INFO	====> Epoch: 2796, cost 22.26 s
2024-01-02 11:36:58,451	44k	INFO	====> Epoch: 2797, cost 22.19 s
2024-01-02 11:37:20,725	44k	INFO	====> Epoch: 2798, cost 22.27 s
2024-01-02 11:37:43,023	44k	INFO	====> Epoch: 2799, cost 22.30 s
2024-01-02 11:38:05,417	44k	INFO	Train Epoch: 2800 [96%]
2024-01-02 11:38:05,419	44k	INFO	Losses: [1.935152292251587, 2.9975156784057617, 6.765989780426025, 10.339282989501953, -1.5898587703704834], step: 70000, lr: 7.04760768646671e-05, reference_loss: 20.448081970214844
2024-01-02 11:38:06,033	44k	INFO	====> Epoch: 2800, cost 23.01 s
2024-01-02 11:38:28,590	44k	INFO	====> Epoch: 2801, cost 22.56 s
2024-01-02 11:38:51,137	44k	INFO	====> Epoch: 2802, cost 22.55 s
2024-01-02 11:39:13,703	44k	INFO	====> Epoch: 2803, cost 22.57 s
2024-01-02 11:39:36,188	44k	INFO	====> Epoch: 2804, cost 22.48 s
2024-01-02 11:39:58,594	44k	INFO	====> Epoch: 2805, cost 22.41 s
2024-01-02 11:40:21,001	44k	INFO	====> Epoch: 2806, cost 22.41 s
2024-01-02 11:40:43,440	44k	INFO	====> Epoch: 2807, cost 22.44 s
2024-01-02 11:41:05,801	44k	INFO	Train Epoch: 2808 [96%]
2024-01-02 11:41:05,803	44k	INFO	Losses: [1.961696743965149, 3.330486297607422, 10.904870986938477, 13.413732528686523, -1.8417423963546753], step: 70200, lr: 7.040563161337892e-05, reference_loss: 27.769044876098633
2024-01-02 11:41:06,209	44k	INFO	====> Epoch: 2808, cost 22.77 s
2024-01-02 11:41:28,559	44k	INFO	====> Epoch: 2809, cost 22.35 s
2024-01-02 11:41:51,057	44k	INFO	====> Epoch: 2810, cost 22.50 s
2024-01-02 11:42:13,358	44k	INFO	====> Epoch: 2811, cost 22.30 s
2024-01-02 11:42:35,611	44k	INFO	====> Epoch: 2812, cost 22.25 s
2024-01-02 11:42:57,843	44k	INFO	====> Epoch: 2813, cost 22.23 s
2024-01-02 11:43:20,110	44k	INFO	====> Epoch: 2814, cost 22.27 s
2024-01-02 11:43:42,358	44k	INFO	====> Epoch: 2815, cost 22.25 s
2024-01-02 11:44:04,494	44k	INFO	Train Epoch: 2816 [96%]
2024-01-02 11:44:04,496	44k	INFO	Losses: [1.9506226778030396, 3.038540840148926, 7.58748722076416, 11.74036979675293, -1.790029764175415], step: 70400, lr: 7.033525677652995e-05, reference_loss: 22.52699089050293
2024-01-02 11:44:10,734	44k	INFO	Saving model and optimizer state at iteration 2816 to ./logs/44k/G_70400.pth
2024-01-02 11:44:11,668	44k	INFO	Saving model and optimizer state at iteration 2816 to ./logs/44k/D_70400.pth
2024-01-02 11:44:12,196	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_68000.pth
2024-01-02 11:44:12,236	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_68000.pth
2024-01-02 11:44:12,236	44k	INFO	====> Epoch: 2816, cost 29.88 s
2024-01-02 11:44:34,503	44k	INFO	====> Epoch: 2817, cost 22.27 s
2024-01-02 11:44:57,119	44k	INFO	====> Epoch: 2818, cost 22.62 s
2024-01-02 11:45:19,418	44k	INFO	====> Epoch: 2819, cost 22.30 s
2024-01-02 11:45:41,551	44k	INFO	====> Epoch: 2820, cost 22.13 s
2024-01-02 11:46:03,751	44k	INFO	====> Epoch: 2821, cost 22.20 s
2024-01-02 11:46:26,159	44k	INFO	====> Epoch: 2822, cost 22.41 s
2024-01-02 11:46:48,708	44k	INFO	====> Epoch: 2823, cost 22.55 s
2024-01-02 11:47:11,074	44k	INFO	Train Epoch: 2824 [96%]
2024-01-02 11:47:11,075	44k	INFO	Losses: [1.7999740839004517, 3.3521158695220947, 9.392348289489746, 12.981149673461914, -1.7627904415130615], step: 70600, lr: 7.02649522837365e-05, reference_loss: 25.762798309326172
2024-01-02 11:47:11,477	44k	INFO	====> Epoch: 2824, cost 22.77 s
2024-01-02 11:47:33,844	44k	INFO	====> Epoch: 2825, cost 22.37 s
2024-01-02 11:47:56,159	44k	INFO	====> Epoch: 2826, cost 22.32 s
2024-01-02 11:48:18,518	44k	INFO	====> Epoch: 2827, cost 22.36 s
2024-01-02 11:48:40,860	44k	INFO	====> Epoch: 2828, cost 22.34 s
2024-01-02 11:49:03,168	44k	INFO	====> Epoch: 2829, cost 22.31 s
2024-01-02 11:49:25,489	44k	INFO	====> Epoch: 2830, cost 22.32 s
2024-01-02 11:49:47,671	44k	INFO	====> Epoch: 2831, cost 22.18 s
2024-01-02 11:50:10,011	44k	INFO	Train Epoch: 2832 [96%]
2024-01-02 11:50:10,012	44k	INFO	Losses: [2.018105983734131, 3.034184694290161, 7.76809024810791, 12.254777908325195, -1.6013072729110718], step: 70800, lr: 7.019471806468536e-05, reference_loss: 23.473852157592773
2024-01-02 11:50:10,419	44k	INFO	====> Epoch: 2832, cost 22.75 s
2024-01-02 11:50:32,792	44k	INFO	====> Epoch: 2833, cost 22.37 s
2024-01-02 11:50:55,090	44k	INFO	====> Epoch: 2834, cost 22.30 s
2024-01-02 11:51:17,451	44k	INFO	====> Epoch: 2835, cost 22.36 s
2024-01-02 11:51:39,805	44k	INFO	====> Epoch: 2836, cost 22.35 s
2024-01-02 11:52:02,136	44k	INFO	====> Epoch: 2837, cost 22.33 s
2024-01-02 11:52:24,634	44k	INFO	====> Epoch: 2838, cost 22.50 s
2024-01-02 11:52:46,946	44k	INFO	====> Epoch: 2839, cost 22.31 s
2024-01-02 11:53:09,326	44k	INFO	Train Epoch: 2840 [96%]
2024-01-02 11:53:09,327	44k	INFO	Losses: [1.7030656337738037, 3.3517520427703857, 10.364728927612305, 12.956928253173828, -1.8825795650482178], step: 71000, lr: 7.012455404913344e-05, reference_loss: 26.493894577026367
2024-01-02 11:53:09,918	44k	INFO	====> Epoch: 2840, cost 22.97 s
2024-01-02 11:53:32,266	44k	INFO	====> Epoch: 2841, cost 22.35 s
2024-01-02 11:53:54,486	44k	INFO	====> Epoch: 2842, cost 22.22 s
2024-01-02 11:54:16,743	44k	INFO	====> Epoch: 2843, cost 22.26 s
2024-01-02 11:54:39,152	44k	INFO	====> Epoch: 2844, cost 22.41 s
2024-01-02 11:55:01,572	44k	INFO	====> Epoch: 2845, cost 22.42 s
2024-01-02 11:55:23,998	44k	INFO	====> Epoch: 2846, cost 22.43 s
2024-01-02 11:55:46,355	44k	INFO	====> Epoch: 2847, cost 22.36 s
2024-01-02 11:56:08,558	44k	INFO	Train Epoch: 2848 [96%]
2024-01-02 11:56:08,559	44k	INFO	Losses: [1.8934015035629272, 3.133395195007324, 9.007709503173828, 13.028080940246582, -1.8803125619888306], step: 71200, lr: 7.0054460166908e-05, reference_loss: 25.182275772094727
2024-01-02 11:56:14,815	44k	INFO	Saving model and optimizer state at iteration 2848 to ./logs/44k/G_71200.pth
2024-01-02 11:56:15,750	44k	INFO	Saving model and optimizer state at iteration 2848 to ./logs/44k/D_71200.pth
2024-01-02 11:56:16,255	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_68800.pth
2024-01-02 11:56:16,294	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_68800.pth
2024-01-02 11:56:16,294	44k	INFO	====> Epoch: 2848, cost 29.94 s
2024-01-02 11:56:38,671	44k	INFO	====> Epoch: 2849, cost 22.38 s
2024-01-02 11:57:00,949	44k	INFO	====> Epoch: 2850, cost 22.28 s
2024-01-02 11:57:23,203	44k	INFO	====> Epoch: 2851, cost 22.25 s
2024-01-02 11:57:45,522	44k	INFO	====> Epoch: 2852, cost 22.32 s
2024-01-02 11:58:07,929	44k	INFO	====> Epoch: 2853, cost 22.41 s
2024-01-02 11:58:30,247	44k	INFO	====> Epoch: 2854, cost 22.32 s
2024-01-02 11:58:52,584	44k	INFO	====> Epoch: 2855, cost 22.34 s
2024-01-02 11:59:14,851	44k	INFO	Train Epoch: 2856 [96%]
2024-01-02 11:59:14,853	44k	INFO	Losses: [1.753711223602295, 3.1808600425720215, 9.690293312072754, 12.904224395751953, -1.7911027669906616], step: 71400, lr: 6.998443634790639e-05, reference_loss: 25.737985610961914
2024-01-02 11:59:15,333	44k	INFO	====> Epoch: 2856, cost 22.75 s
2024-01-02 11:59:37,528	44k	INFO	====> Epoch: 2857, cost 22.20 s
2024-01-02 11:59:59,946	44k	INFO	====> Epoch: 2858, cost 22.42 s
2024-01-02 12:00:22,329	44k	INFO	====> Epoch: 2859, cost 22.38 s
2024-01-02 12:00:44,897	44k	INFO	====> Epoch: 2860, cost 22.57 s
2024-01-02 12:01:07,341	44k	INFO	====> Epoch: 2861, cost 22.44 s
2024-01-02 12:01:29,655	44k	INFO	====> Epoch: 2862, cost 22.31 s
2024-01-02 12:01:51,886	44k	INFO	====> Epoch: 2863, cost 22.23 s
2024-01-02 12:02:14,168	44k	INFO	Train Epoch: 2864 [96%]
2024-01-02 12:02:14,169	44k	INFO	Losses: [2.061805009841919, 2.6541738510131836, 6.817200183868408, 11.80868911743164, -1.7262485027313232], step: 71600, lr: 6.991448252209599e-05, reference_loss: 21.615619659423828
2024-01-02 12:02:14,669	44k	INFO	====> Epoch: 2864, cost 22.78 s
2024-01-02 12:02:36,935	44k	INFO	====> Epoch: 2865, cost 22.27 s
2024-01-02 12:02:59,115	44k	INFO	====> Epoch: 2866, cost 22.18 s
2024-01-02 12:03:21,433	44k	INFO	====> Epoch: 2867, cost 22.32 s
2024-01-02 12:03:43,676	44k	INFO	====> Epoch: 2868, cost 22.24 s
2024-01-02 12:04:05,853	44k	INFO	====> Epoch: 2869, cost 22.18 s
2024-01-02 12:04:28,364	44k	INFO	====> Epoch: 2870, cost 22.51 s
2024-01-02 12:04:50,530	44k	INFO	====> Epoch: 2871, cost 22.17 s
2024-01-02 12:05:12,804	44k	INFO	Train Epoch: 2872 [96%]
2024-01-02 12:05:12,806	44k	INFO	Losses: [1.7274171113967896, 3.3043863773345947, 10.306130409240723, 12.669442176818848, -1.8900350332260132], step: 71800, lr: 6.984459861951427e-05, reference_loss: 26.117341995239258
2024-01-02 12:05:13,301	44k	INFO	====> Epoch: 2872, cost 22.77 s
2024-01-02 12:05:35,794	44k	INFO	====> Epoch: 2873, cost 22.49 s
2024-01-02 12:05:58,286	44k	INFO	====> Epoch: 2874, cost 22.49 s
2024-01-02 12:06:20,672	44k	INFO	====> Epoch: 2875, cost 22.39 s
2024-01-02 12:06:43,080	44k	INFO	====> Epoch: 2876, cost 22.41 s
2024-01-02 12:07:05,544	44k	INFO	====> Epoch: 2877, cost 22.46 s
2024-01-02 12:07:27,965	44k	INFO	====> Epoch: 2878, cost 22.42 s
2024-01-02 12:07:50,397	44k	INFO	====> Epoch: 2879, cost 22.43 s
2024-01-02 12:08:12,994	44k	INFO	Train Epoch: 2880 [96%]
2024-01-02 12:08:12,996	44k	INFO	Losses: [1.893150806427002, 3.1517367362976074, 7.982821941375732, 11.704568862915039, -1.8812448978424072], step: 72000, lr: 6.977478457026858e-05, reference_loss: 22.85103416442871
2024-01-02 12:08:19,105	44k	INFO	Saving model and optimizer state at iteration 2880 to ./logs/44k/G_72000.pth
2024-01-02 12:08:20,022	44k	INFO	Saving model and optimizer state at iteration 2880 to ./logs/44k/D_72000.pth
2024-01-02 12:08:20,528	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_69600.pth
2024-01-02 12:08:20,567	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_69600.pth
2024-01-02 12:08:20,567	44k	INFO	====> Epoch: 2880, cost 30.17 s
2024-01-02 12:08:42,986	44k	INFO	====> Epoch: 2881, cost 22.42 s
2024-01-02 12:09:05,358	44k	INFO	====> Epoch: 2882, cost 22.37 s
2024-01-02 12:09:27,741	44k	INFO	====> Epoch: 2883, cost 22.38 s
2024-01-02 12:09:50,048	44k	INFO	====> Epoch: 2884, cost 22.31 s
2024-01-02 12:10:12,358	44k	INFO	====> Epoch: 2885, cost 22.31 s
2024-01-02 12:10:34,582	44k	INFO	====> Epoch: 2886, cost 22.22 s
2024-01-02 12:10:56,998	44k	INFO	====> Epoch: 2887, cost 22.42 s
2024-01-02 12:11:19,275	44k	INFO	Train Epoch: 2888 [96%]
2024-01-02 12:11:19,277	44k	INFO	Losses: [1.7602570056915283, 3.272075653076172, 8.802191734313965, 11.943902015686035, -1.7718793153762817], step: 72200, lr: 6.97050403045361e-05, reference_loss: 24.006547927856445
2024-01-02 12:11:19,765	44k	INFO	====> Epoch: 2888, cost 22.77 s
2024-01-02 12:11:41,877	44k	INFO	====> Epoch: 2889, cost 22.11 s
2024-01-02 12:12:04,026	44k	INFO	====> Epoch: 2890, cost 22.15 s
2024-01-02 12:12:26,189	44k	INFO	====> Epoch: 2891, cost 22.16 s
2024-01-02 12:12:48,389	44k	INFO	====> Epoch: 2892, cost 22.20 s
2024-01-02 12:13:10,629	44k	INFO	====> Epoch: 2893, cost 22.24 s
2024-01-02 12:13:32,892	44k	INFO	====> Epoch: 2894, cost 22.26 s
2024-01-02 12:13:55,272	44k	INFO	====> Epoch: 2895, cost 22.38 s
2024-01-02 12:14:17,641	44k	INFO	Train Epoch: 2896 [96%]
2024-01-02 12:14:17,642	44k	INFO	Losses: [1.9572805166244507, 2.798567771911621, 6.956141471862793, 10.226692199707031, -1.7910019159317017], step: 72400, lr: 6.963536575256389e-05, reference_loss: 20.147680282592773
2024-01-02 12:14:18,337	44k	INFO	====> Epoch: 2896, cost 23.07 s
2024-01-02 12:14:40,656	44k	INFO	====> Epoch: 2897, cost 22.32 s
2024-01-02 12:15:02,970	44k	INFO	====> Epoch: 2898, cost 22.31 s
2024-01-02 12:15:25,242	44k	INFO	====> Epoch: 2899, cost 22.27 s
2024-01-02 12:15:47,430	44k	INFO	====> Epoch: 2900, cost 22.19 s
2024-01-02 12:16:09,624	44k	INFO	====> Epoch: 2901, cost 22.19 s
2024-01-02 12:16:31,954	44k	INFO	====> Epoch: 2902, cost 22.33 s
2024-01-02 12:16:54,380	44k	INFO	====> Epoch: 2903, cost 22.43 s
2024-01-02 12:17:16,761	44k	INFO	Train Epoch: 2904 [96%]
2024-01-02 12:17:16,762	44k	INFO	Losses: [1.7374284267425537, 3.4564952850341797, 10.972334861755371, 13.214452743530273, -1.9113914966583252], step: 72600, lr: 6.956576084466863e-05, reference_loss: 27.46932029724121
2024-01-02 12:17:17,161	44k	INFO	====> Epoch: 2904, cost 22.78 s
2024-01-02 12:17:39,658	44k	INFO	====> Epoch: 2905, cost 22.50 s
2024-01-02 12:18:02,245	44k	INFO	====> Epoch: 2906, cost 22.59 s
2024-01-02 12:18:24,649	44k	INFO	====> Epoch: 2907, cost 22.40 s
2024-01-02 12:18:47,116	44k	INFO	====> Epoch: 2908, cost 22.47 s
2024-01-02 12:19:09,677	44k	INFO	====> Epoch: 2909, cost 22.56 s
2024-01-02 12:19:32,190	44k	INFO	====> Epoch: 2910, cost 22.51 s
2024-01-02 12:19:54,514	44k	INFO	====> Epoch: 2911, cost 22.32 s
2024-01-02 12:20:16,895	44k	INFO	Train Epoch: 2912 [96%]
2024-01-02 12:20:16,897	44k	INFO	Losses: [1.9196457862854004, 3.0601282119750977, 8.751041412353516, 11.922219276428223, -1.8992512226104736], step: 72800, lr: 6.949622551123673e-05, reference_loss: 23.753782272338867
2024-01-02 12:20:23,195	44k	INFO	Saving model and optimizer state at iteration 2912 to ./logs/44k/G_72800.pth
2024-01-02 12:20:24,129	44k	INFO	Saving model and optimizer state at iteration 2912 to ./logs/44k/D_72800.pth
2024-01-02 12:20:24,655	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_70400.pth
2024-01-02 12:20:24,694	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_70400.pth
2024-01-02 12:20:24,695	44k	INFO	====> Epoch: 2912, cost 30.18 s
2024-01-02 12:20:47,221	44k	INFO	====> Epoch: 2913, cost 22.53 s
2024-01-02 12:21:10,037	44k	INFO	====> Epoch: 2914, cost 22.82 s
2024-01-02 12:21:32,360	44k	INFO	====> Epoch: 2915, cost 22.32 s
2024-01-02 12:21:54,763	44k	INFO	====> Epoch: 2916, cost 22.40 s
2024-01-02 12:22:17,080	44k	INFO	====> Epoch: 2917, cost 22.32 s
2024-01-02 12:22:39,358	44k	INFO	====> Epoch: 2918, cost 22.28 s
2024-01-02 12:23:01,725	44k	INFO	====> Epoch: 2919, cost 22.37 s
2024-01-02 12:23:24,007	44k	INFO	Train Epoch: 2920 [96%]
2024-01-02 12:23:24,010	44k	INFO	Losses: [1.8410229682922363, 3.1872105598449707, 8.596810340881348, 11.94760513305664, -1.8801333904266357], step: 73000, lr: 6.942675968272417e-05, reference_loss: 23.692516326904297
2024-01-02 12:23:24,394	44k	INFO	====> Epoch: 2920, cost 22.67 s
2024-01-02 12:23:46,674	44k	INFO	====> Epoch: 2921, cost 22.28 s
2024-01-02 12:24:08,969	44k	INFO	====> Epoch: 2922, cost 22.30 s
2024-01-02 12:24:31,121	44k	INFO	====> Epoch: 2923, cost 22.15 s
2024-01-02 12:24:53,355	44k	INFO	====> Epoch: 2924, cost 22.23 s
2024-01-02 12:25:15,685	44k	INFO	====> Epoch: 2925, cost 22.33 s
2024-01-02 12:25:38,233	44k	INFO	====> Epoch: 2926, cost 22.55 s
2024-01-02 12:26:00,460	44k	INFO	====> Epoch: 2927, cost 22.23 s
2024-01-02 12:26:22,662	44k	INFO	Train Epoch: 2928 [96%]
2024-01-02 12:26:22,664	44k	INFO	Losses: [2.018843650817871, 3.2829549312591553, 7.909865856170654, 12.378629684448242, -1.7963826656341553], step: 73200, lr: 6.935736328965642e-05, reference_loss: 23.79391098022461
2024-01-02 12:26:23,051	44k	INFO	====> Epoch: 2928, cost 22.59 s
2024-01-02 12:26:45,415	44k	INFO	====> Epoch: 2929, cost 22.36 s
2024-01-02 12:27:07,938	44k	INFO	====> Epoch: 2930, cost 22.52 s
2024-01-02 12:27:30,273	44k	INFO	====> Epoch: 2931, cost 22.33 s
2024-01-02 12:27:52,519	44k	INFO	====> Epoch: 2932, cost 22.25 s
2024-01-02 12:28:14,810	44k	INFO	====> Epoch: 2933, cost 22.29 s
2024-01-02 12:28:37,006	44k	INFO	====> Epoch: 2934, cost 22.20 s
2024-01-02 12:28:59,202	44k	INFO	====> Epoch: 2935, cost 22.20 s
2024-01-02 12:29:21,731	44k	INFO	Train Epoch: 2936 [96%]
2024-01-02 12:29:21,732	44k	INFO	Losses: [1.728330135345459, 3.2964789867401123, 11.35500431060791, 12.894027709960938, -1.960440993309021], step: 73400, lr: 6.928803626262842e-05, reference_loss: 27.313400268554688
2024-01-02 12:29:22,361	44k	INFO	====> Epoch: 2936, cost 23.16 s
2024-01-02 12:29:44,871	44k	INFO	====> Epoch: 2937, cost 22.51 s
2024-01-02 12:30:07,289	44k	INFO	====> Epoch: 2938, cost 22.42 s
2024-01-02 12:30:29,697	44k	INFO	====> Epoch: 2939, cost 22.41 s
2024-01-02 12:30:52,037	44k	INFO	====> Epoch: 2940, cost 22.34 s
2024-01-02 12:31:14,406	44k	INFO	====> Epoch: 2941, cost 22.37 s
2024-01-02 12:31:36,637	44k	INFO	====> Epoch: 2942, cost 22.23 s
2024-01-02 12:31:58,892	44k	INFO	====> Epoch: 2943, cost 22.25 s
2024-01-02 12:32:21,256	44k	INFO	Train Epoch: 2944 [96%]
2024-01-02 12:32:21,257	44k	INFO	Losses: [1.9839372634887695, 2.844241142272949, 7.844000339508057, 11.832037925720215, -1.9588823318481445], step: 73600, lr: 6.921877853230442e-05, reference_loss: 22.545333862304688
2024-01-02 12:32:27,570	44k	INFO	Saving model and optimizer state at iteration 2944 to ./logs/44k/G_73600.pth
2024-01-02 12:32:28,509	44k	INFO	Saving model and optimizer state at iteration 2944 to ./logs/44k/D_73600.pth
2024-01-02 12:32:29,028	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_71200.pth
2024-01-02 12:32:29,068	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_71200.pth
2024-01-02 12:32:29,068	44k	INFO	====> Epoch: 2944, cost 30.18 s
2024-01-02 12:32:51,470	44k	INFO	====> Epoch: 2945, cost 22.40 s
2024-01-02 12:33:13,984	44k	INFO	====> Epoch: 2946, cost 22.51 s
2024-01-02 12:33:36,408	44k	INFO	====> Epoch: 2947, cost 22.42 s
2024-01-02 12:33:58,749	44k	INFO	====> Epoch: 2948, cost 22.34 s
2024-01-02 12:34:21,079	44k	INFO	====> Epoch: 2949, cost 22.33 s
2024-01-02 12:34:43,353	44k	INFO	====> Epoch: 2950, cost 22.27 s
2024-01-02 12:35:05,666	44k	INFO	====> Epoch: 2951, cost 22.31 s
2024-01-02 12:35:28,168	44k	INFO	Train Epoch: 2952 [96%]
2024-01-02 12:35:28,170	44k	INFO	Losses: [1.6606500148773193, 3.387404203414917, 10.314282417297363, 13.154096603393555, -1.8749518394470215], step: 73800, lr: 6.914959002941808e-05, reference_loss: 26.641481399536133
2024-01-02 12:35:28,569	44k	INFO	====> Epoch: 2952, cost 22.90 s
2024-01-02 12:35:50,980	44k	INFO	====> Epoch: 2953, cost 22.41 s
2024-01-02 12:36:13,472	44k	INFO	====> Epoch: 2954, cost 22.49 s
2024-01-02 12:36:35,848	44k	INFO	====> Epoch: 2955, cost 22.38 s
2024-01-02 12:36:58,392	44k	INFO	====> Epoch: 2956, cost 22.54 s
2024-01-02 12:37:20,808	44k	INFO	====> Epoch: 2957, cost 22.42 s
2024-01-02 12:37:43,188	44k	INFO	====> Epoch: 2958, cost 22.38 s
2024-01-02 12:38:05,584	44k	INFO	====> Epoch: 2959, cost 22.40 s
2024-01-02 12:38:27,972	44k	INFO	Train Epoch: 2960 [96%]
2024-01-02 12:38:27,974	44k	INFO	Losses: [1.9375455379486084, 2.9242794513702393, 6.671256065368652, 11.008625984191895, -1.8539223670959473], step: 74000, lr: 6.908047068477221e-05, reference_loss: 20.68778419494629
2024-01-02 12:38:28,371	44k	INFO	====> Epoch: 2960, cost 22.79 s
2024-01-02 12:38:50,725	44k	INFO	====> Epoch: 2961, cost 22.35 s
2024-01-02 12:39:13,026	44k	INFO	====> Epoch: 2962, cost 22.30 s
2024-01-02 12:39:35,280	44k	INFO	====> Epoch: 2963, cost 22.25 s
2024-01-02 12:39:57,671	44k	INFO	====> Epoch: 2964, cost 22.39 s
2024-01-02 12:40:20,160	44k	INFO	====> Epoch: 2965, cost 22.49 s
2024-01-02 12:40:42,760	44k	INFO	====> Epoch: 2966, cost 22.60 s
2024-01-02 12:41:05,190	44k	INFO	====> Epoch: 2967, cost 22.43 s
2024-01-02 12:41:27,471	44k	INFO	Train Epoch: 2968 [96%]
2024-01-02 12:41:27,473	44k	INFO	Losses: [1.671582579612732, 3.429375171661377, 9.899327278137207, 12.754429817199707, -1.968092441558838], step: 74200, lr: 6.901142042923885e-05, reference_loss: 25.786623001098633
2024-01-02 12:41:27,868	44k	INFO	====> Epoch: 2968, cost 22.68 s
2024-01-02 12:41:50,092	44k	INFO	====> Epoch: 2969, cost 22.22 s
2024-01-02 12:42:12,530	44k	INFO	====> Epoch: 2970, cost 22.44 s
2024-01-02 12:42:34,798	44k	INFO	====> Epoch: 2971, cost 22.27 s
2024-01-02 12:42:57,108	44k	INFO	====> Epoch: 2972, cost 22.31 s
2024-01-02 12:43:19,489	44k	INFO	====> Epoch: 2973, cost 22.38 s
2024-01-02 12:43:41,878	44k	INFO	====> Epoch: 2974, cost 22.39 s
2024-01-02 12:44:04,322	44k	INFO	====> Epoch: 2975, cost 22.44 s
2024-01-02 12:44:26,973	44k	INFO	Train Epoch: 2976 [96%]
2024-01-02 12:44:26,975	44k	INFO	Losses: [1.9535123109817505, 3.0352163314819336, 7.2729668617248535, 11.180612564086914, -1.9507570266723633], step: 74400, lr: 6.894243919375908e-05, reference_loss: 21.49155044555664
2024-01-02 12:44:32,964	44k	INFO	Saving model and optimizer state at iteration 2976 to ./logs/44k/G_74400.pth
2024-01-02 12:44:33,889	44k	INFO	Saving model and optimizer state at iteration 2976 to ./logs/44k/D_74400.pth
2024-01-02 12:44:34,397	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_72000.pth
2024-01-02 12:44:34,436	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_72000.pth
2024-01-02 12:44:34,436	44k	INFO	====> Epoch: 2976, cost 30.11 s
2024-01-02 12:44:56,772	44k	INFO	====> Epoch: 2977, cost 22.34 s
2024-01-02 12:45:19,181	44k	INFO	====> Epoch: 2978, cost 22.41 s
2024-01-02 12:45:41,567	44k	INFO	====> Epoch: 2979, cost 22.39 s
2024-01-02 12:46:03,808	44k	INFO	====> Epoch: 2980, cost 22.24 s
2024-01-02 12:46:26,057	44k	INFO	====> Epoch: 2981, cost 22.25 s
2024-01-02 12:46:48,366	44k	INFO	====> Epoch: 2982, cost 22.31 s
2024-01-02 12:47:10,778	44k	INFO	====> Epoch: 2983, cost 22.41 s
2024-01-02 12:47:33,022	44k	INFO	Train Epoch: 2984 [96%]
2024-01-02 12:47:33,024	44k	INFO	Losses: [1.8389126062393188, 3.259387731552124, 10.16644287109375, 12.588935852050781, -1.95205819606781], step: 74600, lr: 6.887352690934304e-05, reference_loss: 25.901620864868164
2024-01-02 12:47:33,408	44k	INFO	====> Epoch: 2984, cost 22.63 s
2024-01-02 12:47:55,547	44k	INFO	====> Epoch: 2985, cost 22.14 s
2024-01-02 12:48:17,777	44k	INFO	====> Epoch: 2986, cost 22.23 s
2024-01-02 12:48:40,025	44k	INFO	====> Epoch: 2987, cost 22.25 s
2024-01-02 12:49:02,130	44k	INFO	====> Epoch: 2988, cost 22.10 s
2024-01-02 12:49:24,271	44k	INFO	====> Epoch: 2989, cost 22.14 s
2024-01-02 12:49:46,427	44k	INFO	====> Epoch: 2990, cost 22.16 s
2024-01-02 12:50:08,508	44k	INFO	====> Epoch: 2991, cost 22.08 s
2024-01-02 12:50:30,675	44k	INFO	Train Epoch: 2992 [96%]
2024-01-02 12:50:30,676	44k	INFO	Losses: [1.978066325187683, 3.0912368297576904, 7.019756317138672, 10.787083625793457, -1.9228930473327637], step: 74800, lr: 6.880468350706982e-05, reference_loss: 20.953250885009766
2024-01-02 12:50:31,349	44k	INFO	====> Epoch: 2992, cost 22.84 s
2024-01-02 12:50:53,530	44k	INFO	====> Epoch: 2993, cost 22.18 s
2024-01-02 12:51:15,729	44k	INFO	====> Epoch: 2994, cost 22.20 s
2024-01-02 12:51:37,990	44k	INFO	====> Epoch: 2995, cost 22.26 s
2024-01-02 12:52:00,350	44k	INFO	====> Epoch: 2996, cost 22.36 s
2024-01-02 12:52:22,706	44k	INFO	====> Epoch: 2997, cost 22.36 s
2024-01-02 12:52:45,003	44k	INFO	====> Epoch: 2998, cost 22.30 s
2024-01-02 12:53:07,347	44k	INFO	====> Epoch: 2999, cost 22.34 s
2024-01-02 12:53:29,684	44k	INFO	Train Epoch: 3000 [96%]
2024-01-02 12:53:29,685	44k	INFO	Losses: [1.5202386379241943, 3.5801589488983154, 11.561962127685547, 13.136204719543457, -2.0858774185180664], step: 75000, lr: 6.873590891808743e-05, reference_loss: 27.712688446044922
2024-01-02 12:53:30,086	44k	INFO	====> Epoch: 3000, cost 22.74 s
2024-01-02 12:53:52,392	44k	INFO	====> Epoch: 3001, cost 22.31 s
2024-01-02 12:54:14,746	44k	INFO	====> Epoch: 3002, cost 22.35 s
2024-01-02 12:54:36,943	44k	INFO	====> Epoch: 3003, cost 22.20 s
2024-01-02 12:54:59,062	44k	INFO	====> Epoch: 3004, cost 22.12 s
2024-01-02 12:55:21,254	44k	INFO	====> Epoch: 3005, cost 22.19 s
2024-01-02 12:55:43,449	44k	INFO	====> Epoch: 3006, cost 22.20 s
2024-01-02 12:56:05,644	44k	INFO	====> Epoch: 3007, cost 22.20 s
2024-01-02 12:56:27,921	44k	INFO	Train Epoch: 3008 [96%]
2024-01-02 12:56:27,924	44k	INFO	Losses: [1.79925537109375, 3.2938785552978516, 9.370794296264648, 12.68583869934082, -1.9517544507980347], step: 75200, lr: 6.866720307361265e-05, reference_loss: 25.198013305664062
2024-01-02 12:56:33,476	44k	INFO	Saving model and optimizer state at iteration 3008 to ./logs/44k/G_75200.pth
2024-01-02 12:56:34,398	44k	INFO	Saving model and optimizer state at iteration 3008 to ./logs/44k/D_75200.pth
2024-01-02 12:56:34,883	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_72800.pth
2024-01-02 12:56:34,921	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_72800.pth
2024-01-02 12:56:34,921	44k	INFO	====> Epoch: 3008, cost 29.28 s
2024-01-02 12:56:57,099	44k	INFO	====> Epoch: 3009, cost 22.18 s
2024-01-02 12:57:19,558	44k	INFO	====> Epoch: 3010, cost 22.46 s
2024-01-02 12:57:41,770	44k	INFO	====> Epoch: 3011, cost 22.21 s
2024-01-02 12:58:04,070	44k	INFO	====> Epoch: 3012, cost 22.30 s
2024-01-02 12:58:26,423	44k	INFO	====> Epoch: 3013, cost 22.35 s
2024-01-02 12:58:48,748	44k	INFO	====> Epoch: 3014, cost 22.33 s
2024-01-02 12:59:11,082	44k	INFO	====> Epoch: 3015, cost 22.33 s
2024-01-02 12:59:33,500	44k	INFO	Train Epoch: 3016 [96%]
2024-01-02 12:59:33,502	44k	INFO	Losses: [1.8931772708892822, 3.14469838142395, 9.584399223327637, 13.322704315185547, -1.9655405282974243], step: 75400, lr: 6.859856590493108e-05, reference_loss: 25.97943878173828
2024-01-02 12:59:33,890	44k	INFO	====> Epoch: 3016, cost 22.81 s
2024-01-02 12:59:56,158	44k	INFO	====> Epoch: 3017, cost 22.27 s
2024-01-02 13:00:18,359	44k	INFO	====> Epoch: 3018, cost 22.20 s
2024-01-02 13:00:40,624	44k	INFO	====> Epoch: 3019, cost 22.27 s
2024-01-02 13:01:02,883	44k	INFO	====> Epoch: 3020, cost 22.26 s
2024-01-02 13:01:25,071	44k	INFO	====> Epoch: 3021, cost 22.19 s
2024-01-02 13:01:47,484	44k	INFO	====> Epoch: 3022, cost 22.41 s
2024-01-02 13:02:09,786	44k	INFO	====> Epoch: 3023, cost 22.30 s
2024-01-02 13:02:32,129	44k	INFO	Train Epoch: 3024 [96%]
2024-01-02 13:02:32,131	44k	INFO	Losses: [2.0506997108459473, 3.212250232696533, 8.50404167175293, 12.306777000427246, -1.9279582500457764], step: 75600, lr: 6.852999734339691e-05, reference_loss: 24.145811080932617
2024-01-02 13:02:32,523	44k	INFO	====> Epoch: 3024, cost 22.74 s
2024-01-02 13:02:54,913	44k	INFO	====> Epoch: 3025, cost 22.39 s
2024-01-02 13:03:17,125	44k	INFO	====> Epoch: 3026, cost 22.21 s
2024-01-02 13:03:39,415	44k	INFO	====> Epoch: 3027, cost 22.29 s
2024-01-02 13:04:01,681	44k	INFO	====> Epoch: 3028, cost 22.27 s
2024-01-02 13:04:23,812	44k	INFO	====> Epoch: 3029, cost 22.13 s
2024-01-02 13:04:46,078	44k	INFO	====> Epoch: 3030, cost 22.27 s
2024-01-02 13:05:08,421	44k	INFO	====> Epoch: 3031, cost 22.34 s
2024-01-02 13:05:30,819	44k	INFO	Train Epoch: 3032 [96%]
2024-01-02 13:05:30,821	44k	INFO	Losses: [1.7150734663009644, 3.735067367553711, 11.042569160461426, 13.299778938293457, -2.111009120941162], step: 75800, lr: 6.846149732043302e-05, reference_loss: 27.68147850036621
2024-01-02 13:05:31,205	44k	INFO	====> Epoch: 3032, cost 22.78 s
2024-01-02 13:05:53,354	44k	INFO	====> Epoch: 3033, cost 22.15 s
2024-01-02 13:06:15,585	44k	INFO	====> Epoch: 3034, cost 22.23 s
2024-01-02 13:06:37,751	44k	INFO	====> Epoch: 3035, cost 22.17 s
2024-01-02 13:06:59,919	44k	INFO	====> Epoch: 3036, cost 22.17 s
2024-01-02 13:07:22,081	44k	INFO	====> Epoch: 3037, cost 22.16 s
2024-01-02 13:07:44,180	44k	INFO	====> Epoch: 3038, cost 22.10 s
2024-01-02 13:08:06,311	44k	INFO	====> Epoch: 3039, cost 22.13 s
2024-01-02 13:08:28,478	44k	INFO	Train Epoch: 3040 [96%]
2024-01-02 13:08:28,480	44k	INFO	Losses: [1.9810785055160522, 2.8143227100372314, 7.553792953491211, 11.385774612426758, -1.9577728509902954], step: 76000, lr: 6.839306576753085e-05, reference_loss: 21.77719497680664
2024-01-02 13:08:34,785	44k	INFO	Saving model and optimizer state at iteration 3040 to ./logs/44k/G_76000.pth
2024-01-02 13:08:35,724	44k	INFO	Saving model and optimizer state at iteration 3040 to ./logs/44k/D_76000.pth
2024-01-02 13:08:36,238	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_73600.pth
2024-01-02 13:08:36,277	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_73600.pth
2024-01-02 13:08:36,277	44k	INFO	====> Epoch: 3040, cost 29.97 s
2024-01-02 13:08:58,374	44k	INFO	====> Epoch: 3041, cost 22.10 s
2024-01-02 13:09:20,545	44k	INFO	====> Epoch: 3042, cost 22.17 s
2024-01-02 13:09:42,650	44k	INFO	====> Epoch: 3043, cost 22.11 s
2024-01-02 13:10:04,825	44k	INFO	====> Epoch: 3044, cost 22.17 s
2024-01-02 13:10:27,253	44k	INFO	====> Epoch: 3045, cost 22.43 s
2024-01-02 13:10:49,428	44k	INFO	====> Epoch: 3046, cost 22.17 s
2024-01-02 13:11:11,640	44k	INFO	====> Epoch: 3047, cost 22.21 s
2024-01-02 13:11:33,892	44k	INFO	Train Epoch: 3048 [96%]
2024-01-02 13:11:33,894	44k	INFO	Losses: [1.6696985960006714, 3.507742404937744, 10.417915344238281, 13.074847221374512, -2.0242297649383545], step: 76200, lr: 6.832470261625025e-05, reference_loss: 26.64597511291504
2024-01-02 13:11:34,290	44k	INFO	====> Epoch: 3048, cost 22.65 s
2024-01-02 13:11:56,623	44k	INFO	====> Epoch: 3049, cost 22.33 s
2024-01-02 13:12:18,809	44k	INFO	====> Epoch: 3050, cost 22.19 s
2024-01-02 13:12:40,855	44k	INFO	====> Epoch: 3051, cost 22.05 s
2024-01-02 13:13:03,090	44k	INFO	====> Epoch: 3052, cost 22.24 s
2024-01-02 13:13:25,325	44k	INFO	====> Epoch: 3053, cost 22.24 s
2024-01-02 13:13:47,416	44k	INFO	====> Epoch: 3054, cost 22.09 s
2024-01-02 13:14:09,525	44k	INFO	====> Epoch: 3055, cost 22.11 s
2024-01-02 13:14:31,745	44k	INFO	Train Epoch: 3056 [96%]
2024-01-02 13:14:31,747	44k	INFO	Losses: [1.9938268661499023, 3.1210691928863525, 8.96212387084961, 12.037559509277344, -1.9766117334365845], step: 76400, lr: 6.825640779821954e-05, reference_loss: 24.13796615600586
2024-01-02 13:14:32,134	44k	INFO	====> Epoch: 3056, cost 22.61 s
2024-01-02 13:14:54,180	44k	INFO	====> Epoch: 3057, cost 22.05 s
2024-01-02 13:15:16,194	44k	INFO	====> Epoch: 3058, cost 22.01 s
2024-01-02 13:15:38,385	44k	INFO	====> Epoch: 3059, cost 22.19 s
2024-01-02 13:16:00,538	44k	INFO	====> Epoch: 3060, cost 22.15 s
2024-01-02 13:16:22,799	44k	INFO	====> Epoch: 3061, cost 22.26 s
2024-01-02 13:16:45,403	44k	INFO	====> Epoch: 3062, cost 22.60 s
2024-01-02 13:17:07,718	44k	INFO	====> Epoch: 3063, cost 22.32 s
2024-01-02 13:17:30,070	44k	INFO	Train Epoch: 3064 [96%]
2024-01-02 13:17:30,072	44k	INFO	Losses: [1.6281238794326782, 3.161499500274658, 9.790541648864746, 12.34075927734375, -2.102684497833252], step: 76600, lr: 6.818818124513536e-05, reference_loss: 24.818241119384766
2024-01-02 13:17:30,477	44k	INFO	====> Epoch: 3064, cost 22.76 s
2024-01-02 13:17:52,814	44k	INFO	====> Epoch: 3065, cost 22.34 s
2024-01-02 13:18:15,091	44k	INFO	====> Epoch: 3066, cost 22.28 s
2024-01-02 13:18:37,344	44k	INFO	====> Epoch: 3067, cost 22.25 s
2024-01-02 13:18:59,637	44k	INFO	====> Epoch: 3068, cost 22.29 s
2024-01-02 13:19:21,754	44k	INFO	====> Epoch: 3069, cost 22.12 s
2024-01-02 13:19:43,833	44k	INFO	====> Epoch: 3070, cost 22.08 s
2024-01-02 13:20:06,061	44k	INFO	====> Epoch: 3071, cost 22.23 s
2024-01-02 13:20:28,424	44k	INFO	Train Epoch: 3072 [96%]
2024-01-02 13:20:28,426	44k	INFO	Losses: [1.8874074220657349, 3.2818267345428467, 9.162830352783203, 12.146771430969238, -2.0535781383514404], step: 76800, lr: 6.812002288876259e-05, reference_loss: 24.42525863647461
2024-01-02 13:20:34,180	44k	INFO	Saving model and optimizer state at iteration 3072 to ./logs/44k/G_76800.pth
2024-01-02 13:20:35,119	44k	INFO	Saving model and optimizer state at iteration 3072 to ./logs/44k/D_76800.pth
2024-01-02 13:20:35,617	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_74400.pth
2024-01-02 13:20:35,656	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_74400.pth
2024-01-02 13:20:35,656	44k	INFO	====> Epoch: 3072, cost 29.60 s
2024-01-02 13:20:57,857	44k	INFO	====> Epoch: 3073, cost 22.20 s
2024-01-02 13:21:19,945	44k	INFO	====> Epoch: 3074, cost 22.09 s
2024-01-02 13:21:42,013	44k	INFO	====> Epoch: 3075, cost 22.07 s
2024-01-02 13:22:04,228	44k	INFO	====> Epoch: 3076, cost 22.22 s
2024-01-02 13:22:26,547	44k	INFO	====> Epoch: 3077, cost 22.32 s
2024-01-02 13:22:48,873	44k	INFO	====> Epoch: 3078, cost 22.33 s
2024-01-02 13:23:11,373	44k	INFO	====> Epoch: 3079, cost 22.50 s
2024-01-02 13:23:33,587	44k	INFO	Train Epoch: 3080 [96%]
2024-01-02 13:23:33,589	44k	INFO	Losses: [1.752143144607544, 3.606555938720703, 9.415660858154297, 12.05115032196045, -2.022953987121582], step: 77000, lr: 6.805193266093435e-05, reference_loss: 24.802555084228516
2024-01-02 13:23:34,089	44k	INFO	====> Epoch: 3080, cost 22.72 s
2024-01-02 13:23:56,290	44k	INFO	====> Epoch: 3081, cost 22.20 s
2024-01-02 13:24:18,473	44k	INFO	====> Epoch: 3082, cost 22.18 s
2024-01-02 13:24:40,638	44k	INFO	====> Epoch: 3083, cost 22.17 s
2024-01-02 13:25:02,961	44k	INFO	====> Epoch: 3084, cost 22.32 s
2024-01-02 13:25:25,267	44k	INFO	====> Epoch: 3085, cost 22.31 s
2024-01-02 13:25:47,390	44k	INFO	====> Epoch: 3086, cost 22.12 s
2024-01-02 13:26:09,509	44k	INFO	====> Epoch: 3087, cost 22.12 s
2024-01-02 13:26:31,736	44k	INFO	Train Epoch: 3088 [96%]
2024-01-02 13:26:31,739	44k	INFO	Losses: [1.9235514402389526, 3.013331890106201, 7.204543590545654, 10.928997993469238, -1.975799560546875], step: 77200, lr: 6.798391049355191e-05, reference_loss: 21.09462547302246
2024-01-02 13:26:32,405	44k	INFO	====> Epoch: 3088, cost 22.90 s
2024-01-02 13:26:54,575	44k	INFO	====> Epoch: 3089, cost 22.17 s
2024-01-02 13:27:16,753	44k	INFO	====> Epoch: 3090, cost 22.18 s
2024-01-02 13:27:38,939	44k	INFO	====> Epoch: 3091, cost 22.19 s
2024-01-02 13:28:01,150	44k	INFO	====> Epoch: 3092, cost 22.21 s
2024-01-02 13:28:23,355	44k	INFO	====> Epoch: 3093, cost 22.20 s
2024-01-02 13:28:45,393	44k	INFO	====> Epoch: 3094, cost 22.04 s
2024-01-02 13:29:07,558	44k	INFO	====> Epoch: 3095, cost 22.16 s
2024-01-02 13:29:29,653	44k	INFO	Train Epoch: 3096 [96%]
2024-01-02 13:29:29,654	44k	INFO	Losses: [1.6661546230316162, 3.4041998386383057, 9.934333801269531, 12.04917049407959, -2.189756393432617], step: 77400, lr: 6.791595631858461e-05, reference_loss: 24.864103317260742
2024-01-02 13:29:30,127	44k	INFO	====> Epoch: 3096, cost 22.57 s
2024-01-02 13:29:52,238	44k	INFO	====> Epoch: 3097, cost 22.11 s
2024-01-02 13:30:14,656	44k	INFO	====> Epoch: 3098, cost 22.42 s
2024-01-02 13:30:36,979	44k	INFO	====> Epoch: 3099, cost 22.32 s
2024-01-02 13:30:59,336	44k	INFO	====> Epoch: 3100, cost 22.36 s
2024-01-02 13:31:21,704	44k	INFO	====> Epoch: 3101, cost 22.37 s
2024-01-02 13:31:44,041	44k	INFO	====> Epoch: 3102, cost 22.34 s
2024-01-02 13:32:06,437	44k	INFO	====> Epoch: 3103, cost 22.40 s
2024-01-02 13:32:28,736	44k	INFO	Train Epoch: 3104 [96%]
2024-01-02 13:32:28,738	44k	INFO	Losses: [1.9540866613388062, 3.1638541221618652, 9.119860649108887, 11.717720985412598, -2.1381475925445557], step: 77600, lr: 6.784807006806973e-05, reference_loss: 23.81737518310547
2024-01-02 13:32:35,088	44k	INFO	Saving model and optimizer state at iteration 3104 to ./logs/44k/G_77600.pth
2024-01-02 13:32:36,040	44k	INFO	Saving model and optimizer state at iteration 3104 to ./logs/44k/D_77600.pth
2024-01-02 13:32:36,553	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_75200.pth
2024-01-02 13:32:36,592	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_75200.pth
2024-01-02 13:32:36,592	44k	INFO	====> Epoch: 3104, cost 30.15 s
2024-01-02 13:32:58,942	44k	INFO	====> Epoch: 3105, cost 22.35 s
2024-01-02 13:33:21,632	44k	INFO	====> Epoch: 3106, cost 22.69 s
2024-01-02 13:33:44,131	44k	INFO	====> Epoch: 3107, cost 22.50 s
2024-01-02 13:34:06,430	44k	INFO	====> Epoch: 3108, cost 22.30 s
2024-01-02 13:34:28,746	44k	INFO	====> Epoch: 3109, cost 22.32 s
2024-01-02 13:34:51,091	44k	INFO	====> Epoch: 3110, cost 22.34 s
2024-01-02 13:35:13,395	44k	INFO	====> Epoch: 3111, cost 22.30 s
2024-01-02 13:35:35,696	44k	INFO	Train Epoch: 3112 [96%]
2024-01-02 13:35:35,699	44k	INFO	Losses: [1.753989577293396, 3.1982579231262207, 9.435870170593262, 11.811022758483887, -2.129167318344116], step: 77800, lr: 6.778025167411257e-05, reference_loss: 24.06997299194336
2024-01-02 13:35:36,078	44k	INFO	====> Epoch: 3112, cost 22.68 s
2024-01-02 13:35:58,192	44k	INFO	====> Epoch: 3113, cost 22.11 s
2024-01-02 13:36:20,501	44k	INFO	====> Epoch: 3114, cost 22.31 s
2024-01-02 13:36:42,899	44k	INFO	====> Epoch: 3115, cost 22.40 s
2024-01-02 13:37:05,399	44k	INFO	====> Epoch: 3116, cost 22.50 s
2024-01-02 13:37:27,868	44k	INFO	====> Epoch: 3117, cost 22.47 s
2024-01-02 13:37:50,589	44k	INFO	====> Epoch: 3118, cost 22.72 s
2024-01-02 13:38:13,081	44k	INFO	====> Epoch: 3119, cost 22.49 s
2024-01-02 13:38:35,366	44k	INFO	Train Epoch: 3120 [96%]
2024-01-02 13:38:35,368	44k	INFO	Losses: [1.9035508632659912, 3.0746710300445557, 6.8561787605285645, 10.861318588256836, -2.0205185413360596], step: 78000, lr: 6.771250106888624e-05, reference_loss: 20.675199508666992
2024-01-02 13:38:35,780	44k	INFO	====> Epoch: 3120, cost 22.70 s
2024-01-02 13:38:58,106	44k	INFO	====> Epoch: 3121, cost 22.33 s
2024-01-02 13:39:20,483	44k	INFO	====> Epoch: 3122, cost 22.38 s
2024-01-02 13:39:42,880	44k	INFO	====> Epoch: 3123, cost 22.40 s
2024-01-02 13:40:05,311	44k	INFO	====> Epoch: 3124, cost 22.43 s
2024-01-02 13:40:27,760	44k	INFO	====> Epoch: 3125, cost 22.45 s
2024-01-02 13:40:50,149	44k	INFO	====> Epoch: 3126, cost 22.39 s
2024-01-02 13:41:12,445	44k	INFO	====> Epoch: 3127, cost 22.30 s
2024-01-02 13:41:34,959	44k	INFO	Train Epoch: 3128 [96%]
2024-01-02 13:41:34,961	44k	INFO	Losses: [1.5613740682601929, 3.499154567718506, 11.975788116455078, 12.852449417114258, -2.165947437286377], step: 78200, lr: 6.764481818463165e-05, reference_loss: 27.72281837463379
2024-01-02 13:41:35,596	44k	INFO	====> Epoch: 3128, cost 23.15 s
2024-01-02 13:41:57,879	44k	INFO	====> Epoch: 3129, cost 22.28 s
2024-01-02 13:42:20,223	44k	INFO	====> Epoch: 3130, cost 22.34 s
2024-01-02 13:42:42,508	44k	INFO	====> Epoch: 3131, cost 22.29 s
2024-01-02 13:43:04,944	44k	INFO	====> Epoch: 3132, cost 22.44 s
2024-01-02 13:43:27,478	44k	INFO	====> Epoch: 3133, cost 22.53 s
2024-01-02 13:43:49,878	44k	INFO	====> Epoch: 3134, cost 22.40 s
2024-01-02 13:44:12,258	44k	INFO	====> Epoch: 3135, cost 22.38 s
2024-01-02 13:44:34,724	44k	INFO	Train Epoch: 3136 [96%]
2024-01-02 13:44:34,725	44k	INFO	Losses: [1.8921774625778198, 3.1297340393066406, 8.932167053222656, 11.818282127380371, -2.1777164936065674], step: 78400, lr: 6.757720295365747e-05, reference_loss: 23.59464454650879
2024-01-02 13:44:41,401	44k	INFO	Saving model and optimizer state at iteration 3136 to ./logs/44k/G_78400.pth
2024-01-02 13:44:42,327	44k	INFO	Saving model and optimizer state at iteration 3136 to ./logs/44k/D_78400.pth
2024-01-02 13:44:42,864	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_76000.pth
2024-01-02 13:44:42,903	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_76000.pth
2024-01-02 13:44:42,903	44k	INFO	====> Epoch: 3136, cost 30.65 s
2024-01-02 13:45:05,167	44k	INFO	====> Epoch: 3137, cost 22.26 s
2024-01-02 13:45:27,527	44k	INFO	====> Epoch: 3138, cost 22.36 s
2024-01-02 13:45:49,851	44k	INFO	====> Epoch: 3139, cost 22.32 s
2024-01-02 13:46:12,330	44k	INFO	====> Epoch: 3140, cost 22.48 s
2024-01-02 13:46:34,812	44k	INFO	====> Epoch: 3141, cost 22.48 s
2024-01-02 13:46:57,198	44k	INFO	====> Epoch: 3142, cost 22.39 s
2024-01-02 13:47:19,746	44k	INFO	====> Epoch: 3143, cost 22.55 s
2024-01-02 13:47:42,208	44k	INFO	Train Epoch: 3144 [96%]
2024-01-02 13:47:42,209	44k	INFO	Losses: [1.6992872953414917, 3.3490779399871826, 9.015950202941895, 11.638941764831543, -2.1522960662841797], step: 78600, lr: 6.750965530833997e-05, reference_loss: 23.550962448120117
2024-01-02 13:47:42,635	44k	INFO	====> Epoch: 3144, cost 22.89 s
2024-01-02 13:48:05,053	44k	INFO	====> Epoch: 3145, cost 22.42 s
2024-01-02 13:48:27,479	44k	INFO	====> Epoch: 3146, cost 22.43 s
2024-01-02 13:48:49,816	44k	INFO	====> Epoch: 3147, cost 22.34 s
2024-01-02 13:49:12,428	44k	INFO	====> Epoch: 3148, cost 22.61 s
2024-01-02 13:49:34,832	44k	INFO	====> Epoch: 3149, cost 22.40 s
2024-01-02 13:49:57,217	44k	INFO	====> Epoch: 3150, cost 22.38 s
2024-01-02 13:50:19,647	44k	INFO	====> Epoch: 3151, cost 22.43 s
2024-01-02 13:50:42,023	44k	INFO	Train Epoch: 3152 [96%]
2024-01-02 13:50:42,025	44k	INFO	Losses: [1.8989081382751465, 3.1442575454711914, 7.186768054962158, 11.061412811279297, -2.060147762298584], step: 78800, lr: 6.744217518112312e-05, reference_loss: 21.231199264526367
2024-01-02 13:50:42,426	44k	INFO	====> Epoch: 3152, cost 22.78 s
2024-01-02 13:51:04,831	44k	INFO	====> Epoch: 3153, cost 22.41 s
2024-01-02 13:51:27,199	44k	INFO	====> Epoch: 3154, cost 22.37 s
2024-01-02 13:51:49,558	44k	INFO	====> Epoch: 3155, cost 22.36 s
2024-01-02 13:52:11,948	44k	INFO	====> Epoch: 3156, cost 22.39 s
2024-01-02 13:52:34,372	44k	INFO	====> Epoch: 3157, cost 22.42 s
2024-01-02 13:52:56,752	44k	INFO	====> Epoch: 3158, cost 22.38 s
2024-01-02 13:53:19,059	44k	INFO	====> Epoch: 3159, cost 22.31 s
2024-01-02 13:53:41,458	44k	INFO	Train Epoch: 3160 [96%]
2024-01-02 13:53:41,460	44k	INFO	Losses: [1.5558629035949707, 3.659578561782837, 11.81864070892334, 12.73089599609375, -2.18300724029541], step: 79000, lr: 6.737476250451829e-05, reference_loss: 27.58197021484375
2024-01-02 13:53:41,853	44k	INFO	====> Epoch: 3160, cost 22.79 s
2024-01-02 13:54:04,094	44k	INFO	====> Epoch: 3161, cost 22.24 s
2024-01-02 13:54:26,374	44k	INFO	====> Epoch: 3162, cost 22.28 s
2024-01-02 13:54:48,510	44k	INFO	====> Epoch: 3163, cost 22.14 s
2024-01-02 13:55:10,722	44k	INFO	====> Epoch: 3164, cost 22.21 s
2024-01-02 13:55:32,932	44k	INFO	====> Epoch: 3165, cost 22.21 s
2024-01-02 13:55:55,286	44k	INFO	====> Epoch: 3166, cost 22.35 s
2024-01-02 13:56:17,618	44k	INFO	====> Epoch: 3167, cost 22.33 s
2024-01-02 13:56:40,023	44k	INFO	Train Epoch: 3168 [96%]
2024-01-02 13:56:40,025	44k	INFO	Losses: [1.9139461517333984, 2.9670345783233643, 7.583834648132324, 11.24893856048584, -2.1152191162109375], step: 79200, lr: 6.73074172111044e-05, reference_loss: 21.598533630371094
2024-01-02 13:56:45,849	44k	INFO	Saving model and optimizer state at iteration 3168 to ./logs/44k/G_79200.pth
2024-01-02 13:56:46,782	44k	INFO	Saving model and optimizer state at iteration 3168 to ./logs/44k/D_79200.pth
2024-01-02 13:56:47,302	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_76800.pth
2024-01-02 13:56:47,341	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_76800.pth
2024-01-02 13:56:47,341	44k	INFO	====> Epoch: 3168, cost 29.72 s
2024-01-02 13:57:09,673	44k	INFO	====> Epoch: 3169, cost 22.33 s
2024-01-02 13:57:32,154	44k	INFO	====> Epoch: 3170, cost 22.48 s
2024-01-02 13:57:54,479	44k	INFO	====> Epoch: 3171, cost 22.33 s
2024-01-02 13:58:16,865	44k	INFO	====> Epoch: 3172, cost 22.39 s
2024-01-02 13:58:39,141	44k	INFO	====> Epoch: 3173, cost 22.28 s
2024-01-02 13:59:01,459	44k	INFO	====> Epoch: 3174, cost 22.32 s
2024-01-02 13:59:23,972	44k	INFO	====> Epoch: 3175, cost 22.51 s
2024-01-02 13:59:46,228	44k	INFO	Train Epoch: 3176 [96%]
2024-01-02 13:59:46,230	44k	INFO	Losses: [1.709864616394043, 3.2518117427825928, 9.056378364562988, 12.005395889282227, -2.1149826049804688], step: 79400, lr: 6.724013923352769e-05, reference_loss: 23.90846824645996
2024-01-02 13:59:46,627	44k	INFO	====> Epoch: 3176, cost 22.66 s
2024-01-02 14:00:09,041	44k	INFO	====> Epoch: 3177, cost 22.41 s
2024-01-02 14:00:31,471	44k	INFO	====> Epoch: 3178, cost 22.43 s
2024-01-02 14:00:53,798	44k	INFO	====> Epoch: 3179, cost 22.33 s
2024-01-02 14:01:16,327	44k	INFO	====> Epoch: 3180, cost 22.53 s
2024-01-02 14:01:38,767	44k	INFO	====> Epoch: 3181, cost 22.44 s
2024-01-02 14:02:01,131	44k	INFO	====> Epoch: 3182, cost 22.36 s
2024-01-02 14:02:23,474	44k	INFO	====> Epoch: 3183, cost 22.34 s
2024-01-02 14:02:45,784	44k	INFO	Train Epoch: 3184 [96%]
2024-01-02 14:02:45,786	44k	INFO	Losses: [1.8528709411621094, 3.0702192783355713, 7.268439292907715, 10.239056587219238, -2.0941503047943115], step: 79600, lr: 6.717292850450181e-05, reference_loss: 20.336435317993164
2024-01-02 14:02:46,360	44k	INFO	====> Epoch: 3184, cost 22.89 s
2024-01-02 14:03:08,673	44k	INFO	====> Epoch: 3185, cost 22.31 s
2024-01-02 14:03:31,030	44k	INFO	====> Epoch: 3186, cost 22.36 s
2024-01-02 14:03:53,311	44k	INFO	====> Epoch: 3187, cost 22.28 s
2024-01-02 14:04:15,565	44k	INFO	====> Epoch: 3188, cost 22.25 s
2024-01-02 14:04:37,788	44k	INFO	====> Epoch: 3189, cost 22.22 s
2024-01-02 14:05:00,120	44k	INFO	====> Epoch: 3190, cost 22.33 s
2024-01-02 14:05:22,495	44k	INFO	====> Epoch: 3191, cost 22.38 s
2024-01-02 14:05:44,840	44k	INFO	Train Epoch: 3192 [96%]
2024-01-02 14:05:44,842	44k	INFO	Losses: [1.6171422004699707, 3.4165456295013428, 10.311751365661621, 12.07823371887207, -2.2704880237579346], step: 79800, lr: 6.710578495680762e-05, reference_loss: 25.153182983398438
2024-01-02 14:05:45,231	44k	INFO	====> Epoch: 3192, cost 22.74 s
2024-01-02 14:06:07,568	44k	INFO	====> Epoch: 3193, cost 22.34 s
2024-01-02 14:06:29,990	44k	INFO	====> Epoch: 3194, cost 22.42 s
2024-01-02 14:06:52,371	44k	INFO	====> Epoch: 3195, cost 22.38 s
2024-01-02 14:07:14,798	44k	INFO	====> Epoch: 3196, cost 22.43 s
2024-01-02 14:07:37,052	44k	INFO	====> Epoch: 3197, cost 22.25 s
2024-01-02 14:07:59,279	44k	INFO	====> Epoch: 3198, cost 22.23 s
2024-01-02 14:08:21,639	44k	INFO	====> Epoch: 3199, cost 22.36 s
2024-01-02 14:08:43,948	44k	INFO	Train Epoch: 3200 [96%]
2024-01-02 14:08:43,950	44k	INFO	Losses: [1.9300556182861328, 3.049840211868286, 7.565561294555664, 11.255006790161133, -2.232503890991211], step: 80000, lr: 6.703870852329315e-05, reference_loss: 21.567960739135742
2024-01-02 14:08:50,014	44k	INFO	Saving model and optimizer state at iteration 3200 to ./logs/44k/G_80000.pth
2024-01-02 14:08:50,951	44k	INFO	Saving model and optimizer state at iteration 3200 to ./logs/44k/D_80000.pth
2024-01-02 14:08:51,462	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_77600.pth
2024-01-02 14:08:51,501	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_77600.pth
2024-01-02 14:08:51,501	44k	INFO	====> Epoch: 3200, cost 29.86 s
2024-01-02 14:09:13,817	44k	INFO	====> Epoch: 3201, cost 22.32 s
2024-01-02 14:09:36,471	44k	INFO	====> Epoch: 3202, cost 22.65 s
2024-01-02 14:09:58,908	44k	INFO	====> Epoch: 3203, cost 22.44 s
2024-01-02 14:10:21,269	44k	INFO	====> Epoch: 3204, cost 22.36 s
2024-01-02 14:10:43,569	44k	INFO	====> Epoch: 3205, cost 22.30 s
2024-01-02 14:11:05,980	44k	INFO	====> Epoch: 3206, cost 22.41 s
2024-01-02 14:11:28,377	44k	INFO	====> Epoch: 3207, cost 22.40 s
2024-01-02 14:11:50,787	44k	INFO	Train Epoch: 3208 [96%]
2024-01-02 14:11:50,789	44k	INFO	Losses: [1.7442643642425537, 3.1551883220672607, 10.526013374328613, 13.092933654785156, -2.1481940746307373], step: 80200, lr: 6.69716991368736e-05, reference_loss: 26.370206832885742
2024-01-02 14:11:51,283	44k	INFO	====> Epoch: 3208, cost 22.91 s
2024-01-02 14:12:13,546	44k	INFO	====> Epoch: 3209, cost 22.26 s
2024-01-02 14:12:35,960	44k	INFO	====> Epoch: 3210, cost 22.41 s
2024-01-02 14:12:58,428	44k	INFO	====> Epoch: 3211, cost 22.47 s
2024-01-02 14:13:20,873	44k	INFO	====> Epoch: 3212, cost 22.45 s
2024-01-02 14:13:43,292	44k	INFO	====> Epoch: 3213, cost 22.42 s
2024-01-02 14:14:05,813	44k	INFO	====> Epoch: 3214, cost 22.52 s
2024-01-02 14:14:28,197	44k	INFO	====> Epoch: 3215, cost 22.38 s
2024-01-02 14:14:50,446	44k	INFO	Train Epoch: 3216 [96%]
2024-01-02 14:14:50,448	44k	INFO	Losses: [1.846307635307312, 3.169511556625366, 8.003357887268066, 11.540199279785156, -2.1665143966674805], step: 80400, lr: 6.690475673053119e-05, reference_loss: 22.392860412597656
2024-01-02 14:14:50,838	44k	INFO	====> Epoch: 3216, cost 22.64 s
2024-01-02 14:15:13,104	44k	INFO	====> Epoch: 3217, cost 22.27 s
2024-01-02 14:15:35,403	44k	INFO	====> Epoch: 3218, cost 22.30 s
2024-01-02 14:15:57,607	44k	INFO	====> Epoch: 3219, cost 22.20 s
2024-01-02 14:16:19,935	44k	INFO	====> Epoch: 3220, cost 22.33 s
2024-01-02 14:16:42,350	44k	INFO	====> Epoch: 3221, cost 22.42 s
2024-01-02 14:17:04,802	44k	INFO	====> Epoch: 3222, cost 22.45 s
2024-01-02 14:17:27,214	44k	INFO	====> Epoch: 3223, cost 22.41 s
2024-01-02 14:17:49,599	44k	INFO	Train Epoch: 3224 [96%]
2024-01-02 14:17:49,601	44k	INFO	Losses: [1.6916427612304688, 3.431401252746582, 10.070383071899414, 12.150602340698242, -2.257232427597046], step: 80600, lr: 6.683788123731515e-05, reference_loss: 25.086795806884766
2024-01-02 14:17:50,179	44k	INFO	====> Epoch: 3224, cost 22.97 s
2024-01-02 14:18:12,619	44k	INFO	====> Epoch: 3225, cost 22.44 s
2024-01-02 14:18:35,081	44k	INFO	====> Epoch: 3226, cost 22.46 s
2024-01-02 14:18:57,568	44k	INFO	====> Epoch: 3227, cost 22.49 s
2024-01-02 14:19:20,063	44k	INFO	====> Epoch: 3228, cost 22.50 s
2024-01-02 14:19:42,451	44k	INFO	====> Epoch: 3229, cost 22.39 s
2024-01-02 14:20:04,914	44k	INFO	====> Epoch: 3230, cost 22.46 s
2024-01-02 14:20:27,490	44k	INFO	====> Epoch: 3231, cost 22.58 s
2024-01-02 14:20:49,987	44k	INFO	Train Epoch: 3232 [96%]
2024-01-02 14:20:49,989	44k	INFO	Losses: [2.0207560062408447, 2.8494644165039062, 8.741928100585938, 12.189753532409668, -2.2850699424743652], step: 80800, lr: 6.67710725903416e-05, reference_loss: 23.51683235168457
2024-01-02 14:20:56,981	44k	INFO	Saving model and optimizer state at iteration 3232 to ./logs/44k/G_80800.pth
2024-01-02 14:20:57,974	44k	INFO	Saving model and optimizer state at iteration 3232 to ./logs/44k/D_80800.pth
2024-01-02 14:20:58,528	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_78400.pth
2024-01-02 14:20:58,568	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_78400.pth
2024-01-02 14:20:58,568	44k	INFO	====> Epoch: 3232, cost 31.08 s
2024-01-02 14:21:21,014	44k	INFO	====> Epoch: 3233, cost 22.45 s
2024-01-02 14:21:43,386	44k	INFO	====> Epoch: 3234, cost 22.37 s
2024-01-02 14:22:05,849	44k	INFO	====> Epoch: 3235, cost 22.46 s
2024-01-02 14:22:28,133	44k	INFO	====> Epoch: 3236, cost 22.28 s
2024-01-02 14:22:50,463	44k	INFO	====> Epoch: 3237, cost 22.33 s
2024-01-02 14:23:12,856	44k	INFO	====> Epoch: 3238, cost 22.39 s
2024-01-02 14:23:35,113	44k	INFO	====> Epoch: 3239, cost 22.26 s
2024-01-02 14:23:57,307	44k	INFO	Train Epoch: 3240 [96%]
2024-01-02 14:23:57,309	44k	INFO	Losses: [1.608078122138977, 3.314697742462158, 9.972085952758789, 12.772741317749023, -2.1958553791046143], step: 81000, lr: 6.670433072279354e-05, reference_loss: 25.47174644470215
2024-01-02 14:23:57,718	44k	INFO	====> Epoch: 3240, cost 22.61 s
2024-01-02 14:24:20,096	44k	INFO	====> Epoch: 3241, cost 22.38 s
2024-01-02 14:24:42,303	44k	INFO	====> Epoch: 3242, cost 22.21 s
2024-01-02 14:25:04,638	44k	INFO	====> Epoch: 3243, cost 22.34 s
2024-01-02 14:25:27,276	44k	INFO	====> Epoch: 3244, cost 22.64 s
2024-01-02 14:25:49,583	44k	INFO	====> Epoch: 3245, cost 22.31 s
2024-01-02 14:26:11,852	44k	INFO	====> Epoch: 3246, cost 22.27 s
2024-01-02 14:26:34,261	44k	INFO	====> Epoch: 3247, cost 22.41 s
2024-01-02 14:26:56,569	44k	INFO	Train Epoch: 3248 [96%]
2024-01-02 14:26:56,571	44k	INFO	Losses: [1.9599971771240234, 3.277095079421997, 8.86302661895752, 11.80420207977295, -2.200711250305176], step: 81200, lr: 6.663765556792078e-05, reference_loss: 23.703609466552734
2024-01-02 14:26:56,980	44k	INFO	====> Epoch: 3248, cost 22.72 s
2024-01-02 14:27:19,164	44k	INFO	====> Epoch: 3249, cost 22.18 s
2024-01-02 14:27:41,469	44k	INFO	====> Epoch: 3250, cost 22.31 s
2024-01-02 14:28:03,878	44k	INFO	====> Epoch: 3251, cost 22.41 s
2024-01-02 14:28:26,278	44k	INFO	====> Epoch: 3252, cost 22.40 s
2024-01-02 14:28:48,624	44k	INFO	====> Epoch: 3253, cost 22.35 s
2024-01-02 14:29:10,991	44k	INFO	====> Epoch: 3254, cost 22.37 s
2024-01-02 14:29:33,234	44k	INFO	====> Epoch: 3255, cost 22.24 s
2024-01-02 14:29:55,718	44k	INFO	Train Epoch: 3256 [96%]
2024-01-02 14:29:55,719	44k	INFO	Losses: [1.6109263896942139, 3.2332468032836914, 10.27306842803955, 12.317770957946777, -2.2886109352111816], step: 81400, lr: 6.657104705903978e-05, reference_loss: 25.14640235900879
2024-01-02 14:29:56,219	44k	INFO	====> Epoch: 3256, cost 22.98 s
2024-01-02 14:30:18,377	44k	INFO	====> Epoch: 3257, cost 22.16 s
2024-01-02 14:30:40,539	44k	INFO	====> Epoch: 3258, cost 22.16 s
2024-01-02 14:31:02,883	44k	INFO	====> Epoch: 3259, cost 22.34 s
2024-01-02 14:31:25,186	44k	INFO	====> Epoch: 3260, cost 22.30 s
2024-01-02 14:31:47,502	44k	INFO	====> Epoch: 3261, cost 22.32 s
2024-01-02 14:32:09,757	44k	INFO	====> Epoch: 3262, cost 22.26 s
2024-01-02 14:32:31,984	44k	INFO	====> Epoch: 3263, cost 22.23 s
2024-01-02 14:32:54,393	44k	INFO	Train Epoch: 3264 [96%]
2024-01-02 14:32:54,394	44k	INFO	Losses: [1.8915650844573975, 3.079911947250366, 9.581114768981934, 11.9926176071167, -2.1818950176239014], step: 81600, lr: 6.650450512953374e-05, reference_loss: 24.363313674926758
2024-01-02 14:33:00,645	44k	INFO	Saving model and optimizer state at iteration 3264 to ./logs/44k/G_81600.pth
2024-01-02 14:33:01,564	44k	INFO	Saving model and optimizer state at iteration 3264 to ./logs/44k/D_81600.pth
2024-01-02 14:33:02,090	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_79200.pth
2024-01-02 14:33:02,130	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_79200.pth
2024-01-02 14:33:02,130	44k	INFO	====> Epoch: 3264, cost 30.15 s
2024-01-02 14:33:24,237	44k	INFO	====> Epoch: 3265, cost 22.11 s
2024-01-02 14:33:46,395	44k	INFO	====> Epoch: 3266, cost 22.16 s
2024-01-02 14:34:08,603	44k	INFO	====> Epoch: 3267, cost 22.21 s
2024-01-02 14:34:30,839	44k	INFO	====> Epoch: 3268, cost 22.24 s
2024-01-02 14:34:53,084	44k	INFO	====> Epoch: 3269, cost 22.24 s
2024-01-02 14:35:15,223	44k	INFO	====> Epoch: 3270, cost 22.14 s
2024-01-02 14:35:37,530	44k	INFO	====> Epoch: 3271, cost 22.31 s
2024-01-02 14:35:59,571	44k	INFO	Train Epoch: 3272 [96%]
2024-01-02 14:35:59,573	44k	INFO	Losses: [1.7417083978652954, 3.300931692123413, 10.345017433166504, 12.959310531616211, -2.270587921142578], step: 81800, lr: 6.643802971285238e-05, reference_loss: 26.076379776000977
2024-01-02 14:35:59,962	44k	INFO	====> Epoch: 3272, cost 22.43 s
2024-01-02 14:36:22,035	44k	INFO	====> Epoch: 3273, cost 22.07 s
2024-01-02 14:36:44,075	44k	INFO	====> Epoch: 3274, cost 22.04 s
2024-01-02 14:37:06,230	44k	INFO	====> Epoch: 3275, cost 22.15 s
2024-01-02 14:37:28,257	44k	INFO	====> Epoch: 3276, cost 22.03 s
2024-01-02 14:37:50,271	44k	INFO	====> Epoch: 3277, cost 22.01 s
2024-01-02 14:38:12,344	44k	INFO	====> Epoch: 3278, cost 22.07 s
2024-01-02 14:38:34,529	44k	INFO	====> Epoch: 3279, cost 22.18 s
2024-01-02 14:38:56,607	44k	INFO	Train Epoch: 3280 [96%]
2024-01-02 14:38:56,609	44k	INFO	Losses: [1.951298475265503, 2.7866811752319336, 7.395369529724121, 11.282004356384277, -2.2613027095794678], step: 82000, lr: 6.637162074251199e-05, reference_loss: 21.154050827026367
2024-01-02 14:38:57,184	44k	INFO	====> Epoch: 3280, cost 22.66 s
2024-01-02 14:39:19,253	44k	INFO	====> Epoch: 3281, cost 22.07 s
2024-01-02 14:39:41,249	44k	INFO	====> Epoch: 3282, cost 22.00 s
2024-01-02 14:40:03,283	44k	INFO	====> Epoch: 3283, cost 22.03 s
2024-01-02 14:40:25,465	44k	INFO	====> Epoch: 3284, cost 22.18 s
2024-01-02 14:40:47,700	44k	INFO	====> Epoch: 3285, cost 22.24 s
2024-01-02 14:41:09,998	44k	INFO	====> Epoch: 3286, cost 22.30 s
2024-01-02 14:41:32,231	44k	INFO	====> Epoch: 3287, cost 22.23 s
2024-01-02 14:41:54,551	44k	INFO	Train Epoch: 3288 [96%]
2024-01-02 14:41:54,551	44k	INFO	Losses: [1.5361526012420654, 4.000129699707031, 11.93947982788086, 13.196828842163086, -2.3246610164642334], step: 82200, lr: 6.630527815209527e-05, reference_loss: 28.347929000854492
2024-01-02 14:41:55,054	44k	INFO	====> Epoch: 3288, cost 22.82 s
2024-01-02 14:42:17,387	44k	INFO	====> Epoch: 3289, cost 22.33 s
2024-01-02 14:42:39,879	44k	INFO	====> Epoch: 3290, cost 22.49 s
2024-01-02 14:43:02,121	44k	INFO	====> Epoch: 3291, cost 22.24 s
2024-01-02 14:43:24,386	44k	INFO	====> Epoch: 3292, cost 22.27 s
2024-01-02 14:43:46,634	44k	INFO	====> Epoch: 3293, cost 22.25 s
2024-01-02 14:44:08,748	44k	INFO	====> Epoch: 3294, cost 22.11 s
2024-01-02 14:44:30,939	44k	INFO	====> Epoch: 3295, cost 22.19 s
2024-01-02 14:44:53,084	44k	INFO	Train Epoch: 3296 [96%]
2024-01-02 14:44:53,086	44k	INFO	Losses: [1.9390592575073242, 3.0630948543548584, 9.376240730285645, 12.045965194702148, -2.357252359390259], step: 82400, lr: 6.623900187525131e-05, reference_loss: 24.067108154296875
2024-01-02 14:44:59,004	44k	INFO	Saving model and optimizer state at iteration 3296 to ./logs/44k/G_82400.pth
2024-01-02 14:44:59,919	44k	INFO	Saving model and optimizer state at iteration 3296 to ./logs/44k/D_82400.pth
2024-01-02 14:45:00,409	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_80000.pth
2024-01-02 14:45:00,447	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_80000.pth
2024-01-02 14:45:00,448	44k	INFO	====> Epoch: 3296, cost 29.51 s
2024-01-02 14:45:22,452	44k	INFO	====> Epoch: 3297, cost 22.00 s
2024-01-02 14:45:44,715	44k	INFO	====> Epoch: 3298, cost 22.26 s
2024-01-02 14:46:06,958	44k	INFO	====> Epoch: 3299, cost 22.24 s
2024-01-02 14:46:29,142	44k	INFO	====> Epoch: 3300, cost 22.18 s
2024-01-02 14:46:51,380	44k	INFO	====> Epoch: 3301, cost 22.24 s
2024-01-02 14:47:13,708	44k	INFO	====> Epoch: 3302, cost 22.33 s
2024-01-02 14:47:36,115	44k	INFO	====> Epoch: 3303, cost 22.41 s
2024-01-02 14:47:58,431	44k	INFO	Train Epoch: 3304 [96%]
2024-01-02 14:47:58,432	44k	INFO	Losses: [1.718341588973999, 3.391913890838623, 9.265844345092773, 11.511021614074707, -2.302781581878662], step: 82600, lr: 6.61727918456956e-05, reference_loss: 23.584339141845703
2024-01-02 14:47:58,848	44k	INFO	====> Epoch: 3304, cost 22.73 s
2024-01-02 14:48:21,190	44k	INFO	====> Epoch: 3305, cost 22.34 s
2024-01-02 14:48:43,487	44k	INFO	====> Epoch: 3306, cost 22.30 s
2024-01-02 14:49:05,838	44k	INFO	====> Epoch: 3307, cost 22.35 s
2024-01-02 14:49:28,161	44k	INFO	====> Epoch: 3308, cost 22.32 s
2024-01-02 14:49:50,457	44k	INFO	====> Epoch: 3309, cost 22.30 s
2024-01-02 14:50:12,995	44k	INFO	====> Epoch: 3310, cost 22.54 s
2024-01-02 14:50:35,354	44k	INFO	====> Epoch: 3311, cost 22.36 s
2024-01-02 14:50:57,625	44k	INFO	Train Epoch: 3312 [96%]
2024-01-02 14:50:57,627	44k	INFO	Losses: [1.905498743057251, 3.0517115592956543, 7.035705089569092, 9.62485122680664, -2.2425734996795654], step: 82800, lr: 6.610664799720978e-05, reference_loss: 19.375194549560547
2024-01-02 14:50:58,024	44k	INFO	====> Epoch: 3312, cost 22.67 s
2024-01-02 14:51:20,217	44k	INFO	====> Epoch: 3313, cost 22.19 s
2024-01-02 14:51:42,448	44k	INFO	====> Epoch: 3314, cost 22.23 s
2024-01-02 14:52:04,687	44k	INFO	====> Epoch: 3315, cost 22.24 s
2024-01-02 14:52:27,084	44k	INFO	====> Epoch: 3316, cost 22.40 s
2024-01-02 14:52:49,365	44k	INFO	====> Epoch: 3317, cost 22.28 s
2024-01-02 14:53:11,682	44k	INFO	====> Epoch: 3318, cost 22.32 s
2024-01-02 14:53:34,029	44k	INFO	====> Epoch: 3319, cost 22.35 s
2024-01-02 14:53:56,251	44k	INFO	Train Epoch: 3320 [96%]
2024-01-02 14:53:56,252	44k	INFO	Losses: [1.5469304323196411, 3.8092732429504395, 11.613243103027344, 12.747918128967285, -2.433079719543457], step: 83000, lr: 6.604057026364177e-05, reference_loss: 27.284286499023438
2024-01-02 14:53:56,862	44k	INFO	====> Epoch: 3320, cost 22.83 s
2024-01-02 14:54:19,261	44k	INFO	====> Epoch: 3321, cost 22.40 s
2024-01-02 14:54:41,601	44k	INFO	====> Epoch: 3322, cost 22.34 s
2024-01-02 14:55:03,881	44k	INFO	====> Epoch: 3323, cost 22.28 s
2024-01-02 14:55:26,055	44k	INFO	====> Epoch: 3324, cost 22.17 s
2024-01-02 14:55:48,100	44k	INFO	====> Epoch: 3325, cost 22.05 s
2024-01-02 14:56:10,252	44k	INFO	====> Epoch: 3326, cost 22.15 s
2024-01-02 14:56:32,412	44k	INFO	====> Epoch: 3327, cost 22.16 s
2024-01-02 14:56:54,615	44k	INFO	Train Epoch: 3328 [96%]
2024-01-02 14:56:54,616	44k	INFO	Losses: [1.8537275791168213, 3.0560028553009033, 9.307995796203613, 11.771824836730957, -2.3106696605682373], step: 83200, lr: 6.597455857890554e-05, reference_loss: 23.678882598876953
2024-01-02 14:57:01,234	44k	INFO	Saving model and optimizer state at iteration 3328 to ./logs/44k/G_83200.pth
2024-01-02 14:57:02,181	44k	INFO	Saving model and optimizer state at iteration 3328 to ./logs/44k/D_83200.pth
2024-01-02 14:57:02,718	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_80800.pth
2024-01-02 14:57:02,758	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_80800.pth
2024-01-02 14:57:02,759	44k	INFO	====> Epoch: 3328, cost 30.35 s
2024-01-02 14:57:24,930	44k	INFO	====> Epoch: 3329, cost 22.17 s
2024-01-02 14:57:47,070	44k	INFO	====> Epoch: 3330, cost 22.14 s
2024-01-02 14:58:09,169	44k	INFO	====> Epoch: 3331, cost 22.10 s
2024-01-02 14:58:31,143	44k	INFO	====> Epoch: 3332, cost 21.97 s
2024-01-02 14:58:53,216	44k	INFO	====> Epoch: 3333, cost 22.07 s
2024-01-02 14:59:15,464	44k	INFO	====> Epoch: 3334, cost 22.25 s
2024-01-02 14:59:37,676	44k	INFO	====> Epoch: 3335, cost 22.21 s
2024-01-02 14:59:59,944	44k	INFO	Train Epoch: 3336 [96%]
2024-01-02 14:59:59,945	44k	INFO	Losses: [1.7339062690734863, 3.4661316871643066, 9.783865928649902, 12.432368278503418, -2.2676544189453125], step: 83400, lr: 6.590861287698117e-05, reference_loss: 25.148616790771484
2024-01-02 15:00:00,359	44k	INFO	====> Epoch: 3336, cost 22.68 s
2024-01-02 15:00:22,650	44k	INFO	====> Epoch: 3337, cost 22.29 s
2024-01-02 15:00:44,944	44k	INFO	====> Epoch: 3338, cost 22.29 s
2024-01-02 15:01:07,139	44k	INFO	====> Epoch: 3339, cost 22.19 s
2024-01-02 15:01:29,495	44k	INFO	====> Epoch: 3340, cost 22.36 s
2024-01-02 15:01:51,700	44k	INFO	====> Epoch: 3341, cost 22.20 s
2024-01-02 15:02:13,826	44k	INFO	====> Epoch: 3342, cost 22.13 s
2024-01-02 15:02:36,040	44k	INFO	====> Epoch: 3343, cost 22.21 s
2024-01-02 15:02:58,158	44k	INFO	Train Epoch: 3344 [96%]
2024-01-02 15:02:58,159	44k	INFO	Losses: [1.895729899406433, 3.0781044960021973, 7.308706283569336, 10.709543228149414, -2.3175783157348633], step: 83600, lr: 6.584273309191467e-05, reference_loss: 20.67450714111328
2024-01-02 15:02:58,571	44k	INFO	====> Epoch: 3344, cost 22.53 s
2024-01-02 15:03:20,853	44k	INFO	====> Epoch: 3345, cost 22.28 s
2024-01-02 15:03:43,120	44k	INFO	====> Epoch: 3346, cost 22.27 s
2024-01-02 15:04:05,362	44k	INFO	====> Epoch: 3347, cost 22.24 s
2024-01-02 15:04:27,529	44k	INFO	====> Epoch: 3348, cost 22.17 s
2024-01-02 15:04:49,836	44k	INFO	====> Epoch: 3349, cost 22.31 s
2024-01-02 15:05:12,262	44k	INFO	====> Epoch: 3350, cost 22.43 s
2024-01-02 15:05:34,680	44k	INFO	====> Epoch: 3351, cost 22.42 s
2024-01-02 15:05:56,894	44k	INFO	Train Epoch: 3352 [96%]
2024-01-02 15:05:56,896	44k	INFO	Losses: [1.6773669719696045, 3.2976932525634766, 10.960466384887695, 12.510744094848633, -2.482346773147583], step: 83800, lr: 6.577691915781806e-05, reference_loss: 25.96392250061035
2024-01-02 15:05:57,299	44k	INFO	====> Epoch: 3352, cost 22.62 s
2024-01-02 15:06:19,578	44k	INFO	====> Epoch: 3353, cost 22.28 s
2024-01-02 15:06:41,812	44k	INFO	====> Epoch: 3354, cost 22.23 s
2024-01-02 15:07:04,071	44k	INFO	====> Epoch: 3355, cost 22.26 s
2024-01-02 15:07:26,209	44k	INFO	====> Epoch: 3356, cost 22.14 s
2024-01-02 15:07:48,335	44k	INFO	====> Epoch: 3357, cost 22.13 s
2024-01-02 15:08:10,636	44k	INFO	====> Epoch: 3358, cost 22.30 s
2024-01-02 15:08:32,986	44k	INFO	====> Epoch: 3359, cost 22.35 s
2024-01-02 15:08:55,383	44k	INFO	Train Epoch: 3360 [96%]
2024-01-02 15:08:55,385	44k	INFO	Losses: [1.8865511417388916, 3.095205068588257, 9.205146789550781, 11.951149940490723, -2.394700765609741], step: 84000, lr: 6.571117100886913e-05, reference_loss: 23.74335289001465
2024-01-02 15:09:01,699	44k	INFO	Saving model and optimizer state at iteration 3360 to ./logs/44k/G_84000.pth
2024-01-02 15:09:02,642	44k	INFO	Saving model and optimizer state at iteration 3360 to ./logs/44k/D_84000.pth
2024-01-02 15:09:03,149	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_81600.pth
2024-01-02 15:09:03,187	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_81600.pth
2024-01-02 15:09:03,188	44k	INFO	====> Epoch: 3360, cost 30.20 s
2024-01-02 15:09:25,300	44k	INFO	====> Epoch: 3361, cost 22.11 s
2024-01-02 15:09:47,336	44k	INFO	====> Epoch: 3362, cost 22.04 s
2024-01-02 15:10:09,461	44k	INFO	====> Epoch: 3363, cost 22.13 s
2024-01-02 15:10:31,649	44k	INFO	====> Epoch: 3364, cost 22.19 s
2024-01-02 15:10:53,782	44k	INFO	====> Epoch: 3365, cost 22.13 s
2024-01-02 15:11:15,859	44k	INFO	====> Epoch: 3366, cost 22.08 s
2024-01-02 15:11:38,131	44k	INFO	====> Epoch: 3367, cost 22.27 s
2024-01-02 15:12:00,250	44k	INFO	Train Epoch: 3368 [96%]
2024-01-02 15:12:00,253	44k	INFO	Losses: [1.6346354484558105, 3.4347751140594482, 9.365788459777832, 11.691387176513672, -2.366515874862671], step: 84200, lr: 6.564548857931153e-05, reference_loss: 23.76007080078125
2024-01-02 15:12:00,637	44k	INFO	====> Epoch: 3368, cost 22.51 s
2024-01-02 15:12:22,721	44k	INFO	====> Epoch: 3369, cost 22.08 s
2024-01-02 15:12:44,777	44k	INFO	====> Epoch: 3370, cost 22.06 s
2024-01-02 15:13:06,989	44k	INFO	====> Epoch: 3371, cost 22.21 s
2024-01-02 15:13:29,230	44k	INFO	====> Epoch: 3372, cost 22.24 s
2024-01-02 15:13:51,504	44k	INFO	====> Epoch: 3373, cost 22.27 s
2024-01-02 15:14:13,848	44k	INFO	====> Epoch: 3374, cost 22.34 s
2024-01-02 15:14:35,987	44k	INFO	====> Epoch: 3375, cost 22.14 s
2024-01-02 15:14:58,145	44k	INFO	Train Epoch: 3376 [96%]
2024-01-02 15:14:58,146	44k	INFO	Losses: [1.8439645767211914, 3.135268449783325, 8.227973937988281, 11.465221405029297, -2.3623383045196533], step: 84400, lr: 6.55798718034546e-05, reference_loss: 22.310089111328125
2024-01-02 15:14:58,751	44k	INFO	====> Epoch: 3376, cost 22.76 s
2024-01-02 15:15:20,903	44k	INFO	====> Epoch: 3377, cost 22.15 s
2024-01-02 15:15:42,859	44k	INFO	====> Epoch: 3378, cost 21.96 s
2024-01-02 15:16:04,908	44k	INFO	====> Epoch: 3379, cost 22.05 s
2024-01-02 15:16:27,115	44k	INFO	====> Epoch: 3380, cost 22.21 s
2024-01-02 15:16:49,241	44k	INFO	====> Epoch: 3381, cost 22.13 s
2024-01-02 15:17:11,293	44k	INFO	====> Epoch: 3382, cost 22.05 s
2024-01-02 15:17:33,319	44k	INFO	====> Epoch: 3383, cost 22.03 s
2024-01-02 15:17:55,363	44k	INFO	Train Epoch: 3384 [96%]
2024-01-02 15:17:55,365	44k	INFO	Losses: [1.6119379997253418, 3.8544960021972656, 11.8699951171875, 12.7471284866333, -2.471935272216797], step: 84600, lr: 6.551432061567337e-05, reference_loss: 27.611621856689453
2024-01-02 15:17:55,851	44k	INFO	====> Epoch: 3384, cost 22.53 s
2024-01-02 15:18:18,044	44k	INFO	====> Epoch: 3385, cost 22.19 s
2024-01-02 15:18:40,180	44k	INFO	====> Epoch: 3386, cost 22.14 s
2024-01-02 15:19:02,131	44k	INFO	====> Epoch: 3387, cost 21.95 s
2024-01-02 15:19:24,299	44k	INFO	====> Epoch: 3388, cost 22.17 s
2024-01-02 15:19:46,464	44k	INFO	====> Epoch: 3389, cost 22.16 s
2024-01-02 15:20:08,546	44k	INFO	====> Epoch: 3390, cost 22.08 s
2024-01-02 15:20:30,624	44k	INFO	====> Epoch: 3391, cost 22.08 s
2024-01-02 15:20:52,883	44k	INFO	Train Epoch: 3392 [96%]
2024-01-02 15:20:52,885	44k	INFO	Losses: [1.9515049457550049, 3.048278331756592, 8.06190299987793, 11.189411163330078, -2.4427638053894043], step: 84800, lr: 6.544883495040844e-05, reference_loss: 21.808334350585938
2024-01-02 15:20:59,119	44k	INFO	Saving model and optimizer state at iteration 3392 to ./logs/44k/G_84800.pth
2024-01-02 15:21:00,048	44k	INFO	Saving model and optimizer state at iteration 3392 to ./logs/44k/D_84800.pth
2024-01-02 15:21:00,573	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_82400.pth
2024-01-02 15:21:00,612	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_82400.pth
2024-01-02 15:21:00,612	44k	INFO	====> Epoch: 3392, cost 29.99 s
2024-01-02 15:21:22,715	44k	INFO	====> Epoch: 3393, cost 22.10 s
2024-01-02 15:21:44,900	44k	INFO	====> Epoch: 3394, cost 22.19 s
2024-01-02 15:22:06,853	44k	INFO	====> Epoch: 3395, cost 21.95 s
2024-01-02 15:22:29,054	44k	INFO	====> Epoch: 3396, cost 22.20 s
2024-01-02 15:22:51,276	44k	INFO	====> Epoch: 3397, cost 22.22 s
2024-01-02 15:23:13,512	44k	INFO	====> Epoch: 3398, cost 22.24 s
2024-01-02 15:23:35,644	44k	INFO	====> Epoch: 3399, cost 22.13 s
2024-01-02 15:23:57,755	44k	INFO	Train Epoch: 3400 [96%]
2024-01-02 15:23:57,756	44k	INFO	Losses: [1.6125617027282715, 3.5325021743774414, 11.339521408081055, 12.800904273986816, -2.3553552627563477], step: 85000, lr: 6.538341474216595e-05, reference_loss: 26.930133819580078
2024-01-02 15:23:58,189	44k	INFO	====> Epoch: 3400, cost 22.54 s
2024-01-02 15:24:20,371	44k	INFO	====> Epoch: 3401, cost 22.18 s
2024-01-02 15:24:42,451	44k	INFO	====> Epoch: 3402, cost 22.08 s
2024-01-02 15:25:04,552	44k	INFO	====> Epoch: 3403, cost 22.10 s
2024-01-02 15:25:26,711	44k	INFO	====> Epoch: 3404, cost 22.16 s
2024-01-02 15:25:48,884	44k	INFO	====> Epoch: 3405, cost 22.17 s
2024-01-02 15:26:11,250	44k	INFO	====> Epoch: 3406, cost 22.37 s
2024-01-02 15:26:33,437	44k	INFO	====> Epoch: 3407, cost 22.19 s
2024-01-02 15:26:55,698	44k	INFO	Train Epoch: 3408 [96%]
2024-01-02 15:26:55,699	44k	INFO	Losses: [1.897430419921875, 3.016143798828125, 7.316211700439453, 10.366180419921875, -2.364143133163452], step: 85200, lr: 6.531805992551754e-05, reference_loss: 20.231822967529297
2024-01-02 15:26:56,208	44k	INFO	====> Epoch: 3408, cost 22.77 s
2024-01-02 15:27:18,480	44k	INFO	====> Epoch: 3409, cost 22.27 s
2024-01-02 15:27:40,724	44k	INFO	====> Epoch: 3410, cost 22.24 s
2024-01-02 15:28:03,009	44k	INFO	====> Epoch: 3411, cost 22.29 s
2024-01-02 15:28:25,232	44k	INFO	====> Epoch: 3412, cost 22.22 s
2024-01-02 15:28:47,453	44k	INFO	====> Epoch: 3413, cost 22.22 s
2024-01-02 15:29:09,635	44k	INFO	====> Epoch: 3414, cost 22.18 s
2024-01-02 15:29:31,849	44k	INFO	====> Epoch: 3415, cost 22.21 s
2024-01-02 15:29:54,196	44k	INFO	Train Epoch: 3416 [96%]
2024-01-02 15:29:54,198	44k	INFO	Losses: [1.5971390008926392, 3.4536914825439453, 10.079924583435059, 11.77214527130127, -2.4332282543182373], step: 85400, lr: 6.525277043510016e-05, reference_loss: 24.46967315673828
2024-01-02 15:29:54,581	44k	INFO	====> Epoch: 3416, cost 22.73 s
2024-01-02 15:30:16,662	44k	INFO	====> Epoch: 3417, cost 22.08 s
2024-01-02 15:30:38,859	44k	INFO	====> Epoch: 3418, cost 22.20 s
2024-01-02 15:31:01,205	44k	INFO	====> Epoch: 3419, cost 22.35 s
2024-01-02 15:31:23,424	44k	INFO	====> Epoch: 3420, cost 22.22 s
2024-01-02 15:31:45,707	44k	INFO	====> Epoch: 3421, cost 22.28 s
2024-01-02 15:32:07,969	44k	INFO	====> Epoch: 3422, cost 22.26 s
2024-01-02 15:32:30,163	44k	INFO	====> Epoch: 3423, cost 22.19 s
2024-01-02 15:32:52,463	44k	INFO	Train Epoch: 3424 [96%]
2024-01-02 15:32:52,464	44k	INFO	Losses: [1.8595536947250366, 2.998263359069824, 9.520843505859375, 11.780708312988281, -2.4166183471679688], step: 85600, lr: 6.51875462056162e-05, reference_loss: 23.74275016784668
2024-01-02 15:32:59,216	44k	INFO	Saving model and optimizer state at iteration 3424 to ./logs/44k/G_85600.pth
2024-01-02 15:33:00,127	44k	INFO	Saving model and optimizer state at iteration 3424 to ./logs/44k/D_85600.pth
2024-01-02 15:33:00,648	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_83200.pth
2024-01-02 15:33:00,688	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_83200.pth
2024-01-02 15:33:00,688	44k	INFO	====> Epoch: 3424, cost 30.52 s
2024-01-02 15:33:22,836	44k	INFO	====> Epoch: 3425, cost 22.15 s
2024-01-02 15:33:44,948	44k	INFO	====> Epoch: 3426, cost 22.11 s
2024-01-02 15:34:07,176	44k	INFO	====> Epoch: 3427, cost 22.23 s
2024-01-02 15:34:29,441	44k	INFO	====> Epoch: 3428, cost 22.27 s
2024-01-02 15:34:51,812	44k	INFO	====> Epoch: 3429, cost 22.37 s
2024-01-02 15:35:14,317	44k	INFO	====> Epoch: 3430, cost 22.50 s
2024-01-02 15:35:36,752	44k	INFO	====> Epoch: 3431, cost 22.44 s
2024-01-02 15:35:59,172	44k	INFO	Train Epoch: 3432 [96%]
2024-01-02 15:35:59,173	44k	INFO	Losses: [1.6925426721572876, 3.6415226459503174, 9.77629280090332, 12.007261276245117, -2.430312156677246], step: 85800, lr: 6.512238717183328e-05, reference_loss: 24.687305450439453
2024-01-02 15:35:59,587	44k	INFO	====> Epoch: 3432, cost 22.83 s
2024-01-02 15:36:21,938	44k	INFO	====> Epoch: 3433, cost 22.35 s
2024-01-02 15:36:44,339	44k	INFO	====> Epoch: 3434, cost 22.40 s
2024-01-02 15:37:06,668	44k	INFO	====> Epoch: 3435, cost 22.33 s
2024-01-02 15:37:29,094	44k	INFO	====> Epoch: 3436, cost 22.43 s
2024-01-02 15:37:51,361	44k	INFO	====> Epoch: 3437, cost 22.27 s
2024-01-02 15:38:13,818	44k	INFO	====> Epoch: 3438, cost 22.46 s
2024-01-02 15:38:36,381	44k	INFO	====> Epoch: 3439, cost 22.56 s
2024-01-02 15:38:58,841	44k	INFO	Train Epoch: 3440 [96%]
2024-01-02 15:38:58,843	44k	INFO	Losses: [1.8889358043670654, 2.828336715698242, 7.190459728240967, 10.682610511779785, -2.3757846355438232], step: 86000, lr: 6.505729326858415e-05, reference_loss: 20.21455955505371
2024-01-02 15:38:59,246	44k	INFO	====> Epoch: 3440, cost 22.86 s
2024-01-02 15:39:21,703	44k	INFO	====> Epoch: 3441, cost 22.46 s
2024-01-02 15:39:43,975	44k	INFO	====> Epoch: 3442, cost 22.27 s
2024-01-02 15:40:06,073	44k	INFO	====> Epoch: 3443, cost 22.10 s
2024-01-02 15:40:28,290	44k	INFO	====> Epoch: 3444, cost 22.22 s
2024-01-02 15:40:50,553	44k	INFO	====> Epoch: 3445, cost 22.26 s
2024-01-02 15:41:13,004	44k	INFO	====> Epoch: 3446, cost 22.45 s
2024-01-02 15:41:35,152	44k	INFO	====> Epoch: 3447, cost 22.15 s
2024-01-02 15:41:57,440	44k	INFO	Train Epoch: 3448 [96%]
2024-01-02 15:41:57,442	44k	INFO	Losses: [1.5747524499893188, 3.6056430339813232, 11.485321044921875, 12.882596015930176, -2.580106019973755], step: 86200, lr: 6.499226443076681e-05, reference_loss: 26.96820640563965
2024-01-02 15:41:57,853	44k	INFO	====> Epoch: 3448, cost 22.70 s
2024-01-02 15:42:20,167	44k	INFO	====> Epoch: 3449, cost 22.31 s
2024-01-02 15:42:42,417	44k	INFO	====> Epoch: 3450, cost 22.25 s
2024-01-02 15:43:04,652	44k	INFO	====> Epoch: 3451, cost 22.24 s
2024-01-02 15:43:26,887	44k	INFO	====> Epoch: 3452, cost 22.23 s
2024-01-02 15:43:49,048	44k	INFO	====> Epoch: 3453, cost 22.16 s
2024-01-02 15:44:11,171	44k	INFO	====> Epoch: 3454, cost 22.12 s
2024-01-02 15:44:33,279	44k	INFO	====> Epoch: 3455, cost 22.11 s
2024-01-02 15:44:55,670	44k	INFO	Train Epoch: 3456 [96%]
2024-01-02 15:44:55,671	44k	INFO	Losses: [1.803057074546814, 3.05570125579834, 9.029563903808594, 11.698492050170898, -2.544034719467163], step: 86400, lr: 6.492730059334428e-05, reference_loss: 23.04277992248535
2024-01-02 15:45:01,923	44k	INFO	Saving model and optimizer state at iteration 3456 to ./logs/44k/G_86400.pth
2024-01-02 15:45:02,867	44k	INFO	Saving model and optimizer state at iteration 3456 to ./logs/44k/D_86400.pth
2024-01-02 15:45:03,401	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_84000.pth
2024-01-02 15:45:03,442	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_84000.pth
2024-01-02 15:45:03,442	44k	INFO	====> Epoch: 3456, cost 30.16 s
2024-01-02 15:45:25,732	44k	INFO	====> Epoch: 3457, cost 22.29 s
2024-01-02 15:45:47,967	44k	INFO	====> Epoch: 3458, cost 22.23 s
2024-01-02 15:46:10,202	44k	INFO	====> Epoch: 3459, cost 22.24 s
2024-01-02 15:46:32,348	44k	INFO	====> Epoch: 3460, cost 22.15 s
2024-01-02 15:46:54,467	44k	INFO	====> Epoch: 3461, cost 22.12 s
2024-01-02 15:47:16,615	44k	INFO	====> Epoch: 3462, cost 22.15 s
2024-01-02 15:47:39,093	44k	INFO	====> Epoch: 3463, cost 22.48 s
2024-01-02 15:48:01,299	44k	INFO	Train Epoch: 3464 [96%]
2024-01-02 15:48:01,301	44k	INFO	Losses: [1.6891953945159912, 3.603210926055908, 11.181181907653809, 12.282403945922852, -2.456824541091919], step: 86600, lr: 6.486240169134462e-05, reference_loss: 26.299165725708008
2024-01-02 15:48:01,710	44k	INFO	====> Epoch: 3464, cost 22.62 s
2024-01-02 15:48:23,922	44k	INFO	====> Epoch: 3465, cost 22.21 s
2024-01-02 15:48:46,144	44k	INFO	====> Epoch: 3466, cost 22.22 s
2024-01-02 15:49:08,351	44k	INFO	====> Epoch: 3467, cost 22.21 s
2024-01-02 15:49:30,499	44k	INFO	====> Epoch: 3468, cost 22.15 s
2024-01-02 15:49:52,778	44k	INFO	====> Epoch: 3469, cost 22.28 s
2024-01-02 15:50:15,121	44k	INFO	====> Epoch: 3470, cost 22.34 s
2024-01-02 15:50:37,394	44k	INFO	====> Epoch: 3471, cost 22.27 s
2024-01-02 15:50:59,504	44k	INFO	Train Epoch: 3472 [96%]
2024-01-02 15:50:59,506	44k	INFO	Losses: [1.8787322044372559, 3.0433008670806885, 7.282128810882568, 10.475360870361328, -2.414119005203247], step: 86800, lr: 6.479756765986076e-05, reference_loss: 20.265403747558594
2024-01-02 15:51:00,121	44k	INFO	====> Epoch: 3472, cost 22.73 s
2024-01-02 15:51:22,444	44k	INFO	====> Epoch: 3473, cost 22.32 s
2024-01-02 15:51:44,664	44k	INFO	====> Epoch: 3474, cost 22.22 s
2024-01-02 15:52:06,911	44k	INFO	====> Epoch: 3475, cost 22.25 s
2024-01-02 15:52:29,128	44k	INFO	====> Epoch: 3476, cost 22.22 s
2024-01-02 15:52:51,350	44k	INFO	====> Epoch: 3477, cost 22.22 s
2024-01-02 15:53:13,507	44k	INFO	====> Epoch: 3478, cost 22.16 s
2024-01-02 15:53:35,879	44k	INFO	====> Epoch: 3479, cost 22.37 s
2024-01-02 15:53:58,180	44k	INFO	Train Epoch: 3480 [96%]
2024-01-02 15:53:58,181	44k	INFO	Losses: [1.657950758934021, 3.484227418899536, 10.640972137451172, 12.047338485717773, -2.535651922225952], step: 87000, lr: 6.47327984340506e-05, reference_loss: 25.294836044311523
2024-01-02 15:53:58,590	44k	INFO	====> Epoch: 3480, cost 22.71 s
2024-01-02 15:54:20,976	44k	INFO	====> Epoch: 3481, cost 22.39 s
2024-01-02 15:54:43,350	44k	INFO	====> Epoch: 3482, cost 22.37 s
2024-01-02 15:55:05,498	44k	INFO	====> Epoch: 3483, cost 22.15 s
2024-01-02 15:55:27,609	44k	INFO	====> Epoch: 3484, cost 22.11 s
2024-01-02 15:55:49,678	44k	INFO	====> Epoch: 3485, cost 22.07 s
2024-01-02 15:56:11,802	44k	INFO	====> Epoch: 3486, cost 22.12 s
2024-01-02 15:56:34,052	44k	INFO	====> Epoch: 3487, cost 22.25 s
2024-01-02 15:56:56,231	44k	INFO	Train Epoch: 3488 [96%]
2024-01-02 15:56:56,233	44k	INFO	Losses: [1.9211554527282715, 3.1103720664978027, 9.229060173034668, 11.637879371643066, -2.5756537914276123], step: 87200, lr: 6.466809394913681e-05, reference_loss: 23.32281494140625
2024-01-02 15:57:02,514	44k	INFO	Saving model and optimizer state at iteration 3488 to ./logs/44k/G_87200.pth
2024-01-02 15:57:03,437	44k	INFO	Saving model and optimizer state at iteration 3488 to ./logs/44k/D_87200.pth
2024-01-02 15:57:03,958	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_84800.pth
2024-01-02 15:57:03,997	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_84800.pth
2024-01-02 15:57:03,997	44k	INFO	====> Epoch: 3488, cost 29.95 s
2024-01-02 15:57:26,206	44k	INFO	====> Epoch: 3489, cost 22.21 s
2024-01-02 15:57:48,574	44k	INFO	====> Epoch: 3490, cost 22.37 s
2024-01-02 15:58:10,771	44k	INFO	====> Epoch: 3491, cost 22.20 s
2024-01-02 15:58:33,009	44k	INFO	====> Epoch: 3492, cost 22.24 s
2024-01-02 15:58:55,257	44k	INFO	====> Epoch: 3493, cost 22.25 s
2024-01-02 15:59:17,321	44k	INFO	====> Epoch: 3494, cost 22.06 s
2024-01-02 15:59:39,425	44k	INFO	====> Epoch: 3495, cost 22.10 s
2024-01-02 16:00:01,526	44k	INFO	Train Epoch: 3496 [96%]
2024-01-02 16:00:01,528	44k	INFO	Losses: [1.7085673809051514, 3.386457681655884, 8.998903274536133, 11.426088333129883, -2.498823404312134], step: 87400, lr: 6.460345414040679e-05, reference_loss: 23.02119255065918
2024-01-02 16:00:01,959	44k	INFO	====> Epoch: 3496, cost 22.53 s
2024-01-02 16:00:24,060	44k	INFO	====> Epoch: 3497, cost 22.10 s
2024-01-02 16:00:46,164	44k	INFO	====> Epoch: 3498, cost 22.10 s
2024-01-02 16:01:08,260	44k	INFO	====> Epoch: 3499, cost 22.10 s
2024-01-02 16:01:30,454	44k	INFO	====> Epoch: 3500, cost 22.19 s
2024-01-02 16:01:52,716	44k	INFO	====> Epoch: 3501, cost 22.26 s
2024-01-02 16:02:15,233	44k	INFO	====> Epoch: 3502, cost 22.52 s
2024-01-02 16:02:37,418	44k	INFO	====> Epoch: 3503, cost 22.18 s
2024-01-02 16:02:59,426	44k	INFO	Train Epoch: 3504 [96%]
2024-01-02 16:02:59,428	44k	INFO	Losses: [1.9021968841552734, 2.9933128356933594, 7.1866865158081055, 10.458499908447266, -2.4844789505004883], step: 87600, lr: 6.453887894321264e-05, reference_loss: 20.056217193603516
2024-01-02 16:02:59,824	44k	INFO	====> Epoch: 3504, cost 22.41 s
2024-01-02 16:03:21,867	44k	INFO	====> Epoch: 3505, cost 22.04 s
2024-01-02 16:03:44,014	44k	INFO	====> Epoch: 3506, cost 22.15 s
2024-01-02 16:04:06,057	44k	INFO	====> Epoch: 3507, cost 22.04 s
2024-01-02 16:04:28,184	44k	INFO	====> Epoch: 3508, cost 22.13 s
2024-01-02 16:04:50,335	44k	INFO	====> Epoch: 3509, cost 22.15 s
2024-01-02 16:05:12,640	44k	INFO	====> Epoch: 3510, cost 22.31 s
2024-01-02 16:05:34,914	44k	INFO	====> Epoch: 3511, cost 22.27 s
2024-01-02 16:05:57,524	44k	INFO	Train Epoch: 3512 [96%]
2024-01-02 16:05:57,525	44k	INFO	Losses: [1.5835068225860596, 3.4458558559417725, 10.488868713378906, 11.629372596740723, -2.654761791229248], step: 87800, lr: 6.447436829297109e-05, reference_loss: 24.492841720581055
2024-01-02 16:05:57,928	44k	INFO	====> Epoch: 3512, cost 23.01 s
2024-01-02 16:06:20,197	44k	INFO	====> Epoch: 3513, cost 22.27 s
2024-01-02 16:06:42,394	44k	INFO	====> Epoch: 3514, cost 22.20 s
2024-01-02 16:07:04,559	44k	INFO	====> Epoch: 3515, cost 22.17 s
2024-01-02 16:07:26,874	44k	INFO	====> Epoch: 3516, cost 22.31 s
2024-01-02 16:07:48,970	44k	INFO	====> Epoch: 3517, cost 22.10 s
2024-01-02 16:08:11,190	44k	INFO	====> Epoch: 3518, cost 22.22 s
2024-01-02 16:08:33,355	44k	INFO	====> Epoch: 3519, cost 22.16 s
2024-01-02 16:08:55,466	44k	INFO	Train Epoch: 3520 [96%]
2024-01-02 16:08:55,467	44k	INFO	Losses: [1.9034276008605957, 3.237340211868286, 9.22514533996582, 11.470723152160645, -2.6040191650390625], step: 88000, lr: 6.440992212516346e-05, reference_loss: 23.232616424560547
2024-01-02 16:09:01,998	44k	INFO	Saving model and optimizer state at iteration 3520 to ./logs/44k/G_88000.pth
2024-01-02 16:09:02,939	44k	INFO	Saving model and optimizer state at iteration 3520 to ./logs/44k/D_88000.pth
2024-01-02 16:09:03,467	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_85600.pth
2024-01-02 16:09:03,506	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_85600.pth
2024-01-02 16:09:03,506	44k	INFO	====> Epoch: 3520, cost 30.15 s
2024-01-02 16:09:25,665	44k	INFO	====> Epoch: 3521, cost 22.16 s
2024-01-02 16:09:47,713	44k	INFO	====> Epoch: 3522, cost 22.05 s
2024-01-02 16:10:09,779	44k	INFO	====> Epoch: 3523, cost 22.07 s
2024-01-02 16:10:31,977	44k	INFO	====> Epoch: 3524, cost 22.20 s
2024-01-02 16:10:54,230	44k	INFO	====> Epoch: 3525, cost 22.25 s
2024-01-02 16:11:16,444	44k	INFO	====> Epoch: 3526, cost 22.21 s
2024-01-02 16:11:38,537	44k	INFO	====> Epoch: 3527, cost 22.09 s
2024-01-02 16:12:00,563	44k	INFO	Train Epoch: 3528 [96%]
2024-01-02 16:12:00,564	44k	INFO	Losses: [1.8018869161605835, 3.3249576091766357, 10.678945541381836, 12.480630874633789, -2.519035816192627], step: 88200, lr: 6.434554037533547e-05, reference_loss: 25.767385482788086
2024-01-02 16:12:00,961	44k	INFO	====> Epoch: 3528, cost 22.42 s
2024-01-02 16:12:23,090	44k	INFO	====> Epoch: 3529, cost 22.13 s
2024-01-02 16:12:45,155	44k	INFO	====> Epoch: 3530, cost 22.07 s
2024-01-02 16:13:07,252	44k	INFO	====> Epoch: 3531, cost 22.10 s
2024-01-02 16:13:29,551	44k	INFO	====> Epoch: 3532, cost 22.30 s
2024-01-02 16:13:51,757	44k	INFO	====> Epoch: 3533, cost 22.21 s
2024-01-02 16:14:13,967	44k	INFO	====> Epoch: 3534, cost 22.21 s
2024-01-02 16:14:36,226	44k	INFO	====> Epoch: 3535, cost 22.26 s
2024-01-02 16:14:58,478	44k	INFO	Train Epoch: 3536 [96%]
2024-01-02 16:14:58,480	44k	INFO	Losses: [1.9653851985931396, 3.1815648078918457, 9.207796096801758, 11.924921989440918, -2.52624249458313], step: 88400, lr: 6.428122297909735e-05, reference_loss: 23.7534236907959
2024-01-02 16:14:58,979	44k	INFO	====> Epoch: 3536, cost 22.75 s
2024-01-02 16:15:21,189	44k	INFO	====> Epoch: 3537, cost 22.21 s
2024-01-02 16:15:43,379	44k	INFO	====> Epoch: 3538, cost 22.19 s
2024-01-02 16:16:05,546	44k	INFO	====> Epoch: 3539, cost 22.17 s
2024-01-02 16:16:27,735	44k	INFO	====> Epoch: 3540, cost 22.19 s
2024-01-02 16:16:49,856	44k	INFO	====> Epoch: 3541, cost 22.12 s
2024-01-02 16:17:12,232	44k	INFO	====> Epoch: 3542, cost 22.38 s
2024-01-02 16:17:34,501	44k	INFO	====> Epoch: 3543, cost 22.27 s
2024-01-02 16:17:56,736	44k	INFO	Train Epoch: 3544 [96%]
2024-01-02 16:17:56,737	44k	INFO	Losses: [1.5570921897888184, 3.666893482208252, 11.141664505004883, 12.33350658416748, -2.7166333198547363], step: 88600, lr: 6.421696987212362e-05, reference_loss: 25.982524871826172
2024-01-02 16:17:57,158	44k	INFO	====> Epoch: 3544, cost 22.66 s
2024-01-02 16:18:19,256	44k	INFO	====> Epoch: 3545, cost 22.10 s
2024-01-02 16:18:41,349	44k	INFO	====> Epoch: 3546, cost 22.09 s
2024-01-02 16:19:03,444	44k	INFO	====> Epoch: 3547, cost 22.10 s
2024-01-02 16:19:25,716	44k	INFO	====> Epoch: 3548, cost 22.27 s
2024-01-02 16:19:47,865	44k	INFO	====> Epoch: 3549, cost 22.15 s
2024-01-02 16:20:09,966	44k	INFO	====> Epoch: 3550, cost 22.10 s
2024-01-02 16:20:32,154	44k	INFO	====> Epoch: 3551, cost 22.19 s
2024-01-02 16:20:54,523	44k	INFO	Train Epoch: 3552 [96%]
2024-01-02 16:20:54,524	44k	INFO	Losses: [1.7984178066253662, 3.1737823486328125, 9.074018478393555, 11.534765243530273, -2.654916286468506], step: 88800, lr: 6.415278099015317e-05, reference_loss: 22.926067352294922
2024-01-02 16:21:00,713	44k	INFO	Saving model and optimizer state at iteration 3552 to ./logs/44k/G_88800.pth
2024-01-02 16:21:01,640	44k	INFO	Saving model and optimizer state at iteration 3552 to ./logs/44k/D_88800.pth
2024-01-02 16:21:02,152	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_86400.pth
2024-01-02 16:21:02,191	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_86400.pth
2024-01-02 16:21:02,192	44k	INFO	====> Epoch: 3552, cost 30.04 s
2024-01-02 16:21:24,248	44k	INFO	====> Epoch: 3553, cost 22.06 s
2024-01-02 16:21:46,407	44k	INFO	====> Epoch: 3554, cost 22.16 s
2024-01-02 16:22:08,546	44k	INFO	====> Epoch: 3555, cost 22.14 s
2024-01-02 16:22:30,699	44k	INFO	====> Epoch: 3556, cost 22.15 s
2024-01-02 16:22:52,925	44k	INFO	====> Epoch: 3557, cost 22.23 s
2024-01-02 16:23:15,229	44k	INFO	====> Epoch: 3558, cost 22.30 s
2024-01-02 16:23:37,711	44k	INFO	====> Epoch: 3559, cost 22.48 s
2024-01-02 16:23:59,988	44k	INFO	Train Epoch: 3560 [96%]
2024-01-02 16:23:59,990	44k	INFO	Losses: [1.7063473463058472, 3.4380369186401367, 9.298140525817871, 11.407402992248535, -2.619929552078247], step: 89000, lr: 6.408865626898906e-05, reference_loss: 23.229997634887695
2024-01-02 16:24:00,393	44k	INFO	====> Epoch: 3560, cost 22.68 s
2024-01-02 16:24:22,515	44k	INFO	====> Epoch: 3561, cost 22.12 s
2024-01-02 16:24:44,775	44k	INFO	====> Epoch: 3562, cost 22.26 s
2024-01-02 16:25:07,055	44k	INFO	====> Epoch: 3563, cost 22.28 s
2024-01-02 16:25:29,283	44k	INFO	====> Epoch: 3564, cost 22.23 s
2024-01-02 16:25:51,407	44k	INFO	====> Epoch: 3565, cost 22.12 s
2024-01-02 16:26:13,622	44k	INFO	====> Epoch: 3566, cost 22.22 s
2024-01-02 16:26:35,762	44k	INFO	====> Epoch: 3567, cost 22.14 s
2024-01-02 16:26:57,960	44k	INFO	Train Epoch: 3568 [96%]
2024-01-02 16:26:57,962	44k	INFO	Losses: [1.9339258670806885, 3.10275936126709, 7.013610363006592, 10.132720947265625, -2.5868337154388428], step: 89200, lr: 6.402459564449859e-05, reference_loss: 19.596181869506836
2024-01-02 16:26:58,567	44k	INFO	====> Epoch: 3568, cost 22.81 s
2024-01-02 16:27:20,755	44k	INFO	====> Epoch: 3569, cost 22.19 s
2024-01-02 16:27:42,976	44k	INFO	====> Epoch: 3570, cost 22.22 s
2024-01-02 16:28:05,255	44k	INFO	====> Epoch: 3571, cost 22.28 s
2024-01-02 16:28:27,498	44k	INFO	====> Epoch: 3572, cost 22.24 s
2024-01-02 16:28:49,833	44k	INFO	====> Epoch: 3573, cost 22.33 s
2024-01-02 16:29:12,141	44k	INFO	====> Epoch: 3574, cost 22.31 s
2024-01-02 16:29:34,332	44k	INFO	====> Epoch: 3575, cost 22.19 s
2024-01-02 16:29:56,393	44k	INFO	Train Epoch: 3576 [96%]
2024-01-02 16:29:56,394	44k	INFO	Losses: [1.570135474205017, 3.7334494590759277, 11.847370147705078, 12.775528907775879, -2.686920166015625], step: 89400, lr: 6.396059905261307e-05, reference_loss: 27.23956298828125
2024-01-02 16:29:56,907	44k	INFO	====> Epoch: 3576, cost 22.57 s
2024-01-02 16:30:19,095	44k	INFO	====> Epoch: 3577, cost 22.19 s
2024-01-02 16:30:41,364	44k	INFO	====> Epoch: 3578, cost 22.27 s
2024-01-02 16:31:03,594	44k	INFO	====> Epoch: 3579, cost 22.23 s
2024-01-02 16:31:25,925	44k	INFO	====> Epoch: 3580, cost 22.33 s
2024-01-02 16:31:47,969	44k	INFO	====> Epoch: 3581, cost 22.04 s
2024-01-02 16:32:10,088	44k	INFO	====> Epoch: 3582, cost 22.12 s
2024-01-02 16:32:32,339	44k	INFO	====> Epoch: 3583, cost 22.25 s
2024-01-02 16:32:54,502	44k	INFO	Train Epoch: 3584 [96%]
2024-01-02 16:32:54,504	44k	INFO	Losses: [1.787010669708252, 3.0719852447509766, 9.336092948913574, 11.724308013916016, -2.705775022506714], step: 89600, lr: 6.389666642932794e-05, reference_loss: 23.213623046875
2024-01-02 16:33:00,438	44k	INFO	Saving model and optimizer state at iteration 3584 to ./logs/44k/G_89600.pth
2024-01-02 16:33:01,379	44k	INFO	Saving model and optimizer state at iteration 3584 to ./logs/44k/D_89600.pth
2024-01-02 16:33:01,893	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_87200.pth
2024-01-02 16:33:01,932	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_87200.pth
2024-01-02 16:33:01,932	44k	INFO	====> Epoch: 3584, cost 29.59 s
2024-01-02 16:33:24,138	44k	INFO	====> Epoch: 3585, cost 22.21 s
2024-01-02 16:33:46,549	44k	INFO	====> Epoch: 3586, cost 22.41 s
2024-01-02 16:34:08,780	44k	INFO	====> Epoch: 3587, cost 22.23 s
2024-01-02 16:34:31,089	44k	INFO	====> Epoch: 3588, cost 22.31 s
2024-01-02 16:34:53,303	44k	INFO	====> Epoch: 3589, cost 22.21 s
2024-01-02 16:35:15,407	44k	INFO	====> Epoch: 3590, cost 22.10 s
2024-01-02 16:35:37,586	44k	INFO	====> Epoch: 3591, cost 22.18 s
2024-01-02 16:35:59,897	44k	INFO	Train Epoch: 3592 [96%]
2024-01-02 16:35:59,899	44k	INFO	Losses: [1.6731202602386475, 3.351346015930176, 9.64454174041748, 11.930681228637695, -2.5857088565826416], step: 89800, lr: 6.383279771070253e-05, reference_loss: 24.013980865478516
2024-01-02 16:36:00,394	44k	INFO	====> Epoch: 3592, cost 22.81 s
2024-01-02 16:36:22,638	44k	INFO	====> Epoch: 3593, cost 22.24 s
2024-01-02 16:36:44,891	44k	INFO	====> Epoch: 3594, cost 22.25 s
2024-01-02 16:37:07,144	44k	INFO	====> Epoch: 3595, cost 22.25 s
2024-01-02 16:37:29,408	44k	INFO	====> Epoch: 3596, cost 22.26 s
2024-01-02 16:37:51,542	44k	INFO	====> Epoch: 3597, cost 22.13 s
2024-01-02 16:38:13,736	44k	INFO	====> Epoch: 3598, cost 22.19 s
2024-01-02 16:38:35,787	44k	INFO	====> Epoch: 3599, cost 22.05 s
2024-01-02 16:38:57,820	44k	INFO	Train Epoch: 3600 [96%]
2024-01-02 16:38:57,822	44k	INFO	Losses: [1.9962639808654785, 3.007624387741089, 6.890942573547363, 10.292731285095215, -2.4656436443328857], step: 90000, lr: 6.376899283286019e-05, reference_loss: 19.7219181060791
2024-01-02 16:38:58,213	44k	INFO	====> Epoch: 3600, cost 22.43 s
2024-01-02 16:39:20,416	44k	INFO	====> Epoch: 3601, cost 22.20 s
2024-01-02 16:39:42,644	44k	INFO	====> Epoch: 3602, cost 22.23 s
2024-01-02 16:40:04,729	44k	INFO	====> Epoch: 3603, cost 22.09 s
2024-01-02 16:40:26,889	44k	INFO	====> Epoch: 3604, cost 22.16 s
2024-01-02 16:40:49,075	44k	INFO	====> Epoch: 3605, cost 22.19 s
2024-01-02 16:41:11,232	44k	INFO	====> Epoch: 3606, cost 22.16 s
2024-01-02 16:41:33,208	44k	INFO	====> Epoch: 3607, cost 21.98 s
2024-01-02 16:41:55,323	44k	INFO	Train Epoch: 3608 [96%]
2024-01-02 16:41:55,324	44k	INFO	Losses: [1.5828452110290527, 3.61574387550354, 11.586956024169922, 12.074440002441406, -2.7476203441619873], step: 90200, lr: 6.370525173198803e-05, reference_loss: 26.11236572265625
2024-01-02 16:41:55,906	44k	INFO	====> Epoch: 3608, cost 22.70 s
2024-01-02 16:42:18,163	44k	INFO	====> Epoch: 3609, cost 22.26 s
2024-01-02 16:42:40,292	44k	INFO	====> Epoch: 3610, cost 22.13 s
2024-01-02 16:43:02,396	44k	INFO	====> Epoch: 3611, cost 22.10 s
2024-01-02 16:43:24,661	44k	INFO	====> Epoch: 3612, cost 22.26 s
2024-01-02 16:43:46,713	44k	INFO	====> Epoch: 3613, cost 22.05 s
2024-01-02 16:44:08,757	44k	INFO	====> Epoch: 3614, cost 22.04 s
2024-01-02 16:44:30,866	44k	INFO	====> Epoch: 3615, cost 22.11 s
2024-01-02 16:44:53,084	44k	INFO	Train Epoch: 3616 [96%]
2024-01-02 16:44:53,085	44k	INFO	Losses: [1.877123475074768, 2.9168496131896973, 8.290632247924805, 11.009833335876465, -2.6491026878356934], step: 90400, lr: 6.364157434433698e-05, reference_loss: 21.445335388183594
2024-01-02 16:44:59,449	44k	INFO	Saving model and optimizer state at iteration 3616 to ./logs/44k/G_90400.pth
2024-01-02 16:45:00,382	44k	INFO	Saving model and optimizer state at iteration 3616 to ./logs/44k/D_90400.pth
2024-01-02 16:45:00,896	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_88000.pth
2024-01-02 16:45:00,935	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_88000.pth
2024-01-02 16:45:00,936	44k	INFO	====> Epoch: 3616, cost 30.07 s
2024-01-02 16:45:22,932	44k	INFO	====> Epoch: 3617, cost 22.00 s
2024-01-02 16:45:44,980	44k	INFO	====> Epoch: 3618, cost 22.05 s
2024-01-02 16:46:07,131	44k	INFO	====> Epoch: 3619, cost 22.15 s
2024-01-02 16:46:29,286	44k	INFO	====> Epoch: 3620, cost 22.16 s
2024-01-02 16:46:51,386	44k	INFO	====> Epoch: 3621, cost 22.10 s
2024-01-02 16:47:13,641	44k	INFO	====> Epoch: 3622, cost 22.26 s
2024-01-02 16:47:35,898	44k	INFO	====> Epoch: 3623, cost 22.26 s
2024-01-02 16:47:57,873	44k	INFO	Train Epoch: 3624 [96%]
2024-01-02 16:47:57,876	44k	INFO	Losses: [1.6598578691482544, 3.7442636489868164, 11.353495597839355, 12.392601013183594, -2.5856432914733887], step: 90600, lr: 6.357796060622167e-05, reference_loss: 26.5645751953125
2024-01-02 16:47:58,250	44k	INFO	====> Epoch: 3624, cost 22.35 s
2024-01-02 16:48:20,318	44k	INFO	====> Epoch: 3625, cost 22.07 s
2024-01-02 16:48:42,507	44k	INFO	====> Epoch: 3626, cost 22.19 s
2024-01-02 16:49:04,709	44k	INFO	====> Epoch: 3627, cost 22.20 s
2024-01-02 16:49:27,256	44k	INFO	====> Epoch: 3628, cost 22.55 s
2024-01-02 16:49:49,458	44k	INFO	====> Epoch: 3629, cost 22.20 s
2024-01-02 16:50:11,707	44k	INFO	====> Epoch: 3630, cost 22.25 s
2024-01-02 16:50:33,926	44k	INFO	====> Epoch: 3631, cost 22.22 s
2024-01-02 16:50:56,061	44k	INFO	Train Epoch: 3632 [96%]
2024-01-02 16:50:56,063	44k	INFO	Losses: [1.9821622371673584, 2.939932346343994, 8.131736755371094, 11.362748146057129, -2.614570140838623], step: 90800, lr: 6.351441045402045e-05, reference_loss: 21.80200958251953
2024-01-02 16:50:56,444	44k	INFO	====> Epoch: 3632, cost 22.52 s
2024-01-02 16:51:18,615	44k	INFO	====> Epoch: 3633, cost 22.17 s
2024-01-02 16:51:40,763	44k	INFO	====> Epoch: 3634, cost 22.15 s
2024-01-02 16:52:02,937	44k	INFO	====> Epoch: 3635, cost 22.17 s
2024-01-02 16:52:25,229	44k	INFO	====> Epoch: 3636, cost 22.29 s
2024-01-02 16:52:47,377	44k	INFO	====> Epoch: 3637, cost 22.15 s
2024-01-02 16:53:09,643	44k	INFO	====> Epoch: 3638, cost 22.27 s
2024-01-02 16:53:31,967	44k	INFO	====> Epoch: 3639, cost 22.32 s
2024-01-02 16:53:54,346	44k	INFO	Train Epoch: 3640 [96%]
2024-01-02 16:53:54,347	44k	INFO	Losses: [1.604054570198059, 3.575934886932373, 10.46941089630127, 12.047280311584473, -2.809968948364258], step: 91000, lr: 6.34509238241752e-05, reference_loss: 24.8867130279541
2024-01-02 16:53:54,849	44k	INFO	====> Epoch: 3640, cost 22.88 s
2024-01-02 16:54:17,228	44k	INFO	====> Epoch: 3641, cost 22.38 s
2024-01-02 16:54:39,539	44k	INFO	====> Epoch: 3642, cost 22.31 s
2024-01-02 16:55:01,847	44k	INFO	====> Epoch: 3643, cost 22.31 s
2024-01-02 16:55:24,097	44k	INFO	====> Epoch: 3644, cost 22.25 s
2024-01-02 16:55:46,429	44k	INFO	====> Epoch: 3645, cost 22.33 s
2024-01-02 16:56:08,698	44k	INFO	====> Epoch: 3646, cost 22.27 s
2024-01-02 16:56:30,890	44k	INFO	====> Epoch: 3647, cost 22.19 s
2024-01-02 16:56:53,328	44k	INFO	Train Epoch: 3648 [96%]
2024-01-02 16:56:53,330	44k	INFO	Losses: [1.848888635635376, 3.016666889190674, 8.001916885375977, 11.00032901763916, -2.719735622406006], step: 91200, lr: 6.33875006531913e-05, reference_loss: 21.1480655670166
2024-01-02 16:56:59,606	44k	INFO	Saving model and optimizer state at iteration 3648 to ./logs/44k/G_91200.pth
2024-01-02 16:57:00,541	44k	INFO	Saving model and optimizer state at iteration 3648 to ./logs/44k/D_91200.pth
2024-01-02 16:57:01,071	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_88800.pth
2024-01-02 16:57:01,110	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_88800.pth
2024-01-02 16:57:01,110	44k	INFO	====> Epoch: 3648, cost 30.22 s
2024-01-02 16:57:23,397	44k	INFO	====> Epoch: 3649, cost 22.29 s
2024-01-02 16:57:45,714	44k	INFO	====> Epoch: 3650, cost 22.32 s
2024-01-02 16:58:08,030	44k	INFO	====> Epoch: 3651, cost 22.32 s
2024-01-02 16:58:30,289	44k	INFO	====> Epoch: 3652, cost 22.26 s
2024-01-02 16:58:52,481	44k	INFO	====> Epoch: 3653, cost 22.19 s
2024-01-02 16:59:14,733	44k	INFO	====> Epoch: 3654, cost 22.25 s
2024-01-02 16:59:37,107	44k	INFO	====> Epoch: 3655, cost 22.37 s
2024-01-02 16:59:59,340	44k	INFO	Train Epoch: 3656 [96%]
2024-01-02 16:59:59,341	44k	INFO	Losses: [1.6542675495147705, 3.4358386993408203, 10.764025688171387, 12.423335075378418, -2.649813175201416], step: 91400, lr: 6.332414087763771e-05, reference_loss: 25.627653121948242
2024-01-02 16:59:59,742	44k	INFO	====> Epoch: 3656, cost 22.63 s
2024-01-02 17:00:21,999	44k	INFO	====> Epoch: 3657, cost 22.26 s
2024-01-02 17:00:44,169	44k	INFO	====> Epoch: 3658, cost 22.17 s
2024-01-02 17:01:06,346	44k	INFO	====> Epoch: 3659, cost 22.18 s
2024-01-02 17:01:28,499	44k	INFO	====> Epoch: 3660, cost 22.15 s
2024-01-02 17:01:50,715	44k	INFO	====> Epoch: 3661, cost 22.22 s
2024-01-02 17:02:13,132	44k	INFO	====> Epoch: 3662, cost 22.42 s
2024-01-02 17:02:35,627	44k	INFO	====> Epoch: 3663, cost 22.50 s
2024-01-02 17:02:58,036	44k	INFO	Train Epoch: 3664 [96%]
2024-01-02 17:02:58,037	44k	INFO	Losses: [1.8917587995529175, 3.1304993629455566, 7.362357139587402, 10.32390022277832, -2.6403064727783203], step: 91600, lr: 6.32608444341467e-05, reference_loss: 20.068208694458008
2024-01-02 17:02:58,654	44k	INFO	====> Epoch: 3664, cost 23.03 s
2024-01-02 17:03:20,945	44k	INFO	====> Epoch: 3665, cost 22.29 s
2024-01-02 17:03:43,258	44k	INFO	====> Epoch: 3666, cost 22.31 s
2024-01-02 17:04:05,576	44k	INFO	====> Epoch: 3667, cost 22.32 s
2024-01-02 17:04:27,764	44k	INFO	====> Epoch: 3668, cost 22.19 s
2024-01-02 17:04:49,859	44k	INFO	====> Epoch: 3669, cost 22.10 s
2024-01-02 17:05:11,989	44k	INFO	====> Epoch: 3670, cost 22.13 s
2024-01-02 17:05:34,319	44k	INFO	====> Epoch: 3671, cost 22.33 s
2024-01-02 17:05:56,472	44k	INFO	Train Epoch: 3672 [96%]
2024-01-02 17:05:56,473	44k	INFO	Losses: [1.4750847816467285, 3.6908302307128906, 11.818466186523438, 12.736104965209961, -2.860541582107544], step: 91800, lr: 6.31976112594139e-05, reference_loss: 26.859943389892578
2024-01-02 17:05:56,871	44k	INFO	====> Epoch: 3672, cost 22.55 s
2024-01-02 17:06:19,073	44k	INFO	====> Epoch: 3673, cost 22.20 s
2024-01-02 17:06:41,504	44k	INFO	====> Epoch: 3674, cost 22.43 s
2024-01-02 17:07:03,628	44k	INFO	====> Epoch: 3675, cost 22.12 s
2024-01-02 17:07:25,849	44k	INFO	====> Epoch: 3676, cost 22.22 s
2024-01-02 17:07:48,190	44k	INFO	====> Epoch: 3677, cost 22.34 s
2024-01-02 17:08:10,485	44k	INFO	====> Epoch: 3678, cost 22.29 s
2024-01-02 17:08:32,617	44k	INFO	====> Epoch: 3679, cost 22.13 s
2024-01-02 17:08:54,767	44k	INFO	Train Epoch: 3680 [96%]
2024-01-02 17:08:54,769	44k	INFO	Losses: [1.7992935180664062, 3.0107851028442383, 8.20948600769043, 11.01182746887207, -2.752100706100464], step: 92000, lr: 6.313444129019825e-05, reference_loss: 21.2792911529541
2024-01-02 17:09:00,477	44k	INFO	Saving model and optimizer state at iteration 3680 to ./logs/44k/G_92000.pth
2024-01-02 17:09:01,388	44k	INFO	Saving model and optimizer state at iteration 3680 to ./logs/44k/D_92000.pth
2024-01-02 17:09:01,870	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_89600.pth
2024-01-02 17:09:01,908	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_89600.pth
2024-01-02 17:09:01,909	44k	INFO	====> Epoch: 3680, cost 29.29 s
2024-01-02 17:09:24,036	44k	INFO	====> Epoch: 3681, cost 22.13 s
2024-01-02 17:09:46,421	44k	INFO	====> Epoch: 3682, cost 22.39 s
2024-01-02 17:10:08,532	44k	INFO	====> Epoch: 3683, cost 22.11 s
2024-01-02 17:10:30,711	44k	INFO	====> Epoch: 3684, cost 22.18 s
2024-01-02 17:10:52,786	44k	INFO	====> Epoch: 3685, cost 22.08 s
2024-01-02 17:11:14,959	44k	INFO	====> Epoch: 3686, cost 22.17 s
2024-01-02 17:11:37,180	44k	INFO	====> Epoch: 3687, cost 22.22 s
2024-01-02 17:11:59,538	44k	INFO	Train Epoch: 3688 [96%]
2024-01-02 17:11:59,540	44k	INFO	Losses: [1.6161346435546875, 3.728595495223999, 11.367051124572754, 12.491111755371094, -2.6834471225738525], step: 92200, lr: 6.307133446332185e-05, reference_loss: 26.519445419311523
2024-01-02 17:11:59,950	44k	INFO	====> Epoch: 3688, cost 22.77 s
2024-01-02 17:12:22,173	44k	INFO	====> Epoch: 3689, cost 22.22 s
2024-01-02 17:12:44,355	44k	INFO	====> Epoch: 3690, cost 22.18 s
2024-01-02 17:13:06,494	44k	INFO	====> Epoch: 3691, cost 22.14 s
2024-01-02 17:13:28,641	44k	INFO	====> Epoch: 3692, cost 22.15 s
2024-01-02 17:13:50,793	44k	INFO	====> Epoch: 3693, cost 22.15 s
2024-01-02 17:14:13,153	44k	INFO	====> Epoch: 3694, cost 22.36 s
2024-01-02 17:14:35,168	44k	INFO	====> Epoch: 3695, cost 22.01 s
2024-01-02 17:14:57,309	44k	INFO	Train Epoch: 3696 [96%]
2024-01-02 17:14:57,311	44k	INFO	Losses: [1.9020577669143677, 2.968172311782837, 7.798726558685303, 11.243109703063965, -2.684117555618286], step: 92400, lr: 6.300829071566999e-05, reference_loss: 21.227949142456055
2024-01-02 17:14:57,706	44k	INFO	====> Epoch: 3696, cost 22.54 s
2024-01-02 17:15:20,040	44k	INFO	====> Epoch: 3697, cost 22.33 s
2024-01-02 17:15:42,279	44k	INFO	====> Epoch: 3698, cost 22.24 s
2024-01-02 17:16:04,414	44k	INFO	====> Epoch: 3699, cost 22.14 s
2024-01-02 17:16:26,615	44k	INFO	====> Epoch: 3700, cost 22.20 s
2024-01-02 17:16:48,831	44k	INFO	====> Epoch: 3701, cost 22.22 s
2024-01-02 17:17:11,023	44k	INFO	====> Epoch: 3702, cost 22.19 s
2024-01-02 17:17:33,269	44k	INFO	====> Epoch: 3703, cost 22.25 s
2024-01-02 17:17:55,474	44k	INFO	Train Epoch: 3704 [96%]
2024-01-02 17:17:55,476	44k	INFO	Losses: [1.6734256744384766, 3.544250965118408, 10.542688369750977, 12.241571426391602, -2.898634910583496], step: 92600, lr: 6.294530998419103e-05, reference_loss: 25.103302001953125
2024-01-02 17:17:56,022	44k	INFO	====> Epoch: 3704, cost 22.75 s
2024-01-02 17:18:18,161	44k	INFO	====> Epoch: 3705, cost 22.14 s
2024-01-02 17:18:40,164	44k	INFO	====> Epoch: 3706, cost 22.00 s
2024-01-02 17:19:02,257	44k	INFO	====> Epoch: 3707, cost 22.09 s
2024-01-02 17:19:24,390	44k	INFO	====> Epoch: 3708, cost 22.13 s
2024-01-02 17:19:46,385	44k	INFO	====> Epoch: 3709, cost 22.00 s
2024-01-02 17:20:08,321	44k	INFO	====> Epoch: 3710, cost 21.94 s
2024-01-02 17:20:30,380	44k	INFO	====> Epoch: 3711, cost 22.06 s
2024-01-02 17:20:52,435	44k	INFO	Train Epoch: 3712 [96%]
2024-01-02 17:20:52,437	44k	INFO	Losses: [1.7083053588867188, 3.41414737701416, 9.399169921875, 11.325333595275879, -2.8465843200683594], step: 92800, lr: 6.288239220589637e-05, reference_loss: 23.0003719329834
2024-01-02 17:20:58,659	44k	INFO	Saving model and optimizer state at iteration 3712 to ./logs/44k/G_92800.pth
2024-01-02 17:20:59,571	44k	INFO	Saving model and optimizer state at iteration 3712 to ./logs/44k/D_92800.pth
2024-01-02 17:21:00,125	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_90400.pth
2024-01-02 17:21:00,166	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_90400.pth
2024-01-02 17:21:00,166	44k	INFO	====> Epoch: 3712, cost 29.79 s
2024-01-02 17:21:22,436	44k	INFO	====> Epoch: 3713, cost 22.27 s
2024-01-02 17:21:44,718	44k	INFO	====> Epoch: 3714, cost 22.28 s
2024-01-02 17:22:06,966	44k	INFO	====> Epoch: 3715, cost 22.25 s
2024-01-02 17:22:29,225	44k	INFO	====> Epoch: 3716, cost 22.26 s
2024-01-02 17:22:51,330	44k	INFO	====> Epoch: 3717, cost 22.11 s
2024-01-02 17:23:13,474	44k	INFO	====> Epoch: 3718, cost 22.14 s
2024-01-02 17:23:35,685	44k	INFO	====> Epoch: 3719, cost 22.21 s
2024-01-02 17:23:57,867	44k	INFO	Train Epoch: 3720 [96%]
2024-01-02 17:23:57,869	44k	INFO	Losses: [1.733139991760254, 3.5605874061584473, 10.991799354553223, 12.540220260620117, -2.759610414505005], step: 93000, lr: 6.281953731786035e-05, reference_loss: 26.06613540649414
2024-01-02 17:23:58,267	44k	INFO	====> Epoch: 3720, cost 22.58 s
2024-01-02 17:24:20,580	44k	INFO	====> Epoch: 3721, cost 22.31 s
2024-01-02 17:24:42,844	44k	INFO	====> Epoch: 3722, cost 22.26 s
2024-01-02 17:25:04,958	44k	INFO	====> Epoch: 3723, cost 22.11 s
2024-01-02 17:25:27,278	44k	INFO	====> Epoch: 3724, cost 22.32 s
2024-01-02 17:25:49,507	44k	INFO	====> Epoch: 3725, cost 22.23 s
2024-01-02 17:26:11,759	44k	INFO	====> Epoch: 3726, cost 22.25 s
2024-01-02 17:26:33,855	44k	INFO	====> Epoch: 3727, cost 22.10 s
2024-01-02 17:26:55,851	44k	INFO	Train Epoch: 3728 [96%]
2024-01-02 17:26:55,853	44k	INFO	Losses: [2.00081205368042, 3.1167328357696533, 9.394723892211914, 11.566083908081055, -2.742600440979004], step: 93200, lr: 6.275674525722024e-05, reference_loss: 23.33575439453125
2024-01-02 17:26:56,239	44k	INFO	====> Epoch: 3728, cost 22.38 s
2024-01-02 17:27:18,593	44k	INFO	====> Epoch: 3729, cost 22.35 s
2024-01-02 17:27:40,757	44k	INFO	====> Epoch: 3730, cost 22.16 s
2024-01-02 17:28:02,972	44k	INFO	====> Epoch: 3731, cost 22.21 s
2024-01-02 17:28:25,301	44k	INFO	====> Epoch: 3732, cost 22.33 s
2024-01-02 17:28:47,441	44k	INFO	====> Epoch: 3733, cost 22.14 s
2024-01-02 17:29:09,733	44k	INFO	====> Epoch: 3734, cost 22.29 s
2024-01-02 17:29:31,864	44k	INFO	====> Epoch: 3735, cost 22.13 s
2024-01-02 17:29:54,067	44k	INFO	Train Epoch: 3736 [96%]
2024-01-02 17:29:54,069	44k	INFO	Losses: [1.5107760429382324, 3.4735329151153564, 10.386550903320312, 11.607129096984863, -2.9873244762420654], step: 93400, lr: 6.269401596117609e-05, reference_loss: 23.990665435791016
2024-01-02 17:29:54,465	44k	INFO	====> Epoch: 3736, cost 22.60 s
2024-01-02 17:30:16,588	44k	INFO	====> Epoch: 3737, cost 22.12 s
2024-01-02 17:30:38,747	44k	INFO	====> Epoch: 3738, cost 22.16 s
2024-01-02 17:31:00,798	44k	INFO	====> Epoch: 3739, cost 22.05 s
2024-01-02 17:31:22,848	44k	INFO	====> Epoch: 3740, cost 22.05 s
2024-01-02 17:31:45,078	44k	INFO	====> Epoch: 3741, cost 22.23 s
2024-01-02 17:32:07,231	44k	INFO	====> Epoch: 3742, cost 22.15 s
2024-01-02 17:32:29,466	44k	INFO	====> Epoch: 3743, cost 22.24 s
2024-01-02 17:32:51,654	44k	INFO	Train Epoch: 3744 [96%]
2024-01-02 17:32:51,656	44k	INFO	Losses: [1.8469196557998657, 2.993943691253662, 8.126599311828613, 10.742323875427246, -2.888432741165161], step: 93600, lr: 6.26313493669908e-05, reference_loss: 20.821352005004883
2024-01-02 17:32:57,406	44k	INFO	Saving model and optimizer state at iteration 3744 to ./logs/44k/G_93600.pth
2024-01-02 17:32:58,316	44k	INFO	Saving model and optimizer state at iteration 3744 to ./logs/44k/D_93600.pth
2024-01-02 17:32:58,807	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_91200.pth
2024-01-02 17:32:58,846	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_91200.pth
2024-01-02 17:32:58,846	44k	INFO	====> Epoch: 3744, cost 29.38 s
2024-01-02 17:33:20,899	44k	INFO	====> Epoch: 3745, cost 22.05 s
2024-01-02 17:33:42,969	44k	INFO	====> Epoch: 3746, cost 22.07 s
2024-01-02 17:34:05,152	44k	INFO	====> Epoch: 3747, cost 22.18 s
2024-01-02 17:34:27,391	44k	INFO	====> Epoch: 3748, cost 22.24 s
2024-01-02 17:34:49,573	44k	INFO	====> Epoch: 3749, cost 22.18 s
2024-01-02 17:35:11,745	44k	INFO	====> Epoch: 3750, cost 22.17 s
2024-01-02 17:35:34,109	44k	INFO	====> Epoch: 3751, cost 22.36 s
2024-01-02 17:35:56,363	44k	INFO	Train Epoch: 3752 [96%]
2024-01-02 17:35:56,364	44k	INFO	Losses: [1.6402515172958374, 3.4447195529937744, 9.377511024475098, 11.159720420837402, -2.807546377182007], step: 93800, lr: 6.25687454119899e-05, reference_loss: 22.81465721130371
2024-01-02 17:35:56,747	44k	INFO	====> Epoch: 3752, cost 22.64 s
2024-01-02 17:36:19,026	44k	INFO	====> Epoch: 3753, cost 22.28 s
2024-01-02 17:36:41,269	44k	INFO	====> Epoch: 3754, cost 22.24 s
2024-01-02 17:37:03,558	44k	INFO	====> Epoch: 3755, cost 22.29 s
2024-01-02 17:37:25,882	44k	INFO	====> Epoch: 3756, cost 22.32 s
2024-01-02 17:37:48,163	44k	INFO	====> Epoch: 3757, cost 22.28 s
2024-01-02 17:38:10,322	44k	INFO	====> Epoch: 3758, cost 22.16 s
2024-01-02 17:38:32,524	44k	INFO	====> Epoch: 3759, cost 22.20 s
2024-01-02 17:38:54,662	44k	INFO	Train Epoch: 3760 [96%]
2024-01-02 17:38:54,663	44k	INFO	Losses: [1.7524439096450806, 3.228224754333496, 8.565413475036621, 11.73455810546875, -2.775944948196411], step: 94000, lr: 6.250620403356163e-05, reference_loss: 22.50469398498535
2024-01-02 17:38:55,254	44k	INFO	====> Epoch: 3760, cost 22.73 s
2024-01-02 17:39:17,341	44k	INFO	====> Epoch: 3761, cost 22.09 s
2024-01-02 17:39:39,381	44k	INFO	====> Epoch: 3762, cost 22.04 s
2024-01-02 17:40:01,410	44k	INFO	====> Epoch: 3763, cost 22.03 s
2024-01-02 17:40:23,470	44k	INFO	====> Epoch: 3764, cost 22.06 s
2024-01-02 17:40:45,601	44k	INFO	====> Epoch: 3765, cost 22.13 s
2024-01-02 17:41:07,828	44k	INFO	====> Epoch: 3766, cost 22.23 s
2024-01-02 17:41:30,013	44k	INFO	====> Epoch: 3767, cost 22.19 s
2024-01-02 17:41:52,188	44k	INFO	Train Epoch: 3768 [96%]
2024-01-02 17:41:52,190	44k	INFO	Losses: [1.6656594276428223, 3.5239341259002686, 10.56701374053955, 11.46908950805664, -2.9896240234375], step: 94200, lr: 6.244372516915678e-05, reference_loss: 24.236072540283203
2024-01-02 17:41:52,674	44k	INFO	====> Epoch: 3768, cost 22.66 s
2024-01-02 17:42:15,008	44k	INFO	====> Epoch: 3769, cost 22.33 s
2024-01-02 17:42:37,505	44k	INFO	====> Epoch: 3770, cost 22.50 s
2024-01-02 17:42:59,816	44k	INFO	====> Epoch: 3771, cost 22.31 s
2024-01-02 17:43:22,092	44k	INFO	====> Epoch: 3772, cost 22.28 s
2024-01-02 17:43:44,388	44k	INFO	====> Epoch: 3773, cost 22.30 s
2024-01-02 17:44:06,589	44k	INFO	====> Epoch: 3774, cost 22.20 s
2024-01-02 17:44:28,796	44k	INFO	====> Epoch: 3775, cost 22.21 s
2024-01-02 17:44:51,038	44k	INFO	Train Epoch: 3776 [96%]
2024-01-02 17:44:51,040	44k	INFO	Losses: [1.8295515775680542, 3.085507392883301, 8.111654281616211, 10.656859397888184, -2.8301615715026855], step: 94400, lr: 6.238130875628865e-05, reference_loss: 20.853410720825195
2024-01-02 17:44:57,985	44k	INFO	Saving model and optimizer state at iteration 3776 to ./logs/44k/G_94400.pth
2024-01-02 17:44:58,986	44k	INFO	Saving model and optimizer state at iteration 3776 to ./logs/44k/D_94400.pth
2024-01-02 17:44:59,568	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_92000.pth
2024-01-02 17:44:59,609	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_92000.pth
2024-01-02 17:44:59,609	44k	INFO	====> Epoch: 3776, cost 30.81 s
2024-01-02 17:45:21,896	44k	INFO	====> Epoch: 3777, cost 22.29 s
2024-01-02 17:45:44,276	44k	INFO	====> Epoch: 3778, cost 22.38 s
2024-01-02 17:46:06,537	44k	INFO	====> Epoch: 3779, cost 22.26 s
2024-01-02 17:46:28,778	44k	INFO	====> Epoch: 3780, cost 22.24 s
2024-01-02 17:46:51,020	44k	INFO	====> Epoch: 3781, cost 22.24 s
2024-01-02 17:47:13,255	44k	INFO	====> Epoch: 3782, cost 22.24 s
2024-01-02 17:47:35,465	44k	INFO	====> Epoch: 3783, cost 22.21 s
2024-01-02 17:47:57,715	44k	INFO	Train Epoch: 3784 [96%]
2024-01-02 17:47:57,717	44k	INFO	Losses: [1.6490026712417603, 3.407626152038574, 10.64003849029541, 12.350237846374512, -2.8127243518829346], step: 94600, lr: 6.231895473253304e-05, reference_loss: 25.234180450439453
2024-01-02 17:47:58,122	44k	INFO	====> Epoch: 3784, cost 22.66 s
2024-01-02 17:48:20,389	44k	INFO	====> Epoch: 3785, cost 22.27 s
2024-01-02 17:48:42,652	44k	INFO	====> Epoch: 3786, cost 22.26 s
2024-01-02 17:49:04,935	44k	INFO	====> Epoch: 3787, cost 22.28 s
2024-01-02 17:49:27,218	44k	INFO	====> Epoch: 3788, cost 22.28 s
2024-01-02 17:49:49,540	44k	INFO	====> Epoch: 3789, cost 22.32 s
2024-01-02 17:50:11,865	44k	INFO	====> Epoch: 3790, cost 22.32 s
2024-01-02 17:50:33,947	44k	INFO	====> Epoch: 3791, cost 22.08 s
2024-01-02 17:50:56,109	44k	INFO	Train Epoch: 3792 [96%]
2024-01-02 17:50:56,111	44k	INFO	Losses: [1.893551230430603, 3.1544408798217773, 7.410025596618652, 10.569290161132812, -2.832932233810425], step: 94800, lr: 6.225666303552813e-05, reference_loss: 20.19437599182129
2024-01-02 17:50:56,515	44k	INFO	====> Epoch: 3792, cost 22.57 s
2024-01-02 17:51:18,680	44k	INFO	====> Epoch: 3793, cost 22.16 s
2024-01-02 17:51:40,959	44k	INFO	====> Epoch: 3794, cost 22.28 s
2024-01-02 17:52:03,199	44k	INFO	====> Epoch: 3795, cost 22.24 s
2024-01-02 17:52:25,527	44k	INFO	====> Epoch: 3796, cost 22.33 s
2024-01-02 17:52:47,757	44k	INFO	====> Epoch: 3797, cost 22.23 s
2024-01-02 17:53:09,945	44k	INFO	====> Epoch: 3798, cost 22.19 s
2024-01-02 17:53:32,134	44k	INFO	====> Epoch: 3799, cost 22.19 s
2024-01-02 17:53:54,328	44k	INFO	Train Epoch: 3800 [96%]
2024-01-02 17:53:54,330	44k	INFO	Losses: [1.634407639503479, 3.436210870742798, 10.710996627807617, 11.706443786621094, -3.0500712394714355], step: 95000, lr: 6.21944336029744e-05, reference_loss: 24.43798828125
2024-01-02 17:53:54,939	44k	INFO	====> Epoch: 3800, cost 22.80 s
2024-01-02 17:54:17,337	44k	INFO	====> Epoch: 3801, cost 22.40 s
2024-01-02 17:54:39,666	44k	INFO	====> Epoch: 3802, cost 22.33 s
2024-01-02 17:55:01,950	44k	INFO	====> Epoch: 3803, cost 22.28 s
2024-01-02 17:55:24,175	44k	INFO	====> Epoch: 3804, cost 22.23 s
2024-01-02 17:55:46,471	44k	INFO	====> Epoch: 3805, cost 22.30 s
2024-01-02 17:56:08,647	44k	INFO	====> Epoch: 3806, cost 22.18 s
2024-01-02 17:56:30,902	44k	INFO	====> Epoch: 3807, cost 22.25 s
2024-01-02 17:56:53,105	44k	INFO	Train Epoch: 3808 [96%]
2024-01-02 17:56:53,107	44k	INFO	Losses: [1.9113733768463135, 3.066058874130249, 8.298064231872559, 10.843148231506348, -2.945875644683838], step: 95200, lr: 6.213226637263466e-05, reference_loss: 21.17276954650879
2024-01-02 17:56:59,099	44k	INFO	Saving model and optimizer state at iteration 3808 to ./logs/44k/G_95200.pth
2024-01-02 17:56:59,999	44k	INFO	Saving model and optimizer state at iteration 3808 to ./logs/44k/D_95200.pth
2024-01-02 17:57:00,502	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_92800.pth
2024-01-02 17:57:00,541	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_92800.pth
2024-01-02 17:57:00,541	44k	INFO	====> Epoch: 3808, cost 29.64 s
2024-01-02 17:57:22,858	44k	INFO	====> Epoch: 3809, cost 22.32 s
2024-01-02 17:57:45,267	44k	INFO	====> Epoch: 3810, cost 22.41 s
2024-01-02 17:58:07,636	44k	INFO	====> Epoch: 3811, cost 22.37 s
2024-01-02 17:58:29,955	44k	INFO	====> Epoch: 3812, cost 22.32 s
2024-01-02 17:58:52,290	44k	INFO	====> Epoch: 3813, cost 22.33 s
2024-01-02 17:59:14,588	44k	INFO	====> Epoch: 3814, cost 22.30 s
2024-01-02 17:59:36,870	44k	INFO	====> Epoch: 3815, cost 22.28 s
2024-01-02 17:59:59,227	44k	INFO	Train Epoch: 3816 [96%]
2024-01-02 17:59:59,229	44k	INFO	Losses: [1.5223722457885742, 3.6128597259521484, 10.790567398071289, 12.2359037399292, -2.838635206222534], step: 95400, lr: 6.207016128233389e-05, reference_loss: 25.323068618774414
2024-01-02 17:59:59,630	44k	INFO	====> Epoch: 3816, cost 22.76 s
2024-01-02 18:00:22,005	44k	INFO	====> Epoch: 3817, cost 22.37 s
2024-01-02 18:00:44,457	44k	INFO	====> Epoch: 3818, cost 22.45 s
2024-01-02 18:01:06,930	44k	INFO	====> Epoch: 3819, cost 22.47 s
2024-01-02 18:01:29,591	44k	INFO	====> Epoch: 3820, cost 22.66 s
2024-01-02 18:01:52,075	44k	INFO	====> Epoch: 3821, cost 22.48 s
2024-01-02 18:02:14,395	44k	INFO	====> Epoch: 3822, cost 22.32 s
2024-01-02 18:02:36,635	44k	INFO	====> Epoch: 3823, cost 22.24 s
2024-01-02 18:02:58,778	44k	INFO	Train Epoch: 3824 [96%]
2024-01-02 18:02:58,780	44k	INFO	Losses: [1.7980420589447021, 2.967532157897949, 8.460366249084473, 11.365497589111328, -2.8163232803344727], step: 95600, lr: 6.200811826995922e-05, reference_loss: 21.775115966796875
2024-01-02 18:02:59,163	44k	INFO	====> Epoch: 3824, cost 22.53 s
2024-01-02 18:03:21,274	44k	INFO	====> Epoch: 3825, cost 22.11 s
2024-01-02 18:03:43,526	44k	INFO	====> Epoch: 3826, cost 22.25 s
2024-01-02 18:04:05,842	44k	INFO	====> Epoch: 3827, cost 22.32 s
2024-01-02 18:04:28,147	44k	INFO	====> Epoch: 3828, cost 22.30 s
2024-01-02 18:04:50,455	44k	INFO	====> Epoch: 3829, cost 22.31 s
2024-01-02 18:05:12,988	44k	INFO	====> Epoch: 3830, cost 22.53 s
2024-01-02 18:05:35,266	44k	INFO	====> Epoch: 3831, cost 22.28 s
2024-01-02 18:05:57,541	44k	INFO	Train Epoch: 3832 [96%]
2024-01-02 18:05:57,543	44k	INFO	Losses: [1.5953364372253418, 3.464207887649536, 10.793935775756836, 11.682901382446289, -3.0609493255615234], step: 95800, lr: 6.19461372734599e-05, reference_loss: 24.475431442260742
2024-01-02 18:05:57,926	44k	INFO	====> Epoch: 3832, cost 22.66 s
2024-01-02 18:06:20,244	44k	INFO	====> Epoch: 3833, cost 22.32 s
2024-01-02 18:06:42,530	44k	INFO	====> Epoch: 3834, cost 22.29 s
2024-01-02 18:07:04,762	44k	INFO	====> Epoch: 3835, cost 22.23 s
2024-01-02 18:07:26,826	44k	INFO	====> Epoch: 3836, cost 22.06 s
2024-01-02 18:07:49,066	44k	INFO	====> Epoch: 3837, cost 22.24 s
2024-01-02 18:08:11,270	44k	INFO	====> Epoch: 3838, cost 22.20 s
2024-01-02 18:08:33,463	44k	INFO	====> Epoch: 3839, cost 22.19 s
2024-01-02 18:08:55,703	44k	INFO	Train Epoch: 3840 [96%]
2024-01-02 18:08:55,705	44k	INFO	Losses: [1.9148128032684326, 3.014974594116211, 9.280555725097656, 11.877411842346191, -3.0194292068481445], step: 96000, lr: 6.188421823084718e-05, reference_loss: 23.06832504272461
2024-01-02 18:09:01,538	44k	INFO	Saving model and optimizer state at iteration 3840 to ./logs/44k/G_96000.pth
2024-01-02 18:09:02,459	44k	INFO	Saving model and optimizer state at iteration 3840 to ./logs/44k/D_96000.pth
2024-01-02 18:09:02,945	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_93600.pth
2024-01-02 18:09:02,983	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_93600.pth
2024-01-02 18:09:02,984	44k	INFO	====> Epoch: 3840, cost 29.52 s
2024-01-02 18:09:25,351	44k	INFO	====> Epoch: 3841, cost 22.37 s
2024-01-02 18:09:47,670	44k	INFO	====> Epoch: 3842, cost 22.32 s
2024-01-02 18:10:10,021	44k	INFO	====> Epoch: 3843, cost 22.35 s
2024-01-02 18:10:32,288	44k	INFO	====> Epoch: 3844, cost 22.27 s
2024-01-02 18:10:54,402	44k	INFO	====> Epoch: 3845, cost 22.11 s
2024-01-02 18:11:16,533	44k	INFO	====> Epoch: 3846, cost 22.13 s
2024-01-02 18:11:38,943	44k	INFO	====> Epoch: 3847, cost 22.41 s
2024-01-02 18:12:01,105	44k	INFO	Train Epoch: 3848 [96%]
2024-01-02 18:12:01,107	44k	INFO	Losses: [1.6818259954452515, 3.645113945007324, 10.909062385559082, 12.216615676879883, -2.8859312534332275], step: 96200, lr: 6.182236108019425e-05, reference_loss: 25.566686630249023
2024-01-02 18:12:01,495	44k	INFO	====> Epoch: 3848, cost 22.55 s
2024-01-02 18:12:23,793	44k	INFO	====> Epoch: 3849, cost 22.30 s
2024-01-02 18:12:45,981	44k	INFO	====> Epoch: 3850, cost 22.19 s
2024-01-02 18:13:08,248	44k	INFO	====> Epoch: 3851, cost 22.27 s
2024-01-02 18:13:30,570	44k	INFO	====> Epoch: 3852, cost 22.32 s
2024-01-02 18:13:52,861	44k	INFO	====> Epoch: 3853, cost 22.29 s
2024-01-02 18:14:15,302	44k	INFO	====> Epoch: 3854, cost 22.44 s
2024-01-02 18:14:37,683	44k	INFO	====> Epoch: 3855, cost 22.38 s
2024-01-02 18:14:59,920	44k	INFO	Train Epoch: 3856 [96%]
2024-01-02 18:14:59,922	44k	INFO	Losses: [1.8733311891555786, 2.9859628677368164, 7.376002311706543, 10.766188621520996, -2.8851170539855957], step: 96400, lr: 6.176056575963625e-05, reference_loss: 20.11636734008789
2024-01-02 18:15:00,482	44k	INFO	====> Epoch: 3856, cost 22.80 s
2024-01-02 18:15:22,842	44k	INFO	====> Epoch: 3857, cost 22.36 s
2024-01-02 18:15:45,213	44k	INFO	====> Epoch: 3858, cost 22.37 s
2024-01-02 18:16:07,488	44k	INFO	====> Epoch: 3859, cost 22.28 s
2024-01-02 18:16:29,698	44k	INFO	====> Epoch: 3860, cost 22.21 s
2024-01-02 18:16:51,896	44k	INFO	====> Epoch: 3861, cost 22.20 s
2024-01-02 18:17:14,188	44k	INFO	====> Epoch: 3862, cost 22.29 s
2024-01-02 18:17:36,504	44k	INFO	====> Epoch: 3863, cost 22.32 s
2024-01-02 18:17:58,792	44k	INFO	Train Epoch: 3864 [96%]
2024-01-02 18:17:58,793	44k	INFO	Losses: [1.6776059865951538, 3.221254587173462, 10.537162780761719, 11.493109703063965, -3.1310644149780273], step: 96600, lr: 6.169883220737008e-05, reference_loss: 23.79806900024414
2024-01-02 18:17:59,283	44k	INFO	====> Epoch: 3864, cost 22.78 s
2024-01-02 18:18:21,695	44k	INFO	====> Epoch: 3865, cost 22.41 s
2024-01-02 18:18:44,138	44k	INFO	====> Epoch: 3866, cost 22.44 s
2024-01-02 18:19:06,433	44k	INFO	====> Epoch: 3867, cost 22.30 s
2024-01-02 18:19:28,795	44k	INFO	====> Epoch: 3868, cost 22.36 s
2024-01-02 18:19:51,029	44k	INFO	====> Epoch: 3869, cost 22.23 s
2024-01-02 18:20:13,296	44k	INFO	====> Epoch: 3870, cost 22.27 s
2024-01-02 18:20:35,565	44k	INFO	====> Epoch: 3871, cost 22.27 s
2024-01-02 18:20:57,800	44k	INFO	Train Epoch: 3872 [96%]
2024-01-02 18:20:57,802	44k	INFO	Losses: [1.9753210544586182, 3.1081812381744385, 9.361738204956055, 11.262332916259766, -3.0577518939971924], step: 96800, lr: 6.163716036165453e-05, reference_loss: 22.64982032775879
2024-01-02 18:21:04,105	44k	INFO	Saving model and optimizer state at iteration 3872 to ./logs/44k/G_96800.pth
2024-01-02 18:21:05,040	44k	INFO	Saving model and optimizer state at iteration 3872 to ./logs/44k/D_96800.pth
2024-01-02 18:21:05,563	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_94400.pth
2024-01-02 18:21:05,603	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_94400.pth
2024-01-02 18:21:05,603	44k	INFO	====> Epoch: 3872, cost 30.04 s
2024-01-02 18:21:28,021	44k	INFO	====> Epoch: 3873, cost 22.42 s
2024-01-02 18:21:50,723	44k	INFO	====> Epoch: 3874, cost 22.70 s
2024-01-02 18:22:13,040	44k	INFO	====> Epoch: 3875, cost 22.32 s
2024-01-02 18:22:35,256	44k	INFO	====> Epoch: 3876, cost 22.22 s
2024-01-02 18:22:57,462	44k	INFO	====> Epoch: 3877, cost 22.21 s
2024-01-02 18:23:19,683	44k	INFO	====> Epoch: 3878, cost 22.22 s
2024-01-02 18:23:42,050	44k	INFO	====> Epoch: 3879, cost 22.37 s
2024-01-02 18:24:04,442	44k	INFO	Train Epoch: 3880 [96%]
2024-01-02 18:24:04,443	44k	INFO	Losses: [1.6139030456542969, 3.244821071624756, 11.299296379089355, 12.197749137878418, -2.9090399742126465], step: 97000, lr: 6.157555016081001e-05, reference_loss: 25.44672966003418
2024-01-02 18:24:04,855	44k	INFO	====> Epoch: 3880, cost 22.81 s
2024-01-02 18:24:27,312	44k	INFO	====> Epoch: 3881, cost 22.46 s
2024-01-02 18:24:49,783	44k	INFO	====> Epoch: 3882, cost 22.47 s
2024-01-02 18:25:12,133	44k	INFO	====> Epoch: 3883, cost 22.35 s
2024-01-02 18:25:34,338	44k	INFO	====> Epoch: 3884, cost 22.20 s
2024-01-02 18:25:56,592	44k	INFO	====> Epoch: 3885, cost 22.25 s
2024-01-02 18:26:18,986	44k	INFO	====> Epoch: 3886, cost 22.39 s
2024-01-02 18:26:41,199	44k	INFO	====> Epoch: 3887, cost 22.21 s
2024-01-02 18:27:03,218	44k	INFO	Train Epoch: 3888 [96%]
2024-01-02 18:27:03,220	44k	INFO	Losses: [1.8570365905761719, 3.040026903152466, 7.249961853027344, 10.444533348083496, -2.864757537841797], step: 97200, lr: 6.151400154321863e-05, reference_loss: 19.7268009185791
2024-01-02 18:27:03,613	44k	INFO	====> Epoch: 3888, cost 22.41 s
2024-01-02 18:27:25,760	44k	INFO	====> Epoch: 3889, cost 22.15 s
2024-01-02 18:27:47,866	44k	INFO	====> Epoch: 3890, cost 22.11 s
2024-01-02 18:28:09,994	44k	INFO	====> Epoch: 3891, cost 22.13 s
2024-01-02 18:28:32,229	44k	INFO	====> Epoch: 3892, cost 22.24 s
2024-01-02 18:28:54,547	44k	INFO	====> Epoch: 3893, cost 22.32 s
2024-01-02 18:29:16,829	44k	INFO	====> Epoch: 3894, cost 22.28 s
2024-01-02 18:29:39,065	44k	INFO	====> Epoch: 3895, cost 22.24 s
2024-01-02 18:30:01,220	44k	INFO	Train Epoch: 3896 [96%]
2024-01-02 18:30:01,222	44k	INFO	Losses: [1.548087239265442, 3.4126827716827393, 11.909984588623047, 12.077445030212402, -3.1568386554718018], step: 97400, lr: 6.145251444732401e-05, reference_loss: 25.79136085510254
2024-01-02 18:30:01,803	44k	INFO	====> Epoch: 3896, cost 22.74 s
2024-01-02 18:30:24,103	44k	INFO	====> Epoch: 3897, cost 22.30 s
2024-01-02 18:30:46,177	44k	INFO	====> Epoch: 3898, cost 22.07 s
2024-01-02 18:31:08,217	44k	INFO	====> Epoch: 3899, cost 22.04 s
2024-01-02 18:31:30,433	44k	INFO	====> Epoch: 3900, cost 22.22 s
2024-01-02 18:31:52,654	44k	INFO	====> Epoch: 3901, cost 22.22 s
2024-01-02 18:32:14,837	44k	INFO	====> Epoch: 3902, cost 22.18 s
2024-01-02 18:32:37,050	44k	INFO	====> Epoch: 3903, cost 22.21 s
2024-01-02 18:32:59,356	44k	INFO	Train Epoch: 3904 [96%]
2024-01-02 18:32:59,357	44k	INFO	Losses: [1.8007891178131104, 2.9350240230560303, 8.099822998046875, 10.514579772949219, -3.026305675506592], step: 97600, lr: 6.139108881163144e-05, reference_loss: 20.323909759521484
2024-01-02 18:33:05,728	44k	INFO	Saving model and optimizer state at iteration 3904 to ./logs/44k/G_97600.pth
2024-01-02 18:33:06,661	44k	INFO	Saving model and optimizer state at iteration 3904 to ./logs/44k/D_97600.pth
2024-01-02 18:33:07,183	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_95200.pth
2024-01-02 18:33:07,221	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_95200.pth
2024-01-02 18:33:07,222	44k	INFO	====> Epoch: 3904, cost 30.17 s
2024-01-02 18:33:29,487	44k	INFO	====> Epoch: 3905, cost 22.27 s
2024-01-02 18:33:51,889	44k	INFO	====> Epoch: 3906, cost 22.40 s
2024-01-02 18:34:14,018	44k	INFO	====> Epoch: 3907, cost 22.13 s
2024-01-02 18:34:36,186	44k	INFO	====> Epoch: 3908, cost 22.17 s
2024-01-02 18:34:58,419	44k	INFO	====> Epoch: 3909, cost 22.23 s
2024-01-02 18:35:20,642	44k	INFO	====> Epoch: 3910, cost 22.22 s
2024-01-02 18:35:42,939	44k	INFO	====> Epoch: 3911, cost 22.30 s
2024-01-02 18:36:05,337	44k	INFO	Train Epoch: 3912 [96%]
2024-01-02 18:36:05,339	44k	INFO	Losses: [1.494449496269226, 3.6261634826660156, 11.311805725097656, 12.079141616821289, -2.9764466285705566], step: 97800, lr: 6.132972457470755e-05, reference_loss: 25.535114288330078
2024-01-02 18:36:05,735	44k	INFO	====> Epoch: 3912, cost 22.80 s
2024-01-02 18:36:28,105	44k	INFO	====> Epoch: 3913, cost 22.37 s
2024-01-02 18:36:50,416	44k	INFO	====> Epoch: 3914, cost 22.31 s
2024-01-02 18:37:12,687	44k	INFO	====> Epoch: 3915, cost 22.27 s
2024-01-02 18:37:35,247	44k	INFO	====> Epoch: 3916, cost 22.56 s
2024-01-02 18:37:57,711	44k	INFO	====> Epoch: 3917, cost 22.46 s
2024-01-02 18:38:20,100	44k	INFO	====> Epoch: 3918, cost 22.39 s
2024-01-02 18:38:42,340	44k	INFO	====> Epoch: 3919, cost 22.24 s
2024-01-02 18:39:04,515	44k	INFO	Train Epoch: 3920 [96%]
2024-01-02 18:39:04,517	44k	INFO	Losses: [1.9864356517791748, 2.9059665203094482, 6.926996231079102, 9.298110008239746, -2.9089515209198], step: 98000, lr: 6.126842167518043e-05, reference_loss: 18.20855712890625
2024-01-02 18:39:04,898	44k	INFO	====> Epoch: 3920, cost 22.56 s
2024-01-02 18:39:27,126	44k	INFO	====> Epoch: 3921, cost 22.23 s
2024-01-02 18:39:49,322	44k	INFO	====> Epoch: 3922, cost 22.20 s
2024-01-02 18:40:11,541	44k	INFO	====> Epoch: 3923, cost 22.22 s
2024-01-02 18:40:33,818	44k	INFO	====> Epoch: 3924, cost 22.28 s
2024-01-02 18:40:56,121	44k	INFO	====> Epoch: 3925, cost 22.30 s
2024-01-02 18:41:18,405	44k	INFO	====> Epoch: 3926, cost 22.28 s
2024-01-02 18:41:40,451	44k	INFO	====> Epoch: 3927, cost 22.05 s
2024-01-02 18:42:02,599	44k	INFO	Train Epoch: 3928 [96%]
2024-01-02 18:42:02,601	44k	INFO	Losses: [1.4809964895248413, 3.6767406463623047, 11.935616493225098, 12.008185386657715, -3.1824066638946533], step: 98200, lr: 6.120718005173953e-05, reference_loss: 25.919132232666016
2024-01-02 18:42:03,074	44k	INFO	====> Epoch: 3928, cost 22.62 s
2024-01-02 18:42:25,250	44k	INFO	====> Epoch: 3929, cost 22.18 s
2024-01-02 18:42:47,468	44k	INFO	====> Epoch: 3930, cost 22.22 s
2024-01-02 18:43:09,601	44k	INFO	====> Epoch: 3931, cost 22.13 s
2024-01-02 18:43:31,725	44k	INFO	====> Epoch: 3932, cost 22.12 s
2024-01-02 18:43:53,871	44k	INFO	====> Epoch: 3933, cost 22.15 s
2024-01-02 18:44:15,997	44k	INFO	====> Epoch: 3934, cost 22.13 s
2024-01-02 18:44:38,136	44k	INFO	====> Epoch: 3935, cost 22.14 s
2024-01-02 18:45:00,436	44k	INFO	Train Epoch: 3936 [96%]
2024-01-02 18:45:00,438	44k	INFO	Losses: [1.8744580745697021, 3.128195285797119, 8.125904083251953, 10.226141929626465, -3.0406222343444824], step: 98400, lr: 6.114599964313556e-05, reference_loss: 20.314075469970703
2024-01-02 18:45:06,513	44k	INFO	Saving model and optimizer state at iteration 3936 to ./logs/44k/G_98400.pth
2024-01-02 18:45:07,428	44k	INFO	Saving model and optimizer state at iteration 3936 to ./logs/44k/D_98400.pth
2024-01-02 18:45:07,932	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_96000.pth
2024-01-02 18:45:07,971	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_96000.pth
2024-01-02 18:45:07,971	44k	INFO	====> Epoch: 3936, cost 29.84 s
2024-01-02 18:45:30,060	44k	INFO	====> Epoch: 3937, cost 22.09 s
2024-01-02 18:45:52,100	44k	INFO	====> Epoch: 3938, cost 22.04 s
2024-01-02 18:46:14,016	44k	INFO	====> Epoch: 3939, cost 21.92 s
2024-01-02 18:46:35,975	44k	INFO	====> Epoch: 3940, cost 21.96 s
2024-01-02 18:46:58,001	44k	INFO	====> Epoch: 3941, cost 22.03 s
2024-01-02 18:47:20,188	44k	INFO	====> Epoch: 3942, cost 22.19 s
2024-01-02 18:47:42,521	44k	INFO	====> Epoch: 3943, cost 22.33 s
2024-01-02 18:48:04,653	44k	INFO	Train Epoch: 3944 [96%]
2024-01-02 18:48:04,656	44k	INFO	Losses: [1.6152913570404053, 3.422184705734253, 9.384523391723633, 11.006165504455566, -2.828876495361328], step: 98600, lr: 6.108488038818045e-05, reference_loss: 22.599288940429688
2024-01-02 18:48:05,027	44k	INFO	====> Epoch: 3944, cost 22.51 s
2024-01-02 18:48:27,125	44k	INFO	====> Epoch: 3945, cost 22.10 s
2024-01-02 18:48:49,191	44k	INFO	====> Epoch: 3946, cost 22.07 s
2024-01-02 18:49:11,237	44k	INFO	====> Epoch: 3947, cost 22.05 s
2024-01-02 18:49:33,445	44k	INFO	====> Epoch: 3948, cost 22.21 s
2024-01-02 18:49:55,744	44k	INFO	====> Epoch: 3949, cost 22.30 s
2024-01-02 18:50:17,903	44k	INFO	====> Epoch: 3950, cost 22.16 s
2024-01-02 18:50:39,985	44k	INFO	====> Epoch: 3951, cost 22.08 s
2024-01-02 18:51:02,236	44k	INFO	Train Epoch: 3952 [96%]
2024-01-02 18:51:02,237	44k	INFO	Losses: [1.924891710281372, 2.9410805702209473, 7.247004508972168, 9.502472877502441, -2.927037000656128], step: 98800, lr: 6.102382222574731e-05, reference_loss: 18.688413619995117
2024-01-02 18:51:02,825	44k	INFO	====> Epoch: 3952, cost 22.84 s
2024-01-02 18:51:24,958	44k	INFO	====> Epoch: 3953, cost 22.13 s
2024-01-02 18:51:47,046	44k	INFO	====> Epoch: 3954, cost 22.09 s
2024-01-02 18:52:09,259	44k	INFO	====> Epoch: 3955, cost 22.21 s
2024-01-02 18:52:31,435	44k	INFO	====> Epoch: 3956, cost 22.18 s
2024-01-02 18:52:53,545	44k	INFO	====> Epoch: 3957, cost 22.11 s
2024-01-02 18:53:15,713	44k	INFO	====> Epoch: 3958, cost 22.17 s
2024-01-02 18:53:37,975	44k	INFO	====> Epoch: 3959, cost 22.26 s
2024-01-02 18:54:00,086	44k	INFO	Train Epoch: 3960 [96%]
2024-01-02 18:54:00,087	44k	INFO	Losses: [1.596555233001709, 3.3307547569274902, 12.094402313232422, 12.098844528198242, -3.2306313514709473], step: 99000, lr: 6.096282509477033e-05, reference_loss: 25.88992691040039
2024-01-02 18:54:00,479	44k	INFO	====> Epoch: 3960, cost 22.50 s
2024-01-02 18:54:22,563	44k	INFO	====> Epoch: 3961, cost 22.08 s
2024-01-02 18:54:44,861	44k	INFO	====> Epoch: 3962, cost 22.30 s
2024-01-02 18:55:07,225	44k	INFO	====> Epoch: 3963, cost 22.36 s
2024-01-02 18:55:29,703	44k	INFO	====> Epoch: 3964, cost 22.48 s
2024-01-02 18:55:51,956	44k	INFO	====> Epoch: 3965, cost 22.25 s
2024-01-02 18:56:14,173	44k	INFO	====> Epoch: 3966, cost 22.22 s
2024-01-02 18:56:36,295	44k	INFO	====> Epoch: 3967, cost 22.12 s
2024-01-02 18:56:58,403	44k	INFO	Train Epoch: 3968 [96%]
2024-01-02 18:56:58,405	44k	INFO	Losses: [1.8345985412597656, 3.0209801197052, 8.824508666992188, 11.445634841918945, -3.083838701248169], step: 99200, lr: 6.090188893424474e-05, reference_loss: 22.041881561279297
2024-01-02 18:57:04,349	44k	INFO	Saving model and optimizer state at iteration 3968 to ./logs/44k/G_99200.pth
2024-01-02 18:57:05,255	44k	INFO	Saving model and optimizer state at iteration 3968 to ./logs/44k/D_99200.pth
2024-01-02 18:57:05,764	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_96800.pth
2024-01-02 18:57:05,803	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_96800.pth
2024-01-02 18:57:05,803	44k	INFO	====> Epoch: 3968, cost 29.51 s
2024-01-02 18:57:27,999	44k	INFO	====> Epoch: 3969, cost 22.20 s
2024-01-02 18:57:50,278	44k	INFO	====> Epoch: 3970, cost 22.28 s
2024-01-02 18:58:12,456	44k	INFO	====> Epoch: 3971, cost 22.18 s
2024-01-02 18:58:34,605	44k	INFO	====> Epoch: 3972, cost 22.15 s
2024-01-02 18:58:56,747	44k	INFO	====> Epoch: 3973, cost 22.14 s
2024-01-02 18:59:18,961	44k	INFO	====> Epoch: 3974, cost 22.21 s
2024-01-02 18:59:41,346	44k	INFO	====> Epoch: 3975, cost 22.39 s
2024-01-02 19:00:03,758	44k	INFO	Train Epoch: 3976 [96%]
2024-01-02 19:00:03,759	44k	INFO	Losses: [1.5791280269622803, 3.9160690307617188, 11.639538764953613, 11.979263305664062, -3.0145070552825928], step: 99400, lr: 6.084101368322679e-05, reference_loss: 26.099491119384766
2024-01-02 19:00:04,173	44k	INFO	====> Epoch: 3976, cost 22.83 s
2024-01-02 19:00:26,457	44k	INFO	====> Epoch: 3977, cost 22.28 s
2024-01-02 19:00:48,685	44k	INFO	====> Epoch: 3978, cost 22.23 s
2024-01-02 19:01:10,961	44k	INFO	====> Epoch: 3979, cost 22.28 s
2024-01-02 19:01:33,299	44k	INFO	====> Epoch: 3980, cost 22.34 s
2024-01-02 19:01:55,686	44k	INFO	====> Epoch: 3981, cost 22.39 s
2024-01-02 19:02:18,293	44k	INFO	====> Epoch: 3982, cost 22.61 s
2024-01-02 19:02:40,707	44k	INFO	====> Epoch: 3983, cost 22.41 s
2024-01-02 19:03:03,132	44k	INFO	Train Epoch: 3984 [96%]
2024-01-02 19:03:03,133	44k	INFO	Losses: [1.8608920574188232, 3.1286134719848633, 8.729740142822266, 11.14498233795166, -2.9575088024139404], step: 99600, lr: 6.0780199280833586e-05, reference_loss: 21.906719207763672
2024-01-02 19:03:03,548	44k	INFO	====> Epoch: 3984, cost 22.84 s
2024-01-02 19:03:25,842	44k	INFO	====> Epoch: 3985, cost 22.29 s
2024-01-02 19:03:48,091	44k	INFO	====> Epoch: 3986, cost 22.25 s
2024-01-02 19:04:10,386	44k	INFO	====> Epoch: 3987, cost 22.29 s
2024-01-02 19:04:32,722	44k	INFO	====> Epoch: 3988, cost 22.34 s
2024-01-02 19:04:55,041	44k	INFO	====> Epoch: 3989, cost 22.32 s
2024-01-02 19:05:17,183	44k	INFO	====> Epoch: 3990, cost 22.14 s
2024-01-02 19:05:39,302	44k	INFO	====> Epoch: 3991, cost 22.12 s
2024-01-02 19:06:01,481	44k	INFO	Train Epoch: 3992 [96%]
2024-01-02 19:06:01,482	44k	INFO	Losses: [1.5231726169586182, 3.260866165161133, 10.19621467590332, 11.176858901977539, -3.1925132274627686], step: 99800, lr: 6.0719445666243126e-05, reference_loss: 22.964599609375
2024-01-02 19:06:02,065	44k	INFO	====> Epoch: 3992, cost 22.76 s
2024-01-02 19:06:24,404	44k	INFO	====> Epoch: 3993, cost 22.34 s
2024-01-02 19:06:46,665	44k	INFO	====> Epoch: 3994, cost 22.26 s
2024-01-02 19:07:09,043	44k	INFO	====> Epoch: 3995, cost 22.38 s
2024-01-02 19:07:31,399	44k	INFO	====> Epoch: 3996, cost 22.36 s
2024-01-02 19:07:53,555	44k	INFO	====> Epoch: 3997, cost 22.16 s
2024-01-02 19:08:15,883	44k	INFO	====> Epoch: 3998, cost 22.33 s
2024-01-02 19:08:38,129	44k	INFO	====> Epoch: 3999, cost 22.25 s
2024-01-02 19:09:00,314	44k	INFO	Train Epoch: 4000 [96%]
2024-01-02 19:09:00,315	44k	INFO	Losses: [1.830557107925415, 2.9444382190704346, 8.718616485595703, 11.17872428894043, -3.134862184524536], step: 100000, lr: 6.0658752778694185e-05, reference_loss: 21.537473678588867
2024-01-02 19:09:07,014	44k	INFO	Saving model and optimizer state at iteration 4000 to ./logs/44k/G_100000.pth
2024-01-02 19:09:07,961	44k	INFO	Saving model and optimizer state at iteration 4000 to ./logs/44k/D_100000.pth
2024-01-02 19:09:08,486	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_97600.pth
2024-01-02 19:09:08,525	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_97600.pth
2024-01-02 19:09:08,525	44k	INFO	====> Epoch: 4000, cost 30.40 s
2024-01-02 19:09:30,782	44k	INFO	====> Epoch: 4001, cost 22.26 s
2024-01-02 19:09:53,131	44k	INFO	====> Epoch: 4002, cost 22.35 s
2024-01-02 19:10:15,419	44k	INFO	====> Epoch: 4003, cost 22.29 s
2024-01-02 19:10:37,605	44k	INFO	====> Epoch: 4004, cost 22.19 s
2024-01-02 19:10:59,847	44k	INFO	====> Epoch: 4005, cost 22.24 s
2024-01-02 19:11:22,020	44k	INFO	====> Epoch: 4006, cost 22.17 s
2024-01-02 19:11:44,186	44k	INFO	====> Epoch: 4007, cost 22.17 s
2024-01-02 19:12:06,360	44k	INFO	Train Epoch: 4008 [96%]
2024-01-02 19:12:06,361	44k	INFO	Losses: [1.5943800210952759, 3.4946727752685547, 10.78667163848877, 12.294260025024414, -3.0842792987823486], step: 100200, lr: 6.05981205574863e-05, reference_loss: 25.085704803466797
2024-01-02 19:12:06,746	44k	INFO	====> Epoch: 4008, cost 22.56 s
2024-01-02 19:12:29,047	44k	INFO	====> Epoch: 4009, cost 22.30 s
2024-01-02 19:12:51,194	44k	INFO	====> Epoch: 4010, cost 22.15 s
2024-01-02 19:13:13,302	44k	INFO	====> Epoch: 4011, cost 22.11 s
2024-01-02 19:13:35,769	44k	INFO	====> Epoch: 4012, cost 22.47 s
2024-01-02 19:13:58,066	44k	INFO	====> Epoch: 4013, cost 22.30 s
2024-01-02 19:14:20,386	44k	INFO	====> Epoch: 4014, cost 22.32 s
2024-01-02 19:14:42,554	44k	INFO	====> Epoch: 4015, cost 22.17 s
2024-01-02 19:15:04,898	44k	INFO	Train Epoch: 4016 [96%]
2024-01-02 19:15:04,900	44k	INFO	Losses: [2.0079739093780518, 3.059856653213501, 9.250152587890625, 11.472004890441895, -3.0965919494628906], step: 100400, lr: 6.0537548941979654e-05, reference_loss: 22.693397521972656
2024-01-02 19:15:05,300	44k	INFO	====> Epoch: 4016, cost 22.75 s
2024-01-02 19:15:27,666	44k	INFO	====> Epoch: 4017, cost 22.37 s
2024-01-02 19:15:50,006	44k	INFO	====> Epoch: 4018, cost 22.34 s
2024-01-02 19:16:12,315	44k	INFO	====> Epoch: 4019, cost 22.31 s
2024-01-02 19:16:34,614	44k	INFO	====> Epoch: 4020, cost 22.30 s
2024-01-02 19:16:56,867	44k	INFO	====> Epoch: 4021, cost 22.25 s
2024-01-02 19:17:19,182	44k	INFO	====> Epoch: 4022, cost 22.32 s
2024-01-02 19:17:41,416	44k	INFO	====> Epoch: 4023, cost 22.23 s
2024-01-02 19:18:03,699	44k	INFO	Train Epoch: 4024 [96%]
2024-01-02 19:18:03,701	44k	INFO	Losses: [1.5549461841583252, 3.3797850608825684, 10.393847465515137, 11.256817817687988, -3.331972599029541], step: 100600, lr: 6.0477037871595065e-05, reference_loss: 23.2534236907959
2024-01-02 19:18:04,094	44k	INFO	====> Epoch: 4024, cost 22.68 s
2024-01-02 19:18:26,246	44k	INFO	====> Epoch: 4025, cost 22.15 s
2024-01-02 19:18:48,336	44k	INFO	====> Epoch: 4026, cost 22.09 s
2024-01-02 19:19:10,343	44k	INFO	====> Epoch: 4027, cost 22.01 s
2024-01-02 19:19:32,416	44k	INFO	====> Epoch: 4028, cost 22.07 s
2024-01-02 19:19:54,667	44k	INFO	====> Epoch: 4029, cost 22.25 s
2024-01-02 19:20:16,833	44k	INFO	====> Epoch: 4030, cost 22.17 s
2024-01-02 19:20:38,965	44k	INFO	====> Epoch: 4031, cost 22.13 s
2024-01-02 19:21:01,195	44k	INFO	Train Epoch: 4032 [96%]
2024-01-02 19:21:01,197	44k	INFO	Losses: [1.826129674911499, 2.9347238540649414, 8.405174255371094, 10.571494102478027, -3.2144742012023926], step: 100800, lr: 6.041658728581387e-05, reference_loss: 20.523048400878906
2024-01-02 19:21:07,117	44k	INFO	Saving model and optimizer state at iteration 4032 to ./logs/44k/G_100800.pth
2024-01-02 19:21:08,010	44k	INFO	Saving model and optimizer state at iteration 4032 to ./logs/44k/D_100800.pth
2024-01-02 19:21:08,508	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_98400.pth
2024-01-02 19:21:08,546	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_98400.pth
2024-01-02 19:21:08,547	44k	INFO	====> Epoch: 4032, cost 29.58 s
2024-01-02 19:21:30,529	44k	INFO	====> Epoch: 4033, cost 21.98 s
2024-01-02 19:21:52,582	44k	INFO	====> Epoch: 4034, cost 22.05 s
2024-01-02 19:22:14,778	44k	INFO	====> Epoch: 4035, cost 22.20 s
2024-01-02 19:22:37,058	44k	INFO	====> Epoch: 4036, cost 22.28 s
2024-01-02 19:22:59,319	44k	INFO	====> Epoch: 4037, cost 22.26 s
2024-01-02 19:23:21,608	44k	INFO	====> Epoch: 4038, cost 22.29 s
2024-01-02 19:23:44,097	44k	INFO	====> Epoch: 4039, cost 22.49 s
2024-01-02 19:24:06,320	44k	INFO	Train Epoch: 4040 [96%]
2024-01-02 19:24:06,321	44k	INFO	Losses: [1.6256150007247925, 3.2710137367248535, 11.24665641784668, 12.054302215576172, -3.0943260192871094], step: 101000, lr: 6.035619712417794e-05, reference_loss: 25.103261947631836
2024-01-02 19:24:06,712	44k	INFO	====> Epoch: 4040, cost 22.62 s
2024-01-02 19:24:28,801	44k	INFO	====> Epoch: 4041, cost 22.09 s
2024-01-02 19:24:50,795	44k	INFO	====> Epoch: 4042, cost 21.99 s
2024-01-02 19:25:12,887	44k	INFO	====> Epoch: 4043, cost 22.09 s
2024-01-02 19:25:35,059	44k	INFO	====> Epoch: 4044, cost 22.17 s
2024-01-02 19:25:57,166	44k	INFO	====> Epoch: 4045, cost 22.11 s
2024-01-02 19:26:19,447	44k	INFO	====> Epoch: 4046, cost 22.28 s
2024-01-02 19:26:41,699	44k	INFO	====> Epoch: 4047, cost 22.25 s
2024-01-02 19:27:03,844	44k	INFO	Train Epoch: 4048 [96%]
2024-01-02 19:27:03,846	44k	INFO	Losses: [1.9974225759506226, 3.0941271781921387, 8.889101028442383, 11.039999961853027, -3.0738766193389893], step: 101200, lr: 6.0295867326289556e-05, reference_loss: 21.946773529052734
2024-01-02 19:27:04,445	44k	INFO	====> Epoch: 4048, cost 22.75 s
2024-01-02 19:27:26,550	44k	INFO	====> Epoch: 4049, cost 22.10 s
2024-01-02 19:27:48,572	44k	INFO	====> Epoch: 4050, cost 22.02 s
2024-01-02 19:28:10,535	44k	INFO	====> Epoch: 4051, cost 21.96 s
2024-01-02 19:28:32,531	44k	INFO	====> Epoch: 4052, cost 22.00 s
2024-01-02 19:28:54,675	44k	INFO	====> Epoch: 4053, cost 22.14 s
2024-01-02 19:29:16,995	44k	INFO	====> Epoch: 4054, cost 22.32 s
2024-01-02 19:29:39,193	44k	INFO	====> Epoch: 4055, cost 22.20 s
2024-01-02 19:30:01,286	44k	INFO	Train Epoch: 4056 [96%]
2024-01-02 19:30:01,288	44k	INFO	Losses: [1.5069113969802856, 3.5342469215393066, 12.06967830657959, 12.005622863769531, -3.2022368907928467], step: 101400, lr: 6.023559783181137e-05, reference_loss: 25.914222717285156
2024-01-02 19:30:01,682	44k	INFO	====> Epoch: 4056, cost 22.49 s
2024-01-02 19:30:23,866	44k	INFO	====> Epoch: 4057, cost 22.18 s
2024-01-02 19:30:46,338	44k	INFO	====> Epoch: 4058, cost 22.47 s
2024-01-02 19:31:08,587	44k	INFO	====> Epoch: 4059, cost 22.25 s
2024-01-02 19:31:30,759	44k	INFO	====> Epoch: 4060, cost 22.17 s
2024-01-02 19:31:52,994	44k	INFO	====> Epoch: 4061, cost 22.23 s
2024-01-02 19:32:15,226	44k	INFO	====> Epoch: 4062, cost 22.23 s
2024-01-02 19:32:37,384	44k	INFO	====> Epoch: 4063, cost 22.16 s
2024-01-02 19:32:59,569	44k	INFO	Train Epoch: 4064 [96%]
2024-01-02 19:32:59,571	44k	INFO	Losses: [1.8920409679412842, 2.9854483604431152, 8.169292449951172, 10.779261589050293, -3.2029178142547607], step: 101600, lr: 6.0175388580466346e-05, reference_loss: 20.623125076293945
2024-01-02 19:33:05,223	44k	INFO	Saving model and optimizer state at iteration 4064 to ./logs/44k/G_101600.pth
2024-01-02 19:33:06,156	44k	INFO	Saving model and optimizer state at iteration 4064 to ./logs/44k/D_101600.pth
2024-01-02 19:33:06,656	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_99200.pth
2024-01-02 19:33:06,695	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_99200.pth
2024-01-02 19:33:06,695	44k	INFO	====> Epoch: 4064, cost 29.31 s
2024-01-02 19:33:28,710	44k	INFO	====> Epoch: 4065, cost 22.01 s
2024-01-02 19:33:50,808	44k	INFO	====> Epoch: 4066, cost 22.10 s
2024-01-02 19:34:12,767	44k	INFO	====> Epoch: 4067, cost 21.96 s
2024-01-02 19:34:34,715	44k	INFO	====> Epoch: 4068, cost 21.95 s
2024-01-02 19:34:56,724	44k	INFO	====> Epoch: 4069, cost 22.01 s
2024-01-02 19:35:18,754	44k	INFO	====> Epoch: 4070, cost 22.03 s
2024-01-02 19:35:40,756	44k	INFO	====> Epoch: 4071, cost 22.00 s
2024-01-02 19:36:02,867	44k	INFO	Train Epoch: 4072 [96%]
2024-01-02 19:36:02,868	44k	INFO	Losses: [1.6069313287734985, 3.5351061820983887, 11.313756942749023, 12.094348907470703, -3.128601551055908], step: 101800, lr: 6.0115239512037715e-05, reference_loss: 25.42154312133789
2024-01-02 19:36:03,278	44k	INFO	====> Epoch: 4072, cost 22.52 s
2024-01-02 19:36:25,488	44k	INFO	====> Epoch: 4073, cost 22.21 s
2024-01-02 19:36:47,691	44k	INFO	====> Epoch: 4074, cost 22.20 s
2024-01-02 19:37:09,900	44k	INFO	====> Epoch: 4075, cost 22.21 s
2024-01-02 19:37:32,210	44k	INFO	====> Epoch: 4076, cost 22.31 s
2024-01-02 19:37:54,512	44k	INFO	====> Epoch: 4077, cost 22.30 s
2024-01-02 19:38:16,861	44k	INFO	====> Epoch: 4078, cost 22.35 s
2024-01-02 19:38:38,877	44k	INFO	====> Epoch: 4079, cost 22.02 s
2024-01-02 19:39:00,960	44k	INFO	Train Epoch: 4080 [96%]
2024-01-02 19:39:00,963	44k	INFO	Losses: [1.8344714641571045, 3.147379159927368, 8.997167587280273, 11.424590110778809, -3.100724935531616], step: 102000, lr: 6.005515056636887e-05, reference_loss: 22.30288314819336
2024-01-02 19:39:01,353	44k	INFO	====> Epoch: 4080, cost 22.48 s
2024-01-02 19:39:23,490	44k	INFO	====> Epoch: 4081, cost 22.14 s
2024-01-02 19:39:45,616	44k	INFO	====> Epoch: 4082, cost 22.13 s
2024-01-02 19:40:07,675	44k	INFO	====> Epoch: 4083, cost 22.06 s
2024-01-02 19:40:29,775	44k	INFO	====> Epoch: 4084, cost 22.10 s
2024-01-02 19:40:51,965	44k	INFO	====> Epoch: 4085, cost 22.19 s
2024-01-02 19:41:14,354	44k	INFO	====> Epoch: 4086, cost 22.39 s
2024-01-02 19:41:36,637	44k	INFO	====> Epoch: 4087, cost 22.28 s
2024-01-02 19:41:58,972	44k	INFO	Train Epoch: 4088 [96%]
2024-01-02 19:41:58,974	44k	INFO	Losses: [1.5171135663986206, 3.5212295055389404, 11.249418258666992, 11.770503997802734, -3.3912484645843506], step: 102200, lr: 5.999512168336335e-05, reference_loss: 24.667016983032227
2024-01-02 19:41:59,373	44k	INFO	====> Epoch: 4088, cost 22.74 s
2024-01-02 19:42:21,679	44k	INFO	====> Epoch: 4089, cost 22.31 s
2024-01-02 19:42:43,856	44k	INFO	====> Epoch: 4090, cost 22.18 s
2024-01-02 19:43:05,934	44k	INFO	====> Epoch: 4091, cost 22.08 s
2024-01-02 19:43:28,031	44k	INFO	====> Epoch: 4092, cost 22.10 s
2024-01-02 19:43:50,140	44k	INFO	====> Epoch: 4093, cost 22.11 s
2024-01-02 19:44:12,475	44k	INFO	====> Epoch: 4094, cost 22.33 s
2024-01-02 19:44:34,807	44k	INFO	====> Epoch: 4095, cost 22.33 s
2024-01-02 19:44:57,128	44k	INFO	Train Epoch: 4096 [96%]
2024-01-02 19:44:57,130	44k	INFO	Losses: [1.8149356842041016, 2.8919034004211426, 8.331911087036133, 10.77220630645752, -3.2283642292022705], step: 102400, lr: 5.993515280298476e-05, reference_loss: 20.582590103149414
2024-01-02 19:45:03,395	44k	INFO	Saving model and optimizer state at iteration 4096 to ./logs/44k/G_102400.pth
2024-01-02 19:45:04,321	44k	INFO	Saving model and optimizer state at iteration 4096 to ./logs/44k/D_102400.pth
2024-01-02 19:45:04,836	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_100000.pth
2024-01-02 19:45:04,875	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_100000.pth
2024-01-02 19:45:04,875	44k	INFO	====> Epoch: 4096, cost 30.07 s
2024-01-02 19:45:26,954	44k	INFO	====> Epoch: 4097, cost 22.08 s
2024-01-02 19:45:49,146	44k	INFO	====> Epoch: 4098, cost 22.19 s
2024-01-02 19:46:11,370	44k	INFO	====> Epoch: 4099, cost 22.22 s
2024-01-02 19:46:33,564	44k	INFO	====> Epoch: 4100, cost 22.19 s
2024-01-02 19:46:55,645	44k	INFO	====> Epoch: 4101, cost 22.08 s
2024-01-02 19:47:17,745	44k	INFO	====> Epoch: 4102, cost 22.10 s
2024-01-02 19:47:39,773	44k	INFO	====> Epoch: 4103, cost 22.03 s
2024-01-02 19:48:01,932	44k	INFO	Train Epoch: 4104 [96%]
2024-01-02 19:48:01,934	44k	INFO	Losses: [1.7066781520843506, 3.1419315338134766, 9.416776657104492, 10.984392166137695, -3.1794769763946533], step: 102600, lr: 5.9875243865256715e-05, reference_loss: 22.070301055908203
2024-01-02 19:48:02,425	44k	INFO	====> Epoch: 4104, cost 22.65 s
2024-01-02 19:48:24,520	44k	INFO	====> Epoch: 4105, cost 22.09 s
2024-01-02 19:48:46,497	44k	INFO	====> Epoch: 4106, cost 21.98 s
2024-01-02 19:49:08,650	44k	INFO	====> Epoch: 4107, cost 22.15 s
2024-01-02 19:49:30,969	44k	INFO	====> Epoch: 4108, cost 22.32 s
2024-01-02 19:49:53,097	44k	INFO	====> Epoch: 4109, cost 22.13 s
2024-01-02 19:50:15,203	44k	INFO	====> Epoch: 4110, cost 22.11 s
2024-01-02 19:50:37,310	44k	INFO	====> Epoch: 4111, cost 22.11 s
2024-01-02 19:50:59,500	44k	INFO	Train Epoch: 4112 [96%]
2024-01-02 19:50:59,502	44k	INFO	Losses: [1.8334118127822876, 2.752840042114258, 7.231605052947998, 10.450264930725098, -3.093756914138794], step: 102800, lr: 5.981539481026279e-05, reference_loss: 19.17436408996582
2024-01-02 19:50:59,899	44k	INFO	====> Epoch: 4112, cost 22.59 s
2024-01-02 19:51:22,215	44k	INFO	====> Epoch: 4113, cost 22.32 s
2024-01-02 19:51:44,421	44k	INFO	====> Epoch: 4114, cost 22.21 s
2024-01-02 19:52:06,607	44k	INFO	====> Epoch: 4115, cost 22.19 s
2024-01-02 19:52:28,952	44k	INFO	====> Epoch: 4116, cost 22.35 s
2024-01-02 19:52:51,322	44k	INFO	====> Epoch: 4117, cost 22.37 s
2024-01-02 19:53:13,834	44k	INFO	====> Epoch: 4118, cost 22.51 s
2024-01-02 19:53:36,186	44k	INFO	====> Epoch: 4119, cost 22.35 s
2024-01-02 19:53:58,618	44k	INFO	Train Epoch: 4120 [96%]
2024-01-02 19:53:58,619	44k	INFO	Losses: [1.4783319234848022, 3.4842376708984375, 11.851839065551758, 11.930350303649902, -3.4216036796569824], step: 103000, lr: 5.975560557814646e-05, reference_loss: 25.32315444946289
2024-01-02 19:53:59,120	44k	INFO	====> Epoch: 4120, cost 22.93 s
2024-01-02 19:54:21,609	44k	INFO	====> Epoch: 4121, cost 22.49 s
2024-01-02 19:54:43,912	44k	INFO	====> Epoch: 4122, cost 22.30 s
2024-01-02 19:55:06,252	44k	INFO	====> Epoch: 4123, cost 22.34 s
2024-01-02 19:55:28,672	44k	INFO	====> Epoch: 4124, cost 22.42 s
2024-01-02 19:55:51,015	44k	INFO	====> Epoch: 4125, cost 22.34 s
2024-01-02 19:56:13,383	44k	INFO	====> Epoch: 4126, cost 22.37 s
2024-01-02 19:56:35,724	44k	INFO	====> Epoch: 4127, cost 22.34 s
2024-01-02 19:56:58,230	44k	INFO	Train Epoch: 4128 [96%]
2024-01-02 19:56:58,232	44k	INFO	Losses: [1.8188433647155762, 2.91265606880188, 8.426963806152344, 10.877037048339844, -3.2482481002807617], step: 103200, lr: 5.969587610911098e-05, reference_loss: 20.787250518798828
2024-01-02 19:57:04,274	44k	INFO	Saving model and optimizer state at iteration 4128 to ./logs/44k/G_103200.pth
2024-01-02 19:57:05,190	44k	INFO	Saving model and optimizer state at iteration 4128 to ./logs/44k/D_103200.pth
2024-01-02 19:57:05,709	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_100800.pth
2024-01-02 19:57:05,748	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_100800.pth
2024-01-02 19:57:05,749	44k	INFO	====> Epoch: 4128, cost 30.02 s
2024-01-02 19:57:28,081	44k	INFO	====> Epoch: 4129, cost 22.33 s
2024-01-02 19:57:50,385	44k	INFO	====> Epoch: 4130, cost 22.30 s
2024-01-02 19:58:12,638	44k	INFO	====> Epoch: 4131, cost 22.25 s
2024-01-02 19:58:34,790	44k	INFO	====> Epoch: 4132, cost 22.15 s
2024-01-02 19:58:57,034	44k	INFO	====> Epoch: 4133, cost 22.24 s
2024-01-02 19:59:19,297	44k	INFO	====> Epoch: 4134, cost 22.26 s
2024-01-02 19:59:41,764	44k	INFO	====> Epoch: 4135, cost 22.47 s
2024-01-02 20:00:04,076	44k	INFO	Train Epoch: 4136 [96%]
2024-01-02 20:00:04,077	44k	INFO	Losses: [1.5931199789047241, 3.388521671295166, 10.821638107299805, 12.156932830810547, -3.117861747741699], step: 103400, lr: 5.963620634341943e-05, reference_loss: 24.842350006103516
2024-01-02 20:00:04,475	44k	INFO	====> Epoch: 4136, cost 22.71 s
2024-01-02 20:00:26,853	44k	INFO	====> Epoch: 4137, cost 22.38 s
2024-01-02 20:00:49,181	44k	INFO	====> Epoch: 4138, cost 22.33 s
2024-01-02 20:01:11,440	44k	INFO	====> Epoch: 4139, cost 22.26 s
2024-01-02 20:01:33,607	44k	INFO	====> Epoch: 4140, cost 22.17 s
2024-01-02 20:01:55,762	44k	INFO	====> Epoch: 4141, cost 22.15 s
2024-01-02 20:02:17,986	44k	INFO	====> Epoch: 4142, cost 22.22 s
2024-01-02 20:02:40,099	44k	INFO	====> Epoch: 4143, cost 22.11 s
2024-01-02 20:03:02,220	44k	INFO	Train Epoch: 4144 [96%]
2024-01-02 20:03:02,222	44k	INFO	Losses: [2.0485739707946777, 2.996184825897217, 8.274613380432129, 11.114127159118652, -3.18233585357666], step: 103600, lr: 5.9576596221394575e-05, reference_loss: 21.251163482666016
2024-01-02 20:03:02,792	44k	INFO	====> Epoch: 4144, cost 22.69 s
2024-01-02 20:03:25,017	44k	INFO	====> Epoch: 4145, cost 22.23 s
2024-01-02 20:03:47,340	44k	INFO	====> Epoch: 4146, cost 22.32 s
2024-01-02 20:04:09,611	44k	INFO	====> Epoch: 4147, cost 22.27 s
2024-01-02 20:04:31,876	44k	INFO	====> Epoch: 4148, cost 22.27 s
2024-01-02 20:04:54,234	44k	INFO	====> Epoch: 4149, cost 22.36 s
2024-01-02 20:05:16,483	44k	INFO	====> Epoch: 4150, cost 22.25 s
2024-01-02 20:05:38,658	44k	INFO	====> Epoch: 4151, cost 22.17 s
2024-01-02 20:06:00,845	44k	INFO	Train Epoch: 4152 [96%]
2024-01-02 20:06:00,847	44k	INFO	Losses: [1.421568751335144, 3.522336959838867, 12.92384147644043, 12.11144733428955, -3.3940634727478027], step: 103800, lr: 5.951704568341883e-05, reference_loss: 26.58513069152832
2024-01-02 20:06:01,233	44k	INFO	====> Epoch: 4152, cost 22.58 s
2024-01-02 20:06:23,676	44k	INFO	====> Epoch: 4153, cost 22.44 s
2024-01-02 20:06:46,284	44k	INFO	====> Epoch: 4154, cost 22.61 s
2024-01-02 20:07:08,665	44k	INFO	====> Epoch: 4155, cost 22.38 s
2024-01-02 20:07:30,985	44k	INFO	====> Epoch: 4156, cost 22.32 s
2024-01-02 20:07:53,310	44k	INFO	====> Epoch: 4157, cost 22.32 s
2024-01-02 20:08:15,636	44k	INFO	====> Epoch: 4158, cost 22.33 s
2024-01-02 20:08:38,009	44k	INFO	====> Epoch: 4159, cost 22.37 s
2024-01-02 20:09:00,353	44k	INFO	Train Epoch: 4160 [96%]
2024-01-02 20:09:00,355	44k	INFO	Losses: [1.790724515914917, 3.0626158714294434, 8.177331924438477, 10.70677375793457, -3.3647139072418213], step: 104000, lr: 5.945755466993421e-05, reference_loss: 20.372732162475586
2024-01-02 20:09:06,689	44k	INFO	Saving model and optimizer state at iteration 4160 to ./logs/44k/G_104000.pth
2024-01-02 20:09:07,625	44k	INFO	Saving model and optimizer state at iteration 4160 to ./logs/44k/D_104000.pth
2024-01-02 20:09:08,159	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_101600.pth
2024-01-02 20:09:08,198	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_101600.pth
2024-01-02 20:09:08,198	44k	INFO	====> Epoch: 4160, cost 30.19 s
2024-01-02 20:09:30,545	44k	INFO	====> Epoch: 4161, cost 22.35 s
2024-01-02 20:09:53,170	44k	INFO	====> Epoch: 4162, cost 22.62 s
2024-01-02 20:10:15,732	44k	INFO	====> Epoch: 4163, cost 22.56 s
2024-01-02 20:10:38,193	44k	INFO	====> Epoch: 4164, cost 22.46 s
2024-01-02 20:11:00,598	44k	INFO	====> Epoch: 4165, cost 22.40 s
2024-01-02 20:11:22,971	44k	INFO	====> Epoch: 4166, cost 22.37 s
2024-01-02 20:11:45,293	44k	INFO	====> Epoch: 4167, cost 22.32 s
2024-01-02 20:12:07,673	44k	INFO	Train Epoch: 4168 [96%]
2024-01-02 20:12:07,675	44k	INFO	Losses: [1.5762994289398193, 3.686882972717285, 10.771483421325684, 11.531197547912598, -3.2617175579071045], step: 104200, lr: 5.939812312144228e-05, reference_loss: 24.304147720336914
2024-01-02 20:12:08,067	44k	INFO	====> Epoch: 4168, cost 22.77 s
2024-01-02 20:12:30,451	44k	INFO	====> Epoch: 4169, cost 22.38 s
2024-01-02 20:12:52,810	44k	INFO	====> Epoch: 4170, cost 22.36 s
2024-01-02 20:13:15,117	44k	INFO	====> Epoch: 4171, cost 22.31 s
2024-01-02 20:13:37,470	44k	INFO	====> Epoch: 4172, cost 22.35 s
2024-01-02 20:13:59,873	44k	INFO	====> Epoch: 4173, cost 22.40 s
2024-01-02 20:14:22,338	44k	INFO	====> Epoch: 4174, cost 22.46 s
2024-01-02 20:14:44,647	44k	INFO	====> Epoch: 4175, cost 22.31 s
2024-01-02 20:15:06,979	44k	INFO	Train Epoch: 4176 [96%]
2024-01-02 20:15:06,981	44k	INFO	Losses: [1.881398320198059, 2.8259453773498535, 7.281152725219727, 10.271190643310547, -3.2634217739105225], step: 104400, lr: 5.9338750978504026e-05, reference_loss: 18.996265411376953
2024-01-02 20:15:07,384	44k	INFO	====> Epoch: 4176, cost 22.74 s
2024-01-02 20:15:29,676	44k	INFO	====> Epoch: 4177, cost 22.29 s
2024-01-02 20:15:51,870	44k	INFO	====> Epoch: 4178, cost 22.19 s
2024-01-02 20:16:14,091	44k	INFO	====> Epoch: 4179, cost 22.22 s
2024-01-02 20:16:36,387	44k	INFO	====> Epoch: 4180, cost 22.30 s
2024-01-02 20:16:58,681	44k	INFO	====> Epoch: 4181, cost 22.29 s
2024-01-02 20:17:20,875	44k	INFO	====> Epoch: 4182, cost 22.19 s
2024-01-02 20:17:43,093	44k	INFO	====> Epoch: 4183, cost 22.22 s
2024-01-02 20:18:05,480	44k	INFO	Train Epoch: 4184 [96%]
2024-01-02 20:18:05,482	44k	INFO	Losses: [1.5298559665679932, 3.4260902404785156, 10.271821022033691, 11.38757610321045, -3.526400566101074], step: 104600, lr: 5.9279438181739895e-05, reference_loss: 23.088943481445312
2024-01-02 20:18:05,861	44k	INFO	====> Epoch: 4184, cost 22.77 s
2024-01-02 20:18:28,177	44k	INFO	====> Epoch: 4185, cost 22.32 s
2024-01-02 20:18:50,566	44k	INFO	====> Epoch: 4186, cost 22.39 s
2024-01-02 20:19:13,002	44k	INFO	====> Epoch: 4187, cost 22.44 s
2024-01-02 20:19:35,255	44k	INFO	====> Epoch: 4188, cost 22.25 s
2024-01-02 20:19:57,582	44k	INFO	====> Epoch: 4189, cost 22.33 s
2024-01-02 20:20:19,929	44k	INFO	====> Epoch: 4190, cost 22.35 s
2024-01-02 20:20:42,264	44k	INFO	====> Epoch: 4191, cost 22.33 s
2024-01-02 20:21:04,649	44k	INFO	Train Epoch: 4192 [96%]
2024-01-02 20:21:04,650	44k	INFO	Losses: [1.917885422706604, 3.3663744926452637, 8.90129566192627, 11.045104026794434, -3.399627923965454], step: 104800, lr: 5.9220184671829666e-05, reference_loss: 21.831031799316406
2024-01-02 20:21:10,988	44k	INFO	Saving model and optimizer state at iteration 4192 to ./logs/44k/G_104800.pth
2024-01-02 20:21:11,901	44k	INFO	Saving model and optimizer state at iteration 4192 to ./logs/44k/D_104800.pth
2024-01-02 20:21:12,421	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_102400.pth
2024-01-02 20:21:12,460	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_102400.pth
2024-01-02 20:21:12,460	44k	INFO	====> Epoch: 4192, cost 30.20 s
2024-01-02 20:21:34,729	44k	INFO	====> Epoch: 4193, cost 22.27 s
2024-01-02 20:21:57,199	44k	INFO	====> Epoch: 4194, cost 22.47 s
2024-01-02 20:22:19,712	44k	INFO	====> Epoch: 4195, cost 22.51 s
2024-01-02 20:22:41,992	44k	INFO	====> Epoch: 4196, cost 22.28 s
2024-01-02 20:23:04,237	44k	INFO	====> Epoch: 4197, cost 22.24 s
2024-01-02 20:23:26,493	44k	INFO	====> Epoch: 4198, cost 22.26 s
2024-01-02 20:23:48,793	44k	INFO	====> Epoch: 4199, cost 22.30 s
2024-01-02 20:24:11,119	44k	INFO	Train Epoch: 4200 [96%]
2024-01-02 20:24:11,120	44k	INFO	Losses: [1.6885409355163574, 3.3132314682006836, 10.546398162841797, 12.096588134765625, -3.3007335662841797], step: 105000, lr: 5.916099038951241e-05, reference_loss: 24.344024658203125
2024-01-02 20:24:11,530	44k	INFO	====> Epoch: 4200, cost 22.74 s
2024-01-02 20:24:33,761	44k	INFO	====> Epoch: 4201, cost 22.23 s
2024-01-02 20:24:55,982	44k	INFO	====> Epoch: 4202, cost 22.22 s
2024-01-02 20:25:18,244	44k	INFO	====> Epoch: 4203, cost 22.26 s
2024-01-02 20:25:40,587	44k	INFO	====> Epoch: 4204, cost 22.34 s
2024-01-02 20:26:02,905	44k	INFO	====> Epoch: 4205, cost 22.32 s
2024-01-02 20:26:25,094	44k	INFO	====> Epoch: 4206, cost 22.19 s
2024-01-02 20:26:47,490	44k	INFO	====> Epoch: 4207, cost 22.40 s
2024-01-02 20:27:09,918	44k	INFO	Train Epoch: 4208 [96%]
2024-01-02 20:27:09,919	44k	INFO	Losses: [1.9586695432662964, 2.994297504425049, 7.627681255340576, 10.922741889953613, -3.2854394912719727], step: 105200, lr: 5.9101855275586446e-05, reference_loss: 20.217952728271484
2024-01-02 20:27:10,319	44k	INFO	====> Epoch: 4208, cost 22.83 s
2024-01-02 20:27:32,557	44k	INFO	====> Epoch: 4209, cost 22.24 s
2024-01-02 20:27:54,797	44k	INFO	====> Epoch: 4210, cost 22.24 s
2024-01-02 20:28:17,224	44k	INFO	====> Epoch: 4211, cost 22.43 s
2024-01-02 20:28:39,518	44k	INFO	====> Epoch: 4212, cost 22.29 s
2024-01-02 20:29:01,722	44k	INFO	====> Epoch: 4213, cost 22.20 s
2024-01-02 20:29:23,992	44k	INFO	====> Epoch: 4214, cost 22.27 s
2024-01-02 20:29:46,133	44k	INFO	====> Epoch: 4215, cost 22.14 s
2024-01-02 20:30:08,304	44k	INFO	Train Epoch: 4216 [96%]
2024-01-02 20:30:08,307	44k	INFO	Losses: [1.4222428798675537, 3.5299930572509766, 11.314043998718262, 11.46746826171875, -3.411795139312744], step: 105400, lr: 5.9042779270909264e-05, reference_loss: 24.32195472717285
2024-01-02 20:30:08,678	44k	INFO	====> Epoch: 4216, cost 22.54 s
2024-01-02 20:30:30,979	44k	INFO	====> Epoch: 4217, cost 22.30 s
2024-01-02 20:30:53,298	44k	INFO	====> Epoch: 4218, cost 22.32 s
2024-01-02 20:31:15,565	44k	INFO	====> Epoch: 4219, cost 22.27 s
2024-01-02 20:31:37,732	44k	INFO	====> Epoch: 4220, cost 22.17 s
2024-01-02 20:32:00,052	44k	INFO	====> Epoch: 4221, cost 22.32 s
2024-01-02 20:32:22,400	44k	INFO	====> Epoch: 4222, cost 22.35 s
2024-01-02 20:32:44,757	44k	INFO	====> Epoch: 4223, cost 22.36 s
2024-01-02 20:33:07,145	44k	INFO	Train Epoch: 4224 [96%]
2024-01-02 20:33:07,147	44k	INFO	Losses: [1.789744257926941, 3.077977180480957, 9.76667308807373, 11.564577102661133, -3.418119430541992], step: 105600, lr: 5.898376231639747e-05, reference_loss: 22.780851364135742
2024-01-02 20:33:12,910	44k	INFO	Saving model and optimizer state at iteration 4224 to ./logs/44k/G_105600.pth
2024-01-02 20:33:13,830	44k	INFO	Saving model and optimizer state at iteration 4224 to ./logs/44k/D_105600.pth
2024-01-02 20:33:14,318	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_103200.pth
2024-01-02 20:33:14,357	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_103200.pth
2024-01-02 20:33:14,357	44k	INFO	====> Epoch: 4224, cost 29.60 s
2024-01-02 20:33:36,615	44k	INFO	====> Epoch: 4225, cost 22.26 s
2024-01-02 20:33:58,760	44k	INFO	====> Epoch: 4226, cost 22.15 s
2024-01-02 20:34:21,028	44k	INFO	====> Epoch: 4227, cost 22.27 s
2024-01-02 20:34:43,369	44k	INFO	====> Epoch: 4228, cost 22.34 s
2024-01-02 20:35:05,701	44k	INFO	====> Epoch: 4229, cost 22.33 s
2024-01-02 20:35:27,887	44k	INFO	====> Epoch: 4230, cost 22.19 s
2024-01-02 20:35:50,275	44k	INFO	====> Epoch: 4231, cost 22.39 s
2024-01-02 20:36:12,476	44k	INFO	Train Epoch: 4232 [96%]
2024-01-02 20:36:12,478	44k	INFO	Losses: [1.7558560371398926, 3.2321996688842773, 10.541439056396484, 12.011893272399902, -3.2740824222564697], step: 105800, lr: 5.892480435302674e-05, reference_loss: 24.26730728149414
2024-01-02 20:36:12,864	44k	INFO	====> Epoch: 4232, cost 22.59 s
2024-01-02 20:36:35,071	44k	INFO	====> Epoch: 4233, cost 22.21 s
2024-01-02 20:36:57,338	44k	INFO	====> Epoch: 4234, cost 22.27 s
2024-01-02 20:37:19,649	44k	INFO	====> Epoch: 4235, cost 22.31 s
2024-01-02 20:37:41,979	44k	INFO	====> Epoch: 4236, cost 22.33 s
2024-01-02 20:38:04,299	44k	INFO	====> Epoch: 4237, cost 22.32 s
2024-01-02 20:38:26,474	44k	INFO	====> Epoch: 4238, cost 22.18 s
2024-01-02 20:38:48,593	44k	INFO	====> Epoch: 4239, cost 22.12 s
2024-01-02 20:39:10,778	44k	INFO	Train Epoch: 4240 [96%]
2024-01-02 20:39:10,779	44k	INFO	Losses: [1.821568250656128, 3.1844329833984375, 8.698570251464844, 11.262808799743652, -3.32128643989563], step: 106000, lr: 5.88659053218317e-05, reference_loss: 21.646093368530273
2024-01-02 20:39:11,404	44k	INFO	====> Epoch: 4240, cost 22.81 s
2024-01-02 20:39:33,609	44k	INFO	====> Epoch: 4241, cost 22.20 s
2024-01-02 20:39:55,869	44k	INFO	====> Epoch: 4242, cost 22.26 s
2024-01-02 20:40:18,088	44k	INFO	====> Epoch: 4243, cost 22.22 s
2024-01-02 20:40:40,313	44k	INFO	====> Epoch: 4244, cost 22.23 s
2024-01-02 20:41:02,479	44k	INFO	====> Epoch: 4245, cost 22.17 s
2024-01-02 20:41:24,647	44k	INFO	====> Epoch: 4246, cost 22.17 s
2024-01-02 20:41:46,796	44k	INFO	====> Epoch: 4247, cost 22.15 s
2024-01-02 20:42:09,051	44k	INFO	Train Epoch: 4248 [96%]
2024-01-02 20:42:09,053	44k	INFO	Losses: [1.4364116191864014, 3.4020118713378906, 10.848971366882324, 11.410334587097168, -3.5348007678985596], step: 106200, lr: 5.880706516390598e-05, reference_loss: 23.56292724609375
2024-01-02 20:42:09,445	44k	INFO	====> Epoch: 4248, cost 22.65 s
2024-01-02 20:42:31,707	44k	INFO	====> Epoch: 4249, cost 22.26 s
2024-01-02 20:42:54,026	44k	INFO	====> Epoch: 4250, cost 22.32 s
2024-01-02 20:43:16,265	44k	INFO	====> Epoch: 4251, cost 22.24 s
2024-01-02 20:43:38,527	44k	INFO	====> Epoch: 4252, cost 22.26 s
2024-01-02 20:44:00,769	44k	INFO	====> Epoch: 4253, cost 22.24 s
2024-01-02 20:44:23,005	44k	INFO	====> Epoch: 4254, cost 22.24 s
2024-01-02 20:44:45,074	44k	INFO	====> Epoch: 4255, cost 22.07 s
2024-01-02 20:45:07,123	44k	INFO	Train Epoch: 4256 [96%]
2024-01-02 20:45:07,124	44k	INFO	Losses: [1.8090581893920898, 3.150378704071045, 9.34365463256836, 10.9296236038208, -3.4453248977661133], step: 106400, lr: 5.8748283820402036e-05, reference_loss: 21.787391662597656
2024-01-02 20:45:13,189	44k	INFO	Saving model and optimizer state at iteration 4256 to ./logs/44k/G_106400.pth
2024-01-02 20:45:14,099	44k	INFO	Saving model and optimizer state at iteration 4256 to ./logs/44k/D_106400.pth
2024-01-02 20:45:14,608	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_104000.pth
2024-01-02 20:45:14,647	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_104000.pth
2024-01-02 20:45:14,648	44k	INFO	====> Epoch: 4256, cost 29.57 s
2024-01-02 20:45:36,633	44k	INFO	====> Epoch: 4257, cost 21.99 s
2024-01-02 20:45:58,758	44k	INFO	====> Epoch: 4258, cost 22.12 s
2024-01-02 20:46:20,876	44k	INFO	====> Epoch: 4259, cost 22.12 s
2024-01-02 20:46:42,960	44k	INFO	====> Epoch: 4260, cost 22.08 s
2024-01-02 20:47:05,056	44k	INFO	====> Epoch: 4261, cost 22.10 s
2024-01-02 20:47:27,145	44k	INFO	====> Epoch: 4262, cost 22.09 s
2024-01-02 20:47:49,329	44k	INFO	====> Epoch: 4263, cost 22.18 s
2024-01-02 20:48:11,673	44k	INFO	Train Epoch: 4264 [96%]
2024-01-02 20:48:11,675	44k	INFO	Losses: [1.6082451343536377, 3.2125587463378906, 11.039608001708984, 11.870948791503906, -3.358896017074585], step: 106600, lr: 5.86895612325312e-05, reference_loss: 24.372465133666992
2024-01-02 20:48:12,080	44k	INFO	====> Epoch: 4264, cost 22.75 s
2024-01-02 20:48:34,457	44k	INFO	====> Epoch: 4265, cost 22.38 s
2024-01-02 20:48:56,752	44k	INFO	====> Epoch: 4266, cost 22.30 s
2024-01-02 20:49:18,788	44k	INFO	====> Epoch: 4267, cost 22.04 s
2024-01-02 20:49:40,954	44k	INFO	====> Epoch: 4268, cost 22.17 s
2024-01-02 20:50:03,015	44k	INFO	====> Epoch: 4269, cost 22.06 s
2024-01-02 20:50:25,258	44k	INFO	====> Epoch: 4270, cost 22.24 s
2024-01-02 20:50:47,297	44k	INFO	====> Epoch: 4271, cost 22.04 s
2024-01-02 20:51:09,361	44k	INFO	Train Epoch: 4272 [96%]
2024-01-02 20:51:09,362	44k	INFO	Losses: [1.8085684776306152, 2.987823963165283, 7.599260330200195, 10.353741645812988, -3.299459218978882], step: 106800, lr: 5.863089734156352e-05, reference_loss: 19.449934005737305
2024-01-02 20:51:09,766	44k	INFO	====> Epoch: 4272, cost 22.47 s
2024-01-02 20:51:31,857	44k	INFO	====> Epoch: 4273, cost 22.09 s
2024-01-02 20:51:54,112	44k	INFO	====> Epoch: 4274, cost 22.25 s
2024-01-02 20:52:16,437	44k	INFO	====> Epoch: 4275, cost 22.32 s
2024-01-02 20:52:38,874	44k	INFO	====> Epoch: 4276, cost 22.44 s
2024-01-02 20:53:01,218	44k	INFO	====> Epoch: 4277, cost 22.34 s
2024-01-02 20:53:23,481	44k	INFO	====> Epoch: 4278, cost 22.26 s
2024-01-02 20:53:45,771	44k	INFO	====> Epoch: 4279, cost 22.29 s
2024-01-02 20:54:08,198	44k	INFO	Train Epoch: 4280 [96%]
2024-01-02 20:54:08,200	44k	INFO	Losses: [1.4402480125427246, 3.6173112392425537, 10.783374786376953, 11.22696304321289, -3.6085782051086426], step: 107000, lr: 5.857229208882778e-05, reference_loss: 23.459320068359375
2024-01-02 20:54:08,587	44k	INFO	====> Epoch: 4280, cost 22.82 s
2024-01-02 20:54:30,866	44k	INFO	====> Epoch: 4281, cost 22.28 s
2024-01-02 20:54:53,080	44k	INFO	====> Epoch: 4282, cost 22.21 s
2024-01-02 20:55:15,046	44k	INFO	====> Epoch: 4283, cost 21.97 s
2024-01-02 20:55:37,023	44k	INFO	====> Epoch: 4284, cost 21.98 s
2024-01-02 20:55:59,083	44k	INFO	====> Epoch: 4285, cost 22.06 s
2024-01-02 20:56:21,093	44k	INFO	====> Epoch: 4286, cost 22.01 s
2024-01-02 20:56:43,193	44k	INFO	====> Epoch: 4287, cost 22.10 s
2024-01-02 20:57:05,210	44k	INFO	Train Epoch: 4288 [96%]
2024-01-02 20:57:05,213	44k	INFO	Losses: [1.7962579727172852, 3.1406900882720947, 8.574409484863281, 10.53760814666748, -3.5172691345214844], step: 107200, lr: 5.8513745415711375e-05, reference_loss: 20.531696319580078
2024-01-02 20:57:10,999	44k	INFO	Saving model and optimizer state at iteration 4288 to ./logs/44k/G_107200.pth
2024-01-02 20:57:11,912	44k	INFO	Saving model and optimizer state at iteration 4288 to ./logs/44k/D_107200.pth
2024-01-02 20:57:12,404	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_104800.pth
2024-01-02 20:57:12,442	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_104800.pth
2024-01-02 20:57:12,443	44k	INFO	====> Epoch: 4288, cost 29.25 s
2024-01-02 20:57:34,595	44k	INFO	====> Epoch: 4289, cost 22.15 s
2024-01-02 20:57:56,672	44k	INFO	====> Epoch: 4290, cost 22.08 s
2024-01-02 20:58:18,869	44k	INFO	====> Epoch: 4291, cost 22.20 s
2024-01-02 20:58:40,991	44k	INFO	====> Epoch: 4292, cost 22.12 s
2024-01-02 20:59:03,176	44k	INFO	====> Epoch: 4293, cost 22.18 s
2024-01-02 20:59:25,367	44k	INFO	====> Epoch: 4294, cost 22.19 s
2024-01-02 20:59:47,564	44k	INFO	====> Epoch: 4295, cost 22.20 s
2024-01-02 21:00:09,736	44k	INFO	Train Epoch: 4296 [96%]
2024-01-02 21:00:09,738	44k	INFO	Losses: [1.4808688163757324, 3.350518226623535, 11.409955978393555, 11.906997680664062, -3.447446584701538], step: 107400, lr: 5.845525726366033e-05, reference_loss: 24.70089340209961
2024-01-02 21:00:10,135	44k	INFO	====> Epoch: 4296, cost 22.57 s
2024-01-02 21:00:32,402	44k	INFO	====> Epoch: 4297, cost 22.27 s
2024-01-02 21:00:54,646	44k	INFO	====> Epoch: 4298, cost 22.24 s
2024-01-02 21:01:16,810	44k	INFO	====> Epoch: 4299, cost 22.16 s
2024-01-02 21:01:39,206	44k	INFO	====> Epoch: 4300, cost 22.40 s
2024-01-02 21:02:01,485	44k	INFO	====> Epoch: 4301, cost 22.28 s
2024-01-02 21:02:23,696	44k	INFO	====> Epoch: 4302, cost 22.21 s
2024-01-02 21:02:45,833	44k	INFO	====> Epoch: 4303, cost 22.14 s
2024-01-02 21:03:08,082	44k	INFO	Train Epoch: 4304 [96%]
2024-01-02 21:03:08,084	44k	INFO	Losses: [1.8831148147583008, 2.84648060798645, 7.522356033325195, 9.055992126464844, -3.4306721687316895], step: 107600, lr: 5.839682757417915e-05, reference_loss: 17.87727165222168
2024-01-02 21:03:08,489	44k	INFO	====> Epoch: 4304, cost 22.66 s
2024-01-02 21:03:30,723	44k	INFO	====> Epoch: 4305, cost 22.23 s
2024-01-02 21:03:52,929	44k	INFO	====> Epoch: 4306, cost 22.21 s
2024-01-02 21:04:15,245	44k	INFO	====> Epoch: 4307, cost 22.32 s
2024-01-02 21:04:37,454	44k	INFO	====> Epoch: 4308, cost 22.21 s
2024-01-02 21:04:59,678	44k	INFO	====> Epoch: 4309, cost 22.22 s
2024-01-02 21:05:22,079	44k	INFO	====> Epoch: 4310, cost 22.40 s
2024-01-02 21:05:44,255	44k	INFO	====> Epoch: 4311, cost 22.18 s
2024-01-02 21:06:06,388	44k	INFO	Train Epoch: 4312 [96%]
2024-01-02 21:06:06,390	44k	INFO	Losses: [1.5139251947402954, 3.6646525859832764, 10.59131145477295, 11.025618553161621, -3.692077398300171], step: 107800, lr: 5.8338456288830866e-05, reference_loss: 23.103431701660156
2024-01-02 21:06:06,771	44k	INFO	====> Epoch: 4312, cost 22.52 s
2024-01-02 21:06:28,933	44k	INFO	====> Epoch: 4313, cost 22.16 s
2024-01-02 21:06:51,317	44k	INFO	====> Epoch: 4314, cost 22.38 s
2024-01-02 21:07:13,605	44k	INFO	====> Epoch: 4315, cost 22.29 s
2024-01-02 21:07:35,858	44k	INFO	====> Epoch: 4316, cost 22.25 s
2024-01-02 21:07:58,198	44k	INFO	====> Epoch: 4317, cost 22.34 s
2024-01-02 21:08:20,449	44k	INFO	====> Epoch: 4318, cost 22.25 s
2024-01-02 21:08:42,642	44k	INFO	====> Epoch: 4319, cost 22.19 s
2024-01-02 21:09:04,948	44k	INFO	Train Epoch: 4320 [96%]
2024-01-02 21:09:04,950	44k	INFO	Losses: [1.8157663345336914, 2.9154202938079834, 8.469413757324219, 10.795717239379883, -3.5462799072265625], step: 108000, lr: 5.828014334923687e-05, reference_loss: 20.45003890991211
2024-01-02 21:09:10,562	44k	INFO	Saving model and optimizer state at iteration 4320 to ./logs/44k/G_108000.pth
2024-01-02 21:09:11,485	44k	INFO	Saving model and optimizer state at iteration 4320 to ./logs/44k/D_108000.pth
2024-01-02 21:09:11,970	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_105600.pth
2024-01-02 21:09:12,008	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_105600.pth
2024-01-02 21:09:12,008	44k	INFO	====> Epoch: 4320, cost 29.37 s
2024-01-02 21:09:33,982	44k	INFO	====> Epoch: 4321, cost 21.97 s
2024-01-02 21:09:56,025	44k	INFO	====> Epoch: 4322, cost 22.04 s
2024-01-02 21:10:18,058	44k	INFO	====> Epoch: 4323, cost 22.03 s
2024-01-02 21:10:40,156	44k	INFO	====> Epoch: 4324, cost 22.10 s
2024-01-02 21:11:02,307	44k	INFO	====> Epoch: 4325, cost 22.15 s
2024-01-02 21:11:24,491	44k	INFO	====> Epoch: 4326, cost 22.18 s
2024-01-02 21:11:46,934	44k	INFO	====> Epoch: 4327, cost 22.44 s
2024-01-02 21:12:09,244	44k	INFO	Train Epoch: 4328 [96%]
2024-01-02 21:12:09,246	44k	INFO	Losses: [1.6324734687805176, 3.1916487216949463, 10.594545364379883, 11.76284122467041, -3.471388816833496], step: 108200, lr: 5.8221888697076924e-05, reference_loss: 23.710121154785156
2024-01-02 21:12:09,650	44k	INFO	====> Epoch: 4328, cost 22.72 s
2024-01-02 21:12:31,926	44k	INFO	====> Epoch: 4329, cost 22.28 s
2024-01-02 21:12:54,155	44k	INFO	====> Epoch: 4330, cost 22.23 s
2024-01-02 21:13:16,403	44k	INFO	====> Epoch: 4331, cost 22.25 s
2024-01-02 21:13:38,650	44k	INFO	====> Epoch: 4332, cost 22.25 s
2024-01-02 21:14:00,913	44k	INFO	====> Epoch: 4333, cost 22.26 s
2024-01-02 21:14:23,195	44k	INFO	====> Epoch: 4334, cost 22.28 s
2024-01-02 21:14:45,377	44k	INFO	====> Epoch: 4335, cost 22.18 s
2024-01-02 21:15:07,508	44k	INFO	Train Epoch: 4336 [96%]
2024-01-02 21:15:07,510	44k	INFO	Losses: [1.8362996578216553, 2.9747273921966553, 7.480846405029297, 10.088244438171387, -3.372751235961914], step: 108400, lr: 5.816369227408911e-05, reference_loss: 19.007368087768555
2024-01-02 21:15:08,181	44k	INFO	====> Epoch: 4336, cost 22.80 s
2024-01-02 21:15:30,392	44k	INFO	====> Epoch: 4337, cost 22.21 s
2024-01-02 21:15:52,492	44k	INFO	====> Epoch: 4338, cost 22.10 s
2024-01-02 21:16:14,665	44k	INFO	====> Epoch: 4339, cost 22.17 s
2024-01-02 21:16:36,914	44k	INFO	====> Epoch: 4340, cost 22.25 s
2024-01-02 21:16:59,134	44k	INFO	====> Epoch: 4341, cost 22.22 s
2024-01-02 21:17:21,344	44k	INFO	====> Epoch: 4342, cost 22.21 s
2024-01-02 21:17:43,565	44k	INFO	====> Epoch: 4343, cost 22.22 s
2024-01-02 21:18:05,796	44k	INFO	Train Epoch: 4344 [96%]
2024-01-02 21:18:05,798	44k	INFO	Losses: [1.5635864734649658, 3.452258348464966, 10.512223243713379, 11.109715461730957, -3.7382965087890625], step: 108600, lr: 5.8105554022069724e-05, reference_loss: 22.899486541748047
2024-01-02 21:18:06,188	44k	INFO	====> Epoch: 4344, cost 22.62 s
2024-01-02 21:18:28,307	44k	INFO	====> Epoch: 4345, cost 22.12 s
2024-01-02 21:18:50,772	44k	INFO	====> Epoch: 4346, cost 22.46 s
2024-01-02 21:19:12,964	44k	INFO	====> Epoch: 4347, cost 22.19 s
2024-01-02 21:19:35,187	44k	INFO	====> Epoch: 4348, cost 22.22 s
2024-01-02 21:19:57,346	44k	INFO	====> Epoch: 4349, cost 22.16 s
2024-01-02 21:20:19,402	44k	INFO	====> Epoch: 4350, cost 22.06 s
2024-01-02 21:20:41,429	44k	INFO	====> Epoch: 4351, cost 22.03 s
2024-01-02 21:21:03,498	44k	INFO	Train Epoch: 4352 [96%]
2024-01-02 21:21:03,500	44k	INFO	Losses: [1.8384462594985962, 2.9429211616516113, 8.387378692626953, 10.702825546264648, -3.542593240737915], step: 108800, lr: 5.804747388287322e-05, reference_loss: 20.328977584838867
2024-01-02 21:21:09,426	44k	INFO	Saving model and optimizer state at iteration 4352 to ./logs/44k/G_108800.pth
2024-01-02 21:21:10,326	44k	INFO	Saving model and optimizer state at iteration 4352 to ./logs/44k/D_108800.pth
2024-01-02 21:21:10,820	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_106400.pth
2024-01-02 21:21:10,859	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_106400.pth
2024-01-02 21:21:10,860	44k	INFO	====> Epoch: 4352, cost 29.43 s
2024-01-02 21:21:32,948	44k	INFO	====> Epoch: 4353, cost 22.09 s
2024-01-02 21:21:55,141	44k	INFO	====> Epoch: 4354, cost 22.19 s
2024-01-02 21:22:17,072	44k	INFO	====> Epoch: 4355, cost 21.93 s
2024-01-02 21:22:39,022	44k	INFO	====> Epoch: 4356, cost 21.95 s
2024-01-02 21:23:01,076	44k	INFO	====> Epoch: 4357, cost 22.05 s
2024-01-02 21:23:23,179	44k	INFO	====> Epoch: 4358, cost 22.10 s
2024-01-02 21:23:45,371	44k	INFO	====> Epoch: 4359, cost 22.19 s
2024-01-02 21:24:07,556	44k	INFO	Train Epoch: 4360 [96%]
2024-01-02 21:24:07,558	44k	INFO	Losses: [1.5750081539154053, 3.2099828720092773, 9.63256549835205, 10.743549346923828, -3.5093417167663574], step: 109000, lr: 5.7989451798412196e-05, reference_loss: 21.651763916015625
2024-01-02 21:24:08,026	44k	INFO	====> Epoch: 4360, cost 22.66 s
2024-01-02 21:24:30,124	44k	INFO	====> Epoch: 4361, cost 22.10 s
2024-01-02 21:24:52,140	44k	INFO	====> Epoch: 4362, cost 22.02 s
2024-01-02 21:25:14,284	44k	INFO	====> Epoch: 4363, cost 22.14 s
2024-01-02 21:25:36,457	44k	INFO	====> Epoch: 4364, cost 22.17 s
2024-01-02 21:25:58,557	44k	INFO	====> Epoch: 4365, cost 22.10 s
2024-01-02 21:26:20,857	44k	INFO	====> Epoch: 4366, cost 22.30 s
2024-01-02 21:26:43,001	44k	INFO	====> Epoch: 4367, cost 22.14 s
2024-01-02 21:27:05,173	44k	INFO	Train Epoch: 4368 [96%]
2024-01-02 21:27:05,174	44k	INFO	Losses: [1.893579125404358, 3.006404161453247, 7.16476583480835, 10.27603530883789, -3.4397048950195312], step: 109200, lr: 5.793148771065732e-05, reference_loss: 18.901079177856445
2024-01-02 21:27:05,668	44k	INFO	====> Epoch: 4368, cost 22.67 s
2024-01-02 21:27:27,965	44k	INFO	====> Epoch: 4369, cost 22.30 s
2024-01-02 21:27:50,007	44k	INFO	====> Epoch: 4370, cost 22.04 s
2024-01-02 21:28:12,174	44k	INFO	====> Epoch: 4371, cost 22.17 s
2024-01-02 21:28:34,215	44k	INFO	====> Epoch: 4372, cost 22.04 s
2024-01-02 21:28:56,175	44k	INFO	====> Epoch: 4373, cost 21.96 s
2024-01-02 21:29:18,182	44k	INFO	====> Epoch: 4374, cost 22.01 s
2024-01-02 21:29:40,081	44k	INFO	====> Epoch: 4375, cost 21.90 s
2024-01-02 21:30:02,150	44k	INFO	Train Epoch: 4376 [96%]
2024-01-02 21:30:02,153	44k	INFO	Losses: [1.4327443838119507, 3.498518705368042, 12.55081558227539, 11.639196395874023, -3.749037742614746], step: 109400, lr: 5.7873581561637246e-05, reference_loss: 25.372238159179688
2024-01-02 21:30:02,708	44k	INFO	====> Epoch: 4376, cost 22.63 s
2024-01-02 21:30:24,872	44k	INFO	====> Epoch: 4377, cost 22.16 s
2024-01-02 21:30:47,031	44k	INFO	====> Epoch: 4378, cost 22.16 s
2024-01-02 21:31:09,156	44k	INFO	====> Epoch: 4379, cost 22.12 s
2024-01-02 21:31:31,263	44k	INFO	====> Epoch: 4380, cost 22.11 s
2024-01-02 21:31:53,201	44k	INFO	====> Epoch: 4381, cost 21.94 s
2024-01-02 21:32:15,287	44k	INFO	====> Epoch: 4382, cost 22.09 s
2024-01-02 21:32:37,455	44k	INFO	====> Epoch: 4383, cost 22.17 s
2024-01-02 21:32:59,542	44k	INFO	Train Epoch: 4384 [96%]
2024-01-02 21:32:59,544	44k	INFO	Losses: [1.7618191242218018, 3.167271137237549, 9.890771865844727, 11.243536949157715, -3.644918918609619], step: 109600, lr: 5.781573329343859e-05, reference_loss: 22.418481826782227
2024-01-02 21:33:05,597	44k	INFO	Saving model and optimizer state at iteration 4384 to ./logs/44k/G_109600.pth
2024-01-02 21:33:06,504	44k	INFO	Saving model and optimizer state at iteration 4384 to ./logs/44k/D_109600.pth
2024-01-02 21:33:07,012	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_107200.pth
2024-01-02 21:33:07,050	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_107200.pth
2024-01-02 21:33:07,051	44k	INFO	====> Epoch: 4384, cost 29.60 s
2024-01-02 21:33:29,094	44k	INFO	====> Epoch: 4385, cost 22.04 s
2024-01-02 21:33:51,097	44k	INFO	====> Epoch: 4386, cost 22.00 s
2024-01-02 21:34:13,087	44k	INFO	====> Epoch: 4387, cost 21.99 s
2024-01-02 21:34:35,148	44k	INFO	====> Epoch: 4388, cost 22.06 s
2024-01-02 21:34:57,218	44k	INFO	====> Epoch: 4389, cost 22.07 s
2024-01-02 21:35:19,361	44k	INFO	====> Epoch: 4390, cost 22.14 s
2024-01-02 21:35:41,419	44k	INFO	====> Epoch: 4391, cost 22.06 s
2024-01-02 21:36:03,501	44k	INFO	Train Epoch: 4392 [96%]
2024-01-02 21:36:03,503	44k	INFO	Losses: [1.6674509048461914, 3.3874030113220215, 11.36076545715332, 11.955276489257812, -3.5213232040405273], step: 109800, lr: 5.775794284820583e-05, reference_loss: 24.849571228027344
2024-01-02 21:36:03,892	44k	INFO	====> Epoch: 4392, cost 22.47 s
2024-01-02 21:36:26,006	44k	INFO	====> Epoch: 4393, cost 22.11 s
2024-01-02 21:36:48,253	44k	INFO	====> Epoch: 4394, cost 22.25 s
2024-01-02 21:37:10,389	44k	INFO	====> Epoch: 4395, cost 22.14 s
2024-01-02 21:37:32,598	44k	INFO	====> Epoch: 4396, cost 22.21 s
2024-01-02 21:37:54,643	44k	INFO	====> Epoch: 4397, cost 22.04 s
2024-01-02 21:38:16,768	44k	INFO	====> Epoch: 4398, cost 22.12 s
2024-01-02 21:38:38,890	44k	INFO	====> Epoch: 4399, cost 22.12 s
2024-01-02 21:39:01,018	44k	INFO	Train Epoch: 4400 [96%]
2024-01-02 21:39:01,020	44k	INFO	Losses: [1.879321575164795, 2.9594366550445557, 7.389504909515381, 9.959465026855469, -3.436960458755493], step: 110000, lr: 5.770021016814131e-05, reference_loss: 18.750768661499023
2024-01-02 21:39:01,419	44k	INFO	====> Epoch: 4400, cost 22.53 s
2024-01-02 21:39:23,492	44k	INFO	====> Epoch: 4401, cost 22.07 s
2024-01-02 21:39:45,544	44k	INFO	====> Epoch: 4402, cost 22.05 s
2024-01-02 21:40:07,561	44k	INFO	====> Epoch: 4403, cost 22.02 s
2024-01-02 21:40:29,615	44k	INFO	====> Epoch: 4404, cost 22.05 s
2024-01-02 21:40:51,642	44k	INFO	====> Epoch: 4405, cost 22.03 s
2024-01-02 21:41:13,864	44k	INFO	====> Epoch: 4406, cost 22.22 s
2024-01-02 21:41:35,955	44k	INFO	====> Epoch: 4407, cost 22.09 s
2024-01-02 21:41:57,980	44k	INFO	Train Epoch: 4408 [96%]
2024-01-02 21:41:57,982	44k	INFO	Losses: [1.452648639678955, 3.2780044078826904, 11.035528182983398, 11.10363483428955, -3.781803607940674], step: 110200, lr: 5.764253519550512e-05, reference_loss: 23.0880126953125
2024-01-02 21:41:58,444	44k	INFO	====> Epoch: 4408, cost 22.49 s
2024-01-02 21:42:20,626	44k	INFO	====> Epoch: 4409, cost 22.18 s
2024-01-02 21:42:42,707	44k	INFO	====> Epoch: 4410, cost 22.08 s
2024-01-02 21:43:04,808	44k	INFO	====> Epoch: 4411, cost 22.10 s
2024-01-02 21:43:26,880	44k	INFO	====> Epoch: 4412, cost 22.07 s
2024-01-02 21:43:48,907	44k	INFO	====> Epoch: 4413, cost 22.03 s
2024-01-02 21:44:10,954	44k	INFO	====> Epoch: 4414, cost 22.05 s
2024-01-02 21:44:33,131	44k	INFO	====> Epoch: 4415, cost 22.18 s
2024-01-02 21:44:55,466	44k	INFO	Train Epoch: 4416 [96%]
2024-01-02 21:44:55,468	44k	INFO	Losses: [1.7932584285736084, 2.890064239501953, 8.38479995727539, 10.385390281677246, -3.711291790008545], step: 110400, lr: 5.758491787261508e-05, reference_loss: 19.74222183227539
2024-01-02 21:45:01,289	44k	INFO	Saving model and optimizer state at iteration 4416 to ./logs/44k/G_110400.pth
2024-01-02 21:45:02,205	44k	INFO	Saving model and optimizer state at iteration 4416 to ./logs/44k/D_110400.pth
2024-01-02 21:45:02,710	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_108000.pth
2024-01-02 21:45:02,749	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_108000.pth
2024-01-02 21:45:02,749	44k	INFO	====> Epoch: 4416, cost 29.62 s
2024-01-02 21:45:24,929	44k	INFO	====> Epoch: 4417, cost 22.18 s
2024-01-02 21:45:47,117	44k	INFO	====> Epoch: 4418, cost 22.19 s
2024-01-02 21:46:09,222	44k	INFO	====> Epoch: 4419, cost 22.11 s
2024-01-02 21:46:31,295	44k	INFO	====> Epoch: 4420, cost 22.07 s
2024-01-02 21:46:53,384	44k	INFO	====> Epoch: 4421, cost 22.09 s
2024-01-02 21:47:15,557	44k	INFO	====> Epoch: 4422, cost 22.17 s
2024-01-02 21:47:37,917	44k	INFO	====> Epoch: 4423, cost 22.36 s
2024-01-02 21:48:00,104	44k	INFO	Train Epoch: 4424 [96%]
2024-01-02 21:48:00,106	44k	INFO	Losses: [1.601151704788208, 3.3699164390563965, 10.836851119995117, 11.949051856994629, -3.518066167831421], step: 110600, lr: 5.752735814184665e-05, reference_loss: 24.23890495300293
2024-01-02 21:48:00,495	44k	INFO	====> Epoch: 4424, cost 22.58 s
2024-01-02 21:48:22,712	44k	INFO	====> Epoch: 4425, cost 22.22 s
2024-01-02 21:48:44,787	44k	INFO	====> Epoch: 4426, cost 22.08 s
2024-01-02 21:49:06,768	44k	INFO	====> Epoch: 4427, cost 21.98 s
2024-01-02 21:49:28,744	44k	INFO	====> Epoch: 4428, cost 21.98 s
2024-01-02 21:49:50,755	44k	INFO	====> Epoch: 4429, cost 22.01 s
2024-01-02 21:50:12,978	44k	INFO	====> Epoch: 4430, cost 22.22 s
2024-01-02 21:50:34,966	44k	INFO	====> Epoch: 4431, cost 21.99 s
2024-01-02 21:50:56,993	44k	INFO	Train Epoch: 4432 [96%]
2024-01-02 21:50:56,995	44k	INFO	Losses: [1.925778865814209, 3.062129259109497, 8.106206893920898, 10.627449035644531, -3.487196922302246], step: 110800, lr: 5.746985594563289e-05, reference_loss: 20.23436737060547
2024-01-02 21:50:57,594	44k	INFO	====> Epoch: 4432, cost 22.63 s
2024-01-02 21:51:19,749	44k	INFO	====> Epoch: 4433, cost 22.16 s
2024-01-02 21:51:41,780	44k	INFO	====> Epoch: 4434, cost 22.03 s
2024-01-02 21:52:03,889	44k	INFO	====> Epoch: 4435, cost 22.11 s
2024-01-02 21:52:25,951	44k	INFO	====> Epoch: 4436, cost 22.06 s
2024-01-02 21:52:47,953	44k	INFO	====> Epoch: 4437, cost 22.00 s
2024-01-02 21:53:10,073	44k	INFO	====> Epoch: 4438, cost 22.12 s
2024-01-02 21:53:32,177	44k	INFO	====> Epoch: 4439, cost 22.10 s
2024-01-02 21:53:54,336	44k	INFO	Train Epoch: 4440 [96%]
2024-01-02 21:53:54,338	44k	INFO	Losses: [1.4626579284667969, 3.593193531036377, 12.61547565460205, 11.616972923278809, -3.79557728767395], step: 111000, lr: 5.741241122646443e-05, reference_loss: 25.492721557617188
2024-01-02 21:53:54,745	44k	INFO	====> Epoch: 4440, cost 22.57 s
2024-01-02 21:54:16,940	44k	INFO	====> Epoch: 4441, cost 22.20 s
2024-01-02 21:54:39,207	44k	INFO	====> Epoch: 4442, cost 22.27 s
2024-01-02 21:55:01,259	44k	INFO	====> Epoch: 4443, cost 22.05 s
2024-01-02 21:55:23,456	44k	INFO	====> Epoch: 4444, cost 22.20 s
2024-01-02 21:55:45,579	44k	INFO	====> Epoch: 4445, cost 22.12 s
2024-01-02 21:56:07,644	44k	INFO	====> Epoch: 4446, cost 22.06 s
2024-01-02 21:56:29,782	44k	INFO	====> Epoch: 4447, cost 22.14 s
2024-01-02 21:56:51,833	44k	INFO	Train Epoch: 4448 [96%]
2024-01-02 21:56:51,834	44k	INFO	Losses: [1.7897026538848877, 2.9717438220977783, 8.290377616882324, 10.2356538772583, -3.716109037399292], step: 111200, lr: 5.735502392688936e-05, reference_loss: 19.57137107849121
2024-01-02 21:56:57,642	44k	INFO	Saving model and optimizer state at iteration 4448 to ./logs/44k/G_111200.pth
2024-01-02 21:56:58,576	44k	INFO	Saving model and optimizer state at iteration 4448 to ./logs/44k/D_111200.pth
2024-01-02 21:56:59,067	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_108800.pth
2024-01-02 21:56:59,105	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_108800.pth
2024-01-02 21:56:59,106	44k	INFO	====> Epoch: 4448, cost 29.32 s
2024-01-02 21:57:21,057	44k	INFO	====> Epoch: 4449, cost 21.95 s
2024-01-02 21:57:43,158	44k	INFO	====> Epoch: 4450, cost 22.10 s
2024-01-02 21:58:05,046	44k	INFO	====> Epoch: 4451, cost 21.89 s
2024-01-02 21:58:27,076	44k	INFO	====> Epoch: 4452, cost 22.03 s
2024-01-02 21:58:49,125	44k	INFO	====> Epoch: 4453, cost 22.05 s
2024-01-02 21:59:11,183	44k	INFO	====> Epoch: 4454, cost 22.06 s
2024-01-02 21:59:33,265	44k	INFO	====> Epoch: 4455, cost 22.08 s
2024-01-02 21:59:55,426	44k	INFO	Train Epoch: 4456 [96%]
2024-01-02 21:59:55,428	44k	INFO	Losses: [1.7081894874572754, 3.16265869140625, 9.399726867675781, 10.721150398254395, -3.4967949390411377], step: 111400, lr: 5.729769398951319e-05, reference_loss: 21.494930267333984
2024-01-02 21:59:55,820	44k	INFO	====> Epoch: 4456, cost 22.55 s
2024-01-02 22:00:18,112	44k	INFO	====> Epoch: 4457, cost 22.29 s
2024-01-02 22:00:40,303	44k	INFO	====> Epoch: 4458, cost 22.19 s
2024-01-02 22:01:02,459	44k	INFO	====> Epoch: 4459, cost 22.16 s
2024-01-02 22:01:24,708	44k	INFO	====> Epoch: 4460, cost 22.25 s
2024-01-02 22:01:46,933	44k	INFO	====> Epoch: 4461, cost 22.23 s
2024-01-02 22:02:09,371	44k	INFO	====> Epoch: 4462, cost 22.44 s
2024-01-02 22:02:31,561	44k	INFO	====> Epoch: 4463, cost 22.19 s
2024-01-02 22:02:53,777	44k	INFO	Train Epoch: 4464 [96%]
2024-01-02 22:02:53,779	44k	INFO	Losses: [2.026545286178589, 2.925140619277954, 8.50416374206543, 10.527488708496094, -3.441775321960449], step: 111600, lr: 5.7240421356998826e-05, reference_loss: 20.541561126708984
2024-01-02 22:02:54,183	44k	INFO	====> Epoch: 4464, cost 22.62 s
2024-01-02 22:03:16,379	44k	INFO	====> Epoch: 4465, cost 22.20 s
2024-01-02 22:03:38,578	44k	INFO	====> Epoch: 4466, cost 22.20 s
2024-01-02 22:04:00,860	44k	INFO	====> Epoch: 4467, cost 22.28 s
2024-01-02 22:04:23,121	44k	INFO	====> Epoch: 4468, cost 22.26 s
2024-01-02 22:04:45,424	44k	INFO	====> Epoch: 4469, cost 22.30 s
2024-01-02 22:05:07,551	44k	INFO	====> Epoch: 4470, cost 22.13 s
2024-01-02 22:05:29,591	44k	INFO	====> Epoch: 4471, cost 22.04 s
2024-01-02 22:05:51,684	44k	INFO	Train Epoch: 4472 [96%]
2024-01-02 22:05:51,686	44k	INFO	Losses: [1.4252479076385498, 3.5929579734802246, 10.681351661682129, 11.255163192749023, -3.746896505355835], step: 111800, lr: 5.7183205972066454e-05, reference_loss: 23.207822799682617
2024-01-02 22:05:52,073	44k	INFO	====> Epoch: 4472, cost 22.48 s
2024-01-02 22:06:14,158	44k	INFO	====> Epoch: 4473, cost 22.09 s
2024-01-02 22:06:36,278	44k	INFO	====> Epoch: 4474, cost 22.12 s
2024-01-02 22:06:58,406	44k	INFO	====> Epoch: 4475, cost 22.13 s
2024-01-02 22:07:20,512	44k	INFO	====> Epoch: 4476, cost 22.11 s
2024-01-02 22:07:42,655	44k	INFO	====> Epoch: 4477, cost 22.14 s
2024-01-02 22:08:04,869	44k	INFO	====> Epoch: 4478, cost 22.21 s
2024-01-02 22:08:26,967	44k	INFO	====> Epoch: 4479, cost 22.10 s
2024-01-02 22:08:49,104	44k	INFO	Train Epoch: 4480 [96%]
2024-01-02 22:08:49,106	44k	INFO	Losses: [1.6807255744934082, 3.2344655990600586, 10.206233024597168, 11.399276733398438, -3.76304292678833], step: 112000, lr: 5.712604777749354e-05, reference_loss: 22.757658004760742
2024-01-02 22:08:55,138	44k	INFO	Saving model and optimizer state at iteration 4480 to ./logs/44k/G_112000.pth
2024-01-02 22:08:56,049	44k	INFO	Saving model and optimizer state at iteration 4480 to ./logs/44k/D_112000.pth
2024-01-02 22:08:56,549	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_109600.pth
2024-01-02 22:08:56,587	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_109600.pth
2024-01-02 22:08:56,587	44k	INFO	====> Epoch: 4480, cost 29.62 s
2024-01-02 22:09:18,677	44k	INFO	====> Epoch: 4481, cost 22.09 s
2024-01-02 22:09:40,763	44k	INFO	====> Epoch: 4482, cost 22.09 s
2024-01-02 22:10:02,820	44k	INFO	====> Epoch: 4483, cost 22.06 s
2024-01-02 22:10:24,861	44k	INFO	====> Epoch: 4484, cost 22.04 s
2024-01-02 22:10:46,943	44k	INFO	====> Epoch: 4485, cost 22.08 s
2024-01-02 22:11:09,026	44k	INFO	====> Epoch: 4486, cost 22.08 s
2024-01-02 22:11:31,001	44k	INFO	====> Epoch: 4487, cost 21.97 s
2024-01-02 22:11:52,982	44k	INFO	Train Epoch: 4488 [96%]
2024-01-02 22:11:52,983	44k	INFO	Losses: [1.6132822036743164, 3.494912624359131, 11.233536720275879, 11.795624732971191, -3.6245927810668945], step: 112200, lr: 5.706894671611474e-05, reference_loss: 24.51276397705078
2024-01-02 22:11:53,381	44k	INFO	====> Epoch: 4488, cost 22.38 s
2024-01-02 22:12:15,353	44k	INFO	====> Epoch: 4489, cost 21.97 s
2024-01-02 22:12:37,337	44k	INFO	====> Epoch: 4490, cost 21.98 s
2024-01-02 22:12:59,326	44k	INFO	====> Epoch: 4491, cost 21.99 s
2024-01-02 22:13:21,638	44k	INFO	====> Epoch: 4492, cost 22.31 s
2024-01-02 22:13:43,729	44k	INFO	====> Epoch: 4493, cost 22.09 s
2024-01-02 22:14:05,925	44k	INFO	====> Epoch: 4494, cost 22.20 s
2024-01-02 22:14:28,045	44k	INFO	====> Epoch: 4495, cost 22.12 s
2024-01-02 22:14:50,122	44k	INFO	Train Epoch: 4496 [96%]
2024-01-02 22:14:50,124	44k	INFO	Losses: [1.8809020519256592, 3.1333086490631104, 7.923804759979248, 10.499378204345703, -3.6079940795898438], step: 112400, lr: 5.701190273082185e-05, reference_loss: 19.82939910888672
2024-01-02 22:14:50,507	44k	INFO	====> Epoch: 4496, cost 22.46 s
2024-01-02 22:15:12,532	44k	INFO	====> Epoch: 4497, cost 22.02 s
2024-01-02 22:15:34,552	44k	INFO	====> Epoch: 4498, cost 22.02 s
2024-01-02 22:15:56,726	44k	INFO	====> Epoch: 4499, cost 22.17 s
2024-01-02 22:16:18,911	44k	INFO	====> Epoch: 4500, cost 22.18 s
2024-01-02 22:16:41,174	44k	INFO	====> Epoch: 4501, cost 22.26 s
2024-01-02 22:17:03,632	44k	INFO	====> Epoch: 4502, cost 22.46 s
2024-01-02 22:17:25,644	44k	INFO	====> Epoch: 4503, cost 22.01 s
2024-01-02 22:17:47,624	44k	INFO	Train Epoch: 4504 [96%]
2024-01-02 22:17:47,626	44k	INFO	Losses: [1.5403870344161987, 3.32253360748291, 10.595861434936523, 10.937128067016602, -3.8630318641662598], step: 112600, lr: 5.695491576456375e-05, reference_loss: 22.532878875732422
2024-01-02 22:17:48,000	44k	INFO	====> Epoch: 4504, cost 22.36 s
2024-01-02 22:18:10,058	44k	INFO	====> Epoch: 4505, cost 22.06 s
2024-01-02 22:18:32,072	44k	INFO	====> Epoch: 4506, cost 22.01 s
2024-01-02 22:18:54,345	44k	INFO	====> Epoch: 4507, cost 22.27 s
2024-01-02 22:19:16,649	44k	INFO	====> Epoch: 4508, cost 22.30 s
2024-01-02 22:19:38,864	44k	INFO	====> Epoch: 4509, cost 22.22 s
2024-01-02 22:20:01,051	44k	INFO	====> Epoch: 4510, cost 22.19 s
2024-01-02 22:20:23,313	44k	INFO	====> Epoch: 4511, cost 22.26 s
2024-01-02 22:20:45,661	44k	INFO	Train Epoch: 4512 [96%]
2024-01-02 22:20:45,663	44k	INFO	Losses: [1.7661932706832886, 3.2386107444763184, 8.799593925476074, 10.547533988952637, -3.7402913570404053], step: 112800, lr: 5.6897985760346344e-05, reference_loss: 20.61164093017578
2024-01-02 22:20:51,784	44k	INFO	Saving model and optimizer state at iteration 4512 to ./logs/44k/G_112800.pth
2024-01-02 22:20:52,701	44k	INFO	Saving model and optimizer state at iteration 4512 to ./logs/44k/D_112800.pth
2024-01-02 22:20:53,223	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_110400.pth
2024-01-02 22:20:53,262	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_110400.pth
2024-01-02 22:20:53,263	44k	INFO	====> Epoch: 4512, cost 29.95 s
2024-01-02 22:21:15,579	44k	INFO	====> Epoch: 4513, cost 22.32 s
2024-01-02 22:21:37,879	44k	INFO	====> Epoch: 4514, cost 22.30 s
2024-01-02 22:22:00,166	44k	INFO	====> Epoch: 4515, cost 22.29 s
2024-01-02 22:22:22,275	44k	INFO	====> Epoch: 4516, cost 22.11 s
2024-01-02 22:22:44,337	44k	INFO	====> Epoch: 4517, cost 22.06 s
2024-01-02 22:23:06,530	44k	INFO	====> Epoch: 4518, cost 22.19 s
2024-01-02 22:23:28,725	44k	INFO	====> Epoch: 4519, cost 22.20 s
2024-01-02 22:23:50,817	44k	INFO	Train Epoch: 4520 [96%]
2024-01-02 22:23:50,819	44k	INFO	Losses: [1.6412913799285889, 3.3567471504211426, 9.606410026550293, 10.667068481445312, -3.5765607357025146], step: 113000, lr: 5.684111266123251e-05, reference_loss: 21.694955825805664
2024-01-02 22:23:51,291	44k	INFO	====> Epoch: 4520, cost 22.57 s
2024-01-02 22:24:13,393	44k	INFO	====> Epoch: 4521, cost 22.10 s
2024-01-02 22:24:35,549	44k	INFO	====> Epoch: 4522, cost 22.16 s
2024-01-02 22:24:57,719	44k	INFO	====> Epoch: 4523, cost 22.17 s
2024-01-02 22:25:19,934	44k	INFO	====> Epoch: 4524, cost 22.21 s
2024-01-02 22:25:42,139	44k	INFO	====> Epoch: 4525, cost 22.21 s
2024-01-02 22:26:04,181	44k	INFO	====> Epoch: 4526, cost 22.04 s
2024-01-02 22:26:26,292	44k	INFO	====> Epoch: 4527, cost 22.11 s
2024-01-02 22:26:48,647	44k	INFO	Train Epoch: 4528 [96%]
2024-01-02 22:26:48,649	44k	INFO	Losses: [1.8399702310562134, 3.0941269397735596, 8.981585502624512, 10.825653076171875, -3.675859212875366], step: 113200, lr: 5.6784296410342015e-05, reference_loss: 21.06547737121582
2024-01-02 22:26:49,322	44k	INFO	====> Epoch: 4528, cost 23.03 s
2024-01-02 22:27:11,739	44k	INFO	====> Epoch: 4529, cost 22.42 s
2024-01-02 22:27:34,048	44k	INFO	====> Epoch: 4530, cost 22.31 s
2024-01-02 22:27:56,300	44k	INFO	====> Epoch: 4531, cost 22.25 s
2024-01-02 22:28:18,532	44k	INFO	====> Epoch: 4532, cost 22.23 s
2024-01-02 22:28:40,742	44k	INFO	====> Epoch: 4533, cost 22.21 s
2024-01-02 22:29:03,084	44k	INFO	====> Epoch: 4534, cost 22.34 s
2024-01-02 22:29:25,407	44k	INFO	====> Epoch: 4535, cost 22.32 s
2024-01-02 22:29:47,643	44k	INFO	Train Epoch: 4536 [96%]
2024-01-02 22:29:47,645	44k	INFO	Losses: [1.4955954551696777, 3.6214663982391357, 10.507842063903809, 11.278605461120605, -3.9145610332489014], step: 113400, lr: 5.6727536950851506e-05, reference_loss: 22.988948822021484
2024-01-02 22:29:48,119	44k	INFO	====> Epoch: 4536, cost 22.71 s
2024-01-02 22:30:10,296	44k	INFO	====> Epoch: 4537, cost 22.18 s
2024-01-02 22:30:32,674	44k	INFO	====> Epoch: 4538, cost 22.38 s
2024-01-02 22:30:54,912	44k	INFO	====> Epoch: 4539, cost 22.24 s
2024-01-02 22:31:17,177	44k	INFO	====> Epoch: 4540, cost 22.26 s
2024-01-02 22:31:39,406	44k	INFO	====> Epoch: 4541, cost 22.23 s
2024-01-02 22:32:01,692	44k	INFO	====> Epoch: 4542, cost 22.29 s
2024-01-02 22:32:24,029	44k	INFO	====> Epoch: 4543, cost 22.34 s
2024-01-02 22:32:46,349	44k	INFO	Train Epoch: 4544 [96%]
2024-01-02 22:32:46,351	44k	INFO	Losses: [1.7369836568832397, 3.108613967895508, 8.659404754638672, 10.49997615814209, -3.8236196041107178], step: 113600, lr: 5.667083422599444e-05, reference_loss: 20.181358337402344
2024-01-02 22:32:52,145	44k	INFO	Saving model and optimizer state at iteration 4544 to ./logs/44k/G_113600.pth
2024-01-02 22:32:53,042	44k	INFO	Saving model and optimizer state at iteration 4544 to ./logs/44k/D_113600.pth
2024-01-02 22:32:53,536	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_111200.pth
2024-01-02 22:32:53,575	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_111200.pth
2024-01-02 22:32:53,575	44k	INFO	====> Epoch: 4544, cost 29.55 s
2024-01-02 22:33:15,778	44k	INFO	====> Epoch: 4545, cost 22.20 s
2024-01-02 22:33:38,191	44k	INFO	====> Epoch: 4546, cost 22.41 s
2024-01-02 22:34:00,407	44k	INFO	====> Epoch: 4547, cost 22.22 s
2024-01-02 22:34:22,703	44k	INFO	====> Epoch: 4548, cost 22.30 s
2024-01-02 22:34:45,094	44k	INFO	====> Epoch: 4549, cost 22.39 s
2024-01-02 22:35:07,471	44k	INFO	====> Epoch: 4550, cost 22.38 s
2024-01-02 22:35:29,870	44k	INFO	====> Epoch: 4551, cost 22.40 s
2024-01-02 22:35:52,128	44k	INFO	Train Epoch: 4552 [96%]
2024-01-02 22:35:52,130	44k	INFO	Losses: [1.6434895992279053, 3.5249075889587402, 10.388311386108398, 11.665292739868164, -3.740257978439331], step: 113800, lr: 5.6614188179061e-05, reference_loss: 23.48174285888672
2024-01-02 22:35:52,525	44k	INFO	====> Epoch: 4552, cost 22.65 s
2024-01-02 22:36:14,763	44k	INFO	====> Epoch: 4553, cost 22.24 s
2024-01-02 22:36:37,091	44k	INFO	====> Epoch: 4554, cost 22.33 s
2024-01-02 22:36:59,493	44k	INFO	====> Epoch: 4555, cost 22.40 s
2024-01-02 22:37:21,864	44k	INFO	====> Epoch: 4556, cost 22.37 s
2024-01-02 22:37:44,295	44k	INFO	====> Epoch: 4557, cost 22.43 s
2024-01-02 22:38:06,748	44k	INFO	====> Epoch: 4558, cost 22.45 s
2024-01-02 22:38:28,989	44k	INFO	====> Epoch: 4559, cost 22.24 s
2024-01-02 22:38:51,131	44k	INFO	Train Epoch: 4560 [96%]
2024-01-02 22:38:51,133	44k	INFO	Losses: [1.9285943508148193, 2.9331858158111572, 7.226746559143066, 9.451778411865234, -3.6606013774871826], step: 114000, lr: 5.6557598753398046e-05, reference_loss: 17.87970542907715
2024-01-02 22:38:51,598	44k	INFO	====> Epoch: 4560, cost 22.61 s
2024-01-02 22:39:13,820	44k	INFO	====> Epoch: 4561, cost 22.22 s
2024-01-02 22:39:36,064	44k	INFO	====> Epoch: 4562, cost 22.24 s
2024-01-02 22:39:58,306	44k	INFO	====> Epoch: 4563, cost 22.24 s
2024-01-02 22:40:20,443	44k	INFO	====> Epoch: 4564, cost 22.14 s
2024-01-02 22:40:42,670	44k	INFO	====> Epoch: 4565, cost 22.23 s
2024-01-02 22:41:04,856	44k	INFO	====> Epoch: 4566, cost 22.19 s
2024-01-02 22:41:27,096	44k	INFO	====> Epoch: 4567, cost 22.24 s
2024-01-02 22:41:49,447	44k	INFO	Train Epoch: 4568 [96%]
2024-01-02 22:41:49,448	44k	INFO	Losses: [1.4459120035171509, 3.7714338302612305, 11.831128120422363, 11.668310165405273, -3.9913110733032227], step: 114200, lr: 5.6501065892409056e-05, reference_loss: 24.72547149658203
2024-01-02 22:41:50,067	44k	INFO	====> Epoch: 4568, cost 22.97 s
2024-01-02 22:42:12,389	44k	INFO	====> Epoch: 4569, cost 22.32 s
2024-01-02 22:42:34,713	44k	INFO	====> Epoch: 4570, cost 22.32 s
2024-01-02 22:42:57,032	44k	INFO	====> Epoch: 4571, cost 22.32 s
2024-01-02 22:43:19,267	44k	INFO	====> Epoch: 4572, cost 22.23 s
2024-01-02 22:43:41,398	44k	INFO	====> Epoch: 4573, cost 22.13 s
2024-01-02 22:44:03,603	44k	INFO	====> Epoch: 4574, cost 22.20 s
2024-01-02 22:44:25,873	44k	INFO	====> Epoch: 4575, cost 22.27 s
2024-01-02 22:44:48,121	44k	INFO	Train Epoch: 4576 [96%]
2024-01-02 22:44:48,122	44k	INFO	Losses: [1.7253105640411377, 3.3104445934295654, 10.390742301940918, 10.640007972717285, -3.797065258026123], step: 114400, lr: 5.644458953955412e-05, reference_loss: 22.269439697265625
2024-01-02 22:44:54,239	44k	INFO	Saving model and optimizer state at iteration 4576 to ./logs/44k/G_114400.pth
2024-01-02 22:44:55,166	44k	INFO	Saving model and optimizer state at iteration 4576 to ./logs/44k/D_114400.pth
2024-01-02 22:44:55,689	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_112000.pth
2024-01-02 22:44:55,728	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_112000.pth
2024-01-02 22:44:55,729	44k	INFO	====> Epoch: 4576, cost 29.86 s
2024-01-02 22:45:18,071	44k	INFO	====> Epoch: 4577, cost 22.34 s
2024-01-02 22:45:40,354	44k	INFO	====> Epoch: 4578, cost 22.28 s
2024-01-02 22:46:02,719	44k	INFO	====> Epoch: 4579, cost 22.37 s
2024-01-02 22:46:25,094	44k	INFO	====> Epoch: 4580, cost 22.37 s
2024-01-02 22:46:47,506	44k	INFO	====> Epoch: 4581, cost 22.41 s
2024-01-02 22:47:09,745	44k	INFO	====> Epoch: 4582, cost 22.24 s
2024-01-02 22:47:31,946	44k	INFO	====> Epoch: 4583, cost 22.20 s
2024-01-02 22:47:54,058	44k	INFO	Train Epoch: 4584 [96%]
2024-01-02 22:47:54,060	44k	INFO	Losses: [1.5828438997268677, 3.173144817352295, 10.055514335632324, 11.223814964294434, -3.7064483165740967], step: 114600, lr: 5.638816963834981e-05, reference_loss: 22.328868865966797
2024-01-02 22:47:54,439	44k	INFO	====> Epoch: 4584, cost 22.49 s
2024-01-02 22:48:16,663	44k	INFO	====> Epoch: 4585, cost 22.22 s
2024-01-02 22:48:39,007	44k	INFO	====> Epoch: 4586, cost 22.34 s
2024-01-02 22:49:01,252	44k	INFO	====> Epoch: 4587, cost 22.24 s
2024-01-02 22:49:23,590	44k	INFO	====> Epoch: 4588, cost 22.34 s
2024-01-02 22:49:45,848	44k	INFO	====> Epoch: 4589, cost 22.26 s
2024-01-02 22:50:08,202	44k	INFO	====> Epoch: 4590, cost 22.35 s
2024-01-02 22:50:30,353	44k	INFO	====> Epoch: 4591, cost 22.15 s
2024-01-02 22:50:52,492	44k	INFO	Train Epoch: 4592 [96%]
2024-01-02 22:50:52,494	44k	INFO	Losses: [1.7624696493148804, 3.3215599060058594, 9.236226081848145, 10.802048683166504, -3.7808008193969727], step: 114800, lr: 5.633180613236917e-05, reference_loss: 21.341503143310547
2024-01-02 22:50:52,878	44k	INFO	====> Epoch: 4592, cost 22.52 s
2024-01-02 22:51:15,050	44k	INFO	====> Epoch: 4593, cost 22.17 s
2024-01-02 22:51:37,224	44k	INFO	====> Epoch: 4594, cost 22.17 s
2024-01-02 22:51:59,518	44k	INFO	====> Epoch: 4595, cost 22.29 s
2024-01-02 22:52:21,782	44k	INFO	====> Epoch: 4596, cost 22.26 s
2024-01-02 22:52:44,092	44k	INFO	====> Epoch: 4597, cost 22.31 s
2024-01-02 22:53:06,572	44k	INFO	====> Epoch: 4598, cost 22.48 s
2024-01-02 22:53:28,800	44k	INFO	====> Epoch: 4599, cost 22.23 s
2024-01-02 22:53:51,066	44k	INFO	Train Epoch: 4600 [96%]
2024-01-02 22:53:51,069	44k	INFO	Losses: [1.5287710428237915, 3.4758129119873047, 10.535273551940918, 10.97179889678955, -3.9197628498077393], step: 115000, lr: 5.6275498965241634e-05, reference_loss: 22.591894149780273
2024-01-02 22:53:51,449	44k	INFO	====> Epoch: 4600, cost 22.65 s
2024-01-02 22:54:13,763	44k	INFO	====> Epoch: 4601, cost 22.31 s
2024-01-02 22:54:35,970	44k	INFO	====> Epoch: 4602, cost 22.21 s
2024-01-02 22:54:58,206	44k	INFO	====> Epoch: 4603, cost 22.24 s
2024-01-02 22:55:20,404	44k	INFO	====> Epoch: 4604, cost 22.20 s
2024-01-02 22:55:42,578	44k	INFO	====> Epoch: 4605, cost 22.17 s
2024-01-02 22:56:04,806	44k	INFO	====> Epoch: 4606, cost 22.23 s
2024-01-02 22:56:27,254	44k	INFO	====> Epoch: 4607, cost 22.45 s
2024-01-02 22:56:49,793	44k	INFO	Train Epoch: 4608 [96%]
2024-01-02 22:56:49,795	44k	INFO	Losses: [1.788713812828064, 2.992569923400879, 8.358442306518555, 10.112823486328125, -3.885324478149414], step: 115200, lr: 5.6219248080653e-05, reference_loss: 19.367225646972656
2024-01-02 22:56:55,584	44k	INFO	Saving model and optimizer state at iteration 4608 to ./logs/44k/G_115200.pth
2024-01-02 22:56:56,511	44k	INFO	Saving model and optimizer state at iteration 4608 to ./logs/44k/D_115200.pth
2024-01-02 22:56:57,014	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_112800.pth
2024-01-02 22:56:57,053	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_112800.pth
2024-01-02 22:56:57,053	44k	INFO	====> Epoch: 4608, cost 29.80 s
2024-01-02 22:57:19,204	44k	INFO	====> Epoch: 4609, cost 22.15 s
2024-01-02 22:57:41,352	44k	INFO	====> Epoch: 4610, cost 22.15 s
2024-01-02 22:58:03,480	44k	INFO	====> Epoch: 4611, cost 22.13 s
2024-01-02 22:58:25,632	44k	INFO	====> Epoch: 4612, cost 22.15 s
2024-01-02 22:58:47,857	44k	INFO	====> Epoch: 4613, cost 22.23 s
2024-01-02 22:59:10,164	44k	INFO	====> Epoch: 4614, cost 22.31 s
2024-01-02 22:59:32,623	44k	INFO	====> Epoch: 4615, cost 22.46 s
2024-01-02 22:59:54,809	44k	INFO	Train Epoch: 4616 [96%]
2024-01-02 22:59:54,811	44k	INFO	Losses: [1.5753116607666016, 3.4481797218322754, 9.667226791381836, 10.564371109008789, -3.8250620365142822], step: 115400, lr: 5.6163053422345355e-05, reference_loss: 21.43002700805664
2024-01-02 22:59:55,196	44k	INFO	====> Epoch: 4616, cost 22.57 s
2024-01-02 23:00:17,364	44k	INFO	====> Epoch: 4617, cost 22.17 s
2024-01-02 23:00:39,432	44k	INFO	====> Epoch: 4618, cost 22.07 s
2024-01-02 23:01:01,495	44k	INFO	====> Epoch: 4619, cost 22.06 s
2024-01-02 23:01:23,643	44k	INFO	====> Epoch: 4620, cost 22.15 s
2024-01-02 23:01:45,670	44k	INFO	====> Epoch: 4621, cost 22.03 s
2024-01-02 23:02:07,825	44k	INFO	====> Epoch: 4622, cost 22.16 s
2024-01-02 23:02:30,175	44k	INFO	====> Epoch: 4623, cost 22.35 s
2024-01-02 23:02:52,353	44k	INFO	Train Epoch: 4624 [96%]
2024-01-02 23:02:52,356	44k	INFO	Losses: [1.91396164894104, 3.006355047225952, 8.039900779724121, 10.855110168457031, -3.758162260055542], step: 115600, lr: 5.610691493411699e-05, reference_loss: 20.057165145874023
2024-01-02 23:02:52,997	44k	INFO	====> Epoch: 4624, cost 22.82 s
2024-01-02 23:03:15,052	44k	INFO	====> Epoch: 4625, cost 22.06 s
2024-01-02 23:03:37,174	44k	INFO	====> Epoch: 4626, cost 22.12 s
2024-01-02 23:03:59,235	44k	INFO	====> Epoch: 4627, cost 22.06 s
2024-01-02 23:04:21,431	44k	INFO	====> Epoch: 4628, cost 22.20 s
2024-01-02 23:04:43,699	44k	INFO	====> Epoch: 4629, cost 22.27 s
2024-01-02 23:05:05,900	44k	INFO	====> Epoch: 4630, cost 22.20 s
2024-01-02 23:05:28,088	44k	INFO	====> Epoch: 4631, cost 22.19 s
2024-01-02 23:05:50,321	44k	INFO	Train Epoch: 4632 [96%]
2024-01-02 23:05:50,323	44k	INFO	Losses: [1.474776268005371, 3.4387001991271973, 11.799546241760254, 11.268872261047363, -3.978367567062378], step: 115800, lr: 5.60508325598224e-05, reference_loss: 24.003528594970703
2024-01-02 23:05:50,817	44k	INFO	====> Epoch: 4632, cost 22.73 s
2024-01-02 23:06:13,162	44k	INFO	====> Epoch: 4633, cost 22.34 s
2024-01-02 23:06:35,658	44k	INFO	====> Epoch: 4634, cost 22.50 s
2024-01-02 23:06:57,786	44k	INFO	====> Epoch: 4635, cost 22.13 s
2024-01-02 23:07:20,054	44k	INFO	====> Epoch: 4636, cost 22.27 s
2024-01-02 23:07:42,330	44k	INFO	====> Epoch: 4637, cost 22.28 s
2024-01-02 23:08:04,530	44k	INFO	====> Epoch: 4638, cost 22.20 s
2024-01-02 23:08:26,798	44k	INFO	====> Epoch: 4639, cost 22.27 s
2024-01-02 23:08:49,130	44k	INFO	Train Epoch: 4640 [96%]
2024-01-02 23:08:49,132	44k	INFO	Losses: [1.8027831315994263, 2.82934832572937, 8.770417213439941, 10.529019355773926, -3.934957981109619], step: 116000, lr: 5.599480624337221e-05, reference_loss: 19.996610641479492
2024-01-02 23:08:54,753	44k	INFO	Saving model and optimizer state at iteration 4640 to ./logs/44k/G_116000.pth
2024-01-02 23:08:55,674	44k	INFO	Saving model and optimizer state at iteration 4640 to ./logs/44k/D_116000.pth
2024-01-02 23:08:56,171	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_113600.pth
2024-01-02 23:08:56,210	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_113600.pth
2024-01-02 23:08:56,210	44k	INFO	====> Epoch: 4640, cost 29.41 s
2024-01-02 23:09:18,451	44k	INFO	====> Epoch: 4641, cost 22.24 s
2024-01-02 23:09:40,993	44k	INFO	====> Epoch: 4642, cost 22.54 s
2024-01-02 23:10:03,300	44k	INFO	====> Epoch: 4643, cost 22.31 s
2024-01-02 23:10:25,528	44k	INFO	====> Epoch: 4644, cost 22.23 s
2024-01-02 23:10:47,746	44k	INFO	====> Epoch: 4645, cost 22.22 s
2024-01-02 23:11:10,071	44k	INFO	====> Epoch: 4646, cost 22.32 s
2024-01-02 23:11:32,496	44k	INFO	====> Epoch: 4647, cost 22.43 s
2024-01-02 23:11:54,983	44k	INFO	Train Epoch: 4648 [96%]
2024-01-02 23:11:54,984	44k	INFO	Losses: [1.6484885215759277, 3.540440797805786, 10.080511093139648, 11.402332305908203, -3.7864651679992676], step: 116200, lr: 5.593883592873308e-05, reference_loss: 22.88530731201172
2024-01-02 23:11:55,393	44k	INFO	====> Epoch: 4648, cost 22.90 s
2024-01-02 23:12:17,815	44k	INFO	====> Epoch: 4649, cost 22.42 s
2024-01-02 23:12:40,220	44k	INFO	====> Epoch: 4650, cost 22.40 s
2024-01-02 23:13:02,534	44k	INFO	====> Epoch: 4651, cost 22.31 s
2024-01-02 23:13:24,865	44k	INFO	====> Epoch: 4652, cost 22.33 s
2024-01-02 23:13:47,225	44k	INFO	====> Epoch: 4653, cost 22.36 s
2024-01-02 23:14:09,732	44k	INFO	====> Epoch: 4654, cost 22.51 s
2024-01-02 23:14:31,993	44k	INFO	====> Epoch: 4655, cost 22.26 s
2024-01-02 23:14:54,269	44k	INFO	Train Epoch: 4656 [96%]
2024-01-02 23:14:54,271	44k	INFO	Losses: [1.808530330657959, 3.0811939239501953, 7.676447868347168, 8.915189743041992, -3.799830436706543], step: 116400, lr: 5.588292155992769e-05, reference_loss: 17.681529998779297
2024-01-02 23:14:54,651	44k	INFO	====> Epoch: 4656, cost 22.66 s
2024-01-02 23:15:16,883	44k	INFO	====> Epoch: 4657, cost 22.23 s
2024-01-02 23:15:39,195	44k	INFO	====> Epoch: 4658, cost 22.31 s
2024-01-02 23:16:01,536	44k	INFO	====> Epoch: 4659, cost 22.34 s
2024-01-02 23:16:23,694	44k	INFO	====> Epoch: 4660, cost 22.16 s
2024-01-02 23:16:45,881	44k	INFO	====> Epoch: 4661, cost 22.19 s
2024-01-02 23:17:08,142	44k	INFO	====> Epoch: 4662, cost 22.26 s
2024-01-02 23:17:30,502	44k	INFO	====> Epoch: 4663, cost 22.36 s
2024-01-02 23:17:52,765	44k	INFO	Train Epoch: 4664 [96%]
2024-01-02 23:17:52,767	44k	INFO	Losses: [1.4727931022644043, 3.340134382247925, 10.427986145019531, 10.982804298400879, -4.000868797302246], step: 116600, lr: 5.582706308103468e-05, reference_loss: 22.22284698486328
2024-01-02 23:17:53,312	44k	INFO	====> Epoch: 4664, cost 22.81 s
2024-01-02 23:18:15,651	44k	INFO	====> Epoch: 4665, cost 22.34 s
2024-01-02 23:18:37,950	44k	INFO	====> Epoch: 4666, cost 22.30 s
2024-01-02 23:19:00,188	44k	INFO	====> Epoch: 4667, cost 22.24 s
2024-01-02 23:19:22,370	44k	INFO	====> Epoch: 4668, cost 22.18 s
2024-01-02 23:19:44,495	44k	INFO	====> Epoch: 4669, cost 22.12 s
2024-01-02 23:20:06,706	44k	INFO	====> Epoch: 4670, cost 22.21 s
2024-01-02 23:20:28,951	44k	INFO	====> Epoch: 4671, cost 22.25 s
2024-01-02 23:20:51,143	44k	INFO	Train Epoch: 4672 [96%]
2024-01-02 23:20:51,145	44k	INFO	Losses: [1.8143832683563232, 3.1173458099365234, 10.154480934143066, 10.727133750915527, -3.8931264877319336], step: 116800, lr: 5.5771260436188584e-05, reference_loss: 21.920215606689453
2024-01-02 23:20:56,959	44k	INFO	Saving model and optimizer state at iteration 4672 to ./logs/44k/G_116800.pth
2024-01-02 23:20:57,870	44k	INFO	Saving model and optimizer state at iteration 4672 to ./logs/44k/D_116800.pth
2024-01-02 23:20:58,353	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_114400.pth
2024-01-02 23:20:58,392	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_114400.pth
2024-01-02 23:20:58,393	44k	INFO	====> Epoch: 4672, cost 29.44 s
2024-01-02 23:21:20,610	44k	INFO	====> Epoch: 4673, cost 22.22 s
2024-01-02 23:21:42,887	44k	INFO	====> Epoch: 4674, cost 22.28 s
2024-01-02 23:22:05,194	44k	INFO	====> Epoch: 4675, cost 22.31 s
2024-01-02 23:22:27,446	44k	INFO	====> Epoch: 4676, cost 22.25 s
2024-01-02 23:22:49,733	44k	INFO	====> Epoch: 4677, cost 22.29 s
2024-01-02 23:23:11,987	44k	INFO	====> Epoch: 4678, cost 22.25 s
2024-01-02 23:23:34,263	44k	INFO	====> Epoch: 4679, cost 22.28 s
2024-01-02 23:23:56,607	44k	INFO	Train Epoch: 4680 [96%]
2024-01-02 23:23:56,609	44k	INFO	Losses: [1.5972225666046143, 3.390848398208618, 11.589794158935547, 11.896156311035156, -3.8606061935424805], step: 117000, lr: 5.5715513569579785e-05, reference_loss: 24.613414764404297
2024-01-02 23:23:56,997	44k	INFO	====> Epoch: 4680, cost 22.73 s
2024-01-02 23:24:19,217	44k	INFO	====> Epoch: 4681, cost 22.22 s
2024-01-02 23:24:41,315	44k	INFO	====> Epoch: 4682, cost 22.10 s
2024-01-02 23:25:03,566	44k	INFO	====> Epoch: 4683, cost 22.25 s
2024-01-02 23:25:25,880	44k	INFO	====> Epoch: 4684, cost 22.31 s
2024-01-02 23:25:48,003	44k	INFO	====> Epoch: 4685, cost 22.12 s
2024-01-02 23:26:10,110	44k	INFO	====> Epoch: 4686, cost 22.11 s
2024-01-02 23:26:32,220	44k	INFO	====> Epoch: 4687, cost 22.11 s
2024-01-02 23:26:54,563	44k	INFO	Train Epoch: 4688 [96%]
2024-01-02 23:26:54,565	44k	INFO	Losses: [1.923643946647644, 3.303049087524414, 8.608771324157715, 10.52981185913086, -3.8445076942443848], step: 117200, lr: 5.565982242545444e-05, reference_loss: 20.520769119262695
2024-01-02 23:26:54,966	44k	INFO	====> Epoch: 4688, cost 22.75 s
2024-01-02 23:27:17,486	44k	INFO	====> Epoch: 4689, cost 22.52 s
2024-01-02 23:27:39,767	44k	INFO	====> Epoch: 4690, cost 22.28 s
2024-01-02 23:28:02,055	44k	INFO	====> Epoch: 4691, cost 22.29 s
2024-01-02 23:28:24,458	44k	INFO	====> Epoch: 4692, cost 22.40 s
2024-01-02 23:28:46,833	44k	INFO	====> Epoch: 4693, cost 22.37 s
2024-01-02 23:29:09,357	44k	INFO	====> Epoch: 4694, cost 22.52 s
2024-01-02 23:29:31,685	44k	INFO	====> Epoch: 4695, cost 22.33 s
2024-01-02 23:29:53,953	44k	INFO	Train Epoch: 4696 [96%]
2024-01-02 23:29:53,955	44k	INFO	Losses: [1.4680730104446411, 3.5775585174560547, 10.887754440307617, 11.076400756835938, -4.072510719299316], step: 117400, lr: 5.5604186948114444e-05, reference_loss: 22.937274932861328
2024-01-02 23:29:54,356	44k	INFO	====> Epoch: 4696, cost 22.67 s
2024-01-02 23:30:16,728	44k	INFO	====> Epoch: 4697, cost 22.37 s
2024-01-02 23:30:38,898	44k	INFO	====> Epoch: 4698, cost 22.17 s
2024-01-02 23:31:01,026	44k	INFO	====> Epoch: 4699, cost 22.13 s
2024-01-02 23:31:23,303	44k	INFO	====> Epoch: 4700, cost 22.28 s
2024-01-02 23:31:45,544	44k	INFO	====> Epoch: 4701, cost 22.24 s
2024-01-02 23:32:07,826	44k	INFO	====> Epoch: 4702, cost 22.28 s
2024-01-02 23:32:30,169	44k	INFO	====> Epoch: 4703, cost 22.34 s
2024-01-02 23:32:52,674	44k	INFO	Train Epoch: 4704 [96%]
2024-01-02 23:32:52,676	44k	INFO	Losses: [1.705731987953186, 3.050682783126831, 10.149984359741211, 11.405211448669434, -3.9873011112213135], step: 117600, lr: 5.554860708191734e-05, reference_loss: 22.324310302734375
2024-01-02 23:32:58,552	44k	INFO	Saving model and optimizer state at iteration 4704 to ./logs/44k/G_117600.pth
2024-01-02 23:32:59,482	44k	INFO	Saving model and optimizer state at iteration 4704 to ./logs/44k/D_117600.pth
2024-01-02 23:32:59,982	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_115200.pth
2024-01-02 23:33:00,021	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_115200.pth
2024-01-02 23:33:00,021	44k	INFO	====> Epoch: 4704, cost 29.85 s
2024-01-02 23:33:22,171	44k	INFO	====> Epoch: 4705, cost 22.15 s
2024-01-02 23:33:44,615	44k	INFO	====> Epoch: 4706, cost 22.44 s
2024-01-02 23:34:06,868	44k	INFO	====> Epoch: 4707, cost 22.25 s
2024-01-02 23:34:29,017	44k	INFO	====> Epoch: 4708, cost 22.15 s
2024-01-02 23:34:51,082	44k	INFO	====> Epoch: 4709, cost 22.06 s
2024-01-02 23:35:13,166	44k	INFO	====> Epoch: 4710, cost 22.08 s
2024-01-02 23:35:35,637	44k	INFO	====> Epoch: 4711, cost 22.47 s
2024-01-02 23:35:57,969	44k	INFO	Train Epoch: 4712 [96%]
2024-01-02 23:35:57,972	44k	INFO	Losses: [1.5297566652297974, 3.3520054817199707, 9.861685752868652, 10.83265209197998, -3.8833208084106445], step: 117800, lr: 5.5493082771276316e-05, reference_loss: 21.692779541015625
2024-01-02 23:35:58,347	44k	INFO	====> Epoch: 4712, cost 22.71 s
2024-01-02 23:36:20,554	44k	INFO	====> Epoch: 4713, cost 22.21 s
2024-01-02 23:36:42,786	44k	INFO	====> Epoch: 4714, cost 22.23 s
2024-01-02 23:37:05,263	44k	INFO	====> Epoch: 4715, cost 22.48 s
2024-01-02 23:37:27,567	44k	INFO	====> Epoch: 4716, cost 22.30 s
2024-01-02 23:37:49,837	44k	INFO	====> Epoch: 4717, cost 22.27 s
2024-01-02 23:38:12,189	44k	INFO	====> Epoch: 4718, cost 22.35 s
2024-01-02 23:38:34,546	44k	INFO	====> Epoch: 4719, cost 22.36 s
2024-01-02 23:38:56,923	44k	INFO	Train Epoch: 4720 [96%]
2024-01-02 23:38:56,924	44k	INFO	Losses: [1.9323575496673584, 3.368959426879883, 9.16623306274414, 10.793105125427246, -3.897170066833496], step: 118000, lr: 5.5437613960660135e-05, reference_loss: 21.363483428955078
2024-01-02 23:38:57,635	44k	INFO	====> Epoch: 4720, cost 23.09 s
2024-01-02 23:39:20,050	44k	INFO	====> Epoch: 4721, cost 22.41 s
2024-01-02 23:39:42,392	44k	INFO	====> Epoch: 4722, cost 22.34 s
2024-01-02 23:40:04,744	44k	INFO	====> Epoch: 4723, cost 22.35 s
2024-01-02 23:40:27,242	44k	INFO	====> Epoch: 4724, cost 22.50 s
2024-01-02 23:40:49,667	44k	INFO	====> Epoch: 4725, cost 22.42 s
2024-01-02 23:41:12,046	44k	INFO	====> Epoch: 4726, cost 22.38 s
2024-01-02 23:41:34,425	44k	INFO	====> Epoch: 4727, cost 22.38 s
2024-01-02 23:41:56,804	44k	INFO	Train Epoch: 4728 [96%]
2024-01-02 23:41:56,806	44k	INFO	Losses: [1.4570151567459106, 3.5496835708618164, 11.002043724060059, 10.923896789550781, -4.0248517990112305], step: 118200, lr: 5.5382200594593026e-05, reference_loss: 22.907787322998047
2024-01-02 23:41:57,215	44k	INFO	====> Epoch: 4728, cost 22.79 s
2024-01-02 23:42:19,670	44k	INFO	====> Epoch: 4729, cost 22.46 s
2024-01-02 23:42:42,189	44k	INFO	====> Epoch: 4730, cost 22.52 s
2024-01-02 23:43:04,469	44k	INFO	====> Epoch: 4731, cost 22.28 s
2024-01-02 23:43:26,959	44k	INFO	====> Epoch: 4732, cost 22.49 s
2024-01-02 23:43:49,366	44k	INFO	====> Epoch: 4733, cost 22.41 s
2024-01-02 23:44:11,679	44k	INFO	====> Epoch: 4734, cost 22.31 s
2024-01-02 23:44:34,059	44k	INFO	====> Epoch: 4735, cost 22.38 s
2024-01-02 23:44:56,392	44k	INFO	Train Epoch: 4736 [96%]
2024-01-02 23:44:56,394	44k	INFO	Losses: [1.7629767656326294, 2.896937847137451, 8.425819396972656, 10.346556663513184, -4.031816482543945], step: 118400, lr: 5.5326842617654685e-05, reference_loss: 19.40047264099121
2024-01-02 23:45:02,222	44k	INFO	Saving model and optimizer state at iteration 4736 to ./logs/44k/G_118400.pth
2024-01-02 23:45:03,117	44k	INFO	Saving model and optimizer state at iteration 4736 to ./logs/44k/D_118400.pth
2024-01-02 23:45:03,623	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_116000.pth
2024-01-02 23:45:03,662	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_116000.pth
2024-01-02 23:45:03,662	44k	INFO	====> Epoch: 4736, cost 29.60 s
2024-01-02 23:45:25,956	44k	INFO	====> Epoch: 4737, cost 22.29 s
2024-01-02 23:45:48,452	44k	INFO	====> Epoch: 4738, cost 22.50 s
2024-01-02 23:46:10,802	44k	INFO	====> Epoch: 4739, cost 22.35 s
2024-01-02 23:46:32,926	44k	INFO	====> Epoch: 4740, cost 22.12 s
2024-01-02 23:46:55,132	44k	INFO	====> Epoch: 4741, cost 22.21 s
2024-01-02 23:47:17,209	44k	INFO	====> Epoch: 4742, cost 22.08 s
2024-01-02 23:47:39,303	44k	INFO	====> Epoch: 4743, cost 22.09 s
2024-01-02 23:48:01,448	44k	INFO	Train Epoch: 4744 [96%]
2024-01-02 23:48:01,450	44k	INFO	Losses: [1.5691453218460083, 3.4138035774230957, 11.843070030212402, 11.682470321655273, -3.8986055850982666], step: 118600, lr: 5.5271539974480236e-05, reference_loss: 24.60988426208496
2024-01-02 23:48:01,850	44k	INFO	====> Epoch: 4744, cost 22.55 s
2024-01-02 23:48:24,028	44k	INFO	====> Epoch: 4745, cost 22.18 s
2024-01-02 23:48:46,286	44k	INFO	====> Epoch: 4746, cost 22.26 s
2024-01-02 23:49:08,474	44k	INFO	====> Epoch: 4747, cost 22.19 s
2024-01-02 23:49:30,777	44k	INFO	====> Epoch: 4748, cost 22.30 s
2024-01-02 23:49:53,134	44k	INFO	====> Epoch: 4749, cost 22.36 s
2024-01-02 23:50:15,532	44k	INFO	====> Epoch: 4750, cost 22.40 s
2024-01-02 23:50:37,788	44k	INFO	====> Epoch: 4751, cost 22.26 s
2024-01-02 23:51:00,066	44k	INFO	Train Epoch: 4752 [96%]
2024-01-02 23:51:00,068	44k	INFO	Losses: [1.9107112884521484, 3.149348020553589, 7.477781295776367, 9.800368309020996, -3.8642802238464355], step: 118800, lr: 5.52162926097601e-05, reference_loss: 18.473928451538086
2024-01-02 23:51:00,455	44k	INFO	====> Epoch: 4752, cost 22.67 s
2024-01-02 23:51:22,722	44k	INFO	====> Epoch: 4753, cost 22.27 s
2024-01-02 23:51:44,967	44k	INFO	====> Epoch: 4754, cost 22.25 s
2024-01-02 23:52:07,211	44k	INFO	====> Epoch: 4755, cost 22.24 s
2024-01-02 23:52:29,469	44k	INFO	====> Epoch: 4756, cost 22.26 s
2024-01-02 23:52:51,773	44k	INFO	====> Epoch: 4757, cost 22.30 s
2024-01-02 23:53:14,145	44k	INFO	====> Epoch: 4758, cost 22.37 s
2024-01-02 23:53:36,420	44k	INFO	====> Epoch: 4759, cost 22.28 s
2024-01-02 23:53:58,679	44k	INFO	Train Epoch: 4760 [96%]
2024-01-02 23:53:58,681	44k	INFO	Losses: [1.481177568435669, 3.469337224960327, 10.15134334564209, 10.888409614562988, -4.176958084106445], step: 119000, lr: 5.516110046824e-05, reference_loss: 21.813310623168945
2024-01-02 23:53:59,231	44k	INFO	====> Epoch: 4760, cost 22.81 s
2024-01-02 23:54:21,476	44k	INFO	====> Epoch: 4761, cost 22.24 s
2024-01-02 23:54:43,737	44k	INFO	====> Epoch: 4762, cost 22.26 s
2024-01-02 23:55:05,947	44k	INFO	====> Epoch: 4763, cost 22.21 s
2024-01-02 23:55:28,183	44k	INFO	====> Epoch: 4764, cost 22.24 s
2024-01-02 23:55:50,410	44k	INFO	====> Epoch: 4765, cost 22.23 s
2024-01-02 23:56:12,620	44k	INFO	====> Epoch: 4766, cost 22.21 s
2024-01-02 23:56:34,841	44k	INFO	====> Epoch: 4767, cost 22.22 s
2024-01-02 23:56:57,107	44k	INFO	Train Epoch: 4768 [96%]
2024-01-02 23:56:57,109	44k	INFO	Losses: [1.6881041526794434, 3.2038164138793945, 9.77878189086914, 10.427681922912598, -3.931027889251709], step: 119200, lr: 5.510596349472089e-05, reference_loss: 21.167356491088867
2024-01-02 23:57:02,918	44k	INFO	Saving model and optimizer state at iteration 4768 to ./logs/44k/G_119200.pth
2024-01-02 23:57:03,814	44k	INFO	Saving model and optimizer state at iteration 4768 to ./logs/44k/D_119200.pth
2024-01-02 23:57:04,313	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_116800.pth
2024-01-02 23:57:04,351	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_116800.pth
2024-01-02 23:57:04,351	44k	INFO	====> Epoch: 4768, cost 29.51 s
2024-01-02 23:57:26,635	44k	INFO	====> Epoch: 4769, cost 22.28 s
2024-01-02 23:57:48,975	44k	INFO	====> Epoch: 4770, cost 22.34 s
2024-01-02 23:58:11,280	44k	INFO	====> Epoch: 4771, cost 22.31 s
2024-01-02 23:58:33,509	44k	INFO	====> Epoch: 4772, cost 22.23 s
2024-01-02 23:58:55,734	44k	INFO	====> Epoch: 4773, cost 22.22 s
2024-01-02 23:59:18,074	44k	INFO	====> Epoch: 4774, cost 22.34 s
2024-01-02 23:59:40,395	44k	INFO	====> Epoch: 4775, cost 22.32 s
2024-01-03 00:00:02,613	44k	INFO	Train Epoch: 4776 [96%]
2024-01-03 00:00:02,616	44k	INFO	Losses: [1.5437155961990356, 3.190150499343872, 9.532478332519531, 10.894240379333496, -3.9928767681121826], step: 119400, lr: 5.505088163405891e-05, reference_loss: 21.167707443237305
2024-01-03 00:00:02,995	44k	INFO	====> Epoch: 4776, cost 22.60 s
2024-01-03 00:00:25,191	44k	INFO	====> Epoch: 4777, cost 22.20 s
2024-01-03 00:00:47,446	44k	INFO	====> Epoch: 4778, cost 22.25 s
2024-01-03 00:01:09,684	44k	INFO	====> Epoch: 4779, cost 22.24 s
2024-01-03 00:01:31,979	44k	INFO	====> Epoch: 4780, cost 22.30 s
2024-01-03 00:01:54,282	44k	INFO	====> Epoch: 4781, cost 22.30 s
2024-01-03 00:02:16,529	44k	INFO	====> Epoch: 4782, cost 22.25 s
2024-01-03 00:02:38,756	44k	INFO	====> Epoch: 4783, cost 22.23 s
2024-01-03 00:03:01,027	44k	INFO	Train Epoch: 4784 [96%]
2024-01-03 00:03:01,029	44k	INFO	Losses: [1.8520874977111816, 3.25115966796875, 7.748580455780029, 9.278836250305176, -3.907172918319702], step: 119600, lr: 5.49958548311653e-05, reference_loss: 18.223491668701172
2024-01-03 00:03:01,409	44k	INFO	====> Epoch: 4784, cost 22.65 s
2024-01-03 00:03:23,729	44k	INFO	====> Epoch: 4785, cost 22.32 s
2024-01-03 00:03:45,951	44k	INFO	====> Epoch: 4786, cost 22.22 s
2024-01-03 00:04:08,117	44k	INFO	====> Epoch: 4787, cost 22.17 s
2024-01-03 00:04:30,258	44k	INFO	====> Epoch: 4788, cost 22.14 s
2024-01-03 00:04:52,518	44k	INFO	====> Epoch: 4789, cost 22.26 s
2024-01-03 00:05:14,967	44k	INFO	====> Epoch: 4790, cost 22.45 s
2024-01-03 00:05:37,250	44k	INFO	====> Epoch: 4791, cost 22.28 s
2024-01-03 00:05:59,542	44k	INFO	Train Epoch: 4792 [96%]
2024-01-03 00:05:59,544	44k	INFO	Losses: [1.4100492000579834, 3.8217356204986572, 11.531624794006348, 11.66959285736084, -4.18126106262207], step: 119800, lr: 5.494088303100637e-05, reference_loss: 24.251741409301758
2024-01-03 00:05:59,930	44k	INFO	====> Epoch: 4792, cost 22.68 s
2024-01-03 00:06:22,199	44k	INFO	====> Epoch: 4793, cost 22.27 s
2024-01-03 00:06:44,506	44k	INFO	====> Epoch: 4794, cost 22.31 s
2024-01-03 00:07:06,838	44k	INFO	====> Epoch: 4795, cost 22.33 s
2024-01-03 00:07:29,209	44k	INFO	====> Epoch: 4796, cost 22.37 s
2024-01-03 00:07:51,422	44k	INFO	====> Epoch: 4797, cost 22.21 s
2024-01-03 00:08:13,722	44k	INFO	====> Epoch: 4798, cost 22.30 s
2024-01-03 00:08:35,964	44k	INFO	====> Epoch: 4799, cost 22.24 s
2024-01-03 00:08:58,369	44k	INFO	Train Epoch: 4800 [96%]
2024-01-03 00:08:58,370	44k	INFO	Losses: [1.7806789875030518, 3.1496317386627197, 10.260513305664062, 10.574140548706055, -4.117551803588867], step: 120000, lr: 5.4885966178603446e-05, reference_loss: 21.64741325378418
2024-01-03 00:09:04,458	44k	INFO	Saving model and optimizer state at iteration 4800 to ./logs/44k/G_120000.pth
2024-01-03 00:09:05,379	44k	INFO	Saving model and optimizer state at iteration 4800 to ./logs/44k/D_120000.pth
2024-01-03 00:09:05,887	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_117600.pth
2024-01-03 00:09:05,926	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_117600.pth
2024-01-03 00:09:05,926	44k	INFO	====> Epoch: 4800, cost 29.96 s
2024-01-03 00:09:28,164	44k	INFO	====> Epoch: 4801, cost 22.24 s
2024-01-03 00:09:50,306	44k	INFO	====> Epoch: 4802, cost 22.14 s
2024-01-03 00:10:12,504	44k	INFO	====> Epoch: 4803, cost 22.20 s
2024-01-03 00:10:34,668	44k	INFO	====> Epoch: 4804, cost 22.16 s
2024-01-03 00:10:56,827	44k	INFO	====> Epoch: 4805, cost 22.16 s
2024-01-03 00:11:18,952	44k	INFO	====> Epoch: 4806, cost 22.13 s
2024-01-03 00:11:41,252	44k	INFO	====> Epoch: 4807, cost 22.30 s
2024-01-03 00:12:03,341	44k	INFO	Train Epoch: 4808 [96%]
2024-01-03 00:12:03,343	44k	INFO	Losses: [1.5975751876831055, 3.2354469299316406, 11.34579086303711, 11.500661849975586, -3.9924659729003906], step: 120200, lr: 5.483110421903282e-05, reference_loss: 23.687009811401367
2024-01-03 00:12:03,737	44k	INFO	====> Epoch: 4808, cost 22.49 s
2024-01-03 00:12:26,059	44k	INFO	====> Epoch: 4809, cost 22.32 s
2024-01-03 00:12:48,406	44k	INFO	====> Epoch: 4810, cost 22.35 s
2024-01-03 00:13:10,752	44k	INFO	====> Epoch: 4811, cost 22.35 s
2024-01-03 00:13:32,973	44k	INFO	====> Epoch: 4812, cost 22.22 s
2024-01-03 00:13:55,278	44k	INFO	====> Epoch: 4813, cost 22.31 s
2024-01-03 00:14:17,557	44k	INFO	====> Epoch: 4814, cost 22.28 s
2024-01-03 00:14:39,716	44k	INFO	====> Epoch: 4815, cost 22.16 s
2024-01-03 00:15:02,028	44k	INFO	Train Epoch: 4816 [96%]
2024-01-03 00:15:02,030	44k	INFO	Losses: [1.8185005187988281, 2.900911331176758, 7.667906284332275, 8.721622467041016, -3.925794839859009], step: 120400, lr: 5.477629709742565e-05, reference_loss: 17.18314552307129
2024-01-03 00:15:02,618	44k	INFO	====> Epoch: 4816, cost 22.90 s
2024-01-03 00:15:24,959	44k	INFO	====> Epoch: 4817, cost 22.34 s
2024-01-03 00:15:47,202	44k	INFO	====> Epoch: 4818, cost 22.24 s
2024-01-03 00:16:09,422	44k	INFO	====> Epoch: 4819, cost 22.22 s
2024-01-03 00:16:31,691	44k	INFO	====> Epoch: 4820, cost 22.27 s
2024-01-03 00:16:54,061	44k	INFO	====> Epoch: 4821, cost 22.37 s
2024-01-03 00:17:16,389	44k	INFO	====> Epoch: 4822, cost 22.33 s
2024-01-03 00:17:38,778	44k	INFO	====> Epoch: 4823, cost 22.39 s
2024-01-03 00:18:01,191	44k	INFO	Train Epoch: 4824 [96%]
2024-01-03 00:18:01,193	44k	INFO	Losses: [1.4124159812927246, 3.462909698486328, 10.892229080200195, 10.895434379577637, -4.2071380615234375], step: 120600, lr: 5.472154475896797e-05, reference_loss: 22.455852508544922
2024-01-03 00:18:01,594	44k	INFO	====> Epoch: 4824, cost 22.82 s
2024-01-03 00:18:23,950	44k	INFO	====> Epoch: 4825, cost 22.36 s
2024-01-03 00:18:46,521	44k	INFO	====> Epoch: 4826, cost 22.57 s
2024-01-03 00:19:08,842	44k	INFO	====> Epoch: 4827, cost 22.32 s
2024-01-03 00:19:31,174	44k	INFO	====> Epoch: 4828, cost 22.33 s
2024-01-03 00:19:53,456	44k	INFO	====> Epoch: 4829, cost 22.28 s
2024-01-03 00:20:15,741	44k	INFO	====> Epoch: 4830, cost 22.28 s
2024-01-03 00:20:38,061	44k	INFO	====> Epoch: 4831, cost 22.32 s
2024-01-03 00:21:00,361	44k	INFO	Train Epoch: 4832 [96%]
2024-01-03 00:21:00,362	44k	INFO	Losses: [1.7414195537567139, 2.9787774085998535, 8.549221992492676, 10.294944763183594, -4.1331257820129395], step: 120800, lr: 5.466684714890058e-05, reference_loss: 19.431238174438477
2024-01-03 00:21:06,561	44k	INFO	Saving model and optimizer state at iteration 4832 to ./logs/44k/G_120800.pth
2024-01-03 00:21:07,503	44k	INFO	Saving model and optimizer state at iteration 4832 to ./logs/44k/D_120800.pth
2024-01-03 00:21:08,020	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_118400.pth
2024-01-03 00:21:08,059	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_118400.pth
2024-01-03 00:21:08,059	44k	INFO	====> Epoch: 4832, cost 30.00 s
2024-01-03 00:21:30,336	44k	INFO	====> Epoch: 4833, cost 22.28 s
2024-01-03 00:21:52,850	44k	INFO	====> Epoch: 4834, cost 22.51 s
2024-01-03 00:22:15,166	44k	INFO	====> Epoch: 4835, cost 22.32 s
2024-01-03 00:22:37,330	44k	INFO	====> Epoch: 4836, cost 22.16 s
2024-01-03 00:22:59,573	44k	INFO	====> Epoch: 4837, cost 22.24 s
2024-01-03 00:23:21,776	44k	INFO	====> Epoch: 4838, cost 22.20 s
2024-01-03 00:23:43,982	44k	INFO	====> Epoch: 4839, cost 22.21 s
2024-01-03 00:24:06,257	44k	INFO	Train Epoch: 4840 [96%]
2024-01-03 00:24:06,258	44k	INFO	Losses: [1.5229088068008423, 3.1312646865844727, 9.872699737548828, 10.512669563293457, -4.052101135253906], step: 121000, lr: 5.461220421251903e-05, reference_loss: 20.987442016601562
2024-01-03 00:24:06,652	44k	INFO	====> Epoch: 4840, cost 22.67 s
2024-01-03 00:24:28,990	44k	INFO	====> Epoch: 4841, cost 22.34 s
2024-01-03 00:24:51,324	44k	INFO	====> Epoch: 4842, cost 22.33 s
2024-01-03 00:25:13,770	44k	INFO	====> Epoch: 4843, cost 22.45 s
2024-01-03 00:25:36,075	44k	INFO	====> Epoch: 4844, cost 22.30 s
2024-01-03 00:25:58,344	44k	INFO	====> Epoch: 4845, cost 22.27 s
2024-01-03 00:26:20,785	44k	INFO	====> Epoch: 4846, cost 22.44 s
2024-01-03 00:26:42,934	44k	INFO	====> Epoch: 4847, cost 22.15 s
2024-01-03 00:27:05,101	44k	INFO	Train Epoch: 4848 [96%]
2024-01-03 00:27:05,103	44k	INFO	Losses: [1.958423137664795, 3.2260682582855225, 8.605182647705078, 10.40119457244873, -4.050584316253662], step: 121200, lr: 5.455761589517355e-05, reference_loss: 20.140283584594727
2024-01-03 00:27:05,591	44k	INFO	====> Epoch: 4848, cost 22.66 s
2024-01-03 00:27:27,995	44k	INFO	====> Epoch: 4849, cost 22.40 s
2024-01-03 00:27:50,364	44k	INFO	====> Epoch: 4850, cost 22.37 s
2024-01-03 00:28:12,696	44k	INFO	====> Epoch: 4851, cost 22.33 s
2024-01-03 00:28:34,971	44k	INFO	====> Epoch: 4852, cost 22.27 s
2024-01-03 00:28:57,198	44k	INFO	====> Epoch: 4853, cost 22.23 s
2024-01-03 00:29:19,348	44k	INFO	====> Epoch: 4854, cost 22.15 s
2024-01-03 00:29:41,511	44k	INFO	====> Epoch: 4855, cost 22.16 s
2024-01-03 00:30:03,766	44k	INFO	Train Epoch: 4856 [96%]
2024-01-03 00:30:03,768	44k	INFO	Losses: [1.3887251615524292, 3.857700824737549, 12.332281112670898, 11.529212951660156, -4.309846878051758], step: 121400, lr: 5.450308214226902e-05, reference_loss: 24.798072814941406
2024-01-03 00:30:04,348	44k	INFO	====> Epoch: 4856, cost 22.84 s
2024-01-03 00:30:26,529	44k	INFO	====> Epoch: 4857, cost 22.18 s
2024-01-03 00:30:48,709	44k	INFO	====> Epoch: 4858, cost 22.18 s
2024-01-03 00:31:11,044	44k	INFO	====> Epoch: 4859, cost 22.33 s
2024-01-03 00:31:33,415	44k	INFO	====> Epoch: 4860, cost 22.37 s
2024-01-03 00:31:55,813	44k	INFO	====> Epoch: 4861, cost 22.40 s
2024-01-03 00:32:18,245	44k	INFO	====> Epoch: 4862, cost 22.43 s
2024-01-03 00:32:40,559	44k	INFO	====> Epoch: 4863, cost 22.31 s
2024-01-03 00:33:02,777	44k	INFO	Train Epoch: 4864 [96%]
2024-01-03 00:33:02,779	44k	INFO	Losses: [1.7374413013458252, 2.82460880279541, 8.763335227966309, 10.240747451782227, -4.169668197631836], step: 121600, lr: 5.4448602899264825e-05, reference_loss: 19.39646339416504
2024-01-03 00:33:09,224	44k	INFO	Saving model and optimizer state at iteration 4864 to ./logs/44k/G_121600.pth
2024-01-03 00:33:10,162	44k	INFO	Saving model and optimizer state at iteration 4864 to ./logs/44k/D_121600.pth
2024-01-03 00:33:10,691	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_119200.pth
2024-01-03 00:33:10,730	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_119200.pth
2024-01-03 00:33:10,730	44k	INFO	====> Epoch: 4864, cost 30.17 s
2024-01-03 00:33:33,135	44k	INFO	====> Epoch: 4865, cost 22.40 s
2024-01-03 00:33:55,557	44k	INFO	====> Epoch: 4866, cost 22.42 s
2024-01-03 00:34:17,948	44k	INFO	====> Epoch: 4867, cost 22.39 s
2024-01-03 00:34:40,378	44k	INFO	====> Epoch: 4868, cost 22.43 s
2024-01-03 00:35:02,873	44k	INFO	====> Epoch: 4869, cost 22.49 s
2024-01-03 00:35:25,234	44k	INFO	====> Epoch: 4870, cost 22.36 s
2024-01-03 00:35:47,661	44k	INFO	====> Epoch: 4871, cost 22.43 s
2024-01-03 00:36:10,105	44k	INFO	Train Epoch: 4872 [96%]
2024-01-03 00:36:10,107	44k	INFO	Losses: [1.4856501817703247, 3.1581456661224365, 9.902694702148438, 10.61400032043457, -4.031191825866699], step: 121800, lr: 5.4394178111674926e-05, reference_loss: 21.12929916381836
2024-01-03 00:36:10,604	44k	INFO	====> Epoch: 4872, cost 22.94 s
2024-01-03 00:36:33,106	44k	INFO	====> Epoch: 4873, cost 22.50 s
2024-01-03 00:36:55,555	44k	INFO	====> Epoch: 4874, cost 22.45 s
2024-01-03 00:37:17,879	44k	INFO	====> Epoch: 4875, cost 22.32 s
2024-01-03 00:37:40,394	44k	INFO	====> Epoch: 4876, cost 22.51 s
2024-01-03 00:38:02,701	44k	INFO	====> Epoch: 4877, cost 22.31 s
2024-01-03 00:38:25,027	44k	INFO	====> Epoch: 4878, cost 22.33 s
2024-01-03 00:38:47,405	44k	INFO	====> Epoch: 4879, cost 22.38 s
2024-01-03 00:39:09,768	44k	INFO	Train Epoch: 4880 [96%]
2024-01-03 00:39:09,769	44k	INFO	Losses: [1.852874994277954, 3.2202601432800293, 8.339187622070312, 10.328068733215332, -4.075993061065674], step: 122000, lr: 5.433980772506773e-05, reference_loss: 19.664398193359375
2024-01-03 00:39:10,171	44k	INFO	====> Epoch: 4880, cost 22.77 s
2024-01-03 00:39:32,433	44k	INFO	====> Epoch: 4881, cost 22.26 s
2024-01-03 00:39:54,652	44k	INFO	====> Epoch: 4882, cost 22.22 s
2024-01-03 00:40:17,004	44k	INFO	====> Epoch: 4883, cost 22.35 s
2024-01-03 00:40:39,356	44k	INFO	====> Epoch: 4884, cost 22.35 s
2024-01-03 00:41:01,641	44k	INFO	====> Epoch: 4885, cost 22.29 s
2024-01-03 00:41:24,239	44k	INFO	====> Epoch: 4886, cost 22.60 s
2024-01-03 00:41:46,618	44k	INFO	====> Epoch: 4887, cost 22.38 s
2024-01-03 00:42:08,998	44k	INFO	Train Epoch: 4888 [96%]
2024-01-03 00:42:09,000	44k	INFO	Losses: [1.4686429500579834, 3.503235101699829, 10.556797981262207, 10.77476692199707, -4.216072082519531], step: 122200, lr: 5.428549168506604e-05, reference_loss: 22.087371826171875
2024-01-03 00:42:09,400	44k	INFO	====> Epoch: 4888, cost 22.78 s
2024-01-03 00:42:31,759	44k	INFO	====> Epoch: 4889, cost 22.36 s
2024-01-03 00:42:54,096	44k	INFO	====> Epoch: 4890, cost 22.34 s
2024-01-03 00:43:16,506	44k	INFO	====> Epoch: 4891, cost 22.41 s
2024-01-03 00:43:39,002	44k	INFO	====> Epoch: 4892, cost 22.50 s
2024-01-03 00:44:01,394	44k	INFO	====> Epoch: 4893, cost 22.39 s
2024-01-03 00:44:23,781	44k	INFO	====> Epoch: 4894, cost 22.39 s
2024-01-03 00:44:46,105	44k	INFO	====> Epoch: 4895, cost 22.32 s
2024-01-03 00:45:08,654	44k	INFO	Train Epoch: 4896 [96%]
2024-01-03 00:45:08,656	44k	INFO	Losses: [1.7915236949920654, 2.7749712467193604, 8.457574844360352, 9.872681617736816, -4.206149101257324], step: 122400, lr: 5.423122993734702e-05, reference_loss: 18.690601348876953
2024-01-03 00:45:15,307	44k	INFO	Saving model and optimizer state at iteration 4896 to ./logs/44k/G_122400.pth
2024-01-03 00:45:16,308	44k	INFO	Saving model and optimizer state at iteration 4896 to ./logs/44k/D_122400.pth
2024-01-03 00:45:16,861	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_120000.pth
2024-01-03 00:45:16,901	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_120000.pth
2024-01-03 00:45:16,902	44k	INFO	====> Epoch: 4896, cost 30.80 s
2024-01-03 00:45:39,303	44k	INFO	====> Epoch: 4897, cost 22.40 s
2024-01-03 00:46:01,574	44k	INFO	====> Epoch: 4898, cost 22.27 s
2024-01-03 00:46:23,748	44k	INFO	====> Epoch: 4899, cost 22.17 s
2024-01-03 00:46:46,108	44k	INFO	====> Epoch: 4900, cost 22.36 s
2024-01-03 00:47:08,442	44k	INFO	====> Epoch: 4901, cost 22.33 s
2024-01-03 00:47:30,777	44k	INFO	====> Epoch: 4902, cost 22.34 s
2024-01-03 00:47:53,330	44k	INFO	====> Epoch: 4903, cost 22.55 s
2024-01-03 00:48:15,641	44k	INFO	Train Epoch: 4904 [96%]
2024-01-03 00:48:15,642	44k	INFO	Losses: [1.5558050870895386, 3.749952554702759, 11.698956489562988, 11.300725936889648, -4.137161731719971], step: 122600, lr: 5.4177022427642134e-05, reference_loss: 24.16827964782715
2024-01-03 00:48:16,041	44k	INFO	====> Epoch: 4904, cost 22.71 s
2024-01-03 00:48:38,310	44k	INFO	====> Epoch: 4905, cost 22.27 s
2024-01-03 00:49:00,675	44k	INFO	====> Epoch: 4906, cost 22.37 s
