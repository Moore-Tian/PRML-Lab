2024-01-01 17:03:47,168	44k	INFO	{'train': {'log_interval': 200, 'eval_interval': 800, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 14, 'fp16_run': False, 'half_type': 'fp16', 'lr_decay': 0.999875, 'segment_size': 10240, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 512, 'port': '8001', 'keep_ckpts': 3, 'all_in_mem': True, 'vol_aug': False}, 'data': {'training_files': 'filelists/train.txt', 'validation_files': 'filelists/val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 44100, 'filter_length': 2048, 'hop_length': 512, 'win_length': 2048, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 22050, 'unit_interpolate_mode': 'nearest'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4, 4], 'n_layers_q': 3, 'n_layers_trans_flow': 3, 'n_flow_layer': 4, 'use_spectral_norm': False, 'gin_channels': 256, 'ssl_dim': 256, 'n_speakers': 1, 'vocoder_name': 'nsf-hifigan', 'speech_encoder': 'hubertsoft', 'speaker_embedding': False, 'vol_embedding': False, 'use_depthwise_conv': False, 'flow_share_parameter': False, 'use_automatic_f0_prediction': True, 'use_transformer_flow': False}, 'spk': {'Ganyu': 0}, 'model_dir': './logs/44k'}
2024-01-01 17:03:47,168	44k	WARNING	/mnt/workspace/so-vits-svc-4.1-Stable is not a git repository, therefore hash value comparison will be ignored.
2024-01-01 17:04:06,416	44k	INFO	Train Epoch: 1 [0%]
2024-01-01 17:04:06,417	44k	INFO	Losses: [5.937051773071289, 5.188920497894287, 1.0170838832855225, 110.44457244873047, 391.2861633300781], step: 0, lr: 0.0001, reference_loss: 513.873779296875
2024-01-01 17:04:16,826	44k	INFO	Saving model and optimizer state at iteration 1 to ./logs/44k/G_0.pth
2024-01-01 17:04:19,295	44k	INFO	Saving model and optimizer state at iteration 1 to ./logs/44k/D_0.pth
2024-01-01 17:04:59,984	44k	INFO	====> Epoch: 1, cost 72.82 s
2024-01-01 17:05:26,177	44k	INFO	====> Epoch: 2, cost 26.19 s
2024-01-01 17:05:52,403	44k	INFO	====> Epoch: 3, cost 26.23 s
2024-01-01 17:06:18,656	44k	INFO	====> Epoch: 4, cost 26.25 s
2024-01-01 17:06:44,837	44k	INFO	====> Epoch: 5, cost 26.18 s
2024-01-01 17:07:04,317	44k	INFO	Train Epoch: 6 [71%]
2024-01-01 17:07:04,317	44k	INFO	Losses: [1.7697572708129883, 3.3206942081451416, 6.694553852081299, 44.61884689331055, 4.0597004890441895], step: 200, lr: 9.993751562304699e-05, reference_loss: 60.46355438232422
2024-01-01 17:07:11,557	44k	INFO	====> Epoch: 6, cost 26.72 s
2024-01-01 17:07:37,887	44k	INFO	====> Epoch: 7, cost 26.33 s
2024-01-01 17:08:04,632	44k	INFO	====> Epoch: 8, cost 26.75 s
2024-01-01 17:08:30,968	44k	INFO	====> Epoch: 9, cost 26.34 s
2024-01-01 17:08:57,295	44k	INFO	====> Epoch: 10, cost 26.33 s
2024-01-01 17:09:23,674	44k	INFO	====> Epoch: 11, cost 26.38 s
2024-01-01 17:09:35,648	44k	INFO	Train Epoch: 12 [43%]
2024-01-01 17:09:35,649	44k	INFO	Losses: [1.668623685836792, 3.1047465801239014, 7.795080661773682, 35.96327209472656, 2.611868381500244], step: 400, lr: 9.986258590528146e-05, reference_loss: 51.143592834472656
2024-01-01 17:09:50,727	44k	INFO	====> Epoch: 12, cost 27.05 s
2024-01-01 17:10:17,077	44k	INFO	====> Epoch: 13, cost 26.35 s
2024-01-01 17:10:43,483	44k	INFO	====> Epoch: 14, cost 26.41 s
2024-01-01 17:11:10,140	44k	INFO	====> Epoch: 15, cost 26.66 s
2024-01-01 17:11:36,499	44k	INFO	====> Epoch: 16, cost 26.36 s
2024-01-01 17:12:02,927	44k	INFO	====> Epoch: 17, cost 26.43 s
2024-01-01 17:12:07,448	44k	INFO	Train Epoch: 18 [14%]
2024-01-01 17:12:07,449	44k	INFO	Losses: [1.4395818710327148, 3.342482805252075, 7.862577438354492, 35.50639724731445, 1.879391074180603], step: 600, lr: 9.978771236724554e-05, reference_loss: 50.03042984008789
2024-01-01 17:20:36,886	44k	INFO	{'train': {'log_interval': 200, 'eval_interval': 800, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 14, 'fp16_run': False, 'half_type': 'fp16', 'lr_decay': 0.999875, 'segment_size': 10240, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 512, 'port': '8001', 'keep_ckpts': 3, 'all_in_mem': True, 'vol_aug': False}, 'data': {'training_files': 'filelists/train.txt', 'validation_files': 'filelists/val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 44100, 'filter_length': 2048, 'hop_length': 512, 'win_length': 2048, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 22050, 'unit_interpolate_mode': 'nearest'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4, 4], 'n_layers_q': 3, 'n_layers_trans_flow': 3, 'n_flow_layer': 4, 'use_spectral_norm': False, 'gin_channels': 256, 'ssl_dim': 256, 'n_speakers': 1, 'vocoder_name': 'nsf-hifigan', 'speech_encoder': 'hubertsoft', 'speaker_embedding': False, 'vol_embedding': False, 'use_depthwise_conv': False, 'flow_share_parameter': False, 'use_automatic_f0_prediction': True, 'use_transformer_flow': False}, 'spk': {'Ganyu': 0}, 'model_dir': './logs/44k'}
2024-01-01 17:20:36,887	44k	WARNING	/mnt/workspace/so-vits-svc-4.1-Stable is not a git repository, therefore hash value comparison will be ignored.
2024-01-01 17:20:44,758	44k	INFO	Loaded checkpoint './logs/44k/G_0.pth' (iteration 1)
2024-01-01 17:20:45,256	44k	INFO	Loaded checkpoint './logs/44k/D_0.pth' (iteration 1)
2024-01-01 17:21:33,744	44k	INFO	====> Epoch: 1, cost 56.86 s
2024-01-01 17:26:52,293	44k	INFO	{'train': {'log_interval': 200, 'eval_interval': 800, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 14, 'fp16_run': False, 'half_type': 'fp16', 'lr_decay': 0.999875, 'segment_size': 10240, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 512, 'port': '8001', 'keep_ckpts': 3, 'all_in_mem': True, 'vol_aug': False}, 'data': {'training_files': 'filelists/train.txt', 'validation_files': 'filelists/val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 44100, 'filter_length': 2048, 'hop_length': 512, 'win_length': 2048, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 22050, 'unit_interpolate_mode': 'nearest'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4, 4], 'n_layers_q': 3, 'n_layers_trans_flow': 3, 'n_flow_layer': 4, 'use_spectral_norm': False, 'gin_channels': 256, 'ssl_dim': 256, 'n_speakers': 1, 'vocoder_name': 'nsf-hifigan', 'speech_encoder': 'hubertsoft', 'speaker_embedding': False, 'vol_embedding': False, 'use_depthwise_conv': False, 'flow_share_parameter': False, 'use_automatic_f0_prediction': True, 'use_transformer_flow': False}, 'spk': {'Ganyu': 0}, 'model_dir': './logs/44k'}
2024-01-01 17:26:52,293	44k	WARNING	/mnt/workspace/so-vits-svc-4.1-Stable is not a git repository, therefore hash value comparison will be ignored.
2024-01-01 17:27:00,153	44k	INFO	Loaded checkpoint './logs/44k/G_0.pth' (iteration 1)
2024-01-01 17:27:00,642	44k	INFO	Loaded checkpoint './logs/44k/D_0.pth' (iteration 1)
2024-01-01 17:27:49,106	44k	INFO	====> Epoch: 1, cost 56.81 s
2024-01-01 17:28:15,428	44k	INFO	====> Epoch: 2, cost 26.32 s
2024-01-01 17:28:41,913	44k	INFO	====> Epoch: 3, cost 26.49 s
2024-01-01 17:29:08,058	44k	INFO	====> Epoch: 4, cost 26.14 s
2024-01-01 17:29:34,202	44k	INFO	====> Epoch: 5, cost 26.14 s
2024-01-01 17:29:52,802	44k	INFO	Train Epoch: 6 [69%]
2024-01-01 17:29:52,803	44k	INFO	Losses: [2.067458152770996, 2.5437827110290527, 4.246684551239014, 48.474430084228516, 3.599186658859253], step: 200, lr: 9.993751562304699e-05, reference_loss: 60.931541442871094
2024-01-01 17:30:00,879	44k	INFO	====> Epoch: 6, cost 26.68 s
2024-01-01 17:30:27,198	44k	INFO	====> Epoch: 7, cost 26.32 s
2024-01-01 17:30:53,433	44k	INFO	====> Epoch: 8, cost 26.23 s
2024-01-01 17:31:19,710	44k	INFO	====> Epoch: 9, cost 26.28 s
2024-01-01 17:31:46,043	44k	INFO	====> Epoch: 10, cost 26.33 s
2024-01-01 17:32:12,688	44k	INFO	====> Epoch: 11, cost 26.65 s
2024-01-01 17:32:23,825	44k	INFO	Train Epoch: 12 [40%]
2024-01-01 17:32:23,826	44k	INFO	Losses: [1.4590988159179688, 2.7076258659362793, 7.837652206420898, 40.703208923339844, 2.7477011680603027], step: 400, lr: 9.986258590528146e-05, reference_loss: 55.45528793334961
2024-01-01 17:32:39,248	44k	INFO	====> Epoch: 12, cost 26.56 s
2024-01-01 17:33:05,536	44k	INFO	====> Epoch: 13, cost 26.29 s
2024-01-01 17:33:31,856	44k	INFO	====> Epoch: 14, cost 26.32 s
2024-01-01 17:33:58,199	44k	INFO	====> Epoch: 15, cost 26.34 s
2024-01-01 17:34:24,457	44k	INFO	====> Epoch: 16, cost 26.26 s
2024-01-01 17:34:50,707	44k	INFO	====> Epoch: 17, cost 26.25 s
2024-01-01 17:34:54,445	44k	INFO	Train Epoch: 18 [11%]
2024-01-01 17:34:54,445	44k	INFO	Losses: [1.7655011415481567, 2.982966423034668, 6.139715671539307, 38.89841079711914, 2.2421505451202393], step: 600, lr: 9.978771236724554e-05, reference_loss: 52.028743743896484
2024-01-01 17:35:17,889	44k	INFO	====> Epoch: 18, cost 27.18 s
2024-01-01 17:35:44,233	44k	INFO	====> Epoch: 19, cost 26.34 s
2024-01-01 17:36:10,555	44k	INFO	====> Epoch: 20, cost 26.32 s
2024-01-01 17:36:36,913	44k	INFO	====> Epoch: 21, cost 26.36 s
2024-01-01 17:37:03,139	44k	INFO	====> Epoch: 22, cost 26.23 s
2024-01-01 17:37:25,594	44k	INFO	Train Epoch: 23 [83%]
2024-01-01 17:37:25,594	44k	INFO	Losses: [1.3387956619262695, 3.6650023460388184, 8.82331657409668, 36.25147247314453, 1.6776988506317139], step: 800, lr: 9.972536063689719e-05, reference_loss: 51.75628662109375
2024-01-01 17:37:36,049	44k	INFO	Saving model and optimizer state at iteration 23 to ./logs/44k/G_800.pth
2024-01-01 17:37:37,303	44k	INFO	Saving model and optimizer state at iteration 23 to ./logs/44k/D_800.pth
2024-01-01 17:37:41,767	44k	INFO	====> Epoch: 23, cost 38.63 s
2024-01-01 17:38:07,911	44k	INFO	====> Epoch: 24, cost 26.14 s
2024-01-01 17:38:34,084	44k	INFO	====> Epoch: 25, cost 26.17 s
2024-01-01 17:39:00,316	44k	INFO	====> Epoch: 26, cost 26.23 s
2024-01-01 17:39:26,595	44k	INFO	====> Epoch: 27, cost 26.28 s
2024-01-01 17:39:52,954	44k	INFO	====> Epoch: 28, cost 26.36 s
2024-01-01 17:40:07,867	44k	INFO	Train Epoch: 29 [54%]
2024-01-01 17:40:07,867	44k	INFO	Losses: [2.1022331714630127, 2.480684757232666, 4.946406364440918, 32.64914321899414, 1.2864397764205933], step: 1000, lr: 9.965058998565574e-05, reference_loss: 43.46490478515625
2024-01-01 17:40:19,735	44k	INFO	====> Epoch: 29, cost 26.78 s
2024-01-01 17:40:46,235	44k	INFO	====> Epoch: 30, cost 26.50 s
2024-01-01 17:41:12,552	44k	INFO	====> Epoch: 31, cost 26.32 s
2024-01-01 17:41:38,871	44k	INFO	====> Epoch: 32, cost 26.32 s
2024-01-01 17:42:05,144	44k	INFO	====> Epoch: 33, cost 26.27 s
2024-01-01 17:42:31,465	44k	INFO	====> Epoch: 34, cost 26.32 s
2024-01-01 17:42:38,924	44k	INFO	Train Epoch: 35 [26%]
2024-01-01 17:42:38,925	44k	INFO	Losses: [1.7164137363433838, 3.04115891456604, 6.65778112411499, 32.98379898071289, 1.7174721956253052], step: 1200, lr: 9.957587539488128e-05, reference_loss: 46.11662673950195
2024-01-01 17:42:58,397	44k	INFO	====> Epoch: 35, cost 26.93 s
2024-01-01 17:43:24,640	44k	INFO	====> Epoch: 36, cost 26.24 s
2024-01-01 17:43:51,191	44k	INFO	====> Epoch: 37, cost 26.55 s
2024-01-01 17:44:17,451	44k	INFO	====> Epoch: 38, cost 26.26 s
2024-01-01 17:44:43,699	44k	INFO	====> Epoch: 39, cost 26.25 s
2024-01-01 17:45:09,997	44k	INFO	Train Epoch: 40 [97%]
2024-01-01 17:45:09,998	44k	INFO	Losses: [2.0659308433532715, 2.711575508117676, 5.7018537521362305, 32.000511169433594, 1.36902916431427], step: 1400, lr: 9.951365602954526e-05, reference_loss: 43.84890365600586
2024-01-01 17:45:10,499	44k	INFO	====> Epoch: 40, cost 26.80 s
2024-01-01 17:45:36,886	44k	INFO	====> Epoch: 41, cost 26.39 s
2024-01-01 17:46:03,109	44k	INFO	====> Epoch: 42, cost 26.22 s
2024-01-01 17:46:29,438	44k	INFO	====> Epoch: 43, cost 26.33 s
2024-01-01 17:46:55,896	44k	INFO	====> Epoch: 44, cost 26.46 s
2024-01-01 17:47:22,238	44k	INFO	====> Epoch: 45, cost 26.34 s
2024-01-01 17:47:40,882	44k	INFO	Train Epoch: 46 [69%]
2024-01-01 17:47:40,883	44k	INFO	Losses: [2.3005731105804443, 2.8507161140441895, 4.316306114196777, 30.8973445892334, 1.361859679222107], step: 1600, lr: 9.943904410714931e-05, reference_loss: 41.72679901123047
2024-01-01 17:47:48,134	44k	INFO	Saving model and optimizer state at iteration 46 to ./logs/44k/G_1600.pth
2024-01-01 17:47:49,072	44k	INFO	Saving model and optimizer state at iteration 46 to ./logs/44k/D_1600.pth
2024-01-01 17:47:57,315	44k	INFO	====> Epoch: 46, cost 35.08 s
2024-01-01 17:48:23,683	44k	INFO	====> Epoch: 47, cost 26.37 s
2024-01-01 17:48:49,992	44k	INFO	====> Epoch: 48, cost 26.31 s
2024-01-01 17:49:16,241	44k	INFO	====> Epoch: 49, cost 26.25 s
2024-01-01 17:49:42,880	44k	INFO	====> Epoch: 50, cost 26.64 s
2024-01-01 17:50:09,255	44k	INFO	====> Epoch: 51, cost 26.37 s
2024-01-01 17:50:20,467	44k	INFO	Train Epoch: 52 [40%]
2024-01-01 17:50:20,468	44k	INFO	Losses: [2.025266647338867, 2.6537747383117676, 5.653040885925293, 29.011348724365234, 1.0847018957138062], step: 1800, lr: 9.936448812621091e-05, reference_loss: 40.428131103515625
2024-01-01 17:50:36,219	44k	INFO	====> Epoch: 52, cost 26.96 s
2024-01-01 17:51:02,543	44k	INFO	====> Epoch: 53, cost 26.32 s
2024-01-01 17:51:28,710	44k	INFO	====> Epoch: 54, cost 26.17 s
2024-01-01 17:51:55,087	44k	INFO	====> Epoch: 55, cost 26.38 s
2024-01-01 17:52:21,358	44k	INFO	====> Epoch: 56, cost 26.27 s
2024-01-01 17:52:47,553	44k	INFO	====> Epoch: 57, cost 26.19 s
2024-01-01 17:52:51,281	44k	INFO	Train Epoch: 58 [11%]
2024-01-01 17:52:51,281	44k	INFO	Losses: [2.7805533409118652, 2.9851253032684326, 4.645794868469238, 27.590742111206055, 1.044232726097107], step: 2000, lr: 9.928998804478705e-05, reference_loss: 39.04644775390625
2024-01-01 17:53:14,608	44k	INFO	====> Epoch: 58, cost 27.06 s
2024-01-01 17:53:40,887	44k	INFO	====> Epoch: 59, cost 26.28 s
2024-01-01 17:54:07,231	44k	INFO	====> Epoch: 60, cost 26.34 s
2024-01-01 17:54:33,583	44k	INFO	====> Epoch: 61, cost 26.35 s
2024-01-01 17:54:59,868	44k	INFO	====> Epoch: 62, cost 26.29 s
2024-01-01 17:55:22,417	44k	INFO	Train Epoch: 63 [83%]
2024-01-01 17:55:22,418	44k	INFO	Losses: [2.1436033248901367, 3.443877935409546, 5.842545986175537, 29.08852767944336, 1.200974702835083], step: 2200, lr: 9.922794731438052e-05, reference_loss: 41.71952819824219
2024-01-01 17:55:26,815	44k	INFO	====> Epoch: 63, cost 26.95 s
2024-01-01 17:55:53,424	44k	INFO	====> Epoch: 64, cost 26.61 s
2024-01-01 17:56:19,527	44k	INFO	====> Epoch: 65, cost 26.10 s
2024-01-01 17:56:45,900	44k	INFO	====> Epoch: 66, cost 26.37 s
2024-01-01 17:57:12,224	44k	INFO	====> Epoch: 67, cost 26.32 s
2024-01-01 17:57:38,428	44k	INFO	====> Epoch: 68, cost 26.20 s
2024-01-01 17:57:53,355	44k	INFO	Train Epoch: 69 [54%]
2024-01-01 17:57:53,356	44k	INFO	Losses: [1.8328298330307007, 2.6437759399414062, 6.355556964874268, 27.520904541015625, 1.194547176361084], step: 2400, lr: 9.915354960656915e-05, reference_loss: 39.547611236572266
2024-01-01 17:58:00,929	44k	INFO	Saving model and optimizer state at iteration 69 to ./logs/44k/G_2400.pth
2024-01-01 17:58:01,865	44k	INFO	Saving model and optimizer state at iteration 69 to ./logs/44k/D_2400.pth
2024-01-01 17:58:14,279	44k	INFO	====> Epoch: 69, cost 35.85 s
2024-01-01 17:58:40,530	44k	INFO	====> Epoch: 70, cost 26.25 s
2024-01-01 17:59:06,800	44k	INFO	====> Epoch: 71, cost 26.27 s
2024-01-01 17:59:33,080	44k	INFO	====> Epoch: 72, cost 26.28 s
2024-01-01 17:59:59,322	44k	INFO	====> Epoch: 73, cost 26.24 s
2024-01-01 18:00:25,582	44k	INFO	====> Epoch: 74, cost 26.26 s
2024-01-01 18:00:33,093	44k	INFO	Train Epoch: 75 [26%]
2024-01-01 18:00:33,094	44k	INFO	Losses: [2.390361785888672, 2.035762310028076, 4.38267183303833, 27.14371109008789, 1.2471132278442383], step: 2600, lr: 9.907920767960457e-05, reference_loss: 37.19961929321289
2024-01-01 18:00:52,667	44k	INFO	====> Epoch: 75, cost 27.09 s
2024-01-01 18:01:18,964	44k	INFO	====> Epoch: 76, cost 26.30 s
2024-01-01 18:01:45,159	44k	INFO	====> Epoch: 77, cost 26.19 s
2024-01-01 18:02:11,422	44k	INFO	====> Epoch: 78, cost 26.26 s
2024-01-01 18:02:37,904	44k	INFO	====> Epoch: 79, cost 26.48 s
2024-01-01 18:03:04,046	44k	INFO	Train Epoch: 80 [97%]
2024-01-01 18:03:04,047	44k	INFO	Losses: [2.104823112487793, 2.6402676105499268, 5.371048927307129, 26.482189178466797, 0.9445818066596985], step: 2800, lr: 9.901729865399597e-05, reference_loss: 37.54290771484375
2024-01-01 18:03:04,539	44k	INFO	====> Epoch: 80, cost 26.63 s
2024-01-01 18:03:30,850	44k	INFO	====> Epoch: 81, cost 26.31 s
2024-01-01 18:03:57,100	44k	INFO	====> Epoch: 82, cost 26.25 s
2024-01-01 18:04:23,463	44k	INFO	====> Epoch: 83, cost 26.36 s
2024-01-01 18:04:49,688	44k	INFO	====> Epoch: 84, cost 26.23 s
2024-01-01 18:05:15,870	44k	INFO	====> Epoch: 85, cost 26.18 s
2024-01-01 18:05:34,794	44k	INFO	Train Epoch: 86 [69%]
2024-01-01 18:05:34,795	44k	INFO	Losses: [2.3019230365753174, 2.362800359725952, 5.210866451263428, 25.848644256591797, 1.2168375253677368], step: 3000, lr: 9.894305888331732e-05, reference_loss: 36.94107437133789
2024-01-01 18:05:42,890	44k	INFO	====> Epoch: 86, cost 27.02 s
2024-01-01 18:06:09,148	44k	INFO	====> Epoch: 87, cost 26.26 s
2024-01-01 18:06:35,459	44k	INFO	====> Epoch: 88, cost 26.31 s
2024-01-01 18:07:01,790	44k	INFO	====> Epoch: 89, cost 26.33 s
2024-01-01 18:07:28,087	44k	INFO	====> Epoch: 90, cost 26.30 s
2024-01-01 18:07:54,386	44k	INFO	====> Epoch: 91, cost 26.30 s
2024-01-01 18:08:05,522	44k	INFO	Train Epoch: 92 [40%]
2024-01-01 18:08:05,523	44k	INFO	Losses: [2.038851261138916, 2.9015116691589355, 6.603696823120117, 29.015005111694336, 1.113816738128662], step: 3200, lr: 9.886887477506964e-05, reference_loss: 41.672882080078125
2024-01-01 18:08:13,226	44k	INFO	Saving model and optimizer state at iteration 92 to ./logs/44k/G_3200.pth
2024-01-01 18:08:14,175	44k	INFO	Saving model and optimizer state at iteration 92 to ./logs/44k/D_3200.pth
2024-01-01 18:08:14,947	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_800.pth
2024-01-01 18:08:15,003	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_800.pth
2024-01-01 18:08:30,072	44k	INFO	====> Epoch: 92, cost 35.69 s
2024-01-01 18:08:56,237	44k	INFO	====> Epoch: 93, cost 26.16 s
2024-01-01 18:09:22,508	44k	INFO	====> Epoch: 94, cost 26.27 s
2024-01-01 18:09:48,846	44k	INFO	====> Epoch: 95, cost 26.34 s
2024-01-01 18:10:15,124	44k	INFO	====> Epoch: 96, cost 26.28 s
2024-01-01 18:10:41,401	44k	INFO	====> Epoch: 97, cost 26.28 s
2024-01-01 18:10:45,154	44k	INFO	Train Epoch: 98 [11%]
2024-01-01 18:10:45,155	44k	INFO	Losses: [2.2291061878204346, 2.966094732284546, 5.031377792358398, 23.990468978881836, 1.1117435693740845], step: 3400, lr: 9.879474628751914e-05, reference_loss: 35.328792572021484
2024-01-01 18:11:08,605	44k	INFO	====> Epoch: 98, cost 27.20 s
2024-01-01 18:11:34,822	44k	INFO	====> Epoch: 99, cost 26.22 s
2024-01-01 18:12:01,059	44k	INFO	====> Epoch: 100, cost 26.24 s
2024-01-01 18:12:27,323	44k	INFO	====> Epoch: 101, cost 26.26 s
2024-01-01 18:12:53,710	44k	INFO	====> Epoch: 102, cost 26.39 s
2024-01-01 18:13:16,082	44k	INFO	Train Epoch: 103 [83%]
2024-01-01 18:13:16,083	44k	INFO	Losses: [2.4666085243225098, 2.202012538909912, 4.419069290161133, 27.318206787109375, 1.0781272649765015], step: 3600, lr: 9.873301500583906e-05, reference_loss: 37.48402786254883
2024-01-01 18:13:20,492	44k	INFO	====> Epoch: 103, cost 26.78 s
2024-01-01 18:13:46,884	44k	INFO	====> Epoch: 104, cost 26.39 s
2024-01-01 18:14:13,463	44k	INFO	====> Epoch: 105, cost 26.58 s
2024-01-01 18:14:39,817	44k	INFO	====> Epoch: 106, cost 26.35 s
2024-01-01 18:15:06,189	44k	INFO	====> Epoch: 107, cost 26.37 s
2024-01-01 18:15:32,331	44k	INFO	====> Epoch: 108, cost 26.14 s
2024-01-01 18:15:47,176	44k	INFO	Train Epoch: 109 [54%]
2024-01-01 18:15:47,176	44k	INFO	Losses: [2.1188950538635254, 2.5939266681671143, 5.6440887451171875, 27.19387435913086, 1.0206965208053589], step: 3800, lr: 9.865898838127865e-05, reference_loss: 38.57147979736328
2024-01-01 18:15:59,024	44k	INFO	====> Epoch: 109, cost 26.69 s
2024-01-01 18:16:25,420	44k	INFO	====> Epoch: 110, cost 26.40 s
2024-01-01 18:16:51,714	44k	INFO	====> Epoch: 111, cost 26.29 s
2024-01-01 18:17:18,371	44k	INFO	====> Epoch: 112, cost 26.66 s
2024-01-01 18:17:44,673	44k	INFO	====> Epoch: 113, cost 26.30 s
2024-01-01 18:18:10,952	44k	INFO	====> Epoch: 114, cost 26.28 s
2024-01-01 18:18:18,419	44k	INFO	Train Epoch: 115 [26%]
2024-01-01 18:18:18,419	44k	INFO	Losses: [2.639437675476074, 2.313047170639038, 4.509664058685303, 26.324739456176758, 1.0847954750061035], step: 4000, lr: 9.858501725933955e-05, reference_loss: 36.87168502807617
2024-01-01 18:18:25,870	44k	INFO	Saving model and optimizer state at iteration 115 to ./logs/44k/G_4000.pth
2024-01-01 18:18:26,777	44k	INFO	Saving model and optimizer state at iteration 115 to ./logs/44k/D_4000.pth
2024-01-01 18:18:27,567	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_1600.pth
2024-01-01 18:18:27,624	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_1600.pth
2024-01-01 18:18:46,461	44k	INFO	====> Epoch: 115, cost 35.51 s
2024-01-01 18:19:12,922	44k	INFO	====> Epoch: 116, cost 26.46 s
2024-01-01 18:19:39,530	44k	INFO	====> Epoch: 117, cost 26.61 s
2024-01-01 18:20:05,943	44k	INFO	====> Epoch: 118, cost 26.41 s
2024-01-01 18:20:32,300	44k	INFO	====> Epoch: 119, cost 26.36 s
2024-01-01 18:20:58,425	44k	INFO	Train Epoch: 120 [97%]
2024-01-01 18:20:58,425	44k	INFO	Losses: [1.9346237182617188, 3.123845338821411, 6.971520900726318, 28.87676239013672, 0.9447272419929504], step: 4200, lr: 9.8523417025536e-05, reference_loss: 41.85148239135742
2024-01-01 18:20:58,918	44k	INFO	====> Epoch: 120, cost 26.62 s
2024-01-01 18:21:25,112	44k	INFO	====> Epoch: 121, cost 26.19 s
2024-01-01 18:21:51,327	44k	INFO	====> Epoch: 122, cost 26.22 s
2024-01-01 18:22:17,541	44k	INFO	====> Epoch: 123, cost 26.21 s
2024-01-01 18:22:43,783	44k	INFO	====> Epoch: 124, cost 26.24 s
2024-01-01 18:23:10,079	44k	INFO	====> Epoch: 125, cost 26.30 s
2024-01-01 18:23:29,110	44k	INFO	Train Epoch: 126 [69%]
2024-01-01 18:23:29,111	44k	INFO	Losses: [2.0172247886657715, 2.890866279602051, 5.861640453338623, 24.9551944732666, 1.2425003051757812], step: 4400, lr: 9.84495475503445e-05, reference_loss: 36.96742630004883
2024-01-01 18:23:37,127	44k	INFO	====> Epoch: 126, cost 27.05 s
2024-01-01 18:24:03,509	44k	INFO	====> Epoch: 127, cost 26.38 s
2024-01-01 18:24:29,667	44k	INFO	====> Epoch: 128, cost 26.16 s
2024-01-01 18:24:55,893	44k	INFO	====> Epoch: 129, cost 26.23 s
2024-01-01 18:25:22,243	44k	INFO	====> Epoch: 130, cost 26.35 s
2024-01-01 18:25:48,562	44k	INFO	====> Epoch: 131, cost 26.32 s
2024-01-01 18:25:59,733	44k	INFO	Train Epoch: 132 [40%]
2024-01-01 18:25:59,734	44k	INFO	Losses: [2.4469308853149414, 2.5929296016693115, 5.1503190994262695, 24.504615783691406, 1.197393774986267], step: 4600, lr: 9.837573345994909e-05, reference_loss: 35.892189025878906
2024-01-01 18:26:15,735	44k	INFO	====> Epoch: 132, cost 27.17 s
2024-01-01 18:26:41,972	44k	INFO	====> Epoch: 133, cost 26.24 s
2024-01-01 18:27:08,259	44k	INFO	====> Epoch: 134, cost 26.29 s
2024-01-01 18:27:34,628	44k	INFO	====> Epoch: 135, cost 26.37 s
2024-01-01 18:28:00,965	44k	INFO	====> Epoch: 136, cost 26.34 s
2024-01-01 18:28:27,054	44k	INFO	====> Epoch: 137, cost 26.09 s
2024-01-01 18:28:30,816	44k	INFO	Train Epoch: 138 [11%]
2024-01-01 18:28:30,817	44k	INFO	Losses: [2.535244941711426, 2.6785471439361572, 4.555424213409424, 23.090269088745117, 1.2724969387054443], step: 4800, lr: 9.830197471282419e-05, reference_loss: 34.131980895996094
2024-01-01 18:28:38,168	44k	INFO	Saving model and optimizer state at iteration 138 to ./logs/44k/G_4800.pth
2024-01-01 18:28:39,435	44k	INFO	Saving model and optimizer state at iteration 138 to ./logs/44k/D_4800.pth
2024-01-01 18:28:40,204	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_2400.pth
2024-01-01 18:28:40,263	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_2400.pth
2024-01-01 18:29:02,729	44k	INFO	====> Epoch: 138, cost 35.67 s
2024-01-01 18:29:29,027	44k	INFO	====> Epoch: 139, cost 26.30 s
2024-01-01 18:29:55,365	44k	INFO	====> Epoch: 140, cost 26.34 s
2024-01-01 18:30:21,649	44k	INFO	====> Epoch: 141, cost 26.28 s
2024-01-01 18:30:47,971	44k	INFO	====> Epoch: 142, cost 26.32 s
2024-01-01 18:31:10,548	44k	INFO	Train Epoch: 143 [83%]
2024-01-01 18:31:10,549	44k	INFO	Losses: [2.377012014389038, 2.3324532508850098, 4.569937229156494, 22.45376205444336, 0.8769267797470093], step: 5000, lr: 9.824055133639235e-05, reference_loss: 32.61009216308594
2024-01-01 18:31:14,783	44k	INFO	====> Epoch: 143, cost 26.81 s
2024-01-01 18:31:41,144	44k	INFO	====> Epoch: 144, cost 26.36 s
2024-01-01 18:32:07,728	44k	INFO	====> Epoch: 145, cost 26.58 s
2024-01-01 18:32:34,072	44k	INFO	====> Epoch: 146, cost 26.34 s
2024-01-01 18:33:00,349	44k	INFO	====> Epoch: 147, cost 26.28 s
2024-01-01 18:33:26,688	44k	INFO	====> Epoch: 148, cost 26.34 s
2024-01-01 18:33:41,544	44k	INFO	Train Epoch: 149 [54%]
2024-01-01 18:33:41,545	44k	INFO	Losses: [2.2255494594573975, 2.3872601985931396, 4.9623870849609375, 23.373519897460938, 1.1359964609146118], step: 5200, lr: 9.816689394418209e-05, reference_loss: 34.084712982177734
2024-01-01 18:33:53,502	44k	INFO	====> Epoch: 149, cost 26.81 s
2024-01-01 18:34:19,783	44k	INFO	====> Epoch: 150, cost 26.28 s
2024-01-01 18:34:46,043	44k	INFO	====> Epoch: 151, cost 26.26 s
2024-01-01 18:35:12,506	44k	INFO	====> Epoch: 152, cost 26.46 s
2024-01-01 18:35:38,782	44k	INFO	====> Epoch: 153, cost 26.28 s
2024-01-01 18:36:05,123	44k	INFO	====> Epoch: 154, cost 26.34 s
2024-01-01 18:36:12,607	44k	INFO	Train Epoch: 155 [26%]
2024-01-01 18:36:12,608	44k	INFO	Losses: [2.431286096572876, 2.7068138122558594, 4.670261383056641, 25.528507232666016, 1.1468303203582764], step: 5400, lr: 9.809329177775541e-05, reference_loss: 36.483699798583984
2024-01-01 18:36:31,831	44k	INFO	====> Epoch: 155, cost 26.71 s
2024-01-01 18:36:58,090	44k	INFO	====> Epoch: 156, cost 26.26 s
2024-01-01 18:37:24,447	44k	INFO	====> Epoch: 157, cost 26.36 s
2024-01-01 18:37:50,634	44k	INFO	====> Epoch: 158, cost 26.19 s
2024-01-01 18:38:17,217	44k	INFO	====> Epoch: 159, cost 26.58 s
2024-01-01 18:38:43,418	44k	INFO	Train Epoch: 160 [97%]
2024-01-01 18:38:43,419	44k	INFO	Losses: [2.576735496520996, 2.593052387237549, 4.12460994720459, 21.497446060180664, 1.0206973552703857], step: 5600, lr: 9.803199879555537e-05, reference_loss: 31.81254005432129
2024-01-01 18:38:50,791	44k	INFO	Saving model and optimizer state at iteration 160 to ./logs/44k/G_5600.pth
2024-01-01 18:38:51,716	44k	INFO	Saving model and optimizer state at iteration 160 to ./logs/44k/D_5600.pth
2024-01-01 18:38:52,512	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_3200.pth
2024-01-01 18:38:52,569	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_3200.pth
2024-01-01 18:38:52,569	44k	INFO	====> Epoch: 160, cost 35.35 s
2024-01-01 18:39:18,808	44k	INFO	====> Epoch: 161, cost 26.24 s
2024-01-01 18:39:45,062	44k	INFO	====> Epoch: 162, cost 26.25 s
2024-01-01 18:40:11,372	44k	INFO	====> Epoch: 163, cost 26.31 s
2024-01-01 18:40:37,873	44k	INFO	====> Epoch: 164, cost 26.50 s
2024-01-01 18:41:04,115	44k	INFO	====> Epoch: 165, cost 26.24 s
2024-01-01 18:41:22,854	44k	INFO	Train Epoch: 166 [69%]
2024-01-01 18:41:22,854	44k	INFO	Losses: [2.27374267578125, 2.4253854751586914, 5.22137451171875, 23.756877899169922, 1.0644606351852417], step: 5800, lr: 9.795849776887939e-05, reference_loss: 34.74184036254883
2024-01-01 18:41:30,889	44k	INFO	====> Epoch: 166, cost 26.77 s
2024-01-01 18:41:57,084	44k	INFO	====> Epoch: 167, cost 26.19 s
2024-01-01 18:42:23,295	44k	INFO	====> Epoch: 168, cost 26.21 s
2024-01-01 18:42:49,608	44k	INFO	====> Epoch: 169, cost 26.31 s
2024-01-01 18:43:15,860	44k	INFO	====> Epoch: 170, cost 26.25 s
2024-01-01 18:43:42,165	44k	INFO	====> Epoch: 171, cost 26.31 s
2024-01-01 18:43:53,387	44k	INFO	Train Epoch: 172 [40%]
2024-01-01 18:43:53,388	44k	INFO	Losses: [2.208256244659424, 2.5981369018554688, 5.566298484802246, 25.17415428161621, 0.944774866104126], step: 6000, lr: 9.78850518507495e-05, reference_loss: 36.49161911010742
2024-01-01 18:44:09,469	44k	INFO	====> Epoch: 172, cost 27.30 s
2024-01-01 18:44:35,890	44k	INFO	====> Epoch: 173, cost 26.42 s
2024-01-01 18:45:02,195	44k	INFO	====> Epoch: 174, cost 26.31 s
2024-01-01 18:45:28,418	44k	INFO	====> Epoch: 175, cost 26.22 s
2024-01-01 18:45:54,684	44k	INFO	====> Epoch: 176, cost 26.27 s
2024-01-01 18:46:21,061	44k	INFO	====> Epoch: 177, cost 26.38 s
2024-01-01 18:46:24,823	44k	INFO	Train Epoch: 178 [11%]
2024-01-01 18:46:24,823	44k	INFO	Losses: [2.3028926849365234, 2.689828395843506, 4.440033912658691, 23.881397247314453, 0.8229406476020813], step: 6200, lr: 9.781166099984716e-05, reference_loss: 34.13709259033203
2024-01-01 18:46:48,228	44k	INFO	====> Epoch: 178, cost 27.17 s
2024-01-01 18:47:14,551	44k	INFO	====> Epoch: 179, cost 26.32 s
2024-01-01 18:47:40,968	44k	INFO	====> Epoch: 180, cost 26.42 s
2024-01-01 18:48:07,208	44k	INFO	====> Epoch: 181, cost 26.24 s
2024-01-01 18:48:33,543	44k	INFO	====> Epoch: 182, cost 26.34 s
2024-01-01 18:48:56,084	44k	INFO	Train Epoch: 183 [83%]
2024-01-01 18:48:56,085	44k	INFO	Losses: [2.1580584049224854, 2.63525390625, 5.7113800048828125, 22.3445987701416, 1.0468664169311523], step: 6400, lr: 9.7750543992884e-05, reference_loss: 33.896156311035156
2024-01-01 18:49:03,514	44k	INFO	Saving model and optimizer state at iteration 183 to ./logs/44k/G_6400.pth
2024-01-01 18:49:04,446	44k	INFO	Saving model and optimizer state at iteration 183 to ./logs/44k/D_6400.pth
2024-01-01 18:49:05,211	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_4000.pth
2024-01-01 18:49:05,271	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_4000.pth
2024-01-01 18:49:08,993	44k	INFO	====> Epoch: 183, cost 35.45 s
2024-01-01 18:49:35,605	44k	INFO	====> Epoch: 184, cost 26.61 s
2024-01-01 18:50:01,994	44k	INFO	====> Epoch: 185, cost 26.39 s
2024-01-01 18:50:28,298	44k	INFO	====> Epoch: 186, cost 26.30 s
2024-01-01 18:50:54,693	44k	INFO	====> Epoch: 187, cost 26.39 s
2024-01-01 18:51:20,963	44k	INFO	====> Epoch: 188, cost 26.27 s
2024-01-01 18:51:35,805	44k	INFO	Train Epoch: 189 [54%]
2024-01-01 18:51:35,806	44k	INFO	Losses: [2.2086727619171143, 2.7124838829040527, 5.009444713592529, 22.19291877746582, 0.7759081721305847], step: 6600, lr: 9.767725399135504e-05, reference_loss: 32.89942932128906
2024-01-01 18:51:47,750	44k	INFO	====> Epoch: 189, cost 26.79 s
2024-01-01 18:52:14,016	44k	INFO	====> Epoch: 190, cost 26.27 s
2024-01-01 18:52:40,250	44k	INFO	====> Epoch: 191, cost 26.23 s
2024-01-01 18:53:06,419	44k	INFO	====> Epoch: 192, cost 26.17 s
2024-01-01 18:53:33,045	44k	INFO	====> Epoch: 193, cost 26.63 s
2024-01-01 18:53:59,428	44k	INFO	====> Epoch: 194, cost 26.38 s
2024-01-01 18:54:06,948	44k	INFO	Train Epoch: 195 [26%]
2024-01-01 18:54:06,949	44k	INFO	Losses: [2.0857300758361816, 2.6936962604522705, 5.876287460327148, 25.433521270751953, 1.1468604803085327], step: 6800, lr: 9.760401894015275e-05, reference_loss: 37.2360954284668
2024-01-01 18:54:26,267	44k	INFO	====> Epoch: 195, cost 26.84 s
2024-01-01 18:54:52,494	44k	INFO	====> Epoch: 196, cost 26.23 s
2024-01-01 18:55:18,754	44k	INFO	====> Epoch: 197, cost 26.26 s
2024-01-01 18:55:44,994	44k	INFO	====> Epoch: 198, cost 26.24 s
2024-01-01 18:56:11,335	44k	INFO	====> Epoch: 199, cost 26.34 s
2024-01-01 18:56:37,864	44k	INFO	Train Epoch: 200 [97%]
2024-01-01 18:56:37,865	44k	INFO	Losses: [2.3348803520202637, 2.459935188293457, 5.038527011871338, 25.61970329284668, 0.979293942451477], step: 7000, lr: 9.754303167703689e-05, reference_loss: 36.43233871459961
2024-01-01 18:56:38,360	44k	INFO	====> Epoch: 200, cost 27.02 s
2024-01-01 18:57:04,680	44k	INFO	====> Epoch: 201, cost 26.32 s
2024-01-01 18:57:30,756	44k	INFO	====> Epoch: 202, cost 26.08 s
2024-01-01 18:57:57,035	44k	INFO	====> Epoch: 203, cost 26.28 s
2024-01-01 18:58:23,349	44k	INFO	====> Epoch: 204, cost 26.31 s
2024-01-01 18:58:49,686	44k	INFO	====> Epoch: 205, cost 26.34 s
2024-01-01 18:59:08,388	44k	INFO	Train Epoch: 206 [69%]
2024-01-01 18:59:08,388	44k	INFO	Losses: [2.232295036315918, 2.291346788406372, 4.7943854331970215, 19.907007217407227, 0.9852878451347351], step: 7200, lr: 9.746989726111722e-05, reference_loss: 30.210323333740234
2024-01-01 18:59:15,994	44k	INFO	Saving model and optimizer state at iteration 206 to ./logs/44k/G_7200.pth
2024-01-01 18:59:16,900	44k	INFO	Saving model and optimizer state at iteration 206 to ./logs/44k/D_7200.pth
2024-01-01 18:59:17,670	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_4800.pth
2024-01-01 18:59:17,727	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_4800.pth
2024-01-01 18:59:25,270	44k	INFO	====> Epoch: 206, cost 35.58 s
2024-01-01 18:59:51,566	44k	INFO	====> Epoch: 207, cost 26.30 s
2024-01-01 19:00:17,905	44k	INFO	====> Epoch: 208, cost 26.34 s
2024-01-01 19:00:44,254	44k	INFO	====> Epoch: 209, cost 26.35 s
2024-01-01 19:01:10,446	44k	INFO	====> Epoch: 210, cost 26.19 s
2024-01-01 19:01:36,673	44k	INFO	====> Epoch: 211, cost 26.23 s
2024-01-01 19:01:47,922	44k	INFO	Train Epoch: 212 [40%]
2024-01-01 19:01:47,923	44k	INFO	Losses: [2.040332794189453, 2.4512782096862793, 5.962006568908691, 24.847686767578125, 0.8787194490432739], step: 7400, lr: 9.739681767887146e-05, reference_loss: 36.180023193359375
2024-01-01 19:02:04,044	44k	INFO	====> Epoch: 212, cost 27.37 s
2024-01-01 19:02:30,459	44k	INFO	====> Epoch: 213, cost 26.42 s
2024-01-01 19:02:56,715	44k	INFO	====> Epoch: 214, cost 26.26 s
2024-01-01 19:03:23,061	44k	INFO	====> Epoch: 215, cost 26.35 s
2024-01-01 19:03:49,333	44k	INFO	====> Epoch: 216, cost 26.27 s
2024-01-01 19:04:15,540	44k	INFO	====> Epoch: 217, cost 26.21 s
2024-01-01 19:04:19,275	44k	INFO	Train Epoch: 218 [11%]
2024-01-01 19:04:19,275	44k	INFO	Losses: [2.166656494140625, 2.5527732372283936, 5.007851600646973, 23.017330169677734, 0.8307512402534485], step: 7600, lr: 9.732379288918723e-05, reference_loss: 33.57536315917969
2024-01-01 19:04:42,354	44k	INFO	====> Epoch: 218, cost 26.81 s
2024-01-01 19:05:08,972	44k	INFO	====> Epoch: 219, cost 26.62 s
2024-01-01 19:05:35,338	44k	INFO	====> Epoch: 220, cost 26.37 s
2024-01-01 19:06:01,695	44k	INFO	====> Epoch: 221, cost 26.36 s
2024-01-01 19:06:28,113	44k	INFO	====> Epoch: 222, cost 26.42 s
2024-01-01 19:06:50,823	44k	INFO	Train Epoch: 223 [83%]
2024-01-01 19:06:50,823	44k	INFO	Losses: [1.8838226795196533, 2.962292194366455, 6.72011661529541, 23.328781127929688, 0.9383063912391663], step: 7800, lr: 9.726298072357337e-05, reference_loss: 35.833316802978516
2024-01-01 19:06:55,193	44k	INFO	====> Epoch: 223, cost 27.08 s
2024-01-01 19:07:21,388	44k	INFO	====> Epoch: 224, cost 26.19 s
2024-01-01 19:07:47,737	44k	INFO	====> Epoch: 225, cost 26.35 s
2024-01-01 19:08:14,414	44k	INFO	====> Epoch: 226, cost 26.68 s
2024-01-01 19:08:40,772	44k	INFO	====> Epoch: 227, cost 26.36 s
2024-01-01 19:09:07,010	44k	INFO	====> Epoch: 228, cost 26.24 s
2024-01-01 19:09:21,990	44k	INFO	Train Epoch: 229 [54%]
2024-01-01 19:09:21,991	44k	INFO	Losses: [2.0225563049316406, 2.647801160812378, 6.781164169311523, 24.43463706970215, 1.0322139263153076], step: 8000, lr: 9.719005628024282e-05, reference_loss: 36.918373107910156
2024-01-01 19:09:29,274	44k	INFO	Saving model and optimizer state at iteration 229 to ./logs/44k/G_8000.pth
2024-01-01 19:09:30,190	44k	INFO	Saving model and optimizer state at iteration 229 to ./logs/44k/D_8000.pth
2024-01-01 19:09:30,971	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_5600.pth
2024-01-01 19:09:31,030	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_5600.pth
2024-01-01 19:09:42,371	44k	INFO	====> Epoch: 229, cost 35.36 s
2024-01-01 19:10:08,784	44k	INFO	====> Epoch: 230, cost 26.41 s
2024-01-01 19:10:35,437	44k	INFO	====> Epoch: 231, cost 26.65 s
2024-01-01 19:11:01,699	44k	INFO	====> Epoch: 232, cost 26.26 s
2024-01-01 19:11:28,069	44k	INFO	====> Epoch: 233, cost 26.37 s
2024-01-01 19:11:54,410	44k	INFO	====> Epoch: 234, cost 26.34 s
2024-01-01 19:12:01,911	44k	INFO	Train Epoch: 235 [26%]
2024-01-01 19:12:01,912	44k	INFO	Losses: [2.2835097312927246, 2.4049906730651855, 5.422913551330566, 23.989978790283203, 0.9914330244064331], step: 8200, lr: 9.711718651315591e-05, reference_loss: 35.09282684326172
2024-01-01 19:12:21,212	44k	INFO	====> Epoch: 235, cost 26.80 s
2024-01-01 19:12:47,560	44k	INFO	====> Epoch: 236, cost 26.35 s
2024-01-01 19:13:13,860	44k	INFO	====> Epoch: 237, cost 26.30 s
2024-01-01 19:13:40,259	44k	INFO	====> Epoch: 238, cost 26.40 s
2024-01-01 19:14:06,469	44k	INFO	====> Epoch: 239, cost 26.21 s
2024-01-01 19:14:32,937	44k	INFO	Train Epoch: 240 [97%]
2024-01-01 19:14:32,938	44k	INFO	Losses: [1.9181606769561768, 3.105832576751709, 6.1598124504089355, 23.05284881591797, 0.7927927374839783], step: 8400, lr: 9.705650344424885e-05, reference_loss: 35.029449462890625
2024-01-01 19:14:33,430	44k	INFO	====> Epoch: 240, cost 26.96 s
2024-01-01 19:14:59,751	44k	INFO	====> Epoch: 241, cost 26.32 s
2024-01-01 19:15:25,959	44k	INFO	====> Epoch: 242, cost 26.21 s
2024-01-01 19:15:52,105	44k	INFO	====> Epoch: 243, cost 26.15 s
2024-01-01 19:16:18,361	44k	INFO	====> Epoch: 244, cost 26.26 s
2024-01-01 19:16:44,724	44k	INFO	====> Epoch: 245, cost 26.36 s
2024-01-01 19:17:03,461	44k	INFO	Train Epoch: 246 [69%]
2024-01-01 19:17:03,461	44k	INFO	Losses: [2.6130928993225098, 2.68580961227417, 4.746004104614258, 21.101566314697266, 0.9342092871665955], step: 8600, lr: 9.698373381049272e-05, reference_loss: 32.08068084716797
2024-01-01 19:17:11,954	44k	INFO	====> Epoch: 246, cost 27.23 s
2024-01-01 19:17:38,214	44k	INFO	====> Epoch: 247, cost 26.26 s
2024-01-01 19:18:04,417	44k	INFO	====> Epoch: 248, cost 26.20 s
2024-01-01 19:18:30,623	44k	INFO	====> Epoch: 249, cost 26.21 s
2024-01-01 19:18:56,874	44k	INFO	====> Epoch: 250, cost 26.25 s
2024-01-01 19:19:23,134	44k	INFO	====> Epoch: 251, cost 26.26 s
2024-01-01 19:19:34,322	44k	INFO	Train Epoch: 252 [40%]
2024-01-01 19:19:34,323	44k	INFO	Losses: [2.071096181869507, 2.885878562927246, 6.655425071716309, 26.498443603515625, 1.008530855178833], step: 8800, lr: 9.691101873690936e-05, reference_loss: 39.1193733215332
2024-01-01 19:19:41,853	44k	INFO	Saving model and optimizer state at iteration 252 to ./logs/44k/G_8800.pth
2024-01-01 19:19:43,087	44k	INFO	Saving model and optimizer state at iteration 252 to ./logs/44k/D_8800.pth
2024-01-01 19:19:43,861	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_6400.pth
2024-01-01 19:19:43,918	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_6400.pth
2024-01-01 19:19:59,035	44k	INFO	====> Epoch: 252, cost 35.90 s
2024-01-01 19:20:25,319	44k	INFO	====> Epoch: 253, cost 26.28 s
2024-01-01 19:20:51,615	44k	INFO	====> Epoch: 254, cost 26.30 s
2024-01-01 19:21:17,956	44k	INFO	====> Epoch: 255, cost 26.34 s
2024-01-01 19:21:44,219	44k	INFO	====> Epoch: 256, cost 26.26 s
2024-01-01 19:22:10,531	44k	INFO	====> Epoch: 257, cost 26.31 s
2024-01-01 19:22:14,257	44k	INFO	Train Epoch: 258 [11%]
2024-01-01 19:22:14,257	44k	INFO	Losses: [2.362004041671753, 2.5369980335235596, 4.932464122772217, 21.060222625732422, 0.8177928924560547], step: 9000, lr: 9.683835818259144e-05, reference_loss: 31.709482192993164
2024-01-01 19:22:37,415	44k	INFO	====> Epoch: 258, cost 26.88 s
2024-01-01 19:23:04,001	44k	INFO	====> Epoch: 259, cost 26.59 s
2024-01-01 19:23:30,330	44k	INFO	====> Epoch: 260, cost 26.33 s
2024-01-01 19:23:56,634	44k	INFO	====> Epoch: 261, cost 26.30 s
2024-01-01 19:24:22,856	44k	INFO	====> Epoch: 262, cost 26.22 s
2024-01-01 19:24:45,332	44k	INFO	Train Epoch: 263 [83%]
2024-01-01 19:24:45,332	44k	INFO	Losses: [2.5088276863098145, 2.1440374851226807, 4.183777809143066, 24.12021827697754, 0.8898674249649048], step: 9200, lr: 9.67778493378295e-05, reference_loss: 33.84672927856445
2024-01-01 19:24:49,558	44k	INFO	====> Epoch: 263, cost 26.70 s
2024-01-01 19:25:15,832	44k	INFO	====> Epoch: 264, cost 26.27 s
2024-01-01 19:25:42,120	44k	INFO	====> Epoch: 265, cost 26.29 s
2024-01-01 19:26:08,704	44k	INFO	====> Epoch: 266, cost 26.58 s
2024-01-01 19:26:34,970	44k	INFO	====> Epoch: 267, cost 26.27 s
2024-01-01 19:27:01,189	44k	INFO	====> Epoch: 268, cost 26.22 s
2024-01-01 19:27:16,126	44k	INFO	Train Epoch: 269 [54%]
2024-01-01 19:27:16,126	44k	INFO	Losses: [1.9749746322631836, 2.760673761367798, 6.45097017288208, 25.009275436401367, 0.9282158613204956], step: 9400, lr: 9.670528862935451e-05, reference_loss: 37.124107360839844
2024-01-01 19:27:27,909	44k	INFO	====> Epoch: 269, cost 26.72 s
2024-01-01 19:27:54,237	44k	INFO	====> Epoch: 270, cost 26.33 s
2024-01-01 19:28:20,558	44k	INFO	====> Epoch: 271, cost 26.32 s
2024-01-01 19:28:46,855	44k	INFO	====> Epoch: 272, cost 26.30 s
2024-01-01 19:29:13,461	44k	INFO	====> Epoch: 273, cost 26.61 s
2024-01-01 19:29:39,761	44k	INFO	====> Epoch: 274, cost 26.30 s
2024-01-01 19:29:47,270	44k	INFO	Train Epoch: 275 [26%]
2024-01-01 19:29:47,270	44k	INFO	Losses: [2.246479034423828, 2.854814052581787, 5.8541741371154785, 24.012248992919922, 0.8354654312133789], step: 9600, lr: 9.663278232440732e-05, reference_loss: 35.80318069458008
2024-01-01 19:29:54,703	44k	INFO	Saving model and optimizer state at iteration 275 to ./logs/44k/G_9600.pth
2024-01-01 19:29:55,614	44k	INFO	Saving model and optimizer state at iteration 275 to ./logs/44k/D_9600.pth
2024-01-01 19:29:56,391	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_7200.pth
2024-01-01 19:29:56,449	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_7200.pth
2024-01-01 19:30:15,266	44k	INFO	====> Epoch: 275, cost 35.51 s
2024-01-01 19:30:41,574	44k	INFO	====> Epoch: 276, cost 26.31 s
2024-01-01 19:31:07,956	44k	INFO	====> Epoch: 277, cost 26.38 s
2024-01-01 19:31:34,180	44k	INFO	====> Epoch: 278, cost 26.22 s
2024-01-01 19:32:00,778	44k	INFO	====> Epoch: 279, cost 26.60 s
2024-01-01 19:32:27,091	44k	INFO	Train Epoch: 280 [97%]
2024-01-01 19:32:27,091	44k	INFO	Losses: [2.0565505027770996, 3.0107765197753906, 7.04287052154541, 26.728548049926758, 0.8512080311775208], step: 9800, lr: 9.657240193243954e-05, reference_loss: 39.6899528503418
2024-01-01 19:32:27,605	44k	INFO	====> Epoch: 280, cost 26.83 s
2024-01-01 19:32:53,933	44k	INFO	====> Epoch: 281, cost 26.33 s
2024-01-01 19:33:20,097	44k	INFO	====> Epoch: 282, cost 26.16 s
2024-01-01 19:33:46,344	44k	INFO	====> Epoch: 283, cost 26.25 s
2024-01-01 19:34:12,852	44k	INFO	====> Epoch: 284, cost 26.51 s
2024-01-01 19:34:39,232	44k	INFO	====> Epoch: 285, cost 26.38 s
2024-01-01 19:34:57,902	44k	INFO	Train Epoch: 286 [69%]
2024-01-01 19:34:57,902	44k	INFO	Losses: [2.2107698917388916, 3.12522292137146, 6.096820831298828, 24.541616439819336, 1.1531968116760254], step: 10000, lr: 9.649999526137489e-05, reference_loss: 37.127628326416016
2024-01-01 19:35:06,350	44k	INFO	====> Epoch: 286, cost 27.12 s
2024-01-01 19:35:32,497	44k	INFO	====> Epoch: 287, cost 26.15 s
2024-01-01 19:35:58,648	44k	INFO	====> Epoch: 288, cost 26.15 s
2024-01-01 19:36:24,849	44k	INFO	====> Epoch: 289, cost 26.20 s
2024-01-01 19:36:50,961	44k	INFO	====> Epoch: 290, cost 26.11 s
2024-01-01 19:37:17,210	44k	INFO	====> Epoch: 291, cost 26.25 s
2024-01-01 19:37:28,345	44k	INFO	Train Epoch: 292 [40%]
2024-01-01 19:37:28,346	44k	INFO	Losses: [2.4211463928222656, 2.02584171295166, 4.8069000244140625, 21.928380966186523, 1.0406805276870728], step: 10200, lr: 9.642764287834605e-05, reference_loss: 32.22294998168945
2024-01-01 19:37:43,941	44k	INFO	====> Epoch: 292, cost 26.73 s
2024-01-01 19:38:10,511	44k	INFO	====> Epoch: 293, cost 26.57 s
2024-01-01 19:38:36,873	44k	INFO	====> Epoch: 294, cost 26.36 s
2024-01-01 19:39:03,188	44k	INFO	====> Epoch: 295, cost 26.31 s
2024-01-01 19:39:29,484	44k	INFO	====> Epoch: 296, cost 26.30 s
2024-01-01 19:39:55,773	44k	INFO	====> Epoch: 297, cost 26.29 s
2024-01-01 19:39:59,515	44k	INFO	Train Epoch: 298 [11%]
2024-01-01 19:39:59,516	44k	INFO	Losses: [2.164595365524292, 2.557884931564331, 5.58754301071167, 21.140743255615234, 1.1149402856826782], step: 10400, lr: 9.635534474264972e-05, reference_loss: 32.56570816040039
2024-01-01 19:40:07,085	44k	INFO	Saving model and optimizer state at iteration 298 to ./logs/44k/G_10400.pth
2024-01-01 19:40:07,991	44k	INFO	Saving model and optimizer state at iteration 298 to ./logs/44k/D_10400.pth
2024-01-01 19:40:08,772	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_8000.pth
2024-01-01 19:40:08,831	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_8000.pth
2024-01-01 19:40:31,758	44k	INFO	====> Epoch: 298, cost 35.98 s
2024-01-01 19:40:58,089	44k	INFO	====> Epoch: 299, cost 26.33 s
2024-01-01 19:41:24,471	44k	INFO	====> Epoch: 300, cost 26.38 s
2024-01-01 19:41:50,772	44k	INFO	====> Epoch: 301, cost 26.30 s
2024-01-01 19:42:16,991	44k	INFO	====> Epoch: 302, cost 26.22 s
2024-01-01 19:42:39,535	44k	INFO	Train Epoch: 303 [83%]
2024-01-01 19:42:39,535	44k	INFO	Losses: [2.6981542110443115, 2.3736956119537354, 4.3608717918396, 20.2739200592041, 0.7607185244560242], step: 10600, lr: 9.629513770582634e-05, reference_loss: 30.467361450195312
2024-01-01 19:42:43,786	44k	INFO	====> Epoch: 303, cost 26.80 s
2024-01-01 19:43:10,025	44k	INFO	====> Epoch: 304, cost 26.24 s
2024-01-01 19:43:36,244	44k	INFO	====> Epoch: 305, cost 26.22 s
2024-01-01 19:44:02,567	44k	INFO	====> Epoch: 306, cost 26.32 s
2024-01-01 19:44:29,096	44k	INFO	====> Epoch: 307, cost 26.53 s
2024-01-01 19:44:55,452	44k	INFO	====> Epoch: 308, cost 26.36 s
2024-01-01 19:45:10,444	44k	INFO	Train Epoch: 309 [54%]
2024-01-01 19:45:10,445	44k	INFO	Losses: [2.2734456062316895, 2.8012290000915527, 5.766829013824463, 22.957439422607422, 1.0071266889572144], step: 10800, lr: 9.622293891795867e-05, reference_loss: 34.806068420410156
2024-01-01 19:45:22,468	44k	INFO	====> Epoch: 309, cost 27.02 s
2024-01-01 19:45:48,807	44k	INFO	====> Epoch: 310, cost 26.34 s
2024-01-01 19:46:15,143	44k	INFO	====> Epoch: 311, cost 26.34 s
2024-01-01 19:46:41,492	44k	INFO	====> Epoch: 312, cost 26.35 s
2024-01-01 19:47:07,885	44k	INFO	====> Epoch: 313, cost 26.39 s
2024-01-01 19:47:34,580	44k	INFO	====> Epoch: 314, cost 26.69 s
2024-01-01 19:47:42,110	44k	INFO	Train Epoch: 315 [26%]
2024-01-01 19:47:42,111	44k	INFO	Losses: [2.3151803016662598, 2.376685857772827, 5.009812355041504, 22.89582633972168, 0.8572952151298523], step: 11000, lr: 9.615079426226314e-05, reference_loss: 33.45479965209961
2024-01-01 19:48:01,457	44k	INFO	====> Epoch: 315, cost 26.88 s
2024-01-01 19:48:27,803	44k	INFO	====> Epoch: 316, cost 26.35 s
2024-01-01 19:48:53,985	44k	INFO	====> Epoch: 317, cost 26.18 s
2024-01-01 19:49:20,296	44k	INFO	====> Epoch: 318, cost 26.31 s
2024-01-01 19:49:46,574	44k	INFO	====> Epoch: 319, cost 26.28 s
2024-01-01 19:50:12,917	44k	INFO	Train Epoch: 320 [97%]
2024-01-01 19:50:12,918	44k	INFO	Losses: [2.4711270332336426, 2.215167999267578, 4.007040023803711, 19.54452133178711, 0.8387964367866516], step: 11200, lr: 9.609071503753299e-05, reference_loss: 29.07665252685547
2024-01-01 19:50:20,852	44k	INFO	Saving model and optimizer state at iteration 320 to ./logs/44k/G_11200.pth
2024-01-01 19:50:21,759	44k	INFO	Saving model and optimizer state at iteration 320 to ./logs/44k/D_11200.pth
2024-01-01 19:50:22,535	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_8800.pth
2024-01-01 19:50:22,593	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_8800.pth
2024-01-01 19:50:22,593	44k	INFO	====> Epoch: 320, cost 36.02 s
2024-01-01 19:50:48,855	44k	INFO	====> Epoch: 321, cost 26.26 s
2024-01-01 19:51:15,141	44k	INFO	====> Epoch: 322, cost 26.29 s
2024-01-01 19:51:41,389	44k	INFO	====> Epoch: 323, cost 26.25 s
2024-01-01 19:52:07,760	44k	INFO	====> Epoch: 324, cost 26.37 s
2024-01-01 19:52:34,062	44k	INFO	====> Epoch: 325, cost 26.30 s
2024-01-01 19:52:52,781	44k	INFO	Train Epoch: 326 [69%]
2024-01-01 19:52:52,782	44k	INFO	Losses: [2.1073412895202637, 2.857630491256714, 6.443315029144287, 22.784440994262695, 0.956666886806488], step: 11400, lr: 9.601866951876297e-05, reference_loss: 35.149391174316406
2024-01-01 19:53:01,299	44k	INFO	====> Epoch: 326, cost 27.24 s
2024-01-01 19:53:27,582	44k	INFO	====> Epoch: 327, cost 26.28 s
2024-01-01 19:53:53,882	44k	INFO	====> Epoch: 328, cost 26.30 s
2024-01-01 19:54:20,122	44k	INFO	====> Epoch: 329, cost 26.24 s
2024-01-01 19:54:46,251	44k	INFO	====> Epoch: 330, cost 26.13 s
2024-01-01 19:55:12,573	44k	INFO	====> Epoch: 331, cost 26.32 s
2024-01-01 19:55:23,725	44k	INFO	Train Epoch: 332 [40%]
2024-01-01 19:55:23,726	44k	INFO	Losses: [2.6345553398132324, 2.5435030460357666, 5.029116630554199, 23.492658615112305, 0.883345365524292], step: 11600, lr: 9.594667801724916e-05, reference_loss: 34.58317947387695
2024-01-01 19:55:39,257	44k	INFO	====> Epoch: 332, cost 26.68 s
2024-01-01 19:56:05,692	44k	INFO	====> Epoch: 333, cost 26.43 s
2024-01-01 19:56:31,999	44k	INFO	====> Epoch: 334, cost 26.31 s
2024-01-01 19:56:58,242	44k	INFO	====> Epoch: 335, cost 26.24 s
2024-01-01 19:57:24,400	44k	INFO	====> Epoch: 336, cost 26.16 s
2024-01-01 19:57:50,663	44k	INFO	====> Epoch: 337, cost 26.26 s
2024-01-01 19:57:54,429	44k	INFO	Train Epoch: 338 [11%]
2024-01-01 19:57:54,429	44k	INFO	Losses: [2.1420130729675293, 2.7882707118988037, 5.549698829650879, 21.883989334106445, 0.6071677207946777], step: 11800, lr: 9.58747404924913e-05, reference_loss: 32.97113800048828
2024-01-01 19:58:17,582	44k	INFO	====> Epoch: 338, cost 26.92 s
2024-01-01 19:58:43,884	44k	INFO	====> Epoch: 339, cost 26.30 s
2024-01-01 19:59:10,546	44k	INFO	====> Epoch: 340, cost 26.66 s
2024-01-01 19:59:36,856	44k	INFO	====> Epoch: 341, cost 26.31 s
2024-01-01 20:00:03,244	44k	INFO	====> Epoch: 342, cost 26.39 s
2024-01-01 20:00:25,858	44k	INFO	Train Epoch: 343 [83%]
2024-01-01 20:00:25,859	44k	INFO	Losses: [2.190568208694458, 2.388262987136841, 5.0272955894470215, 21.757108688354492, 1.0247890949249268], step: 12000, lr: 9.581483375823925e-05, reference_loss: 32.388023376464844
2024-01-01 20:00:33,217	44k	INFO	Saving model and optimizer state at iteration 343 to ./logs/44k/G_12000.pth
2024-01-01 20:00:34,115	44k	INFO	Saving model and optimizer state at iteration 343 to ./logs/44k/D_12000.pth
2024-01-01 20:00:34,871	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_9600.pth
2024-01-01 20:00:34,929	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_9600.pth
2024-01-01 20:00:38,663	44k	INFO	====> Epoch: 343, cost 35.42 s
2024-01-01 20:01:04,934	44k	INFO	====> Epoch: 344, cost 26.27 s
2024-01-01 20:01:31,129	44k	INFO	====> Epoch: 345, cost 26.20 s
2024-01-01 20:01:57,768	44k	INFO	====> Epoch: 346, cost 26.64 s
2024-01-01 20:02:24,087	44k	INFO	====> Epoch: 347, cost 26.32 s
2024-01-01 20:02:50,269	44k	INFO	====> Epoch: 348, cost 26.18 s
2024-01-01 20:03:05,135	44k	INFO	Train Epoch: 349 [54%]
2024-01-01 20:03:05,136	44k	INFO	Losses: [2.200066089630127, 2.5185160636901855, 4.864982604980469, 20.69623374938965, 0.7746853828430176], step: 12200, lr: 9.574299508577979e-05, reference_loss: 31.05448341369629
2024-01-01 20:03:16,978	44k	INFO	====> Epoch: 349, cost 26.71 s
2024-01-01 20:03:43,261	44k	INFO	====> Epoch: 350, cost 26.28 s
2024-01-01 20:04:09,505	44k	INFO	====> Epoch: 351, cost 26.24 s
2024-01-01 20:04:35,756	44k	INFO	====> Epoch: 352, cost 26.25 s
2024-01-01 20:05:02,092	44k	INFO	====> Epoch: 353, cost 26.34 s
2024-01-01 20:05:28,682	44k	INFO	====> Epoch: 354, cost 26.59 s
2024-01-01 20:05:36,127	44k	INFO	Train Epoch: 355 [26%]
2024-01-01 20:05:36,128	44k	INFO	Losses: [1.83420991897583, 2.856657028198242, 6.970119953155518, 24.794321060180664, 1.0389374494552612], step: 12400, lr: 9.56712102754903e-05, reference_loss: 37.49424362182617
2024-01-01 20:05:55,514	44k	INFO	====> Epoch: 355, cost 26.83 s
2024-01-01 20:06:21,720	44k	INFO	====> Epoch: 356, cost 26.21 s
2024-01-01 20:06:47,939	44k	INFO	====> Epoch: 357, cost 26.22 s
2024-01-01 20:07:14,149	44k	INFO	====> Epoch: 358, cost 26.21 s
2024-01-01 20:07:40,396	44k	INFO	====> Epoch: 359, cost 26.25 s
2024-01-01 20:08:06,759	44k	INFO	Train Epoch: 360 [97%]
2024-01-01 20:08:06,760	44k	INFO	Losses: [2.192547559738159, 2.6179237365722656, 5.906898498535156, 23.959096908569336, 0.9237256050109863], step: 12600, lr: 9.561143071582622e-05, reference_loss: 35.60019302368164
2024-01-01 20:08:07,580	44k	INFO	====> Epoch: 360, cost 27.18 s
2024-01-01 20:08:34,006	44k	INFO	====> Epoch: 361, cost 26.43 s
2024-01-01 20:09:00,320	44k	INFO	====> Epoch: 362, cost 26.31 s
2024-01-01 20:09:26,735	44k	INFO	====> Epoch: 363, cost 26.42 s
2024-01-01 20:09:53,076	44k	INFO	====> Epoch: 364, cost 26.34 s
2024-01-01 20:10:19,360	44k	INFO	====> Epoch: 365, cost 26.28 s
2024-01-01 20:10:38,031	44k	INFO	Train Epoch: 366 [69%]
2024-01-01 20:10:38,031	44k	INFO	Losses: [2.186065196990967, 2.6883535385131836, 5.4935808181762695, 20.337982177734375, 0.8741923570632935], step: 12800, lr: 9.553974454798393e-05, reference_loss: 31.580175399780273
2024-01-01 20:10:45,381	44k	INFO	Saving model and optimizer state at iteration 366 to ./logs/44k/G_12800.pth
2024-01-01 20:10:46,580	44k	INFO	Saving model and optimizer state at iteration 366 to ./logs/44k/D_12800.pth
2024-01-01 20:10:47,342	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_10400.pth
2024-01-01 20:10:47,399	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_10400.pth
2024-01-01 20:10:54,917	44k	INFO	====> Epoch: 366, cost 35.56 s
2024-01-01 20:11:21,214	44k	INFO	====> Epoch: 367, cost 26.30 s
2024-01-01 20:11:47,453	44k	INFO	====> Epoch: 368, cost 26.24 s
2024-01-01 20:12:13,679	44k	INFO	====> Epoch: 369, cost 26.23 s
2024-01-01 20:12:39,962	44k	INFO	====> Epoch: 370, cost 26.28 s
2024-01-01 20:13:06,235	44k	INFO	====> Epoch: 371, cost 26.27 s
2024-01-01 20:13:17,468	44k	INFO	Train Epoch: 372 [40%]
2024-01-01 20:13:17,469	44k	INFO	Losses: [2.148247718811035, 2.680673837661743, 6.5100998878479, 24.071531295776367, 0.7824354767799377], step: 13000, lr: 9.546811212796888e-05, reference_loss: 36.192989349365234
2024-01-01 20:13:33,152	44k	INFO	====> Epoch: 372, cost 26.92 s
2024-01-01 20:13:59,686	44k	INFO	====> Epoch: 373, cost 26.53 s
2024-01-01 20:14:25,885	44k	INFO	====> Epoch: 374, cost 26.20 s
2024-01-01 20:14:52,149	44k	INFO	====> Epoch: 375, cost 26.26 s
2024-01-01 20:15:18,392	44k	INFO	====> Epoch: 376, cost 26.24 s
2024-01-01 20:15:44,712	44k	INFO	====> Epoch: 377, cost 26.32 s
2024-01-01 20:15:48,465	44k	INFO	Train Epoch: 378 [11%]
2024-01-01 20:15:48,465	44k	INFO	Losses: [2.4040374755859375, 2.3336410522460938, 4.731181621551514, 21.663894653320312, 0.750902533531189], step: 13200, lr: 9.53965334154828e-05, reference_loss: 31.883657455444336
2024-01-01 20:16:11,611	44k	INFO	====> Epoch: 378, cost 26.90 s
2024-01-01 20:16:37,958	44k	INFO	====> Epoch: 379, cost 26.35 s
2024-01-01 20:17:04,580	44k	INFO	====> Epoch: 380, cost 26.62 s
2024-01-01 20:17:30,975	44k	INFO	====> Epoch: 381, cost 26.40 s
2024-01-01 20:17:57,339	44k	INFO	====> Epoch: 382, cost 26.36 s
2024-01-01 20:18:19,848	44k	INFO	Train Epoch: 383 [83%]
2024-01-01 20:18:19,848	44k	INFO	Losses: [2.1699955463409424, 2.512786388397217, 5.721649169921875, 21.354703903198242, 0.8853297829627991], step: 13400, lr: 9.533692548594333e-05, reference_loss: 32.644466400146484
2024-01-01 20:18:24,093	44k	INFO	====> Epoch: 383, cost 26.75 s
2024-01-01 20:18:50,413	44k	INFO	====> Epoch: 384, cost 26.32 s
2024-01-01 20:19:16,747	44k	INFO	====> Epoch: 385, cost 26.33 s
2024-01-01 20:19:43,086	44k	INFO	====> Epoch: 386, cost 26.34 s
2024-01-01 20:20:09,790	44k	INFO	====> Epoch: 387, cost 26.70 s
2024-01-01 20:20:36,166	44k	INFO	====> Epoch: 388, cost 26.38 s
2024-01-01 20:20:51,180	44k	INFO	Train Epoch: 389 [54%]
2024-01-01 20:20:51,180	44k	INFO	Losses: [2.1168713569641113, 3.0540530681610107, 7.907403469085693, 23.846527099609375, 0.9591888189315796], step: 13600, lr: 9.526544513269702e-05, reference_loss: 37.8840446472168
2024-01-01 20:20:58,565	44k	INFO	Saving model and optimizer state at iteration 389 to ./logs/44k/G_13600.pth
2024-01-01 20:20:59,461	44k	INFO	Saving model and optimizer state at iteration 389 to ./logs/44k/D_13600.pth
2024-01-01 20:21:00,232	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_11200.pth
2024-01-01 20:21:00,290	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_11200.pth
2024-01-01 20:21:11,676	44k	INFO	====> Epoch: 389, cost 35.51 s
2024-01-01 20:21:37,901	44k	INFO	====> Epoch: 390, cost 26.22 s
2024-01-01 20:22:04,057	44k	INFO	====> Epoch: 391, cost 26.16 s
2024-01-01 20:22:30,296	44k	INFO	====> Epoch: 392, cost 26.24 s
2024-01-01 20:22:56,986	44k	INFO	====> Epoch: 393, cost 26.69 s
2024-01-01 20:23:23,286	44k	INFO	====> Epoch: 394, cost 26.30 s
2024-01-01 20:23:30,760	44k	INFO	Train Epoch: 395 [26%]
2024-01-01 20:23:30,761	44k	INFO	Losses: [2.031942129135132, 3.315570831298828, 6.556353569030762, 20.89754295349121, 1.0135937929153442], step: 13800, lr: 9.519401837296521e-05, reference_loss: 33.815006256103516
2024-01-01 20:23:50,055	44k	INFO	====> Epoch: 395, cost 26.77 s
2024-01-01 20:24:16,443	44k	INFO	====> Epoch: 396, cost 26.39 s
2024-01-01 20:24:42,806	44k	INFO	====> Epoch: 397, cost 26.36 s
2024-01-01 20:25:09,195	44k	INFO	====> Epoch: 398, cost 26.39 s
2024-01-01 20:25:35,609	44k	INFO	====> Epoch: 399, cost 26.41 s
2024-01-01 20:26:01,977	44k	INFO	Train Epoch: 400 [97%]
2024-01-01 20:26:01,978	44k	INFO	Losses: [2.3731465339660645, 2.3715453147888184, 5.306015968322754, 21.692333221435547, 0.7387848496437073], step: 14000, lr: 9.513453698368834e-05, reference_loss: 32.48182678222656
2024-01-01 20:26:02,798	44k	INFO	====> Epoch: 400, cost 27.19 s
2024-01-01 20:26:29,190	44k	INFO	====> Epoch: 401, cost 26.39 s
2024-01-01 20:26:55,653	44k	INFO	====> Epoch: 402, cost 26.46 s
2024-01-01 20:27:21,931	44k	INFO	====> Epoch: 403, cost 26.28 s
2024-01-01 20:27:48,265	44k	INFO	====> Epoch: 404, cost 26.33 s
2024-01-01 20:28:14,496	44k	INFO	====> Epoch: 405, cost 26.23 s
2024-01-01 20:28:33,261	44k	INFO	Train Epoch: 406 [69%]
2024-01-01 20:28:33,262	44k	INFO	Losses: [2.0412113666534424, 2.8436388969421387, 5.6428070068359375, 20.889188766479492, 0.7850174307823181], step: 14200, lr: 9.506320837439182e-05, reference_loss: 32.201866149902344
2024-01-01 20:28:41,329	44k	INFO	====> Epoch: 406, cost 26.83 s
2024-01-01 20:29:07,944	44k	INFO	====> Epoch: 407, cost 26.62 s
2024-01-01 20:29:34,272	44k	INFO	====> Epoch: 408, cost 26.33 s
2024-01-01 20:30:00,651	44k	INFO	====> Epoch: 409, cost 26.38 s
2024-01-01 20:30:27,005	44k	INFO	====> Epoch: 410, cost 26.35 s
2024-01-01 20:30:53,242	44k	INFO	====> Epoch: 411, cost 26.24 s
2024-01-01 20:31:04,405	44k	INFO	Train Epoch: 412 [40%]
2024-01-01 20:31:04,405	44k	INFO	Losses: [2.191866636276245, 2.788076877593994, 6.670120716094971, 24.838417053222656, 0.8420030474662781], step: 14400, lr: 9.49919332448374e-05, reference_loss: 37.330482482910156
2024-01-01 20:31:11,708	44k	INFO	Saving model and optimizer state at iteration 412 to ./logs/44k/G_14400.pth
2024-01-01 20:31:12,620	44k	INFO	Saving model and optimizer state at iteration 412 to ./logs/44k/D_14400.pth
2024-01-01 20:31:13,393	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_12000.pth
2024-01-01 20:31:13,450	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_12000.pth
2024-01-01 20:31:28,900	44k	INFO	====> Epoch: 412, cost 35.66 s
2024-01-01 20:31:55,276	44k	INFO	====> Epoch: 413, cost 26.38 s
2024-01-01 20:32:21,606	44k	INFO	====> Epoch: 414, cost 26.33 s
2024-01-01 20:32:47,903	44k	INFO	====> Epoch: 415, cost 26.30 s
2024-01-01 20:33:14,208	44k	INFO	====> Epoch: 416, cost 26.31 s
2024-01-01 20:33:40,355	44k	INFO	====> Epoch: 417, cost 26.15 s
2024-01-01 20:33:44,086	44k	INFO	Train Epoch: 418 [11%]
2024-01-01 20:33:44,087	44k	INFO	Losses: [2.5724053382873535, 2.816927671432495, 5.650980472564697, 20.906944274902344, 0.8507409691810608], step: 14600, lr: 9.492071155492783e-05, reference_loss: 32.79800033569336
2024-01-01 20:34:07,151	44k	INFO	====> Epoch: 418, cost 26.80 s
2024-01-01 20:34:33,386	44k	INFO	====> Epoch: 419, cost 26.23 s
2024-01-01 20:34:59,600	44k	INFO	====> Epoch: 420, cost 26.21 s
2024-01-01 20:35:26,150	44k	INFO	====> Epoch: 421, cost 26.55 s
2024-01-01 20:35:52,326	44k	INFO	====> Epoch: 422, cost 26.18 s
2024-01-01 20:36:14,909	44k	INFO	Train Epoch: 423 [83%]
2024-01-01 20:36:14,910	44k	INFO	Losses: [2.4194788932800293, 2.656792640686035, 5.5986552238464355, 22.966455459594727, 0.921992301940918], step: 14800, lr: 9.486140093971337e-05, reference_loss: 34.56337356567383
2024-01-01 20:36:19,320	44k	INFO	====> Epoch: 423, cost 26.99 s
2024-01-01 20:36:45,707	44k	INFO	====> Epoch: 424, cost 26.39 s
2024-01-01 20:37:12,024	44k	INFO	====> Epoch: 425, cost 26.32 s
2024-01-01 20:37:38,402	44k	INFO	====> Epoch: 426, cost 26.38 s
2024-01-01 20:38:04,754	44k	INFO	====> Epoch: 427, cost 26.35 s
2024-01-01 20:38:31,102	44k	INFO	====> Epoch: 428, cost 26.35 s
2024-01-01 20:38:46,397	44k	INFO	Train Epoch: 429 [54%]
2024-01-01 20:38:46,398	44k	INFO	Losses: [2.255544424057007, 2.4907302856445312, 6.076578617095947, 23.356426239013672, 0.8578638434410095], step: 15000, lr: 9.479027711844423e-05, reference_loss: 35.03714370727539
2024-01-01 20:38:58,240	44k	INFO	====> Epoch: 429, cost 27.14 s
2024-01-01 20:39:24,499	44k	INFO	====> Epoch: 430, cost 26.26 s
2024-01-01 20:39:50,677	44k	INFO	====> Epoch: 431, cost 26.18 s
2024-01-01 20:40:16,927	44k	INFO	====> Epoch: 432, cost 26.25 s
2024-01-01 20:40:43,117	44k	INFO	====> Epoch: 433, cost 26.19 s
2024-01-01 20:41:09,360	44k	INFO	====> Epoch: 434, cost 26.24 s
2024-01-01 20:41:16,866	44k	INFO	Train Epoch: 435 [26%]
2024-01-01 20:41:16,867	44k	INFO	Losses: [2.236497163772583, 2.8231520652770996, 6.2508039474487305, 22.86960792541504, 0.8193379044532776], step: 15200, lr: 9.471920662337418e-05, reference_loss: 34.9994010925293
2024-01-01 20:41:24,566	44k	INFO	Saving model and optimizer state at iteration 435 to ./logs/44k/G_15200.pth
2024-01-01 20:41:25,467	44k	INFO	Saving model and optimizer state at iteration 435 to ./logs/44k/D_15200.pth
2024-01-01 20:41:26,228	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_12800.pth
2024-01-01 20:41:26,286	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_12800.pth
2024-01-01 20:41:45,029	44k	INFO	====> Epoch: 435, cost 35.67 s
2024-01-01 20:42:11,314	44k	INFO	====> Epoch: 436, cost 26.28 s
2024-01-01 20:42:37,479	44k	INFO	====> Epoch: 437, cost 26.17 s
2024-01-01 20:43:03,823	44k	INFO	====> Epoch: 438, cost 26.34 s
2024-01-01 20:43:30,183	44k	INFO	====> Epoch: 439, cost 26.36 s
2024-01-01 20:43:56,473	44k	INFO	Train Epoch: 440 [97%]
2024-01-01 20:43:56,474	44k	INFO	Losses: [2.3080055713653564, 2.3966944217681885, 6.507918834686279, 24.625497817993164, 0.723601758480072], step: 15400, lr: 9.466002191726074e-05, reference_loss: 36.56171798706055
2024-01-01 20:43:57,274	44k	INFO	====> Epoch: 440, cost 27.09 s
2024-01-01 20:44:23,503	44k	INFO	====> Epoch: 441, cost 26.23 s
2024-01-01 20:44:49,834	44k	INFO	====> Epoch: 442, cost 26.33 s
2024-01-01 20:45:16,220	44k	INFO	====> Epoch: 443, cost 26.39 s
2024-01-01 20:45:42,500	44k	INFO	====> Epoch: 444, cost 26.28 s
2024-01-01 20:46:08,883	44k	INFO	====> Epoch: 445, cost 26.38 s
2024-01-01 20:46:27,672	44k	INFO	Train Epoch: 446 [69%]
2024-01-01 20:46:27,673	44k	INFO	Losses: [2.111182689666748, 2.600356340408325, 5.964646816253662, 21.12962532043457, 1.1854411363601685], step: 15600, lr: 9.458904908306811e-05, reference_loss: 32.99125289916992
2024-01-01 20:46:35,685	44k	INFO	====> Epoch: 446, cost 26.80 s
2024-01-01 20:47:02,369	44k	INFO	====> Epoch: 447, cost 26.68 s
2024-01-01 20:47:28,756	44k	INFO	====> Epoch: 448, cost 26.39 s
2024-01-01 20:47:55,125	44k	INFO	====> Epoch: 449, cost 26.37 s
2024-01-01 20:48:21,466	44k	INFO	====> Epoch: 450, cost 26.34 s
2024-01-01 20:48:47,775	44k	INFO	====> Epoch: 451, cost 26.31 s
2024-01-01 20:48:58,942	44k	INFO	Train Epoch: 452 [40%]
2024-01-01 20:48:58,943	44k	INFO	Losses: [2.038090467453003, 2.527369499206543, 6.427295207977295, 21.169952392578125, 1.0460165739059448], step: 15800, lr: 9.451812946186962e-05, reference_loss: 33.20872497558594
2024-01-01 20:49:14,549	44k	INFO	====> Epoch: 452, cost 26.77 s
2024-01-01 20:49:40,753	44k	INFO	====> Epoch: 453, cost 26.20 s
2024-01-01 20:50:06,945	44k	INFO	====> Epoch: 454, cost 26.19 s
2024-01-01 20:50:33,568	44k	INFO	====> Epoch: 455, cost 26.62 s
2024-01-01 20:50:59,907	44k	INFO	====> Epoch: 456, cost 26.34 s
2024-01-01 20:51:26,265	44k	INFO	====> Epoch: 457, cost 26.36 s
2024-01-01 20:51:29,999	44k	INFO	Train Epoch: 458 [11%]
2024-01-01 20:51:30,000	44k	INFO	Losses: [2.0712337493896484, 3.187849760055542, 7.032210350036621, 20.74505615234375, 1.0819731950759888], step: 16000, lr: 9.4447263013768e-05, reference_loss: 34.118324279785156
2024-01-01 20:51:37,515	44k	INFO	Saving model and optimizer state at iteration 458 to ./logs/44k/G_16000.pth
2024-01-01 20:51:38,388	44k	INFO	Saving model and optimizer state at iteration 458 to ./logs/44k/D_16000.pth
2024-01-01 20:51:39,159	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_13600.pth
2024-01-01 20:51:39,216	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_13600.pth
2024-01-01 20:52:01,705	44k	INFO	====> Epoch: 458, cost 35.44 s
2024-01-01 20:52:28,115	44k	INFO	====> Epoch: 459, cost 26.41 s
2024-01-01 20:52:54,764	44k	INFO	====> Epoch: 460, cost 26.65 s
2024-01-01 20:53:21,094	44k	INFO	====> Epoch: 461, cost 26.33 s
2024-01-01 20:53:47,254	44k	INFO	====> Epoch: 462, cost 26.16 s
2024-01-01 20:54:09,592	44k	INFO	Train Epoch: 463 [83%]
2024-01-01 20:54:09,593	44k	INFO	Losses: [2.454458713531494, 2.6682779788970947, 4.904757499694824, 19.285572052001953, 0.732257604598999], step: 16200, lr: 9.438824822992467e-05, reference_loss: 30.045324325561523
2024-01-01 20:54:13,810	44k	INFO	====> Epoch: 463, cost 26.56 s
2024-01-01 20:54:40,237	44k	INFO	====> Epoch: 464, cost 26.43 s
2024-01-01 20:55:06,599	44k	INFO	====> Epoch: 465, cost 26.36 s
2024-01-01 20:55:32,934	44k	INFO	====> Epoch: 466, cost 26.33 s
2024-01-01 20:55:59,248	44k	INFO	====> Epoch: 467, cost 26.31 s
2024-01-01 20:56:25,916	44k	INFO	====> Epoch: 468, cost 26.67 s
2024-01-01 20:56:40,867	44k	INFO	Train Epoch: 469 [54%]
2024-01-01 20:56:40,867	44k	INFO	Losses: [2.2010960578918457, 2.6083247661590576, 5.262823581695557, 19.742652893066406, 0.9113840460777283], step: 16400, lr: 9.431747916231119e-05, reference_loss: 30.726282119750977
2024-01-01 20:56:52,720	44k	INFO	====> Epoch: 469, cost 26.80 s
2024-01-01 20:57:19,084	44k	INFO	====> Epoch: 470, cost 26.36 s
2024-01-01 20:57:45,358	44k	INFO	====> Epoch: 471, cost 26.27 s
2024-01-01 20:58:11,616	44k	INFO	====> Epoch: 472, cost 26.26 s
2024-01-01 20:58:37,955	44k	INFO	====> Epoch: 473, cost 26.34 s
2024-01-01 20:59:04,325	44k	INFO	====> Epoch: 474, cost 26.37 s
2024-01-01 20:59:11,808	44k	INFO	Train Epoch: 475 [26%]
2024-01-01 20:59:11,809	44k	INFO	Losses: [2.0513105392456055, 2.8036303520202637, 5.619253635406494, 21.03355598449707, 0.8561808466911316], step: 16600, lr: 9.424676315491467e-05, reference_loss: 32.36393356323242
2024-01-01 20:59:31,339	44k	INFO	====> Epoch: 475, cost 27.01 s
2024-01-01 20:59:57,723	44k	INFO	====> Epoch: 476, cost 26.38 s
2024-01-01 21:00:24,057	44k	INFO	====> Epoch: 477, cost 26.33 s
2024-01-01 21:00:50,420	44k	INFO	====> Epoch: 478, cost 26.36 s
2024-01-01 21:01:16,737	44k	INFO	====> Epoch: 479, cost 26.32 s
2024-01-01 21:01:43,147	44k	INFO	Train Epoch: 480 [97%]
2024-01-01 21:01:43,147	44k	INFO	Losses: [2.8311758041381836, 2.6226186752319336, 4.175468921661377, 18.14368438720703, 0.8210127353668213], step: 16800, lr: 9.418787365215894e-05, reference_loss: 28.59395980834961
2024-01-01 21:01:50,593	44k	INFO	Saving model and optimizer state at iteration 480 to ./logs/44k/G_16800.pth
2024-01-01 21:01:51,825	44k	INFO	Saving model and optimizer state at iteration 480 to ./logs/44k/D_16800.pth
2024-01-01 21:01:52,599	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_14400.pth
2024-01-01 21:01:52,656	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_14400.pth
2024-01-01 21:01:52,656	44k	INFO	====> Epoch: 480, cost 35.92 s
2024-01-01 21:02:18,790	44k	INFO	====> Epoch: 481, cost 26.13 s
2024-01-01 21:02:45,148	44k	INFO	====> Epoch: 482, cost 26.36 s
2024-01-01 21:03:11,486	44k	INFO	====> Epoch: 483, cost 26.34 s
2024-01-01 21:03:37,869	44k	INFO	====> Epoch: 484, cost 26.38 s
2024-01-01 21:04:04,206	44k	INFO	====> Epoch: 485, cost 26.34 s
2024-01-01 21:04:23,000	44k	INFO	Train Epoch: 486 [69%]
2024-01-01 21:04:23,001	44k	INFO	Losses: [2.1406004428863525, 2.8078508377075195, 6.3709025382995605, 19.9416561126709, 0.9816249012947083], step: 17000, lr: 9.411725481852385e-05, reference_loss: 32.24263381958008
2024-01-01 21:04:31,062	44k	INFO	====> Epoch: 486, cost 26.86 s
2024-01-01 21:04:57,631	44k	INFO	====> Epoch: 487, cost 26.57 s
2024-01-01 21:05:24,020	44k	INFO	====> Epoch: 488, cost 26.39 s
2024-01-01 21:05:50,296	44k	INFO	====> Epoch: 489, cost 26.28 s
2024-01-01 21:06:16,538	44k	INFO	====> Epoch: 490, cost 26.24 s
2024-01-01 21:06:42,896	44k	INFO	====> Epoch: 491, cost 26.36 s
2024-01-01 21:06:54,079	44k	INFO	Train Epoch: 492 [40%]
2024-01-01 21:06:54,079	44k	INFO	Losses: [2.3945260047912598, 2.6229755878448486, 5.935941219329834, 21.42875862121582, 0.8171751499176025], step: 17200, lr: 9.404668893246542e-05, reference_loss: 33.199378967285156
2024-01-01 21:07:09,704	44k	INFO	====> Epoch: 492, cost 26.81 s
2024-01-01 21:07:36,054	44k	INFO	====> Epoch: 493, cost 26.35 s
2024-01-01 21:08:02,400	44k	INFO	====> Epoch: 494, cost 26.35 s
2024-01-01 21:08:28,890	44k	INFO	====> Epoch: 495, cost 26.49 s
2024-01-01 21:08:55,061	44k	INFO	====> Epoch: 496, cost 26.17 s
2024-01-01 21:09:21,339	44k	INFO	====> Epoch: 497, cost 26.28 s
2024-01-01 21:09:25,043	44k	INFO	Train Epoch: 498 [11%]
2024-01-01 21:09:25,043	44k	INFO	Losses: [2.4641268253326416, 2.4496874809265137, 5.186786651611328, 21.14594078063965, 0.6889601945877075], step: 17400, lr: 9.397617595428541e-05, reference_loss: 31.935503005981445
2024-01-01 21:09:48,073	44k	INFO	====> Epoch: 498, cost 26.73 s
2024-01-01 21:10:14,425	44k	INFO	====> Epoch: 499, cost 26.35 s
2024-01-01 21:10:40,583	44k	INFO	====> Epoch: 500, cost 26.16 s
2024-01-01 21:11:06,888	44k	INFO	====> Epoch: 501, cost 26.31 s
2024-01-01 21:11:33,479	44k	INFO	====> Epoch: 502, cost 26.59 s
2024-01-01 21:11:55,946	44k	INFO	Train Epoch: 503 [83%]
2024-01-01 21:11:55,947	44k	INFO	Losses: [2.202549934387207, 2.608304977416992, 5.7509260177612305, 17.907875061035156, 0.869032084941864], step: 17600, lr: 9.39174555262561e-05, reference_loss: 29.338687896728516
2024-01-01 21:12:03,315	44k	INFO	Saving model and optimizer state at iteration 503 to ./logs/44k/G_17600.pth
2024-01-01 21:12:04,195	44k	INFO	Saving model and optimizer state at iteration 503 to ./logs/44k/D_17600.pth
2024-01-01 21:12:04,964	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_15200.pth
2024-01-01 21:12:05,020	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_15200.pth
2024-01-01 21:12:08,793	44k	INFO	====> Epoch: 503, cost 35.31 s
2024-01-01 21:12:35,162	44k	INFO	====> Epoch: 504, cost 26.37 s
2024-01-01 21:13:01,497	44k	INFO	====> Epoch: 505, cost 26.33 s
2024-01-01 21:13:27,906	44k	INFO	====> Epoch: 506, cost 26.41 s
2024-01-01 21:13:54,421	44k	INFO	====> Epoch: 507, cost 26.52 s
2024-01-01 21:14:20,659	44k	INFO	====> Epoch: 508, cost 26.24 s
2024-01-01 21:14:35,659	44k	INFO	Train Epoch: 509 [54%]
2024-01-01 21:14:35,660	44k	INFO	Losses: [2.212852954864502, 2.5104010105133057, 5.536928653717041, 19.104873657226562, 0.5965662598609924], step: 17800, lr: 9.384703944284672e-05, reference_loss: 29.961624145507812
2024-01-01 21:14:47,538	44k	INFO	====> Epoch: 509, cost 26.88 s
2024-01-01 21:15:13,922	44k	INFO	====> Epoch: 510, cost 26.38 s
2024-01-01 21:15:40,290	44k	INFO	====> Epoch: 511, cost 26.37 s
2024-01-01 21:16:06,617	44k	INFO	====> Epoch: 512, cost 26.33 s
2024-01-01 21:16:32,841	44k	INFO	====> Epoch: 513, cost 26.22 s
2024-01-01 21:16:59,138	44k	INFO	====> Epoch: 514, cost 26.30 s
2024-01-01 21:17:06,610	44k	INFO	Train Epoch: 515 [26%]
2024-01-01 21:17:06,611	44k	INFO	Losses: [2.026857376098633, 3.011509418487549, 6.864241600036621, 20.550647735595703, 1.1088799238204956], step: 18000, lr: 9.377667615499888e-05, reference_loss: 33.5621337890625
2024-01-01 21:17:26,170	44k	INFO	====> Epoch: 515, cost 27.03 s
2024-01-01 21:17:52,361	44k	INFO	====> Epoch: 516, cost 26.19 s
2024-01-01 21:18:18,579	44k	INFO	====> Epoch: 517, cost 26.22 s
2024-01-01 21:18:44,889	44k	INFO	====> Epoch: 518, cost 26.31 s
2024-01-01 21:19:11,223	44k	INFO	====> Epoch: 519, cost 26.33 s
2024-01-01 21:19:37,586	44k	INFO	Train Epoch: 520 [97%]
2024-01-01 21:19:37,586	44k	INFO	Losses: [2.257110595703125, 2.7262277603149414, 6.517843246459961, 22.786972045898438, 0.8501678705215454], step: 18200, lr: 9.371808038317619e-05, reference_loss: 35.13832092285156
2024-01-01 21:19:38,087	44k	INFO	====> Epoch: 520, cost 26.86 s
2024-01-01 21:20:04,652	44k	INFO	====> Epoch: 521, cost 26.57 s
2024-01-01 21:20:31,035	44k	INFO	====> Epoch: 522, cost 26.38 s
2024-01-01 21:20:57,294	44k	INFO	====> Epoch: 523, cost 26.26 s
2024-01-01 21:21:23,592	44k	INFO	====> Epoch: 524, cost 26.30 s
2024-01-01 21:21:49,917	44k	INFO	====> Epoch: 525, cost 26.32 s
2024-01-01 21:22:08,516	44k	INFO	Train Epoch: 526 [69%]
2024-01-01 21:22:08,516	44k	INFO	Losses: [2.2089879512786865, 2.6038453578948975, 5.898712158203125, 19.996931076049805, 0.9341514706611633], step: 18400, lr: 9.364781378440336e-05, reference_loss: 31.642627716064453
2024-01-01 21:22:16,042	44k	INFO	Saving model and optimizer state at iteration 526 to ./logs/44k/G_18400.pth
2024-01-01 21:22:16,942	44k	INFO	Saving model and optimizer state at iteration 526 to ./logs/44k/D_18400.pth
2024-01-01 21:22:17,745	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_16000.pth
2024-01-01 21:22:17,803	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_16000.pth
2024-01-01 21:22:25,380	44k	INFO	====> Epoch: 526, cost 35.46 s
2024-01-01 21:22:52,110	44k	INFO	====> Epoch: 527, cost 26.73 s
2024-01-01 21:23:18,340	44k	INFO	====> Epoch: 528, cost 26.23 s
2024-01-01 21:23:44,560	44k	INFO	====> Epoch: 529, cost 26.22 s
2024-01-01 21:24:10,847	44k	INFO	====> Epoch: 530, cost 26.29 s
2024-01-01 21:24:37,103	44k	INFO	====> Epoch: 531, cost 26.26 s
2024-01-01 21:24:48,304	44k	INFO	Train Epoch: 532 [40%]
2024-01-01 21:24:48,305	44k	INFO	Losses: [2.373469114303589, 2.6769778728485107, 6.095352649688721, 21.4622859954834, 0.7180389761924744], step: 18600, lr: 9.357759986911361e-05, reference_loss: 33.32612609863281
2024-01-01 21:25:03,843	44k	INFO	====> Epoch: 532, cost 26.74 s
2024-01-01 21:25:30,192	44k	INFO	====> Epoch: 533, cost 26.35 s
2024-01-01 21:25:56,577	44k	INFO	====> Epoch: 534, cost 26.39 s
2024-01-01 21:26:22,936	44k	INFO	====> Epoch: 535, cost 26.36 s
2024-01-01 21:26:49,570	44k	INFO	====> Epoch: 536, cost 26.63 s
2024-01-01 21:27:15,827	44k	INFO	====> Epoch: 537, cost 26.26 s
2024-01-01 21:27:19,561	44k	INFO	Train Epoch: 538 [11%]
2024-01-01 21:27:19,561	44k	INFO	Losses: [2.323843240737915, 2.5307698249816895, 5.59810209274292, 21.597970962524414, 0.7264502048492432], step: 18800, lr: 9.350743859780667e-05, reference_loss: 32.777137756347656
2024-01-01 21:27:42,577	44k	INFO	====> Epoch: 538, cost 26.75 s
2024-01-01 21:28:08,930	44k	INFO	====> Epoch: 539, cost 26.35 s
2024-01-01 21:28:35,274	44k	INFO	====> Epoch: 540, cost 26.34 s
2024-01-01 21:29:01,672	44k	INFO	====> Epoch: 541, cost 26.40 s
2024-01-01 21:29:28,102	44k	INFO	====> Epoch: 542, cost 26.43 s
2024-01-01 21:29:50,904	44k	INFO	Train Epoch: 543 [83%]
2024-01-01 21:29:50,904	44k	INFO	Losses: [2.3168060779571533, 2.425738573074341, 5.6806817054748535, 20.344921112060547, 0.9484509229660034], step: 19000, lr: 9.344901105739411e-05, reference_loss: 31.716596603393555
2024-01-01 21:29:55,143	44k	INFO	====> Epoch: 543, cost 27.04 s
2024-01-01 21:30:21,407	44k	INFO	====> Epoch: 544, cost 26.26 s
2024-01-01 21:30:47,638	44k	INFO	====> Epoch: 545, cost 26.23 s
2024-01-01 21:31:13,848	44k	INFO	====> Epoch: 546, cost 26.21 s
2024-01-01 21:31:40,228	44k	INFO	====> Epoch: 547, cost 26.38 s
2024-01-01 21:32:06,645	44k	INFO	====> Epoch: 548, cost 26.42 s
2024-01-01 21:32:21,610	44k	INFO	Train Epoch: 549 [54%]
2024-01-01 21:32:21,611	44k	INFO	Losses: [2.3150081634521484, 2.310861825942993, 6.358094215393066, 20.329349517822266, 0.8975706100463867], step: 19200, lr: 9.337894619756301e-05, reference_loss: 32.21088409423828
2024-01-01 21:32:29,302	44k	INFO	Saving model and optimizer state at iteration 549 to ./logs/44k/G_19200.pth
2024-01-01 21:32:30,216	44k	INFO	Saving model and optimizer state at iteration 549 to ./logs/44k/D_19200.pth
2024-01-01 21:32:30,991	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_16800.pth
2024-01-01 21:32:31,048	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_16800.pth
2024-01-01 21:32:42,348	44k	INFO	====> Epoch: 549, cost 35.70 s
2024-01-01 21:33:08,572	44k	INFO	====> Epoch: 550, cost 26.22 s
2024-01-01 21:33:34,859	44k	INFO	====> Epoch: 551, cost 26.29 s
2024-01-01 21:34:01,245	44k	INFO	====> Epoch: 552, cost 26.39 s
2024-01-01 21:34:27,473	44k	INFO	====> Epoch: 553, cost 26.23 s
2024-01-01 21:34:53,691	44k	INFO	====> Epoch: 554, cost 26.22 s
2024-01-01 21:35:01,155	44k	INFO	Train Epoch: 555 [26%]
2024-01-01 21:35:01,155	44k	INFO	Losses: [2.4372663497924805, 2.4715051651000977, 4.862152576446533, 19.23459243774414, 1.0196912288665771], step: 19400, lr: 9.330893386995804e-05, reference_loss: 30.02520751953125
2024-01-01 21:35:20,792	44k	INFO	====> Epoch: 555, cost 27.10 s
2024-01-01 21:35:47,135	44k	INFO	====> Epoch: 556, cost 26.34 s
2024-01-01 21:36:13,415	44k	INFO	====> Epoch: 557, cost 26.28 s
2024-01-01 21:36:39,763	44k	INFO	====> Epoch: 558, cost 26.35 s
2024-01-01 21:37:05,953	44k	INFO	====> Epoch: 559, cost 26.19 s
2024-01-01 21:37:32,249	44k	INFO	Train Epoch: 560 [97%]
2024-01-01 21:37:32,249	44k	INFO	Losses: [2.6233839988708496, 2.4338388442993164, 4.393218994140625, 18.35381507873535, 0.7105328440666199], step: 19600, lr: 9.325063036398789e-05, reference_loss: 28.514789581298828
2024-01-01 21:37:32,729	44k	INFO	====> Epoch: 560, cost 26.78 s
2024-01-01 21:37:59,060	44k	INFO	====> Epoch: 561, cost 26.33 s
2024-01-01 21:38:25,636	44k	INFO	====> Epoch: 562, cost 26.58 s
2024-01-01 21:38:51,859	44k	INFO	====> Epoch: 563, cost 26.22 s
2024-01-01 21:39:18,036	44k	INFO	====> Epoch: 564, cost 26.18 s
2024-01-01 21:39:44,348	44k	INFO	====> Epoch: 565, cost 26.31 s
2024-01-01 21:40:03,145	44k	INFO	Train Epoch: 566 [69%]
2024-01-01 21:40:03,145	44k	INFO	Losses: [1.9635745286941528, 3.0360848903656006, 7.068606376647949, 19.60428237915039, 0.904154360294342], step: 19800, lr: 9.318071424318909e-05, reference_loss: 32.57670211791992
2024-01-01 21:40:11,323	44k	INFO	====> Epoch: 566, cost 26.97 s
2024-01-01 21:40:37,567	44k	INFO	====> Epoch: 567, cost 26.24 s
2024-01-01 21:41:03,866	44k	INFO	====> Epoch: 568, cost 26.30 s
2024-01-01 21:41:30,444	44k	INFO	====> Epoch: 569, cost 26.58 s
2024-01-01 21:41:56,823	44k	INFO	====> Epoch: 570, cost 26.38 s
2024-01-01 21:42:23,201	44k	INFO	====> Epoch: 571, cost 26.38 s
2024-01-01 21:42:34,364	44k	INFO	Train Epoch: 572 [40%]
2024-01-01 21:42:34,365	44k	INFO	Losses: [2.6157026290893555, 2.886535882949829, 6.654749393463135, 22.44212532043457, 0.8474141359329224], step: 20000, lr: 9.311085054309703e-05, reference_loss: 35.446529388427734
2024-01-01 21:42:41,682	44k	INFO	Saving model and optimizer state at iteration 572 to ./logs/44k/G_20000.pth
2024-01-01 21:42:42,579	44k	INFO	Saving model and optimizer state at iteration 572 to ./logs/44k/D_20000.pth
2024-01-01 21:42:43,369	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_17600.pth
2024-01-01 21:42:43,426	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_17600.pth
2024-01-01 21:42:58,559	44k	INFO	====> Epoch: 572, cost 35.36 s
2024-01-01 21:43:24,808	44k	INFO	====> Epoch: 573, cost 26.25 s
2024-01-01 21:43:51,482	44k	INFO	====> Epoch: 574, cost 26.67 s
2024-01-01 21:44:17,872	44k	INFO	====> Epoch: 575, cost 26.39 s
2024-01-01 21:44:44,256	44k	INFO	====> Epoch: 576, cost 26.38 s
2024-01-01 21:45:10,610	44k	INFO	====> Epoch: 577, cost 26.35 s
2024-01-01 21:45:14,366	44k	INFO	Train Epoch: 578 [11%]
2024-01-01 21:45:14,366	44k	INFO	Losses: [2.4081201553344727, 2.5154011249542236, 4.906094551086426, 18.19757652282715, 0.7601426243782043], step: 20200, lr: 9.304103922440849e-05, reference_loss: 28.787334442138672
2024-01-01 21:45:37,238	44k	INFO	====> Epoch: 578, cost 26.63 s
2024-01-01 21:46:03,600	44k	INFO	====> Epoch: 579, cost 26.36 s
2024-01-01 21:46:29,886	44k	INFO	====> Epoch: 580, cost 26.29 s
2024-01-01 21:46:56,234	44k	INFO	====> Epoch: 581, cost 26.35 s
2024-01-01 21:47:22,566	44k	INFO	====> Epoch: 582, cost 26.33 s
2024-01-01 21:47:45,318	44k	INFO	Train Epoch: 583 [83%]
2024-01-01 21:47:45,319	44k	INFO	Losses: [2.3328545093536377, 2.741691827774048, 5.656286716461182, 21.280513763427734, 0.8927627205848694], step: 20400, lr: 9.29829031107385e-05, reference_loss: 32.90410614013672
2024-01-01 21:47:49,548	44k	INFO	====> Epoch: 583, cost 26.98 s
2024-01-01 21:48:15,850	44k	INFO	====> Epoch: 584, cost 26.30 s
2024-01-01 21:48:42,166	44k	INFO	====> Epoch: 585, cost 26.32 s
2024-01-01 21:49:08,349	44k	INFO	====> Epoch: 586, cost 26.18 s
2024-01-01 21:49:34,690	44k	INFO	====> Epoch: 587, cost 26.34 s
2024-01-01 21:50:01,044	44k	INFO	====> Epoch: 588, cost 26.35 s
2024-01-01 21:50:16,059	44k	INFO	Train Epoch: 589 [54%]
2024-01-01 21:50:16,060	44k	INFO	Losses: [2.489614725112915, 2.091768741607666, 5.835916996002197, 21.318355560302734, 0.8069919943809509], step: 20600, lr: 9.291318772264153e-05, reference_loss: 32.54264831542969
2024-01-01 21:50:28,293	44k	INFO	====> Epoch: 589, cost 27.25 s
2024-01-01 21:50:54,614	44k	INFO	====> Epoch: 590, cost 26.32 s
2024-01-01 21:51:21,011	44k	INFO	====> Epoch: 591, cost 26.40 s
2024-01-01 21:51:47,321	44k	INFO	====> Epoch: 592, cost 26.31 s
2024-01-01 21:52:13,682	44k	INFO	====> Epoch: 593, cost 26.36 s
2024-01-01 21:52:39,934	44k	INFO	====> Epoch: 594, cost 26.25 s
2024-01-01 21:52:47,368	44k	INFO	Train Epoch: 595 [26%]
2024-01-01 21:52:47,369	44k	INFO	Losses: [2.61965012550354, 2.1344940662384033, 4.980733394622803, 20.610403060913086, 0.7035025358200073], step: 20800, lr: 9.284352460474882e-05, reference_loss: 31.048782348632812
2024-01-01 21:52:54,715	44k	INFO	Saving model and optimizer state at iteration 595 to ./logs/44k/G_20800.pth
2024-01-01 21:52:55,934	44k	INFO	Saving model and optimizer state at iteration 595 to ./logs/44k/D_20800.pth
2024-01-01 21:52:56,710	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_18400.pth
2024-01-01 21:52:56,768	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_18400.pth
2024-01-01 21:53:15,637	44k	INFO	====> Epoch: 595, cost 35.70 s
2024-01-01 21:53:41,934	44k	INFO	====> Epoch: 596, cost 26.30 s
2024-01-01 21:54:08,275	44k	INFO	====> Epoch: 597, cost 26.34 s
2024-01-01 21:54:34,578	44k	INFO	====> Epoch: 598, cost 26.30 s
2024-01-01 21:55:00,875	44k	INFO	====> Epoch: 599, cost 26.30 s
2024-01-01 21:55:27,014	44k	INFO	Train Epoch: 600 [97%]
2024-01-01 21:55:27,014	44k	INFO	Losses: [2.3817527294158936, 2.3784217834472656, 5.9785003662109375, 21.596986770629883, 0.6812178492546082], step: 21000, lr: 9.27855119068583e-05, reference_loss: 33.01688003540039
2024-01-01 21:55:27,526	44k	INFO	====> Epoch: 600, cost 26.65 s
2024-01-01 21:55:53,770	44k	INFO	====> Epoch: 601, cost 26.24 s
2024-01-01 21:56:20,438	44k	INFO	====> Epoch: 602, cost 26.67 s
2024-01-01 21:56:46,692	44k	INFO	====> Epoch: 603, cost 26.25 s
2024-01-01 21:57:13,053	44k	INFO	====> Epoch: 604, cost 26.36 s
2024-01-01 21:57:39,413	44k	INFO	====> Epoch: 605, cost 26.36 s
2024-01-01 21:57:58,187	44k	INFO	Train Epoch: 606 [69%]
2024-01-01 21:57:58,188	44k	INFO	Losses: [2.307565212249756, 2.4775171279907227, 5.89841890335083, 20.371068954467773, 0.9533942341804504], step: 21200, lr: 9.27159445159084e-05, reference_loss: 32.007965087890625
2024-01-01 21:58:06,398	44k	INFO	====> Epoch: 606, cost 26.99 s
2024-01-01 21:58:32,695	44k	INFO	====> Epoch: 607, cost 26.30 s
2024-01-01 21:58:58,880	44k	INFO	====> Epoch: 608, cost 26.19 s
2024-01-01 21:59:25,326	44k	INFO	====> Epoch: 609, cost 26.45 s
2024-01-01 21:59:51,678	44k	INFO	====> Epoch: 610, cost 26.35 s
2024-01-01 22:00:18,001	44k	INFO	====> Epoch: 611, cost 26.32 s
2024-01-01 22:00:29,179	44k	INFO	Train Epoch: 612 [40%]
2024-01-01 22:00:29,179	44k	INFO	Losses: [2.563438892364502, 2.137021064758301, 4.907074928283691, 19.848997116088867, 1.0475585460662842], step: 21400, lr: 9.264642928419956e-05, reference_loss: 30.50408935546875
2024-01-01 22:00:44,790	44k	INFO	====> Epoch: 612, cost 26.79 s
2024-01-01 22:01:11,144	44k	INFO	====> Epoch: 613, cost 26.35 s
2024-01-01 22:01:37,483	44k	INFO	====> Epoch: 614, cost 26.34 s
2024-01-01 22:02:03,772	44k	INFO	====> Epoch: 615, cost 26.29 s
2024-01-01 22:02:30,291	44k	INFO	====> Epoch: 616, cost 26.52 s
2024-01-01 22:02:56,391	44k	INFO	====> Epoch: 617, cost 26.10 s
2024-01-01 22:03:00,116	44k	INFO	Train Epoch: 618 [11%]
2024-01-01 22:03:00,117	44k	INFO	Losses: [2.172062397003174, 3.121464729309082, 6.625033378601074, 18.0672664642334, 0.9477307796478271], step: 21600, lr: 9.257696617262459e-05, reference_loss: 30.933557510375977
2024-01-01 22:03:07,459	44k	INFO	Saving model and optimizer state at iteration 618 to ./logs/44k/G_21600.pth
2024-01-01 22:03:08,359	44k	INFO	Saving model and optimizer state at iteration 618 to ./logs/44k/D_21600.pth
2024-01-01 22:03:09,143	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_19200.pth
2024-01-01 22:03:09,200	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_19200.pth
2024-01-01 22:03:31,795	44k	INFO	====> Epoch: 618, cost 35.40 s
2024-01-01 22:03:58,057	44k	INFO	====> Epoch: 619, cost 26.26 s
2024-01-01 22:04:24,208	44k	INFO	====> Epoch: 620, cost 26.15 s
2024-01-01 22:04:50,874	44k	INFO	====> Epoch: 621, cost 26.67 s
2024-01-01 22:05:17,232	44k	INFO	====> Epoch: 622, cost 26.36 s
2024-01-01 22:05:39,831	44k	INFO	Train Epoch: 623 [83%]
2024-01-01 22:05:39,832	44k	INFO	Losses: [2.3046092987060547, 2.8582911491394043, 6.056982517242432, 18.044086456298828, 0.700928270816803], step: 21800, lr: 9.25191200321096e-05, reference_loss: 29.96489715576172
2024-01-01 22:05:44,053	44k	INFO	====> Epoch: 623, cost 26.82 s
2024-01-01 22:06:10,299	44k	INFO	====> Epoch: 624, cost 26.25 s
2024-01-01 22:06:36,601	44k	INFO	====> Epoch: 625, cost 26.30 s
2024-01-01 22:07:03,011	44k	INFO	====> Epoch: 626, cost 26.41 s
2024-01-01 22:07:29,179	44k	INFO	====> Epoch: 627, cost 26.17 s
2024-01-01 22:07:55,448	44k	INFO	====> Epoch: 628, cost 26.27 s
2024-01-01 22:08:10,416	44k	INFO	Train Epoch: 629 [54%]
2024-01-01 22:08:10,416	44k	INFO	Losses: [2.4381229877471924, 2.3081300258636475, 5.253615856170654, 19.57988739013672, 0.8666139245033264], step: 22000, lr: 9.244975237264057e-05, reference_loss: 30.446369171142578
2024-01-01 22:08:22,582	44k	INFO	====> Epoch: 629, cost 27.13 s
2024-01-01 22:08:48,946	44k	INFO	====> Epoch: 630, cost 26.36 s
2024-01-01 22:09:15,385	44k	INFO	====> Epoch: 631, cost 26.44 s
2024-01-01 22:09:41,720	44k	INFO	====> Epoch: 632, cost 26.33 s
2024-01-01 22:10:08,031	44k	INFO	====> Epoch: 633, cost 26.31 s
2024-01-01 22:10:34,372	44k	INFO	====> Epoch: 634, cost 26.34 s
2024-01-01 22:10:41,829	44k	INFO	Train Epoch: 635 [26%]
2024-01-01 22:10:41,830	44k	INFO	Losses: [2.299043655395508, 2.39841365814209, 5.622488975524902, 19.11069679260254, 0.7660245895385742], step: 22200, lr: 9.23804367226608e-05, reference_loss: 30.196666717529297
2024-01-01 22:11:01,438	44k	INFO	====> Epoch: 635, cost 27.07 s
2024-01-01 22:11:27,751	44k	INFO	====> Epoch: 636, cost 26.31 s
2024-01-01 22:11:54,081	44k	INFO	====> Epoch: 637, cost 26.33 s
2024-01-01 22:12:20,397	44k	INFO	====> Epoch: 638, cost 26.32 s
2024-01-01 22:12:46,634	44k	INFO	====> Epoch: 639, cost 26.24 s
2024-01-01 22:13:12,913	44k	INFO	Train Epoch: 640 [97%]
2024-01-01 22:13:12,913	44k	INFO	Losses: [2.0533525943756104, 2.988691806793213, 6.578303337097168, 18.749502182006836, 0.8047992587089539], step: 22400, lr: 9.232271338234815e-05, reference_loss: 31.174650192260742
2024-01-01 22:13:20,453	44k	INFO	Saving model and optimizer state at iteration 640 to ./logs/44k/G_22400.pth
2024-01-01 22:13:21,343	44k	INFO	Saving model and optimizer state at iteration 640 to ./logs/44k/D_22400.pth
2024-01-01 22:13:22,141	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_20000.pth
2024-01-01 22:13:22,199	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_20000.pth
2024-01-01 22:13:22,200	44k	INFO	====> Epoch: 640, cost 35.57 s
2024-01-01 22:13:48,866	44k	INFO	====> Epoch: 641, cost 26.67 s
2024-01-01 22:14:15,206	44k	INFO	====> Epoch: 642, cost 26.34 s
2024-01-01 22:14:41,605	44k	INFO	====> Epoch: 643, cost 26.40 s
2024-01-01 22:15:07,883	44k	INFO	====> Epoch: 644, cost 26.28 s
2024-01-01 22:15:34,148	44k	INFO	====> Epoch: 645, cost 26.26 s
2024-01-01 22:15:52,725	44k	INFO	Train Epoch: 646 [69%]
2024-01-01 22:15:52,726	44k	INFO	Losses: [2.3402488231658936, 2.2333362102508545, 5.749831676483154, 19.223339080810547, 0.7910647988319397], step: 22600, lr: 9.22534929818413e-05, reference_loss: 30.33782196044922
2024-01-01 22:16:00,915	44k	INFO	====> Epoch: 646, cost 26.77 s
2024-01-01 22:16:27,232	44k	INFO	====> Epoch: 647, cost 26.32 s
2024-01-01 22:16:53,650	44k	INFO	====> Epoch: 648, cost 26.42 s
2024-01-01 22:17:19,928	44k	INFO	====> Epoch: 649, cost 26.28 s
2024-01-01 22:17:46,564	44k	INFO	====> Epoch: 650, cost 26.64 s
2024-01-01 22:18:12,977	44k	INFO	====> Epoch: 651, cost 26.41 s
2024-01-01 22:18:24,191	44k	INFO	Train Epoch: 652 [40%]
2024-01-01 22:18:24,192	44k	INFO	Losses: [2.47011137008667, 2.375606060028076, 5.645165920257568, 20.742822647094727, 0.7338836789131165], step: 22800, lr: 9.218432448041401e-05, reference_loss: 31.967588424682617
2024-01-01 22:18:39,802	44k	INFO	====> Epoch: 652, cost 26.83 s
2024-01-01 22:19:06,185	44k	INFO	====> Epoch: 653, cost 26.38 s
2024-01-01 22:19:32,367	44k	INFO	====> Epoch: 654, cost 26.18 s
2024-01-01 22:19:58,597	44k	INFO	====> Epoch: 655, cost 26.23 s
2024-01-01 22:20:24,938	44k	INFO	====> Epoch: 656, cost 26.34 s
2024-01-01 22:20:51,449	44k	INFO	====> Epoch: 657, cost 26.51 s
2024-01-01 22:20:55,193	44k	INFO	Train Epoch: 658 [11%]
2024-01-01 22:20:55,193	44k	INFO	Losses: [1.7195827960968018, 3.1621527671813965, 7.828397274017334, 19.03839111328125, 0.5665708184242249], step: 23000, lr: 9.211520783915413e-05, reference_loss: 32.315093994140625
2024-01-01 22:21:18,142	44k	INFO	====> Epoch: 658, cost 26.69 s
2024-01-01 22:21:44,482	44k	INFO	====> Epoch: 659, cost 26.34 s
2024-01-01 22:22:10,876	44k	INFO	====> Epoch: 660, cost 26.39 s
2024-01-01 22:22:37,139	44k	INFO	====> Epoch: 661, cost 26.26 s
2024-01-01 22:23:03,392	44k	INFO	====> Epoch: 662, cost 26.25 s
2024-01-01 22:23:26,017	44k	INFO	Train Epoch: 663 [83%]
2024-01-01 22:23:26,017	44k	INFO	Losses: [2.511589527130127, 2.141911268234253, 5.539144515991211, 17.83478546142578, 0.7649701833724976], step: 23200, lr: 9.205765022545685e-05, reference_loss: 28.792402267456055
2024-01-01 22:23:33,752	44k	INFO	Saving model and optimizer state at iteration 663 to ./logs/44k/G_23200.pth
2024-01-01 22:23:34,638	44k	INFO	Saving model and optimizer state at iteration 663 to ./logs/44k/D_23200.pth
2024-01-01 22:23:35,421	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_20800.pth
2024-01-01 22:23:35,477	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_20800.pth
2024-01-01 22:23:39,225	44k	INFO	====> Epoch: 663, cost 35.83 s
2024-01-01 22:24:05,462	44k	INFO	====> Epoch: 664, cost 26.24 s
2024-01-01 22:24:31,754	44k	INFO	====> Epoch: 665, cost 26.29 s
2024-01-01 22:24:57,964	44k	INFO	====> Epoch: 666, cost 26.21 s
2024-01-01 22:25:24,353	44k	INFO	====> Epoch: 667, cost 26.39 s
2024-01-01 22:25:50,698	44k	INFO	====> Epoch: 668, cost 26.35 s
2024-01-01 22:26:05,595	44k	INFO	Train Epoch: 669 [54%]
2024-01-01 22:26:05,595	44k	INFO	Losses: [2.6429290771484375, 2.69858980178833, 5.6104559898376465, 19.047292709350586, 0.5117793083190918], step: 23400, lr: 9.198862856020383e-05, reference_loss: 30.51104736328125
2024-01-01 22:26:17,699	44k	INFO	====> Epoch: 669, cost 27.00 s
2024-01-01 22:26:43,865	44k	INFO	====> Epoch: 670, cost 26.17 s
2024-01-01 22:27:10,117	44k	INFO	====> Epoch: 671, cost 26.25 s
2024-01-01 22:27:36,405	44k	INFO	====> Epoch: 672, cost 26.29 s
2024-01-01 22:28:02,651	44k	INFO	====> Epoch: 673, cost 26.25 s
2024-01-01 22:28:28,810	44k	INFO	====> Epoch: 674, cost 26.16 s
2024-01-01 22:28:36,296	44k	INFO	Train Epoch: 675 [26%]
2024-01-01 22:28:36,296	44k	INFO	Losses: [2.2202210426330566, 2.3446850776672363, 6.670417308807373, 22.754688262939453, 1.0343838930130005], step: 23600, lr: 9.191965864502551e-05, reference_loss: 35.02439880371094
2024-01-01 22:28:55,574	44k	INFO	====> Epoch: 675, cost 26.76 s
2024-01-01 22:29:22,191	44k	INFO	====> Epoch: 676, cost 26.62 s
2024-01-01 22:29:48,513	44k	INFO	====> Epoch: 677, cost 26.32 s
2024-01-01 22:30:14,862	44k	INFO	====> Epoch: 678, cost 26.35 s
2024-01-01 22:30:41,156	44k	INFO	====> Epoch: 679, cost 26.29 s
2024-01-01 22:31:07,512	44k	INFO	Train Epoch: 680 [97%]
2024-01-01 22:31:07,513	44k	INFO	Losses: [2.4258084297180176, 2.244736909866333, 6.092929363250732, 21.751596450805664, 0.7944987416267395], step: 23800, lr: 9.186222321902381e-05, reference_loss: 33.3095703125
2024-01-01 22:31:07,997	44k	INFO	====> Epoch: 680, cost 26.84 s
2024-01-01 22:31:34,249	44k	INFO	====> Epoch: 681, cost 26.25 s
2024-01-01 22:32:00,432	44k	INFO	====> Epoch: 682, cost 26.18 s
2024-01-01 22:32:26,910	44k	INFO	====> Epoch: 683, cost 26.48 s
2024-01-01 22:32:53,029	44k	INFO	====> Epoch: 684, cost 26.12 s
2024-01-01 22:33:19,330	44k	INFO	====> Epoch: 685, cost 26.30 s
2024-01-01 22:33:38,012	44k	INFO	Train Epoch: 686 [69%]
2024-01-01 22:33:38,013	44k	INFO	Losses: [2.534099578857422, 2.2585670948028564, 4.807458877563477, 17.49540138244629, 0.7851483821868896], step: 24000, lr: 9.179334807823006e-05, reference_loss: 27.88067626953125
2024-01-01 22:33:45,449	44k	INFO	Saving model and optimizer state at iteration 686 to ./logs/44k/G_24000.pth
2024-01-01 22:33:46,352	44k	INFO	Saving model and optimizer state at iteration 686 to ./logs/44k/D_24000.pth
2024-01-01 22:33:47,123	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_21600.pth
2024-01-01 22:33:47,181	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_21600.pth
2024-01-01 22:33:54,775	44k	INFO	====> Epoch: 686, cost 35.44 s
2024-01-01 22:34:21,266	44k	INFO	====> Epoch: 687, cost 26.49 s
2024-01-01 22:34:47,848	44k	INFO	====> Epoch: 688, cost 26.58 s
2024-01-01 22:35:14,029	44k	INFO	====> Epoch: 689, cost 26.18 s
2024-01-01 22:35:40,368	44k	INFO	====> Epoch: 690, cost 26.34 s
2024-01-01 22:36:06,744	44k	INFO	====> Epoch: 691, cost 26.38 s
2024-01-01 22:36:17,950	44k	INFO	Train Epoch: 692 [40%]
2024-01-01 22:36:17,951	44k	INFO	Losses: [2.5516457557678223, 2.2398858070373535, 5.461790084838867, 21.107219696044922, 0.6390581727027893], step: 24200, lr: 9.172452457765199e-05, reference_loss: 31.999601364135742
2024-01-01 22:36:33,588	44k	INFO	====> Epoch: 692, cost 26.84 s
2024-01-01 22:37:00,001	44k	INFO	====> Epoch: 693, cost 26.41 s
2024-01-01 22:37:26,319	44k	INFO	====> Epoch: 694, cost 26.32 s
2024-01-01 22:37:52,600	44k	INFO	====> Epoch: 695, cost 26.28 s
2024-01-01 22:38:18,881	44k	INFO	====> Epoch: 696, cost 26.28 s
2024-01-01 22:38:45,360	44k	INFO	====> Epoch: 697, cost 26.48 s
2024-01-01 22:38:49,093	44k	INFO	Train Epoch: 698 [11%]
2024-01-01 22:38:49,094	44k	INFO	Losses: [2.01566743850708, 2.728977680206299, 6.985586643218994, 20.92096519470215, 0.6548250913619995], step: 24400, lr: 9.16557526785715e-05, reference_loss: 33.30602264404297
2024-01-01 22:39:12,313	44k	INFO	====> Epoch: 698, cost 26.95 s
2024-01-01 22:39:38,609	44k	INFO	====> Epoch: 699, cost 26.30 s
2024-01-01 22:40:04,879	44k	INFO	====> Epoch: 700, cost 26.27 s
2024-01-01 22:40:31,212	44k	INFO	====> Epoch: 701, cost 26.33 s
2024-01-01 22:40:57,579	44k	INFO	====> Epoch: 702, cost 26.37 s
2024-01-01 22:41:20,115	44k	INFO	Train Epoch: 703 [83%]
2024-01-01 22:41:20,116	44k	INFO	Losses: [2.2346014976501465, 2.6924729347229004, 6.851258277893066, 20.236339569091797, 0.7412338852882385], step: 24600, lr: 9.15984821525687e-05, reference_loss: 32.75590515136719
2024-01-01 22:41:24,715	44k	INFO	====> Epoch: 703, cost 27.14 s
2024-01-01 22:41:51,078	44k	INFO	====> Epoch: 704, cost 26.36 s
2024-01-01 22:42:17,242	44k	INFO	====> Epoch: 705, cost 26.16 s
2024-01-01 22:42:43,316	44k	INFO	====> Epoch: 706, cost 26.07 s
2024-01-01 22:43:09,628	44k	INFO	====> Epoch: 707, cost 26.31 s
2024-01-01 22:43:36,066	44k	INFO	====> Epoch: 708, cost 26.44 s
2024-01-01 22:43:50,965	44k	INFO	Train Epoch: 709 [54%]
2024-01-01 22:43:50,966	44k	INFO	Losses: [2.3299362659454346, 2.0214319229125977, 6.519802570343018, 19.441974639892578, 0.8148238658905029], step: 24800, lr: 9.152980475577075e-05, reference_loss: 31.127967834472656
2024-01-01 22:43:58,340	44k	INFO	Saving model and optimizer state at iteration 709 to ./logs/44k/G_24800.pth
2024-01-01 22:43:59,573	44k	INFO	Saving model and optimizer state at iteration 709 to ./logs/44k/D_24800.pth
2024-01-01 22:44:00,341	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_22400.pth
2024-01-01 22:44:00,398	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_22400.pth
2024-01-01 22:44:11,784	44k	INFO	====> Epoch: 709, cost 35.72 s
2024-01-01 22:44:38,013	44k	INFO	====> Epoch: 710, cost 26.23 s
2024-01-01 22:45:04,256	44k	INFO	====> Epoch: 711, cost 26.24 s
2024-01-01 22:45:30,441	44k	INFO	====> Epoch: 712, cost 26.18 s
2024-01-01 22:45:56,703	44k	INFO	====> Epoch: 713, cost 26.26 s
2024-01-01 22:46:23,035	44k	INFO	====> Epoch: 714, cost 26.33 s
2024-01-01 22:46:30,477	44k	INFO	Train Epoch: 715 [26%]
2024-01-01 22:46:30,478	44k	INFO	Losses: [2.531775951385498, 2.105971336364746, 4.590333938598633, 17.857919692993164, 0.9664472341537476], step: 25000, lr: 9.146117885092685e-05, reference_loss: 28.052448272705078
2024-01-01 22:46:49,938	44k	INFO	====> Epoch: 715, cost 26.90 s
2024-01-01 22:47:16,226	44k	INFO	====> Epoch: 716, cost 26.29 s
2024-01-01 22:47:42,571	44k	INFO	====> Epoch: 717, cost 26.34 s
2024-01-01 22:48:08,865	44k	INFO	====> Epoch: 718, cost 26.29 s
2024-01-01 22:48:35,099	44k	INFO	====> Epoch: 719, cost 26.23 s
2024-01-01 22:49:01,388	44k	INFO	Train Epoch: 720 [97%]
2024-01-01 22:49:01,389	44k	INFO	Losses: [2.2315759658813477, 2.600473403930664, 5.804484844207764, 18.02513885498047, 0.5461348295211792], step: 25200, lr: 9.140402990316795e-05, reference_loss: 29.207807540893555
2024-01-01 22:49:01,899	44k	INFO	====> Epoch: 720, cost 26.80 s
2024-01-01 22:49:28,126	44k	INFO	====> Epoch: 721, cost 26.23 s
2024-01-01 22:49:54,492	44k	INFO	====> Epoch: 722, cost 26.37 s
2024-01-01 22:50:20,975	44k	INFO	====> Epoch: 723, cost 26.48 s
2024-01-01 22:50:47,156	44k	INFO	====> Epoch: 724, cost 26.18 s
2024-01-01 22:51:13,344	44k	INFO	====> Epoch: 725, cost 26.19 s
2024-01-01 22:51:32,030	44k	INFO	Train Epoch: 726 [69%]
2024-01-01 22:51:32,031	44k	INFO	Losses: [2.4338197708129883, 2.2320497035980225, 5.063109874725342, 16.987995147705078, 0.7366188168525696], step: 25400, lr: 9.133549829998994e-05, reference_loss: 27.45359230041504
2024-01-01 22:51:40,108	44k	INFO	====> Epoch: 726, cost 26.76 s
2024-01-01 22:52:06,469	44k	INFO	====> Epoch: 727, cost 26.36 s
2024-01-01 22:52:32,847	44k	INFO	====> Epoch: 728, cost 26.38 s
2024-01-01 22:52:59,115	44k	INFO	====> Epoch: 729, cost 26.27 s
2024-01-01 22:53:25,755	44k	INFO	====> Epoch: 730, cost 26.64 s
2024-01-01 22:53:52,190	44k	INFO	====> Epoch: 731, cost 26.44 s
2024-01-01 22:54:03,432	44k	INFO	Train Epoch: 732 [40%]
2024-01-01 22:54:03,433	44k	INFO	Losses: [2.595365047454834, 2.5970940589904785, 7.027615547180176, 21.442838668823242, 0.6901376843452454], step: 25600, lr: 9.126701807945488e-05, reference_loss: 34.353050231933594
2024-01-01 22:54:10,789	44k	INFO	Saving model and optimizer state at iteration 732 to ./logs/44k/G_25600.pth
2024-01-01 22:54:11,692	44k	INFO	Saving model and optimizer state at iteration 732 to ./logs/44k/D_25600.pth
2024-01-01 22:54:12,466	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_23200.pth
2024-01-01 22:54:12,523	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_23200.pth
2024-01-01 22:54:27,564	44k	INFO	====> Epoch: 732, cost 35.37 s
2024-01-01 22:54:53,947	44k	INFO	====> Epoch: 733, cost 26.38 s
2024-01-01 22:55:20,390	44k	INFO	====> Epoch: 734, cost 26.44 s
2024-01-01 22:55:47,099	44k	INFO	====> Epoch: 735, cost 26.71 s
2024-01-01 22:56:13,403	44k	INFO	====> Epoch: 736, cost 26.30 s
2024-01-01 22:56:39,660	44k	INFO	====> Epoch: 737, cost 26.26 s
2024-01-01 22:56:43,397	44k	INFO	Train Epoch: 738 [11%]
2024-01-01 22:56:43,398	44k	INFO	Losses: [2.14790678024292, 2.6489264965057373, 6.311503887176514, 18.041685104370117, 0.690148115158081], step: 25800, lr: 9.119858920303784e-05, reference_loss: 29.84016990661621
2024-01-01 22:57:06,333	44k	INFO	====> Epoch: 738, cost 26.67 s
2024-01-01 22:57:32,666	44k	INFO	====> Epoch: 739, cost 26.33 s
2024-01-01 22:57:58,949	44k	INFO	====> Epoch: 740, cost 26.28 s
2024-01-01 22:58:25,328	44k	INFO	====> Epoch: 741, cost 26.38 s
2024-01-01 22:58:51,648	44k	INFO	====> Epoch: 742, cost 26.32 s
2024-01-01 22:59:14,416	44k	INFO	Train Epoch: 743 [83%]
2024-01-01 22:59:14,417	44k	INFO	Losses: [2.525434732437134, 2.4910852909088135, 4.8172101974487305, 20.256669998168945, 0.7760074138641357], step: 26000, lr: 9.114160433278438e-05, reference_loss: 30.86640739440918
2024-01-01 22:59:18,644	44k	INFO	====> Epoch: 743, cost 27.00 s
2024-01-01 22:59:44,896	44k	INFO	====> Epoch: 744, cost 26.25 s
2024-01-01 23:00:11,161	44k	INFO	====> Epoch: 745, cost 26.27 s
2024-01-01 23:00:37,554	44k	INFO	====> Epoch: 746, cost 26.39 s
2024-01-01 23:01:03,838	44k	INFO	====> Epoch: 747, cost 26.28 s
2024-01-01 23:01:30,133	44k	INFO	====> Epoch: 748, cost 26.30 s
2024-01-01 23:01:45,024	44k	INFO	Train Epoch: 749 [54%]
2024-01-01 23:01:45,025	44k	INFO	Losses: [2.008643865585327, 2.5770504474639893, 7.564373970031738, 21.0656681060791, 0.6661504507064819], step: 26200, lr: 9.107326948728839e-05, reference_loss: 33.88188552856445
2024-01-01 23:01:57,139	44k	INFO	====> Epoch: 749, cost 27.01 s
2024-01-01 23:02:23,523	44k	INFO	====> Epoch: 750, cost 26.38 s
2024-01-01 23:02:49,946	44k	INFO	====> Epoch: 751, cost 26.42 s
2024-01-01 23:03:16,211	44k	INFO	====> Epoch: 752, cost 26.27 s
2024-01-01 23:03:42,558	44k	INFO	====> Epoch: 753, cost 26.35 s
2024-01-01 23:04:08,815	44k	INFO	====> Epoch: 754, cost 26.26 s
2024-01-01 23:04:16,287	44k	INFO	Train Epoch: 755 [26%]
2024-01-01 23:04:16,288	44k	INFO	Losses: [2.491914749145508, 2.335935354232788, 5.185494422912598, 18.25406265258789, 0.7096738219261169], step: 26400, lr: 9.100498587691323e-05, reference_loss: 28.977079391479492
2024-01-01 23:04:23,784	44k	INFO	Saving model and optimizer state at iteration 755 to ./logs/44k/G_26400.pth
2024-01-01 23:04:25,025	44k	INFO	Saving model and optimizer state at iteration 755 to ./logs/44k/D_26400.pth
2024-01-01 23:04:25,804	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_24000.pth
2024-01-01 23:04:25,861	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_24000.pth
2024-01-01 23:04:44,619	44k	INFO	====> Epoch: 755, cost 35.80 s
2024-01-01 23:05:10,796	44k	INFO	====> Epoch: 756, cost 26.18 s
2024-01-01 23:05:36,996	44k	INFO	====> Epoch: 757, cost 26.20 s
2024-01-01 23:06:03,195	44k	INFO	====> Epoch: 758, cost 26.20 s
2024-01-01 23:06:29,471	44k	INFO	====> Epoch: 759, cost 26.28 s
2024-01-01 23:06:55,607	44k	INFO	Train Epoch: 760 [97%]
2024-01-01 23:06:55,608	44k	INFO	Losses: [2.3374176025390625, 2.7430200576782227, 7.415536403656006, 21.379636764526367, 0.5851298570632935], step: 26600, lr: 9.094812197849185e-05, reference_loss: 34.46073913574219
2024-01-01 23:06:56,235	44k	INFO	====> Epoch: 760, cost 26.76 s
2024-01-01 23:07:22,406	44k	INFO	====> Epoch: 761, cost 26.17 s
2024-01-01 23:07:48,939	44k	INFO	====> Epoch: 762, cost 26.53 s
2024-01-01 23:08:15,334	44k	INFO	====> Epoch: 763, cost 26.40 s
2024-01-01 23:08:41,743	44k	INFO	====> Epoch: 764, cost 26.41 s
2024-01-01 23:09:08,034	44k	INFO	====> Epoch: 765, cost 26.29 s
2024-01-01 23:09:26,809	44k	INFO	Train Epoch: 766 [69%]
2024-01-01 23:09:26,810	44k	INFO	Losses: [2.064382553100586, 2.8841216564178467, 6.984684944152832, 18.70712661743164, 0.864976704120636], step: 26800, lr: 9.087993219942171e-05, reference_loss: 31.505292892456055
2024-01-01 23:09:35,030	44k	INFO	====> Epoch: 766, cost 27.00 s
2024-01-01 23:10:01,412	44k	INFO	====> Epoch: 767, cost 26.38 s
2024-01-01 23:10:27,820	44k	INFO	====> Epoch: 768, cost 26.41 s
2024-01-01 23:10:54,398	44k	INFO	====> Epoch: 769, cost 26.58 s
2024-01-01 23:11:20,717	44k	INFO	====> Epoch: 770, cost 26.32 s
2024-01-01 23:11:46,873	44k	INFO	====> Epoch: 771, cost 26.16 s
2024-01-01 23:11:58,081	44k	INFO	Train Epoch: 772 [40%]
2024-01-01 23:11:58,082	44k	INFO	Losses: [2.6422932147979736, 2.1710193157196045, 5.240184783935547, 18.510852813720703, 0.9473267793655396], step: 27000, lr: 9.081179354670654e-05, reference_loss: 29.511676788330078
2024-01-01 23:12:13,863	44k	INFO	====> Epoch: 772, cost 26.99 s
2024-01-01 23:12:40,279	44k	INFO	====> Epoch: 773, cost 26.42 s
2024-01-01 23:13:06,664	44k	INFO	====> Epoch: 774, cost 26.38 s
2024-01-01 23:13:32,933	44k	INFO	====> Epoch: 775, cost 26.27 s
2024-01-01 23:13:59,325	44k	INFO	====> Epoch: 776, cost 26.39 s
2024-01-01 23:14:25,985	44k	INFO	====> Epoch: 777, cost 26.66 s
2024-01-01 23:14:29,739	44k	INFO	Train Epoch: 778 [11%]
2024-01-01 23:14:29,740	44k	INFO	Losses: [2.2641994953155518, 2.6874184608459473, 5.793433666229248, 18.125879287719727, 1.0073349475860596], step: 27200, lr: 9.074370598201358e-05, reference_loss: 29.878267288208008
2024-01-01 23:14:37,081	44k	INFO	Saving model and optimizer state at iteration 778 to ./logs/44k/G_27200.pth
2024-01-01 23:14:37,971	44k	INFO	Saving model and optimizer state at iteration 778 to ./logs/44k/D_27200.pth
2024-01-01 23:14:38,746	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_24800.pth
2024-01-01 23:14:38,803	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_24800.pth
2024-01-01 23:15:01,358	44k	INFO	====> Epoch: 778, cost 35.37 s
2024-01-01 23:15:27,715	44k	INFO	====> Epoch: 779, cost 26.36 s
2024-01-01 23:15:54,036	44k	INFO	====> Epoch: 780, cost 26.32 s
2024-01-01 23:16:20,243	44k	INFO	====> Epoch: 781, cost 26.21 s
2024-01-01 23:16:46,855	44k	INFO	====> Epoch: 782, cost 26.61 s
2024-01-01 23:17:09,437	44k	INFO	Train Epoch: 783 [83%]
2024-01-01 23:17:09,438	44k	INFO	Losses: [2.5094943046569824, 2.203579902648926, 5.241804599761963, 17.82351303100586, 0.6082140207290649], step: 27400, lr: 9.068700534270665e-05, reference_loss: 28.386606216430664
2024-01-01 23:17:13,828	44k	INFO	====> Epoch: 783, cost 26.97 s
2024-01-01 23:17:39,883	44k	INFO	====> Epoch: 784, cost 26.05 s
2024-01-01 23:18:06,028	44k	INFO	====> Epoch: 785, cost 26.14 s
2024-01-01 23:18:32,092	44k	INFO	====> Epoch: 786, cost 26.06 s
2024-01-01 23:18:58,153	44k	INFO	====> Epoch: 787, cost 26.06 s
2024-01-01 23:19:24,180	44k	INFO	====> Epoch: 788, cost 26.03 s
2024-01-01 23:19:38,993	44k	INFO	Train Epoch: 789 [54%]
2024-01-01 23:19:38,993	44k	INFO	Losses: [2.3991661071777344, 2.2506721019744873, 5.292422294616699, 18.55020523071289, 0.7564679384231567], step: 27600, lr: 9.061901133992436e-05, reference_loss: 29.248933792114258
2024-01-01 23:19:51,045	44k	INFO	====> Epoch: 789, cost 26.87 s
2024-01-01 23:20:17,356	44k	INFO	====> Epoch: 790, cost 26.31 s
2024-01-01 23:20:43,621	44k	INFO	====> Epoch: 791, cost 26.27 s
2024-01-01 23:21:09,770	44k	INFO	====> Epoch: 792, cost 26.15 s
2024-01-01 23:21:36,103	44k	INFO	====> Epoch: 793, cost 26.33 s
2024-01-01 23:22:02,463	44k	INFO	====> Epoch: 794, cost 26.36 s
2024-01-01 23:22:09,980	44k	INFO	Train Epoch: 795 [26%]
2024-01-01 23:22:09,981	44k	INFO	Losses: [2.339585304260254, 2.6830227375030518, 6.248473167419434, 19.102642059326172, 0.7700977325439453], step: 27800, lr: 9.055106831671071e-05, reference_loss: 31.14381980895996
2024-01-01 23:22:29,428	44k	INFO	====> Epoch: 795, cost 26.96 s
2024-01-01 23:22:56,081	44k	INFO	====> Epoch: 796, cost 26.65 s
2024-01-01 23:23:22,590	44k	INFO	====> Epoch: 797, cost 26.51 s
2024-01-01 23:23:48,922	44k	INFO	====> Epoch: 798, cost 26.33 s
2024-01-01 23:24:15,333	44k	INFO	====> Epoch: 799, cost 26.41 s
2024-01-01 23:24:41,625	44k	INFO	Train Epoch: 800 [97%]
2024-01-01 23:24:41,626	44k	INFO	Losses: [2.477259397506714, 2.5849506855010986, 5.675163269042969, 18.623878479003906, 0.7392560243606567], step: 28000, lr: 9.049448804584871e-05, reference_loss: 30.100507736206055
2024-01-01 23:24:49,170	44k	INFO	Saving model and optimizer state at iteration 800 to ./logs/44k/G_28000.pth
2024-01-01 23:24:50,067	44k	INFO	Saving model and optimizer state at iteration 800 to ./logs/44k/D_28000.pth
2024-01-01 23:24:50,849	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_25600.pth
2024-01-01 23:24:50,906	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_25600.pth
2024-01-01 23:24:50,907	44k	INFO	====> Epoch: 800, cost 35.57 s
2024-01-01 23:25:17,690	44k	INFO	====> Epoch: 801, cost 26.78 s
2024-01-01 23:25:44,216	44k	INFO	====> Epoch: 802, cost 26.53 s
2024-01-01 23:26:10,678	44k	INFO	====> Epoch: 803, cost 26.46 s
2024-01-01 23:26:37,129	44k	INFO	====> Epoch: 804, cost 26.45 s
2024-01-01 23:27:03,605	44k	INFO	====> Epoch: 805, cost 26.48 s
2024-01-01 23:27:22,398	44k	INFO	Train Epoch: 806 [69%]
2024-01-01 23:27:22,398	44k	INFO	Losses: [2.4979026317596436, 2.1776299476623535, 6.210046291351318, 19.681169509887695, 0.7607536315917969], step: 28200, lr: 9.042663838592532e-05, reference_loss: 31.32750129699707
2024-01-01 23:27:30,631	44k	INFO	====> Epoch: 806, cost 27.03 s
2024-01-01 23:27:57,029	44k	INFO	====> Epoch: 807, cost 26.40 s
2024-01-01 23:28:23,434	44k	INFO	====> Epoch: 808, cost 26.40 s
2024-01-01 23:28:49,774	44k	INFO	====> Epoch: 809, cost 26.34 s
2024-01-01 23:29:16,534	44k	INFO	====> Epoch: 810, cost 26.76 s
2024-01-01 23:29:43,030	44k	INFO	====> Epoch: 811, cost 26.50 s
2024-01-01 23:29:54,288	44k	INFO	Train Epoch: 812 [40%]
2024-01-01 23:29:54,288	44k	INFO	Losses: [2.4493703842163086, 2.3092894554138184, 5.855355739593506, 19.943496704101562, 0.6826329231262207], step: 28400, lr: 9.035883959734726e-05, reference_loss: 31.240144729614258
2024-01-01 23:30:09,955	44k	INFO	====> Epoch: 812, cost 26.92 s
2024-01-01 23:30:36,423	44k	INFO	====> Epoch: 813, cost 26.47 s
2024-01-01 23:31:02,824	44k	INFO	====> Epoch: 814, cost 26.40 s
2024-01-01 23:31:29,312	44k	INFO	====> Epoch: 815, cost 26.49 s
2024-01-01 23:31:55,779	44k	INFO	====> Epoch: 816, cost 26.47 s
2024-01-01 23:32:22,457	44k	INFO	====> Epoch: 817, cost 26.68 s
2024-01-01 23:32:26,220	44k	INFO	Train Epoch: 818 [11%]
2024-01-01 23:32:26,221	44k	INFO	Losses: [2.2510762214660645, 2.9197936058044434, 6.235588550567627, 19.660396575927734, 0.6870695352554321], step: 28600, lr: 9.029109164197293e-05, reference_loss: 31.753923416137695
2024-01-01 23:32:49,320	44k	INFO	====> Epoch: 818, cost 26.86 s
2024-01-01 23:33:15,843	44k	INFO	====> Epoch: 819, cost 26.52 s
2024-01-01 23:33:42,291	44k	INFO	====> Epoch: 820, cost 26.45 s
2024-01-01 23:34:08,749	44k	INFO	====> Epoch: 821, cost 26.46 s
2024-01-01 23:34:35,162	44k	INFO	====> Epoch: 822, cost 26.41 s
2024-01-01 23:34:57,819	44k	INFO	Train Epoch: 823 [83%]
2024-01-01 23:34:57,820	44k	INFO	Losses: [2.391616106033325, 2.599316120147705, 5.820380210876465, 16.95105743408203, 0.7396823763847351], step: 28800, lr: 9.023467381591636e-05, reference_loss: 28.50205421447754
2024-01-01 23:35:05,680	44k	INFO	Saving model and optimizer state at iteration 823 to ./logs/44k/G_28800.pth
2024-01-01 23:35:06,591	44k	INFO	Saving model and optimizer state at iteration 823 to ./logs/44k/D_28800.pth
2024-01-01 23:35:07,363	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_26400.pth
2024-01-01 23:35:07,420	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_26400.pth
2024-01-01 23:35:11,210	44k	INFO	====> Epoch: 823, cost 36.05 s
2024-01-01 23:35:37,592	44k	INFO	====> Epoch: 824, cost 26.38 s
2024-01-01 23:36:03,932	44k	INFO	====> Epoch: 825, cost 26.34 s
2024-01-01 23:36:30,227	44k	INFO	====> Epoch: 826, cost 26.29 s
2024-01-01 23:36:56,497	44k	INFO	====> Epoch: 827, cost 26.27 s
2024-01-01 23:37:22,911	44k	INFO	====> Epoch: 828, cost 26.41 s
2024-01-01 23:37:37,871	44k	INFO	Train Epoch: 829 [54%]
2024-01-01 23:37:37,872	44k	INFO	Losses: [2.339462995529175, 2.402167558670044, 5.680304050445557, 17.80409049987793, 0.4784868061542511], step: 29000, lr: 9.01670189557816e-05, reference_loss: 28.704511642456055
2024-01-01 23:37:50,066	44k	INFO	====> Epoch: 829, cost 27.15 s
2024-01-01 23:38:16,349	44k	INFO	====> Epoch: 830, cost 26.28 s
2024-01-01 23:38:42,653	44k	INFO	====> Epoch: 831, cost 26.30 s
2024-01-01 23:39:09,146	44k	INFO	====> Epoch: 832, cost 26.49 s
2024-01-01 23:39:35,665	44k	INFO	====> Epoch: 833, cost 26.52 s
2024-01-01 23:40:02,188	44k	INFO	====> Epoch: 834, cost 26.52 s
2024-01-01 23:40:09,722	44k	INFO	Train Epoch: 835 [26%]
2024-01-01 23:40:09,722	44k	INFO	Losses: [2.057145595550537, 2.462667226791382, 7.563200950622559, 22.226829528808594, 0.8935571908950806], step: 29200, lr: 9.009941482093798e-05, reference_loss: 35.20340347290039
2024-01-01 23:40:29,202	44k	INFO	====> Epoch: 835, cost 27.01 s
2024-01-01 23:40:56,007	44k	INFO	====> Epoch: 836, cost 26.80 s
2024-01-01 23:41:22,515	44k	INFO	====> Epoch: 837, cost 26.51 s
2024-01-01 23:41:48,914	44k	INFO	====> Epoch: 838, cost 26.40 s
2024-01-01 23:42:15,244	44k	INFO	====> Epoch: 839, cost 26.33 s
2024-01-01 23:42:41,646	44k	INFO	Train Epoch: 840 [97%]
2024-01-01 23:42:41,647	44k	INFO	Losses: [2.417379856109619, 2.4766311645507812, 6.5596489906311035, 20.27457046508789, 0.7240424752235413], step: 29400, lr: 9.004311676294879e-05, reference_loss: 32.4522705078125
2024-01-01 23:42:42,141	44k	INFO	====> Epoch: 840, cost 26.90 s
2024-01-01 23:43:08,672	44k	INFO	====> Epoch: 841, cost 26.53 s
2024-01-01 23:43:35,197	44k	INFO	====> Epoch: 842, cost 26.53 s
2024-01-01 23:44:01,897	44k	INFO	====> Epoch: 843, cost 26.70 s
2024-01-01 23:44:28,277	44k	INFO	====> Epoch: 844, cost 26.38 s
2024-01-01 23:44:54,706	44k	INFO	====> Epoch: 845, cost 26.43 s
2024-01-01 23:45:13,503	44k	INFO	Train Epoch: 846 [69%]
2024-01-01 23:45:13,503	44k	INFO	Losses: [2.4889121055603027, 2.4118852615356445, 5.908782482147217, 17.031665802001953, 0.7170904874801636], step: 29600, lr: 8.997560552571508e-05, reference_loss: 28.55833625793457
2024-01-01 23:45:20,946	44k	INFO	Saving model and optimizer state at iteration 846 to ./logs/44k/G_29600.pth
2024-01-01 23:45:21,843	44k	INFO	Saving model and optimizer state at iteration 846 to ./logs/44k/D_29600.pth
2024-01-01 23:45:22,621	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_27200.pth
2024-01-01 23:45:22,679	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_27200.pth
2024-01-01 23:45:30,233	44k	INFO	====> Epoch: 846, cost 35.53 s
2024-01-01 23:45:56,704	44k	INFO	====> Epoch: 847, cost 26.47 s
2024-01-01 23:46:23,194	44k	INFO	====> Epoch: 848, cost 26.49 s
2024-01-01 23:46:49,913	44k	INFO	====> Epoch: 849, cost 26.72 s
2024-01-01 23:47:16,414	44k	INFO	====> Epoch: 850, cost 26.50 s
2024-01-01 23:47:42,900	44k	INFO	====> Epoch: 851, cost 26.49 s
2024-01-01 23:47:54,147	44k	INFO	Train Epoch: 852 [40%]
2024-01-01 23:47:54,147	44k	INFO	Losses: [2.5423872470855713, 2.053973436355591, 6.130353927612305, 19.892410278320312, 0.5829639434814453], step: 29800, lr: 8.990814490608897e-05, reference_loss: 31.202089309692383
2024-01-01 23:48:09,750	44k	INFO	====> Epoch: 852, cost 26.85 s
2024-01-01 23:48:36,111	44k	INFO	====> Epoch: 853, cost 26.36 s
2024-01-01 23:49:02,440	44k	INFO	====> Epoch: 854, cost 26.33 s
2024-01-01 23:49:28,858	44k	INFO	====> Epoch: 855, cost 26.42 s
2024-01-01 23:49:55,310	44k	INFO	====> Epoch: 856, cost 26.45 s
2024-01-01 23:50:21,999	44k	INFO	====> Epoch: 857, cost 26.69 s
2024-01-01 23:50:25,762	44k	INFO	Train Epoch: 858 [11%]
2024-01-01 23:50:25,763	44k	INFO	Losses: [2.4880900382995605, 2.3369531631469727, 5.600811004638672, 19.362733840942383, 0.5891942381858826], step: 30000, lr: 8.984073486611914e-05, reference_loss: 30.37778091430664
2024-01-01 23:50:48,784	44k	INFO	====> Epoch: 858, cost 26.79 s
2024-01-01 23:51:15,090	44k	INFO	====> Epoch: 859, cost 26.31 s
2024-01-01 23:51:41,422	44k	INFO	====> Epoch: 860, cost 26.33 s
2024-01-01 23:52:07,736	44k	INFO	====> Epoch: 861, cost 26.31 s
2024-01-01 23:52:34,175	44k	INFO	====> Epoch: 862, cost 26.44 s
2024-01-01 23:52:56,835	44k	INFO	Train Epoch: 863 [83%]
2024-01-01 23:52:56,835	44k	INFO	Losses: [2.3717942237854004, 2.3434104919433594, 6.595458984375, 19.723350524902344, 0.7326294779777527], step: 30200, lr: 8.978459844268802e-05, reference_loss: 31.766643524169922
2024-01-01 23:53:01,418	44k	INFO	====> Epoch: 863, cost 27.24 s
2024-01-01 23:53:27,732	44k	INFO	====> Epoch: 864, cost 26.31 s
2024-01-01 23:53:53,952	44k	INFO	====> Epoch: 865, cost 26.22 s
2024-01-01 23:54:20,377	44k	INFO	====> Epoch: 866, cost 26.42 s
2024-01-01 23:54:46,685	44k	INFO	====> Epoch: 867, cost 26.31 s
2024-01-01 23:55:13,118	44k	INFO	====> Epoch: 868, cost 26.43 s
2024-01-01 23:55:28,152	44k	INFO	Train Epoch: 869 [54%]
2024-01-01 23:55:28,153	44k	INFO	Losses: [2.340710163116455, 2.5589630603790283, 7.414915561676025, 19.27099609375, 0.7934655547142029], step: 30400, lr: 8.971728103361437e-05, reference_loss: 32.379051208496094
2024-01-01 23:55:35,632	44k	INFO	Saving model and optimizer state at iteration 869 to ./logs/44k/G_30400.pth
2024-01-01 23:55:36,858	44k	INFO	Saving model and optimizer state at iteration 869 to ./logs/44k/D_30400.pth
2024-01-01 23:55:37,656	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_28000.pth
2024-01-01 23:55:37,712	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_28000.pth
2024-01-01 23:55:49,079	44k	INFO	====> Epoch: 869, cost 35.96 s
2024-01-01 23:56:15,393	44k	INFO	====> Epoch: 870, cost 26.31 s
2024-01-01 23:56:41,756	44k	INFO	====> Epoch: 871, cost 26.36 s
2024-01-01 23:57:08,190	44k	INFO	====> Epoch: 872, cost 26.43 s
2024-01-01 23:57:34,582	44k	INFO	====> Epoch: 873, cost 26.39 s
2024-01-01 23:58:00,956	44k	INFO	====> Epoch: 874, cost 26.37 s
2024-01-01 23:58:08,439	44k	INFO	Train Epoch: 875 [26%]
2024-01-01 23:58:08,439	44k	INFO	Losses: [2.3168368339538574, 2.3464155197143555, 5.660726547241211, 17.667043685913086, 0.8219040036201477], step: 30600, lr: 8.965001409682262e-05, reference_loss: 28.812925338745117
2024-01-01 23:58:27,737	44k	INFO	====> Epoch: 875, cost 26.78 s
2024-01-01 23:58:54,493	44k	INFO	====> Epoch: 876, cost 26.76 s
2024-01-01 23:59:20,929	44k	INFO	====> Epoch: 877, cost 26.44 s
2024-01-01 23:59:47,272	44k	INFO	====> Epoch: 878, cost 26.34 s
2024-01-02 00:00:13,691	44k	INFO	====> Epoch: 879, cost 26.42 s
2024-01-02 00:00:39,895	44k	INFO	Train Epoch: 880 [97%]
2024-01-02 00:00:39,895	44k	INFO	Losses: [2.7338578701019287, 2.0155816078186035, 5.217826843261719, 19.479225158691406, 0.5073615312576294], step: 30800, lr: 8.959399684407593e-05, reference_loss: 29.953853607177734
2024-01-02 00:00:40,388	44k	INFO	====> Epoch: 880, cost 26.70 s
2024-01-02 00:01:06,625	44k	INFO	====> Epoch: 881, cost 26.24 s
2024-01-02 00:01:32,851	44k	INFO	====> Epoch: 882, cost 26.23 s
2024-01-02 00:01:59,355	44k	INFO	====> Epoch: 883, cost 26.50 s
2024-01-02 00:02:25,669	44k	INFO	====> Epoch: 884, cost 26.31 s
2024-01-02 00:02:52,065	44k	INFO	====> Epoch: 885, cost 26.40 s
2024-01-02 00:03:10,882	44k	INFO	Train Epoch: 886 [69%]
2024-01-02 00:03:10,882	44k	INFO	Losses: [2.292085647583008, 2.5465757846832275, 6.005651473999023, 18.07105255126953, 0.7131960391998291], step: 31000, lr: 8.952682234153643e-05, reference_loss: 29.62856101989746
2024-01-02 00:03:19,091	44k	INFO	====> Epoch: 886, cost 27.03 s
2024-01-02 00:03:45,475	44k	INFO	====> Epoch: 887, cost 26.38 s
2024-01-02 00:04:11,772	44k	INFO	====> Epoch: 888, cost 26.30 s
2024-01-02 00:04:38,028	44k	INFO	====> Epoch: 889, cost 26.26 s
2024-01-02 00:05:04,623	44k	INFO	====> Epoch: 890, cost 26.60 s
2024-01-02 00:05:30,744	44k	INFO	====> Epoch: 891, cost 26.12 s
2024-01-02 00:05:41,906	44k	INFO	Train Epoch: 892 [40%]
2024-01-02 00:05:41,906	44k	INFO	Losses: [2.4940545558929443, 2.5825910568237305, 6.9068803787231445, 21.03941535949707, 0.6699813008308411], step: 31200, lr: 8.945969820413243e-05, reference_loss: 33.69292449951172
2024-01-02 00:05:49,204	44k	INFO	Saving model and optimizer state at iteration 892 to ./logs/44k/G_31200.pth
2024-01-02 00:05:50,103	44k	INFO	Saving model and optimizer state at iteration 892 to ./logs/44k/D_31200.pth
2024-01-02 00:05:50,890	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_28800.pth
2024-01-02 00:05:50,948	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_28800.pth
2024-01-02 00:06:05,969	44k	INFO	====> Epoch: 892, cost 35.22 s
2024-01-02 00:06:32,131	44k	INFO	====> Epoch: 893, cost 26.16 s
2024-01-02 00:06:58,420	44k	INFO	====> Epoch: 894, cost 26.29 s
2024-01-02 00:07:24,719	44k	INFO	====> Epoch: 895, cost 26.30 s
2024-01-02 00:07:51,251	44k	INFO	====> Epoch: 896, cost 26.53 s
2024-01-02 00:08:17,642	44k	INFO	====> Epoch: 897, cost 26.39 s
2024-01-02 00:08:21,396	44k	INFO	Train Epoch: 898 [11%]
2024-01-02 00:08:21,396	44k	INFO	Losses: [2.6560425758361816, 2.227355480194092, 4.874347686767578, 17.61246109008789, 0.7433578968048096], step: 31400, lr: 8.939262439410188e-05, reference_loss: 28.11356544494629
2024-01-02 00:08:44,438	44k	INFO	====> Epoch: 898, cost 26.80 s
2024-01-02 00:09:10,559	44k	INFO	====> Epoch: 899, cost 26.12 s
2024-01-02 00:09:36,953	44k	INFO	====> Epoch: 900, cost 26.39 s
2024-01-02 00:10:03,372	44k	INFO	====> Epoch: 901, cost 26.42 s
2024-01-02 00:10:29,652	44k	INFO	====> Epoch: 902, cost 26.28 s
2024-01-02 00:10:52,040	44k	INFO	Train Epoch: 903 [83%]
2024-01-02 00:10:52,040	44k	INFO	Losses: [2.017064094543457, 2.9193873405456543, 7.190535545349121, 20.71000862121582, 0.6633421778678894], step: 31600, lr: 8.933676796970726e-05, reference_loss: 33.50033950805664
2024-01-02 00:10:56,746	44k	INFO	====> Epoch: 903, cost 27.09 s
2024-01-02 00:11:23,133	44k	INFO	====> Epoch: 904, cost 26.39 s
2024-01-02 00:11:49,468	44k	INFO	====> Epoch: 905, cost 26.33 s
2024-01-02 00:12:15,697	44k	INFO	====> Epoch: 906, cost 26.23 s
2024-01-02 00:12:41,957	44k	INFO	====> Epoch: 907, cost 26.26 s
2024-01-02 00:13:08,320	44k	INFO	====> Epoch: 908, cost 26.36 s
2024-01-02 00:13:23,221	44k	INFO	Train Epoch: 909 [54%]
2024-01-02 00:13:23,222	44k	INFO	Losses: [2.6334996223449707, 2.262037515640259, 6.564068794250488, 20.445924758911133, 0.6399816274642944], step: 31800, lr: 8.926978632854556e-05, reference_loss: 32.54551315307617
2024-01-02 00:13:35,209	44k	INFO	====> Epoch: 909, cost 26.89 s
2024-01-02 00:14:01,887	44k	INFO	====> Epoch: 910, cost 26.68 s
2024-01-02 00:14:28,265	44k	INFO	====> Epoch: 911, cost 26.38 s
2024-01-02 00:14:54,668	44k	INFO	====> Epoch: 912, cost 26.40 s
2024-01-02 00:15:20,889	44k	INFO	====> Epoch: 913, cost 26.22 s
2024-01-02 00:15:47,257	44k	INFO	====> Epoch: 914, cost 26.37 s
2024-01-02 00:15:54,764	44k	INFO	Train Epoch: 915 [26%]
2024-01-02 00:15:54,765	44k	INFO	Losses: [2.403902292251587, 2.584887981414795, 6.10638952255249, 19.29303550720215, 0.6650247573852539], step: 32000, lr: 8.920285490791852e-05, reference_loss: 31.053241729736328
2024-01-02 00:16:02,152	44k	INFO	Saving model and optimizer state at iteration 915 to ./logs/44k/G_32000.pth
2024-01-02 00:16:03,059	44k	INFO	Saving model and optimizer state at iteration 915 to ./logs/44k/D_32000.pth
2024-01-02 00:16:03,834	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_29600.pth
2024-01-02 00:16:03,892	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_29600.pth
2024-01-02 00:16:22,971	44k	INFO	====> Epoch: 915, cost 35.71 s
2024-01-02 00:16:49,369	44k	INFO	====> Epoch: 916, cost 26.40 s
2024-01-02 00:17:15,695	44k	INFO	====> Epoch: 917, cost 26.33 s
2024-01-02 00:17:42,114	44k	INFO	====> Epoch: 918, cost 26.42 s
2024-01-02 00:18:08,507	44k	INFO	====> Epoch: 919, cost 26.39 s
2024-01-02 00:18:34,950	44k	INFO	Train Epoch: 920 [97%]
2024-01-02 00:18:34,951	44k	INFO	Losses: [2.4882209300994873, 2.4448795318603516, 6.923454761505127, 21.003164291381836, 0.5568660497665405], step: 32200, lr: 8.9147117059805e-05, reference_loss: 33.41658401489258
2024-01-02 00:18:35,451	44k	INFO	====> Epoch: 920, cost 26.94 s
2024-01-02 00:19:01,974	44k	INFO	====> Epoch: 921, cost 26.52 s
2024-01-02 00:19:28,413	44k	INFO	====> Epoch: 922, cost 26.44 s
2024-01-02 00:19:54,781	44k	INFO	====> Epoch: 923, cost 26.37 s
2024-01-02 00:20:21,468	44k	INFO	====> Epoch: 924, cost 26.69 s
2024-01-02 00:20:47,862	44k	INFO	====> Epoch: 925, cost 26.39 s
2024-01-02 00:21:06,667	44k	INFO	Train Epoch: 926 [69%]
2024-01-02 00:21:06,667	44k	INFO	Losses: [2.5012335777282715, 2.578174591064453, 6.474361419677734, 17.89504051208496, 0.8778489232063293], step: 32400, lr: 8.908027761238368e-05, reference_loss: 30.32666015625
2024-01-02 00:21:14,696	44k	INFO	====> Epoch: 926, cost 26.83 s
2024-01-02 00:21:41,058	44k	INFO	====> Epoch: 927, cost 26.36 s
2024-01-02 00:22:07,423	44k	INFO	====> Epoch: 928, cost 26.36 s
2024-01-02 00:22:33,745	44k	INFO	====> Epoch: 929, cost 26.32 s
2024-01-02 00:22:59,947	44k	INFO	====> Epoch: 930, cost 26.20 s
2024-01-02 00:23:26,618	44k	INFO	====> Epoch: 931, cost 26.67 s
2024-01-02 00:23:37,828	44k	INFO	Train Epoch: 932 [40%]
2024-01-02 00:23:37,828	44k	INFO	Losses: [2.433953285217285, 2.0360336303710938, 5.804099082946777, 17.96060562133789, 0.8334099054336548], step: 32600, lr: 8.901348827888507e-05, reference_loss: 29.06810188293457
2024-01-02 00:23:53,431	44k	INFO	====> Epoch: 932, cost 26.81 s
2024-01-02 00:24:19,638	44k	INFO	====> Epoch: 933, cost 26.21 s
2024-01-02 00:24:45,827	44k	INFO	====> Epoch: 934, cost 26.19 s
2024-01-02 00:25:12,109	44k	INFO	====> Epoch: 935, cost 26.28 s
2024-01-02 00:25:38,455	44k	INFO	====> Epoch: 936, cost 26.35 s
2024-01-02 00:26:04,707	44k	INFO	====> Epoch: 937, cost 26.25 s
2024-01-02 00:26:08,474	44k	INFO	Train Epoch: 938 [11%]
2024-01-02 00:26:08,475	44k	INFO	Losses: [2.565486431121826, 2.196178436279297, 5.0793986320495605, 17.59415626525879, 0.9273340106010437], step: 32800, lr: 8.894674902173544e-05, reference_loss: 28.362552642822266
2024-01-02 00:26:16,192	44k	INFO	Saving model and optimizer state at iteration 938 to ./logs/44k/G_32800.pth
2024-01-02 00:26:17,073	44k	INFO	Saving model and optimizer state at iteration 938 to ./logs/44k/D_32800.pth
2024-01-02 00:26:17,836	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_30400.pth
2024-01-02 00:26:17,893	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_30400.pth
2024-01-02 00:26:40,370	44k	INFO	====> Epoch: 938, cost 35.66 s
2024-01-02 00:27:06,821	44k	INFO	====> Epoch: 939, cost 26.45 s
2024-01-02 00:27:33,077	44k	INFO	====> Epoch: 940, cost 26.26 s
2024-01-02 00:27:59,301	44k	INFO	====> Epoch: 941, cost 26.22 s
2024-01-02 00:28:25,567	44k	INFO	====> Epoch: 942, cost 26.27 s
2024-01-02 00:28:48,018	44k	INFO	Train Epoch: 943 [83%]
2024-01-02 00:28:48,019	44k	INFO	Losses: [2.6230273246765137, 2.2115609645843506, 5.367973327636719, 16.518348693847656, 0.5966777801513672], step: 33000, lr: 8.889117119978924e-05, reference_loss: 27.31758689880371
2024-01-02 00:28:52,573	44k	INFO	====> Epoch: 943, cost 27.01 s
2024-01-02 00:29:18,916	44k	INFO	====> Epoch: 944, cost 26.34 s
2024-01-02 00:29:45,280	44k	INFO	====> Epoch: 945, cost 26.36 s
2024-01-02 00:30:11,489	44k	INFO	====> Epoch: 946, cost 26.21 s
2024-01-02 00:30:37,643	44k	INFO	====> Epoch: 947, cost 26.15 s
2024-01-02 00:31:03,852	44k	INFO	====> Epoch: 948, cost 26.21 s
2024-01-02 00:31:18,760	44k	INFO	Train Epoch: 949 [54%]
2024-01-02 00:31:18,761	44k	INFO	Losses: [2.2974541187286377, 2.6484737396240234, 6.025496482849121, 17.95225715637207, 0.7468908429145813], step: 33200, lr: 8.882452365178563e-05, reference_loss: 29.67057228088379
2024-01-02 00:31:30,563	44k	INFO	====> Epoch: 949, cost 26.71 s
2024-01-02 00:31:57,149	44k	INFO	====> Epoch: 950, cost 26.59 s
2024-01-02 00:32:23,411	44k	INFO	====> Epoch: 951, cost 26.26 s
2024-01-02 00:32:49,787	44k	INFO	====> Epoch: 952, cost 26.38 s
2024-01-02 00:33:16,203	44k	INFO	====> Epoch: 953, cost 26.42 s
2024-01-02 00:33:42,423	44k	INFO	====> Epoch: 954, cost 26.22 s
2024-01-02 00:33:49,937	44k	INFO	Train Epoch: 955 [26%]
2024-01-02 00:33:49,937	44k	INFO	Losses: [2.5657975673675537, 2.033848285675049, 5.039905548095703, 17.418781280517578, 0.6817888021469116], step: 33400, lr: 8.875792607382512e-05, reference_loss: 27.740121841430664
2024-01-02 00:34:09,260	44k	INFO	====> Epoch: 955, cost 26.84 s
2024-01-02 00:34:35,574	44k	INFO	====> Epoch: 956, cost 26.31 s
2024-01-02 00:35:01,875	44k	INFO	====> Epoch: 957, cost 26.30 s
2024-01-02 00:35:28,533	44k	INFO	====> Epoch: 958, cost 26.66 s
2024-01-02 00:35:54,864	44k	INFO	====> Epoch: 959, cost 26.33 s
2024-01-02 00:36:21,244	44k	INFO	Train Epoch: 960 [97%]
2024-01-02 00:36:21,244	44k	INFO	Losses: [2.421114444732666, 2.7971930503845215, 5.742047309875488, 15.927017211914062, 0.6233208179473877], step: 33600, lr: 8.870246623672146e-05, reference_loss: 27.510692596435547
2024-01-02 00:36:28,697	44k	INFO	Saving model and optimizer state at iteration 960 to ./logs/44k/G_33600.pth
2024-01-02 00:36:29,585	44k	INFO	Saving model and optimizer state at iteration 960 to ./logs/44k/D_33600.pth
2024-01-02 00:36:30,362	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_31200.pth
2024-01-02 00:36:30,419	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_31200.pth
2024-01-02 00:36:30,419	44k	INFO	====> Epoch: 960, cost 35.56 s
2024-01-02 00:36:56,717	44k	INFO	====> Epoch: 961, cost 26.30 s
2024-01-02 00:37:23,149	44k	INFO	====> Epoch: 962, cost 26.43 s
2024-01-02 00:37:49,868	44k	INFO	====> Epoch: 963, cost 26.72 s
2024-01-02 00:38:16,212	44k	INFO	====> Epoch: 964, cost 26.34 s
2024-01-02 00:38:42,660	44k	INFO	====> Epoch: 965, cost 26.45 s
2024-01-02 00:39:01,492	44k	INFO	Train Epoch: 966 [69%]
2024-01-02 00:39:01,493	44k	INFO	Losses: [2.4412038326263428, 2.2808022499084473, 6.266646385192871, 17.77691078186035, 0.7750427722930908], step: 33800, lr: 8.86359601732198e-05, reference_loss: 29.540607452392578
2024-01-02 00:39:09,576	44k	INFO	====> Epoch: 966, cost 26.92 s
2024-01-02 00:39:35,845	44k	INFO	====> Epoch: 967, cost 26.27 s
2024-01-02 00:40:02,210	44k	INFO	====> Epoch: 968, cost 26.37 s
2024-01-02 00:40:28,510	44k	INFO	====> Epoch: 969, cost 26.30 s
2024-01-02 00:40:54,805	44k	INFO	====> Epoch: 970, cost 26.29 s
2024-01-02 00:41:21,438	44k	INFO	====> Epoch: 971, cost 26.63 s
2024-01-02 00:41:32,576	44k	INFO	Train Epoch: 972 [40%]
2024-01-02 00:41:32,577	44k	INFO	Losses: [2.489008903503418, 2.5720930099487305, 6.582104682922363, 20.613039016723633, 0.6654103398323059], step: 34000, lr: 8.856950397368101e-05, reference_loss: 32.921653747558594
2024-01-02 00:41:48,151	44k	INFO	====> Epoch: 972, cost 26.71 s
2024-01-02 00:42:14,542	44k	INFO	====> Epoch: 973, cost 26.39 s
2024-01-02 00:42:40,893	44k	INFO	====> Epoch: 974, cost 26.35 s
2024-01-02 00:43:07,207	44k	INFO	====> Epoch: 975, cost 26.31 s
2024-01-02 00:43:33,472	44k	INFO	====> Epoch: 976, cost 26.27 s
2024-01-02 00:43:59,825	44k	INFO	====> Epoch: 977, cost 26.35 s
2024-01-02 00:44:03,563	44k	INFO	Train Epoch: 978 [11%]
2024-01-02 00:44:03,564	44k	INFO	Losses: [2.5807642936706543, 2.137110471725464, 5.607544422149658, 18.75395965576172, 0.5347071886062622], step: 34200, lr: 8.850309760071881e-05, reference_loss: 29.614086151123047
2024-01-02 00:44:26,878	44k	INFO	====> Epoch: 978, cost 27.05 s
2024-01-02 00:44:53,240	44k	INFO	====> Epoch: 979, cost 26.36 s
2024-01-02 00:45:19,635	44k	INFO	====> Epoch: 980, cost 26.39 s
2024-01-02 00:45:45,950	44k	INFO	====> Epoch: 981, cost 26.32 s
2024-01-02 00:46:12,362	44k	INFO	====> Epoch: 982, cost 26.41 s
2024-01-02 00:46:34,959	44k	INFO	Train Epoch: 983 [83%]
2024-01-02 00:46:34,960	44k	INFO	Losses: [2.4224605560302734, 2.3970749378204346, 5.905027389526367, 16.082094192504883, 0.75397127866745], step: 34400, lr: 8.844779699159887e-05, reference_loss: 27.560626983642578
2024-01-02 00:46:42,491	44k	INFO	Saving model and optimizer state at iteration 983 to ./logs/44k/G_34400.pth
2024-01-02 00:46:43,730	44k	INFO	Saving model and optimizer state at iteration 983 to ./logs/44k/D_34400.pth
2024-01-02 00:46:44,518	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_32000.pth
2024-01-02 00:46:44,576	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_32000.pth
2024-01-02 00:46:48,347	44k	INFO	====> Epoch: 983, cost 35.99 s
2024-01-02 00:47:14,649	44k	INFO	====> Epoch: 984, cost 26.30 s
2024-01-02 00:47:41,030	44k	INFO	====> Epoch: 985, cost 26.38 s
2024-01-02 00:48:07,280	44k	INFO	====> Epoch: 986, cost 26.25 s
2024-01-02 00:48:33,653	44k	INFO	====> Epoch: 987, cost 26.37 s
2024-01-02 00:49:00,027	44k	INFO	====> Epoch: 988, cost 26.37 s
2024-01-02 00:49:14,898	44k	INFO	Train Epoch: 989 [54%]
2024-01-02 00:49:14,899	44k	INFO	Losses: [2.759880542755127, 1.9905427694320679, 5.164251804351807, 17.29625701904297, 0.4850192666053772], step: 34600, lr: 8.83814818703529e-05, reference_loss: 27.695951461791992
2024-01-02 00:49:26,759	44k	INFO	====> Epoch: 989, cost 26.73 s
2024-01-02 00:49:53,359	44k	INFO	====> Epoch: 990, cost 26.60 s
2024-01-02 00:50:19,657	44k	INFO	====> Epoch: 991, cost 26.30 s
2024-01-02 00:50:45,911	44k	INFO	====> Epoch: 992, cost 26.25 s
2024-01-02 00:51:12,119	44k	INFO	====> Epoch: 993, cost 26.21 s
2024-01-02 00:51:38,293	44k	INFO	====> Epoch: 994, cost 26.17 s
2024-01-02 00:51:45,754	44k	INFO	Train Epoch: 995 [26%]
2024-01-02 00:51:45,755	44k	INFO	Losses: [2.366879463195801, 2.337312698364258, 7.123589038848877, 21.30649185180664, 0.9914376735687256], step: 34800, lr: 8.831521646990785e-05, reference_loss: 34.125709533691406
2024-01-02 00:52:05,047	44k	INFO	====> Epoch: 995, cost 26.75 s
2024-01-02 00:52:31,352	44k	INFO	====> Epoch: 996, cost 26.31 s
2024-01-02 00:52:57,988	44k	INFO	====> Epoch: 997, cost 26.64 s
2024-01-02 00:53:24,378	44k	INFO	====> Epoch: 998, cost 26.39 s
2024-01-02 00:53:50,744	44k	INFO	====> Epoch: 999, cost 26.37 s
2024-01-02 00:54:17,053	44k	INFO	Train Epoch: 1000 [97%]
2024-01-02 00:54:17,054	44k	INFO	Losses: [2.48396635055542, 2.197661876678467, 7.595802307128906, 21.12112045288086, 0.6875867247581482], step: 35000, lr: 8.82600332571419e-05, reference_loss: 34.08613967895508
2024-01-02 00:54:17,537	44k	INFO	====> Epoch: 1000, cost 26.79 s
2024-01-02 00:54:43,928	44k	INFO	====> Epoch: 1001, cost 26.39 s
2024-01-02 00:55:10,137	44k	INFO	====> Epoch: 1002, cost 26.21 s
2024-01-02 00:55:36,439	44k	INFO	====> Epoch: 1003, cost 26.30 s
2024-01-02 00:56:02,840	44k	INFO	====> Epoch: 1004, cost 26.40 s
2024-01-02 00:56:29,547	44k	INFO	====> Epoch: 1005, cost 26.71 s
2024-01-02 00:56:48,222	44k	INFO	Train Epoch: 1006 [69%]
2024-01-02 00:56:48,222	44k	INFO	Losses: [2.5131630897521973, 2.557051658630371, 5.794756889343262, 15.520881652832031, 0.6814063191413879], step: 35200, lr: 8.819385891469698e-05, reference_loss: 27.067258834838867
2024-01-02 00:56:55,613	44k	INFO	Saving model and optimizer state at iteration 1006 to ./logs/44k/G_35200.pth
2024-01-02 00:56:56,526	44k	INFO	Saving model and optimizer state at iteration 1006 to ./logs/44k/D_35200.pth
2024-01-02 00:56:57,287	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_32800.pth
2024-01-02 00:56:57,347	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_32800.pth
2024-01-02 00:57:04,878	44k	INFO	====> Epoch: 1006, cost 35.33 s
2024-01-02 00:57:31,122	44k	INFO	====> Epoch: 1007, cost 26.24 s
2024-01-02 00:57:57,394	44k	INFO	====> Epoch: 1008, cost 26.27 s
2024-01-02 00:58:23,657	44k	INFO	====> Epoch: 1009, cost 26.26 s
2024-01-02 00:58:50,297	44k	INFO	====> Epoch: 1010, cost 26.64 s
2024-01-02 00:59:16,707	44k	INFO	====> Epoch: 1011, cost 26.41 s
2024-01-02 00:59:27,926	44k	INFO	Train Epoch: 1012 [40%]
2024-01-02 00:59:27,927	44k	INFO	Losses: [2.4718868732452393, 2.1819677352905273, 7.0842413902282715, 19.686708450317383, 0.5285536646842957], step: 35400, lr: 8.812773418750188e-05, reference_loss: 31.953357696533203
2024-01-02 00:59:43,506	44k	INFO	====> Epoch: 1012, cost 26.80 s
2024-01-02 01:00:09,767	44k	INFO	====> Epoch: 1013, cost 26.26 s
2024-01-02 01:00:35,965	44k	INFO	====> Epoch: 1014, cost 26.20 s
2024-01-02 01:01:02,174	44k	INFO	====> Epoch: 1015, cost 26.21 s
2024-01-02 01:01:28,553	44k	INFO	====> Epoch: 1016, cost 26.38 s
2024-01-02 01:01:54,910	44k	INFO	====> Epoch: 1017, cost 26.36 s
2024-01-02 01:01:58,650	44k	INFO	Train Epoch: 1018 [11%]
2024-01-02 01:01:58,651	44k	INFO	Losses: [2.2570676803588867, 2.5277042388916016, 6.391973495483398, 19.15045928955078, 0.5847880840301514], step: 35600, lr: 8.806165903835676e-05, reference_loss: 30.9119930267334
2024-01-02 01:02:22,055	44k	INFO	====> Epoch: 1018, cost 27.14 s
2024-01-02 01:02:48,297	44k	INFO	====> Epoch: 1019, cost 26.24 s
2024-01-02 01:03:14,424	44k	INFO	====> Epoch: 1020, cost 26.13 s
2024-01-02 01:03:40,685	44k	INFO	====> Epoch: 1021, cost 26.26 s
2024-01-02 01:04:06,889	44k	INFO	====> Epoch: 1022, cost 26.20 s
2024-01-02 01:04:29,461	44k	INFO	Train Epoch: 1023 [83%]
2024-01-02 01:04:29,461	44k	INFO	Losses: [2.3084754943847656, 2.765209674835205, 7.307968616485596, 18.307201385498047, 0.7077597379684448], step: 35800, lr: 8.800663425937214e-05, reference_loss: 31.39661407470703
2024-01-02 01:04:33,673	44k	INFO	====> Epoch: 1023, cost 26.78 s
2024-01-02 01:05:00,338	44k	INFO	====> Epoch: 1024, cost 26.66 s
2024-01-02 01:05:26,740	44k	INFO	====> Epoch: 1025, cost 26.40 s
2024-01-02 01:05:52,804	44k	INFO	====> Epoch: 1026, cost 26.06 s
2024-01-02 01:06:19,099	44k	INFO	====> Epoch: 1027, cost 26.30 s
2024-01-02 01:06:45,287	44k	INFO	====> Epoch: 1028, cost 26.19 s
2024-01-02 01:07:00,285	44k	INFO	Train Epoch: 1029 [54%]
2024-01-02 01:07:00,285	44k	INFO	Losses: [2.456669807434082, 2.1722733974456787, 7.649047374725342, 18.015277862548828, 0.758452296257019], step: 36000, lr: 8.794064990679505e-05, reference_loss: 31.051719665527344
2024-01-02 01:07:07,597	44k	INFO	Saving model and optimizer state at iteration 1029 to ./logs/44k/G_36000.pth
2024-01-02 01:07:08,479	44k	INFO	Saving model and optimizer state at iteration 1029 to ./logs/44k/D_36000.pth
2024-01-02 01:07:09,277	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_33600.pth
2024-01-02 01:07:09,335	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_33600.pth
2024-01-02 01:07:20,950	44k	INFO	====> Epoch: 1029, cost 35.66 s
2024-01-02 01:07:47,278	44k	INFO	====> Epoch: 1030, cost 26.33 s
2024-01-02 01:08:13,496	44k	INFO	====> Epoch: 1031, cost 26.22 s
2024-01-02 01:08:39,781	44k	INFO	====> Epoch: 1032, cost 26.29 s
2024-01-02 01:09:06,031	44k	INFO	====> Epoch: 1033, cost 26.25 s
2024-01-02 01:09:32,362	44k	INFO	====> Epoch: 1034, cost 26.33 s
2024-01-02 01:09:39,881	44k	INFO	Train Epoch: 1035 [26%]
2024-01-02 01:09:39,882	44k	INFO	Losses: [2.3123111724853516, 2.420621871948242, 6.463871955871582, 17.974557876586914, 0.724926233291626], step: 36200, lr: 8.787471502701991e-05, reference_loss: 29.896289825439453
2024-01-02 01:09:59,127	44k	INFO	====> Epoch: 1035, cost 26.76 s
2024-01-02 01:10:25,494	44k	INFO	====> Epoch: 1036, cost 26.37 s
2024-01-02 01:10:51,890	44k	INFO	====> Epoch: 1037, cost 26.40 s
2024-01-02 01:11:18,234	44k	INFO	====> Epoch: 1038, cost 26.34 s
2024-01-02 01:11:44,758	44k	INFO	====> Epoch: 1039, cost 26.52 s
2024-01-02 01:12:11,049	44k	INFO	Train Epoch: 1040 [97%]
2024-01-02 01:12:11,049	44k	INFO	Losses: [2.3682751655578613, 2.6332855224609375, 6.556737422943115, 16.97511863708496, 0.5622445344924927], step: 36400, lr: 8.781980705883603e-05, reference_loss: 29.095661163330078
2024-01-02 01:12:11,539	44k	INFO	====> Epoch: 1040, cost 26.78 s
2024-01-02 01:12:37,794	44k	INFO	====> Epoch: 1041, cost 26.25 s
2024-01-02 01:13:04,186	44k	INFO	====> Epoch: 1042, cost 26.39 s
2024-01-02 01:13:30,587	44k	INFO	====> Epoch: 1043, cost 26.40 s
2024-01-02 01:13:56,911	44k	INFO	====> Epoch: 1044, cost 26.32 s
2024-01-02 01:14:23,279	44k	INFO	====> Epoch: 1045, cost 26.37 s
2024-01-02 01:14:42,356	44k	INFO	Train Epoch: 1046 [69%]
2024-01-02 01:14:42,357	44k	INFO	Losses: [2.073166608810425, 2.7985074520111084, 7.423079013824463, 18.021326065063477, 0.7266419529914856], step: 36600, lr: 8.775396278287901e-05, reference_loss: 31.042720794677734
2024-01-02 01:14:50,400	44k	INFO	====> Epoch: 1046, cost 27.12 s
2024-01-02 01:15:16,650	44k	INFO	====> Epoch: 1047, cost 26.25 s
2024-01-02 01:15:42,844	44k	INFO	====> Epoch: 1048, cost 26.19 s
2024-01-02 01:16:09,054	44k	INFO	====> Epoch: 1049, cost 26.21 s
2024-01-02 01:16:35,392	44k	INFO	====> Epoch: 1050, cost 26.34 s
2024-01-02 01:17:01,584	44k	INFO	====> Epoch: 1051, cost 26.19 s
2024-01-02 01:17:12,760	44k	INFO	Train Epoch: 1052 [40%]
2024-01-02 01:17:12,761	44k	INFO	Losses: [2.378753900527954, 2.798515558242798, 7.300087928771973, 20.558895111083984, 0.7466304898262024], step: 36800, lr: 8.76881678746993e-05, reference_loss: 33.78288650512695
2024-01-02 01:17:20,426	44k	INFO	Saving model and optimizer state at iteration 1052 to ./logs/44k/G_36800.pth
2024-01-02 01:17:21,324	44k	INFO	Saving model and optimizer state at iteration 1052 to ./logs/44k/D_36800.pth
2024-01-02 01:17:22,079	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_34400.pth
2024-01-02 01:17:22,136	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_34400.pth
2024-01-02 01:17:37,267	44k	INFO	====> Epoch: 1052, cost 35.68 s
2024-01-02 01:18:03,494	44k	INFO	====> Epoch: 1053, cost 26.23 s
2024-01-02 01:18:29,827	44k	INFO	====> Epoch: 1054, cost 26.33 s
2024-01-02 01:18:56,115	44k	INFO	====> Epoch: 1055, cost 26.29 s
2024-01-02 01:19:22,493	44k	INFO	====> Epoch: 1056, cost 26.38 s
2024-01-02 01:19:48,835	44k	INFO	====> Epoch: 1057, cost 26.34 s
2024-01-02 01:19:52,602	44k	INFO	Train Epoch: 1058 [11%]
2024-01-02 01:19:52,603	44k	INFO	Losses: [2.4024817943573, 2.5798516273498535, 5.991930961608887, 17.799495697021484, 0.694114625453949], step: 37000, lr: 8.76224222972826e-05, reference_loss: 29.46787452697754
2024-01-02 01:20:15,995	44k	INFO	====> Epoch: 1058, cost 27.16 s
2024-01-02 01:20:42,246	44k	INFO	====> Epoch: 1059, cost 26.25 s
2024-01-02 01:21:08,604	44k	INFO	====> Epoch: 1060, cost 26.36 s
2024-01-02 01:21:34,978	44k	INFO	====> Epoch: 1061, cost 26.37 s
2024-01-02 01:22:01,372	44k	INFO	====> Epoch: 1062, cost 26.39 s
2024-01-02 01:22:23,848	44k	INFO	Train Epoch: 1063 [83%]
2024-01-02 01:22:23,849	44k	INFO	Losses: [2.668099880218506, 2.270230770111084, 5.610766410827637, 19.40566062927246, 0.7167721390724182], step: 37200, lr: 8.756767197263899e-05, reference_loss: 30.67152976989746
2024-01-02 01:22:28,087	44k	INFO	====> Epoch: 1063, cost 26.71 s
2024-01-02 01:22:54,355	44k	INFO	====> Epoch: 1064, cost 26.27 s
2024-01-02 01:23:20,860	44k	INFO	====> Epoch: 1065, cost 26.50 s
2024-01-02 01:23:47,077	44k	INFO	====> Epoch: 1066, cost 26.22 s
2024-01-02 01:24:13,445	44k	INFO	====> Epoch: 1067, cost 26.37 s
2024-01-02 01:24:39,738	44k	INFO	====> Epoch: 1068, cost 26.29 s
2024-01-02 01:24:54,640	44k	INFO	Train Epoch: 1069 [54%]
2024-01-02 01:24:54,641	44k	INFO	Losses: [2.381777763366699, 2.307819128036499, 7.587362289428711, 19.370298385620117, 0.6902682185173035], step: 37400, lr: 8.750201673891232e-05, reference_loss: 32.337528228759766
2024-01-02 01:25:06,619	44k	INFO	====> Epoch: 1069, cost 26.88 s
2024-01-02 01:25:32,944	44k	INFO	====> Epoch: 1070, cost 26.33 s
2024-01-02 01:25:59,288	44k	INFO	====> Epoch: 1071, cost 26.34 s
2024-01-02 01:26:25,838	44k	INFO	====> Epoch: 1072, cost 26.55 s
2024-01-02 01:26:52,147	44k	INFO	====> Epoch: 1073, cost 26.31 s
2024-01-02 01:27:18,499	44k	INFO	====> Epoch: 1074, cost 26.35 s
2024-01-02 01:27:25,984	44k	INFO	Train Epoch: 1075 [26%]
2024-01-02 01:27:25,984	44k	INFO	Losses: [2.3700437545776367, 2.4981391429901123, 6.831808090209961, 19.91748809814453, 0.6232112050056458], step: 37600, lr: 8.743641073122557e-05, reference_loss: 32.240692138671875
2024-01-02 01:27:33,283	44k	INFO	Saving model and optimizer state at iteration 1075 to ./logs/44k/G_37600.pth
2024-01-02 01:27:34,169	44k	INFO	Saving model and optimizer state at iteration 1075 to ./logs/44k/D_37600.pth
2024-01-02 01:27:34,934	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_35200.pth
2024-01-02 01:27:34,991	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_35200.pth
2024-01-02 01:27:53,840	44k	INFO	====> Epoch: 1075, cost 35.34 s
2024-01-02 01:28:20,116	44k	INFO	====> Epoch: 1076, cost 26.28 s
2024-01-02 01:28:46,691	44k	INFO	====> Epoch: 1077, cost 26.57 s
2024-01-02 01:29:12,949	44k	INFO	====> Epoch: 1078, cost 26.26 s
2024-01-02 01:29:39,317	44k	INFO	====> Epoch: 1079, cost 26.37 s
2024-01-02 01:30:05,683	44k	INFO	Train Epoch: 1080 [97%]
2024-01-02 01:30:05,683	44k	INFO	Losses: [2.283673048019409, 2.6009132862091064, 7.500248908996582, 19.210372924804688, 0.5714988708496094], step: 37800, lr: 8.738177663475008e-05, reference_loss: 32.16670608520508
2024-01-02 01:30:06,164	44k	INFO	====> Epoch: 1080, cost 26.85 s
2024-01-02 01:30:32,506	44k	INFO	====> Epoch: 1081, cost 26.34 s
2024-01-02 01:30:58,885	44k	INFO	====> Epoch: 1082, cost 26.38 s
2024-01-02 01:31:25,247	44k	INFO	====> Epoch: 1083, cost 26.36 s
2024-01-02 01:31:51,639	44k	INFO	====> Epoch: 1084, cost 26.39 s
2024-01-02 01:32:17,941	44k	INFO	====> Epoch: 1085, cost 26.30 s
2024-01-02 01:32:36,983	44k	INFO	Train Epoch: 1086 [69%]
2024-01-02 01:32:36,983	44k	INFO	Losses: [2.4226362705230713, 2.2489283084869385, 6.433531761169434, 17.38306999206543, 0.8188753128051758], step: 38000, lr: 8.731626077896486e-05, reference_loss: 29.30704116821289
2024-01-02 01:32:44,935	44k	INFO	====> Epoch: 1086, cost 26.99 s
2024-01-02 01:33:11,144	44k	INFO	====> Epoch: 1087, cost 26.21 s
2024-01-02 01:33:37,442	44k	INFO	====> Epoch: 1088, cost 26.30 s
2024-01-02 01:34:03,832	44k	INFO	====> Epoch: 1089, cost 26.39 s
2024-01-02 01:34:30,193	44k	INFO	====> Epoch: 1090, cost 26.36 s
2024-01-02 01:34:56,548	44k	INFO	====> Epoch: 1091, cost 26.36 s
2024-01-02 01:35:07,790	44k	INFO	Train Epoch: 1092 [40%]
2024-01-02 01:35:07,790	44k	INFO	Losses: [2.552246332168579, 2.302473783493042, 5.772989273071289, 17.42917823791504, 0.7844793796539307], step: 38200, lr: 8.725079404471875e-05, reference_loss: 28.841367721557617
2024-01-02 01:35:23,645	44k	INFO	====> Epoch: 1092, cost 27.10 s
2024-01-02 01:35:49,905	44k	INFO	====> Epoch: 1093, cost 26.26 s
2024-01-02 01:36:16,250	44k	INFO	====> Epoch: 1094, cost 26.34 s
2024-01-02 01:36:42,388	44k	INFO	====> Epoch: 1095, cost 26.14 s
2024-01-02 01:37:08,692	44k	INFO	====> Epoch: 1096, cost 26.30 s
2024-01-02 01:37:35,052	44k	INFO	====> Epoch: 1097, cost 26.36 s
2024-01-02 01:37:38,814	44k	INFO	Train Epoch: 1098 [11%]
2024-01-02 01:37:38,814	44k	INFO	Losses: [2.5649445056915283, 2.1593589782714844, 5.9066691398620605, 17.62371826171875, 0.8442333936691284], step: 38400, lr: 8.718537639518214e-05, reference_loss: 29.098922729492188
2024-01-02 01:37:46,091	44k	INFO	Saving model and optimizer state at iteration 1098 to ./logs/44k/G_38400.pth
2024-01-02 01:37:47,397	44k	INFO	Saving model and optimizer state at iteration 1098 to ./logs/44k/D_38400.pth
2024-01-02 01:37:48,161	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_36000.pth
2024-01-02 01:37:48,218	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_36000.pth
2024-01-02 01:38:10,694	44k	INFO	====> Epoch: 1098, cost 35.64 s
2024-01-02 01:38:36,993	44k	INFO	====> Epoch: 1099, cost 26.30 s
2024-01-02 01:39:03,329	44k	INFO	====> Epoch: 1100, cost 26.34 s
2024-01-02 01:39:29,625	44k	INFO	====> Epoch: 1101, cost 26.30 s
2024-01-02 01:39:55,831	44k	INFO	====> Epoch: 1102, cost 26.21 s
2024-01-02 01:40:18,374	44k	INFO	Train Epoch: 1103 [83%]
2024-01-02 01:40:18,375	44k	INFO	Losses: [2.263017416000366, 2.8069541454315186, 6.8100786209106445, 16.37438201904297, 0.5656011700630188], step: 38600, lr: 8.713089915594747e-05, reference_loss: 28.82003402709961
2024-01-02 01:40:22,639	44k	INFO	====> Epoch: 1103, cost 26.81 s
2024-01-02 01:40:49,030	44k	INFO	====> Epoch: 1104, cost 26.39 s
2024-01-02 01:41:15,713	44k	INFO	====> Epoch: 1105, cost 26.68 s
2024-01-02 01:41:41,923	44k	INFO	====> Epoch: 1106, cost 26.21 s
2024-01-02 01:42:08,091	44k	INFO	====> Epoch: 1107, cost 26.17 s
2024-01-02 01:42:34,445	44k	INFO	====> Epoch: 1108, cost 26.35 s
2024-01-02 01:42:49,427	44k	INFO	Train Epoch: 1109 [54%]
2024-01-02 01:42:49,428	44k	INFO	Losses: [2.3755173683166504, 2.563976526260376, 6.184417724609375, 17.52391815185547, 0.7432613968849182], step: 38800, lr: 8.706557139948175e-05, reference_loss: 29.39109230041504
2024-01-02 01:43:01,426	44k	INFO	====> Epoch: 1109, cost 26.98 s
2024-01-02 01:43:27,773	44k	INFO	====> Epoch: 1110, cost 26.35 s
2024-01-02 01:43:54,056	44k	INFO	====> Epoch: 1111, cost 26.28 s
2024-01-02 01:44:20,649	44k	INFO	====> Epoch: 1112, cost 26.59 s
2024-01-02 01:44:46,994	44k	INFO	====> Epoch: 1113, cost 26.34 s
2024-01-02 01:45:13,185	44k	INFO	====> Epoch: 1114, cost 26.19 s
2024-01-02 01:45:20,681	44k	INFO	Train Epoch: 1115 [26%]
2024-01-02 01:45:20,682	44k	INFO	Losses: [2.4096832275390625, 2.4178450107574463, 6.445448875427246, 18.510828018188477, 0.7363544702529907], step: 39000, lr: 8.700029262352475e-05, reference_loss: 30.520160675048828
2024-01-02 01:45:39,902	44k	INFO	====> Epoch: 1115, cost 26.72 s
2024-01-02 01:46:06,091	44k	INFO	====> Epoch: 1116, cost 26.19 s
2024-01-02 01:46:32,382	44k	INFO	====> Epoch: 1117, cost 26.29 s
2024-01-02 01:46:58,664	44k	INFO	====> Epoch: 1118, cost 26.28 s
2024-01-02 01:47:25,294	44k	INFO	====> Epoch: 1119, cost 26.63 s
2024-01-02 01:47:51,659	44k	INFO	Train Epoch: 1120 [97%]
2024-01-02 01:47:51,659	44k	INFO	Losses: [2.621089220046997, 1.9871662855148315, 4.889947414398193, 15.861175537109375, 0.6458079218864441], step: 39200, lr: 8.694593103273164e-05, reference_loss: 26.005186080932617
2024-01-02 01:47:58,998	44k	INFO	Saving model and optimizer state at iteration 1120 to ./logs/44k/G_39200.pth
2024-01-02 01:47:59,904	44k	INFO	Saving model and optimizer state at iteration 1120 to ./logs/44k/D_39200.pth
2024-01-02 01:48:00,677	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_36800.pth
2024-01-02 01:48:00,733	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_36800.pth
2024-01-02 01:48:00,734	44k	INFO	====> Epoch: 1120, cost 35.44 s
2024-01-02 01:48:27,075	44k	INFO	====> Epoch: 1121, cost 26.34 s
2024-01-02 01:48:53,326	44k	INFO	====> Epoch: 1122, cost 26.25 s
2024-01-02 01:49:19,663	44k	INFO	====> Epoch: 1123, cost 26.34 s
2024-01-02 01:49:46,333	44k	INFO	====> Epoch: 1124, cost 26.67 s
2024-01-02 01:50:12,727	44k	INFO	====> Epoch: 1125, cost 26.39 s
2024-01-02 01:50:31,478	44k	INFO	Train Epoch: 1126 [69%]
2024-01-02 01:50:31,479	44k	INFO	Losses: [2.442183494567871, 2.022810459136963, 6.435742378234863, 17.681364059448242, 0.7606862783432007], step: 39400, lr: 8.688074195901366e-05, reference_loss: 29.34278678894043
2024-01-02 01:50:39,517	44k	INFO	====> Epoch: 1126, cost 26.79 s
2024-01-02 01:51:05,723	44k	INFO	====> Epoch: 1127, cost 26.21 s
2024-01-02 01:51:32,129	44k	INFO	====> Epoch: 1128, cost 26.41 s
2024-01-02 01:51:58,539	44k	INFO	====> Epoch: 1129, cost 26.41 s
2024-01-02 01:52:24,794	44k	INFO	====> Epoch: 1130, cost 26.25 s
2024-01-02 01:52:51,128	44k	INFO	====> Epoch: 1131, cost 26.33 s
2024-01-02 01:53:02,285	44k	INFO	Train Epoch: 1132 [40%]
2024-01-02 01:53:02,286	44k	INFO	Losses: [2.26814603805542, 2.4737682342529297, 6.715676307678223, 19.331918716430664, 0.6561169028282166], step: 39600, lr: 8.681560176182482e-05, reference_loss: 31.44562530517578
2024-01-02 01:53:18,230	44k	INFO	====> Epoch: 1132, cost 27.10 s
2024-01-02 01:53:44,453	44k	INFO	====> Epoch: 1133, cost 26.22 s
2024-01-02 01:54:10,757	44k	INFO	====> Epoch: 1134, cost 26.30 s
2024-01-02 01:54:37,067	44k	INFO	====> Epoch: 1135, cost 26.31 s
2024-01-02 01:55:03,284	44k	INFO	====> Epoch: 1136, cost 26.22 s
2024-01-02 01:55:29,596	44k	INFO	====> Epoch: 1137, cost 26.31 s
2024-01-02 01:55:33,357	44k	INFO	Train Epoch: 1138 [11%]
2024-01-02 01:55:33,357	44k	INFO	Losses: [2.447628974914551, 2.159512996673584, 5.831645488739014, 18.017070770263672, 0.5036569237709045], step: 39800, lr: 8.675051040451917e-05, reference_loss: 28.959514617919922
2024-01-02 01:55:56,737	44k	INFO	====> Epoch: 1138, cost 27.14 s
2024-01-02 01:56:23,127	44k	INFO	====> Epoch: 1139, cost 26.39 s
2024-01-02 01:56:49,468	44k	INFO	====> Epoch: 1140, cost 26.34 s
2024-01-02 01:57:15,836	44k	INFO	====> Epoch: 1141, cost 26.37 s
2024-01-02 01:57:42,229	44k	INFO	====> Epoch: 1142, cost 26.39 s
2024-01-02 01:58:04,769	44k	INFO	Train Epoch: 1143 [83%]
2024-01-02 01:58:04,769	44k	INFO	Losses: [2.498809576034546, 2.3962557315826416, 6.403650283813477, 16.691370010375977, 0.6788771748542786], step: 40000, lr: 8.669630488858935e-05, reference_loss: 28.668962478637695
2024-01-02 01:58:12,068	44k	INFO	Saving model and optimizer state at iteration 1143 to ./logs/44k/G_40000.pth
2024-01-02 01:58:12,966	44k	INFO	Saving model and optimizer state at iteration 1143 to ./logs/44k/D_40000.pth
2024-01-02 01:58:13,729	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_37600.pth
2024-01-02 01:58:13,786	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_37600.pth
2024-01-02 01:58:17,488	44k	INFO	====> Epoch: 1143, cost 35.26 s
2024-01-02 01:58:43,988	44k	INFO	====> Epoch: 1144, cost 26.50 s
2024-01-02 01:59:10,200	44k	INFO	====> Epoch: 1145, cost 26.21 s
2024-01-02 01:59:36,386	44k	INFO	====> Epoch: 1146, cost 26.19 s
2024-01-02 02:00:02,535	44k	INFO	====> Epoch: 1147, cost 26.15 s
2024-01-02 02:00:28,770	44k	INFO	====> Epoch: 1148, cost 26.24 s
2024-01-02 02:00:43,747	44k	INFO	Train Epoch: 1149 [54%]
2024-01-02 02:00:43,747	44k	INFO	Losses: [2.5477747917175293, 2.174095630645752, 5.370443820953369, 17.103836059570312, 0.43075329065322876], step: 40200, lr: 8.663130297598309e-05, reference_loss: 27.626903533935547
2024-01-02 02:00:55,637	44k	INFO	====> Epoch: 1149, cost 26.87 s
2024-01-02 02:01:22,005	44k	INFO	====> Epoch: 1150, cost 26.37 s
2024-01-02 02:01:48,354	44k	INFO	====> Epoch: 1151, cost 26.35 s
2024-01-02 02:02:14,667	44k	INFO	====> Epoch: 1152, cost 26.31 s
2024-01-02 02:02:41,272	44k	INFO	====> Epoch: 1153, cost 26.60 s
2024-01-02 02:03:07,483	44k	INFO	====> Epoch: 1154, cost 26.21 s
2024-01-02 02:03:14,990	44k	INFO	Train Epoch: 1155 [26%]
2024-01-02 02:03:14,991	44k	INFO	Losses: [2.477775812149048, 2.2102062702178955, 6.842884540557861, 20.923463821411133, 0.9147409796714783], step: 40400, lr: 8.656634979957899e-05, reference_loss: 33.36907196044922
2024-01-02 02:03:34,320	44k	INFO	====> Epoch: 1155, cost 26.84 s
2024-01-02 02:04:00,582	44k	INFO	====> Epoch: 1156, cost 26.26 s
2024-01-02 02:04:26,957	44k	INFO	====> Epoch: 1157, cost 26.38 s
2024-01-02 02:04:53,288	44k	INFO	====> Epoch: 1158, cost 26.33 s
2024-01-02 02:05:19,645	44k	INFO	====> Epoch: 1159, cost 26.36 s
2024-01-02 02:05:46,264	44k	INFO	Train Epoch: 1160 [97%]
2024-01-02 02:05:46,265	44k	INFO	Losses: [2.675790309906006, 1.8620582818984985, 6.872819423675537, 19.264856338500977, 0.7000744938850403], step: 40600, lr: 8.651225935525575e-05, reference_loss: 31.375598907470703
2024-01-02 02:05:46,761	44k	INFO	====> Epoch: 1160, cost 27.12 s
2024-01-02 02:06:12,980	44k	INFO	====> Epoch: 1161, cost 26.22 s
2024-01-02 02:06:39,284	44k	INFO	====> Epoch: 1162, cost 26.30 s
2024-01-02 02:07:05,626	44k	INFO	====> Epoch: 1163, cost 26.34 s
2024-01-02 02:07:31,980	44k	INFO	====> Epoch: 1164, cost 26.35 s
2024-01-02 02:07:58,291	44k	INFO	====> Epoch: 1165, cost 26.31 s
2024-01-02 02:08:17,092	44k	INFO	Train Epoch: 1166 [69%]
2024-01-02 02:08:17,093	44k	INFO	Losses: [2.287381649017334, 2.3881266117095947, 6.6990532875061035, 17.038393020629883, 0.6861100196838379], step: 40800, lr: 8.6447395433671e-05, reference_loss: 29.099063873291016
2024-01-02 02:08:24,757	44k	INFO	Saving model and optimizer state at iteration 1166 to ./logs/44k/G_40800.pth
2024-01-02 02:08:25,638	44k	INFO	Saving model and optimizer state at iteration 1166 to ./logs/44k/D_40800.pth
2024-01-02 02:08:26,408	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_38400.pth
2024-01-02 02:08:26,465	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_38400.pth
2024-01-02 02:08:34,013	44k	INFO	====> Epoch: 1166, cost 35.72 s
2024-01-02 02:09:00,297	44k	INFO	====> Epoch: 1167, cost 26.28 s
2024-01-02 02:09:26,540	44k	INFO	====> Epoch: 1168, cost 26.24 s
2024-01-02 02:09:52,884	44k	INFO	====> Epoch: 1169, cost 26.34 s
2024-01-02 02:10:19,211	44k	INFO	====> Epoch: 1170, cost 26.33 s
2024-01-02 02:10:45,325	44k	INFO	====> Epoch: 1171, cost 26.11 s
2024-01-02 02:10:56,440	44k	INFO	Train Epoch: 1172 [40%]
2024-01-02 02:10:56,441	44k	INFO	Losses: [2.584689140319824, 2.06516432762146, 6.788475513458252, 19.147626876831055, 0.5333870053291321], step: 41000, lr: 8.638258014482751e-05, reference_loss: 31.119342803955078
2024-01-02 02:11:12,539	44k	INFO	====> Epoch: 1172, cost 27.21 s
2024-01-02 02:11:38,918	44k	INFO	====> Epoch: 1173, cost 26.38 s
2024-01-02 02:12:05,197	44k	INFO	====> Epoch: 1174, cost 26.28 s
2024-01-02 02:12:31,479	44k	INFO	====> Epoch: 1175, cost 26.28 s
2024-01-02 02:12:57,812	44k	INFO	====> Epoch: 1176, cost 26.33 s
2024-01-02 02:13:24,042	44k	INFO	====> Epoch: 1177, cost 26.23 s
2024-01-02 02:13:27,813	44k	INFO	Train Epoch: 1178 [11%]
2024-01-02 02:13:27,814	44k	INFO	Losses: [2.3704915046691895, 2.3759522438049316, 6.530889511108398, 19.560949325561523, 0.5543080568313599], step: 41200, lr: 8.63178134522621e-05, reference_loss: 31.39259147644043
2024-01-02 02:13:50,918	44k	INFO	====> Epoch: 1178, cost 26.88 s
2024-01-02 02:14:17,460	44k	INFO	====> Epoch: 1179, cost 26.54 s
2024-01-02 02:14:43,816	44k	INFO	====> Epoch: 1180, cost 26.36 s
2024-01-02 02:15:10,062	44k	INFO	====> Epoch: 1181, cost 26.25 s
2024-01-02 02:15:36,209	44k	INFO	====> Epoch: 1182, cost 26.15 s
2024-01-02 02:15:58,633	44k	INFO	Train Epoch: 1183 [83%]
2024-01-02 02:15:58,634	44k	INFO	Losses: [2.35634446144104, 2.5638363361358643, 6.878518104553223, 17.35869598388672, 0.662307620048523], step: 41400, lr: 8.626387830432698e-05, reference_loss: 29.8197021484375
2024-01-02 02:16:02,816	44k	INFO	====> Epoch: 1183, cost 26.61 s
2024-01-02 02:16:29,079	44k	INFO	====> Epoch: 1184, cost 26.26 s
2024-01-02 02:16:55,446	44k	INFO	====> Epoch: 1185, cost 26.37 s
2024-01-02 02:17:21,995	44k	INFO	====> Epoch: 1186, cost 26.55 s
2024-01-02 02:17:48,300	44k	INFO	====> Epoch: 1187, cost 26.31 s
2024-01-02 02:18:14,568	44k	INFO	====> Epoch: 1188, cost 26.27 s
2024-01-02 02:18:29,452	44k	INFO	Train Epoch: 1189 [54%]
2024-01-02 02:18:29,453	44k	INFO	Losses: [2.0892248153686523, 2.509962797164917, 8.92648983001709, 18.26898956298828, 0.7137726545333862], step: 41600, lr: 8.619920061032583e-05, reference_loss: 32.50843811035156
2024-01-02 02:18:37,036	44k	INFO	Saving model and optimizer state at iteration 1189 to ./logs/44k/G_41600.pth
2024-01-02 02:18:37,935	44k	INFO	Saving model and optimizer state at iteration 1189 to ./logs/44k/D_41600.pth
2024-01-02 02:18:38,705	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_39200.pth
2024-01-02 02:18:38,762	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_39200.pth
2024-01-02 02:18:50,075	44k	INFO	====> Epoch: 1189, cost 35.51 s
2024-01-02 02:19:16,318	44k	INFO	====> Epoch: 1190, cost 26.24 s
2024-01-02 02:19:42,996	44k	INFO	====> Epoch: 1191, cost 26.68 s
2024-01-02 02:20:09,424	44k	INFO	====> Epoch: 1192, cost 26.43 s
2024-01-02 02:20:35,703	44k	INFO	====> Epoch: 1193, cost 26.28 s
2024-01-02 02:21:01,890	44k	INFO	====> Epoch: 1194, cost 26.19 s
2024-01-02 02:21:09,400	44k	INFO	Train Epoch: 1195 [26%]
2024-01-02 02:21:09,401	44k	INFO	Losses: [2.303460121154785, 2.5720176696777344, 6.29464864730835, 17.885679244995117, 0.8002550601959229], step: 41800, lr: 8.613457140943886e-05, reference_loss: 29.856060028076172
2024-01-02 02:21:28,690	44k	INFO	====> Epoch: 1195, cost 26.80 s
2024-01-02 02:21:54,899	44k	INFO	====> Epoch: 1196, cost 26.21 s
2024-01-02 02:22:21,098	44k	INFO	====> Epoch: 1197, cost 26.20 s
2024-01-02 02:22:47,446	44k	INFO	====> Epoch: 1198, cost 26.35 s
2024-01-02 02:23:13,714	44k	INFO	====> Epoch: 1199, cost 26.27 s
2024-01-02 02:23:40,256	44k	INFO	Train Epoch: 1200 [97%]
2024-01-02 02:23:40,257	44k	INFO	Losses: [2.3922367095947266, 2.593968391418457, 6.315846920013428, 16.51740074157715, 0.5074196457862854], step: 42000, lr: 8.608075075915251e-05, reference_loss: 28.326871871948242
2024-01-02 02:23:40,747	44k	INFO	====> Epoch: 1200, cost 27.03 s
2024-01-02 02:24:07,128	44k	INFO	====> Epoch: 1201, cost 26.38 s
2024-01-02 02:24:33,355	44k	INFO	====> Epoch: 1202, cost 26.23 s
2024-01-02 02:24:59,635	44k	INFO	====> Epoch: 1203, cost 26.28 s
2024-01-02 02:25:25,809	44k	INFO	====> Epoch: 1204, cost 26.17 s
2024-01-02 02:25:52,137	44k	INFO	====> Epoch: 1205, cost 26.33 s
2024-01-02 02:26:10,912	44k	INFO	Train Epoch: 1206 [69%]
2024-01-02 02:26:10,913	44k	INFO	Losses: [1.9580810070037842, 2.952202796936035, 8.004419326782227, 17.433866500854492, 0.7010135650634766], step: 42200, lr: 8.601621036789686e-05, reference_loss: 31.049583435058594
2024-01-02 02:26:19,284	44k	INFO	====> Epoch: 1206, cost 27.15 s
2024-01-02 02:26:45,684	44k	INFO	====> Epoch: 1207, cost 26.40 s
2024-01-02 02:27:11,899	44k	INFO	====> Epoch: 1208, cost 26.21 s
2024-01-02 02:27:38,049	44k	INFO	====> Epoch: 1209, cost 26.15 s
2024-01-02 02:28:04,346	44k	INFO	====> Epoch: 1210, cost 26.30 s
2024-01-02 02:28:30,563	44k	INFO	====> Epoch: 1211, cost 26.22 s
2024-01-02 02:28:41,769	44k	INFO	Train Epoch: 1212 [40%]
2024-01-02 02:28:41,770	44k	INFO	Losses: [2.311079502105713, 2.2692809104919434, 7.825833320617676, 19.69192123413086, 0.6182700991630554], step: 42400, lr: 8.595171836681053e-05, reference_loss: 32.71638488769531
2024-01-02 02:28:49,290	44k	INFO	Saving model and optimizer state at iteration 1212 to ./logs/44k/G_42400.pth
2024-01-02 02:28:50,540	44k	INFO	Saving model and optimizer state at iteration 1212 to ./logs/44k/D_42400.pth
2024-01-02 02:28:51,326	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_40000.pth
2024-01-02 02:28:51,383	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_40000.pth
2024-01-02 02:29:06,482	44k	INFO	====> Epoch: 1212, cost 35.92 s
2024-01-02 02:29:32,812	44k	INFO	====> Epoch: 1213, cost 26.33 s
2024-01-02 02:29:58,990	44k	INFO	====> Epoch: 1214, cost 26.18 s
2024-01-02 02:30:25,091	44k	INFO	====> Epoch: 1215, cost 26.10 s
2024-01-02 02:30:51,437	44k	INFO	====> Epoch: 1216, cost 26.35 s
2024-01-02 02:31:17,738	44k	INFO	====> Epoch: 1217, cost 26.30 s
2024-01-02 02:31:21,495	44k	INFO	Train Epoch: 1218 [11%]
2024-01-02 02:31:21,495	44k	INFO	Losses: [2.1881301403045654, 2.8754963874816895, 7.475213527679443, 17.96304702758789, 0.6664348244667053], step: 42600, lr: 8.588727471961222e-05, reference_loss: 31.16832160949707
2024-01-02 02:31:44,562	44k	INFO	====> Epoch: 1218, cost 26.82 s
2024-01-02 02:32:11,275	44k	INFO	====> Epoch: 1219, cost 26.71 s
2024-01-02 02:32:37,606	44k	INFO	====> Epoch: 1220, cost 26.33 s
2024-01-02 02:33:03,982	44k	INFO	====> Epoch: 1221, cost 26.38 s
2024-01-02 02:33:30,344	44k	INFO	====> Epoch: 1222, cost 26.36 s
2024-01-02 02:33:52,734	44k	INFO	Train Epoch: 1223 [83%]
2024-01-02 02:33:52,734	44k	INFO	Losses: [2.6842212677001953, 2.1541190147399902, 6.048036098480225, 19.120899200439453, 0.7451292276382446], step: 42800, lr: 8.583360859112174e-05, reference_loss: 30.752403259277344
2024-01-02 02:33:56,980	44k	INFO	====> Epoch: 1223, cost 26.64 s
2024-01-02 02:34:23,296	44k	INFO	====> Epoch: 1224, cost 26.32 s
2024-01-02 02:34:49,664	44k	INFO	====> Epoch: 1225, cost 26.37 s
2024-01-02 02:35:16,295	44k	INFO	====> Epoch: 1226, cost 26.63 s
2024-01-02 02:35:42,612	44k	INFO	====> Epoch: 1227, cost 26.32 s
2024-01-02 02:36:08,875	44k	INFO	====> Epoch: 1228, cost 26.26 s
2024-01-02 02:36:23,876	44k	INFO	Train Epoch: 1229 [54%]
2024-01-02 02:36:23,876	44k	INFO	Losses: [2.4437520503997803, 2.4035356044769287, 7.586026191711426, 18.9427490234375, 0.5715593099594116], step: 43000, lr: 8.576925349857781e-05, reference_loss: 31.947622299194336
2024-01-02 02:36:35,637	44k	INFO	====> Epoch: 1229, cost 26.76 s
2024-01-02 02:37:01,841	44k	INFO	====> Epoch: 1230, cost 26.20 s
2024-01-02 02:37:28,133	44k	INFO	====> Epoch: 1231, cost 26.29 s
2024-01-02 02:37:54,362	44k	INFO	====> Epoch: 1232, cost 26.23 s
2024-01-02 02:38:21,004	44k	INFO	====> Epoch: 1233, cost 26.64 s
2024-01-02 02:38:47,331	44k	INFO	====> Epoch: 1234, cost 26.33 s
2024-01-02 02:38:54,783	44k	INFO	Train Epoch: 1235 [26%]
2024-01-02 02:38:54,783	44k	INFO	Losses: [2.321713447570801, 2.952866554260254, 6.947389602661133, 18.643421173095703, 0.560867428779602], step: 43200, lr: 8.57049466572726e-05, reference_loss: 31.426258087158203
2024-01-02 02:39:02,182	44k	INFO	Saving model and optimizer state at iteration 1235 to ./logs/44k/G_43200.pth
2024-01-02 02:39:03,069	44k	INFO	Saving model and optimizer state at iteration 1235 to ./logs/44k/D_43200.pth
2024-01-02 02:39:03,841	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_40800.pth
2024-01-02 02:39:03,897	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_40800.pth
2024-01-02 02:39:22,598	44k	INFO	====> Epoch: 1235, cost 35.27 s
2024-01-02 02:39:48,932	44k	INFO	====> Epoch: 1236, cost 26.33 s
2024-01-02 02:40:15,293	44k	INFO	====> Epoch: 1237, cost 26.36 s
2024-01-02 02:40:41,616	44k	INFO	====> Epoch: 1238, cost 26.32 s
2024-01-02 02:41:08,193	44k	INFO	====> Epoch: 1239, cost 26.58 s
2024-01-02 02:41:34,540	44k	INFO	Train Epoch: 1240 [97%]
2024-01-02 02:41:34,541	44k	INFO	Losses: [2.483898162841797, 2.530042886734009, 7.596272945404053, 18.715181350708008, 0.49199533462524414], step: 43400, lr: 8.565139445533588e-05, reference_loss: 31.81739044189453
2024-01-02 02:41:35,174	44k	INFO	====> Epoch: 1240, cost 26.98 s
2024-01-02 02:42:01,501	44k	INFO	====> Epoch: 1241, cost 26.33 s
2024-01-02 02:42:27,653	44k	INFO	====> Epoch: 1242, cost 26.15 s
2024-01-02 02:42:53,894	44k	INFO	====> Epoch: 1243, cost 26.24 s
2024-01-02 02:43:20,250	44k	INFO	====> Epoch: 1244, cost 26.36 s
2024-01-02 02:43:46,606	44k	INFO	====> Epoch: 1245, cost 26.36 s
2024-01-02 02:44:05,391	44k	INFO	Train Epoch: 1246 [69%]
2024-01-02 02:44:05,391	44k	INFO	Losses: [2.270911693572998, 2.6511008739471436, 6.891855239868164, 15.910842895507812, 0.8285964727401733], step: 43600, lr: 8.558717598069447e-05, reference_loss: 28.553306579589844
2024-01-02 02:44:13,703	44k	INFO	====> Epoch: 1246, cost 27.10 s
2024-01-02 02:44:39,944	44k	INFO	====> Epoch: 1247, cost 26.24 s
2024-01-02 02:45:06,374	44k	INFO	====> Epoch: 1248, cost 26.43 s
2024-01-02 02:45:32,582	44k	INFO	====> Epoch: 1249, cost 26.21 s
2024-01-02 02:45:58,794	44k	INFO	====> Epoch: 1250, cost 26.21 s
2024-01-02 02:46:25,025	44k	INFO	====> Epoch: 1251, cost 26.23 s
2024-01-02 02:46:36,154	44k	INFO	Train Epoch: 1252 [40%]
2024-01-02 02:46:36,155	44k	INFO	Losses: [2.522303342819214, 2.1961007118225098, 5.923776149749756, 17.2865047454834, 0.7811177372932434], step: 43800, lr: 8.552300565486037e-05, reference_loss: 28.709802627563477
2024-01-02 02:46:51,929	44k	INFO	====> Epoch: 1252, cost 26.90 s
2024-01-02 02:47:18,588	44k	INFO	====> Epoch: 1253, cost 26.66 s
2024-01-02 02:47:44,868	44k	INFO	====> Epoch: 1254, cost 26.28 s
2024-01-02 02:48:11,188	44k	INFO	====> Epoch: 1255, cost 26.32 s
2024-01-02 02:48:37,513	44k	INFO	====> Epoch: 1256, cost 26.33 s
2024-01-02 02:49:03,860	44k	INFO	====> Epoch: 1257, cost 26.35 s
2024-01-02 02:49:07,619	44k	INFO	Train Epoch: 1258 [11%]
2024-01-02 02:49:07,620	44k	INFO	Losses: [2.5438854694366455, 1.96307373046875, 5.70538854598999, 15.882869720458984, 0.9271661043167114], step: 44000, lr: 8.545888344173321e-05, reference_loss: 27.022382736206055
2024-01-02 02:49:14,903	44k	INFO	Saving model and optimizer state at iteration 1258 to ./logs/44k/G_44000.pth
2024-01-02 02:49:15,795	44k	INFO	Saving model and optimizer state at iteration 1258 to ./logs/44k/D_44000.pth
2024-01-02 02:49:16,578	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_41600.pth
2024-01-02 02:49:16,635	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_41600.pth
2024-01-02 02:49:39,577	44k	INFO	====> Epoch: 1258, cost 35.72 s
2024-01-02 02:50:05,825	44k	INFO	====> Epoch: 1259, cost 26.25 s
2024-01-02 02:50:32,185	44k	INFO	====> Epoch: 1260, cost 26.36 s
2024-01-02 02:50:58,551	44k	INFO	====> Epoch: 1261, cost 26.37 s
2024-01-02 02:51:24,734	44k	INFO	====> Epoch: 1262, cost 26.18 s
2024-01-02 02:51:47,251	44k	INFO	Train Epoch: 1263 [83%]
2024-01-02 02:51:47,252	44k	INFO	Losses: [2.269226551055908, 2.404000759124756, 6.778514862060547, 15.615803718566895, 0.4849475026130676], step: 44200, lr: 8.540548499086363e-05, reference_loss: 27.552494049072266
2024-01-02 02:51:51,482	44k	INFO	====> Epoch: 1263, cost 26.75 s
2024-01-02 02:52:17,724	44k	INFO	====> Epoch: 1264, cost 26.24 s
2024-01-02 02:52:44,092	44k	INFO	====> Epoch: 1265, cost 26.37 s
2024-01-02 02:53:10,300	44k	INFO	====> Epoch: 1266, cost 26.21 s
2024-01-02 02:53:36,968	44k	INFO	====> Epoch: 1267, cost 26.67 s
2024-01-02 02:54:03,187	44k	INFO	====> Epoch: 1268, cost 26.22 s
2024-01-02 02:54:18,079	44k	INFO	Train Epoch: 1269 [54%]
2024-01-02 02:54:18,079	44k	INFO	Losses: [2.5439703464508057, 2.207310438156128, 5.999587059020996, 16.84700584411621, 0.7600834965705872], step: 44400, lr: 8.534145089069516e-05, reference_loss: 28.35795783996582
2024-01-02 02:54:29,927	44k	INFO	====> Epoch: 1269, cost 26.74 s
2024-01-02 02:54:56,259	44k	INFO	====> Epoch: 1270, cost 26.33 s
2024-01-02 02:55:22,618	44k	INFO	====> Epoch: 1271, cost 26.36 s
2024-01-02 02:55:48,947	44k	INFO	====> Epoch: 1272, cost 26.33 s
2024-01-02 02:56:15,181	44k	INFO	====> Epoch: 1273, cost 26.23 s
2024-01-02 02:56:41,864	44k	INFO	====> Epoch: 1274, cost 26.68 s
2024-01-02 02:56:49,394	44k	INFO	Train Epoch: 1275 [26%]
2024-01-02 02:56:49,394	44k	INFO	Losses: [2.4712061882019043, 2.4888031482696533, 6.502295970916748, 17.405527114868164, 0.6171145439147949], step: 44600, lr: 8.527746480109634e-05, reference_loss: 29.484947204589844
2024-01-02 02:57:08,759	44k	INFO	====> Epoch: 1275, cost 26.90 s
2024-01-02 02:57:35,091	44k	INFO	====> Epoch: 1276, cost 26.33 s
2024-01-02 02:58:01,487	44k	INFO	====> Epoch: 1277, cost 26.40 s
2024-01-02 02:58:27,799	44k	INFO	====> Epoch: 1278, cost 26.31 s
2024-01-02 02:58:53,961	44k	INFO	====> Epoch: 1279, cost 26.16 s
2024-01-02 02:59:20,349	44k	INFO	Train Epoch: 1280 [97%]
2024-01-02 02:59:20,349	44k	INFO	Losses: [2.603893995285034, 2.4781124591827393, 5.129024982452393, 15.09543228149414, 0.6272422671318054], step: 44800, lr: 8.522417970853403e-05, reference_loss: 25.933706283569336
2024-01-02 02:59:28,065	44k	INFO	Saving model and optimizer state at iteration 1280 to ./logs/44k/G_44800.pth
2024-01-02 02:59:28,973	44k	INFO	Saving model and optimizer state at iteration 1280 to ./logs/44k/D_44800.pth
2024-01-02 02:59:29,775	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_42400.pth
2024-01-02 02:59:29,833	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_42400.pth
2024-01-02 02:59:29,833	44k	INFO	====> Epoch: 1280, cost 35.87 s
2024-01-02 02:59:56,140	44k	INFO	====> Epoch: 1281, cost 26.31 s
2024-01-02 03:00:22,405	44k	INFO	====> Epoch: 1282, cost 26.26 s
2024-01-02 03:00:48,763	44k	INFO	====> Epoch: 1283, cost 26.36 s
2024-01-02 03:01:14,968	44k	INFO	====> Epoch: 1284, cost 26.21 s
2024-01-02 03:01:41,111	44k	INFO	====> Epoch: 1285, cost 26.14 s
2024-01-02 03:01:59,799	44k	INFO	Train Epoch: 1286 [69%]
2024-01-02 03:01:59,800	44k	INFO	Losses: [2.42268705368042, 2.084733486175537, 6.272578239440918, 16.862159729003906, 0.676715075969696], step: 45000, lr: 8.516028154484098e-05, reference_loss: 28.31887435913086
2024-01-02 03:02:08,139	44k	INFO	====> Epoch: 1286, cost 27.03 s
2024-01-02 03:02:34,391	44k	INFO	====> Epoch: 1287, cost 26.25 s
2024-01-02 03:03:00,715	44k	INFO	====> Epoch: 1288, cost 26.32 s
2024-01-02 03:03:27,028	44k	INFO	====> Epoch: 1289, cost 26.31 s
2024-01-02 03:03:53,164	44k	INFO	====> Epoch: 1290, cost 26.14 s
2024-01-02 03:04:19,499	44k	INFO	====> Epoch: 1291, cost 26.33 s
2024-01-02 03:04:30,684	44k	INFO	Train Epoch: 1292 [40%]
2024-01-02 03:04:30,685	44k	INFO	Losses: [2.408352851867676, 2.5789761543273926, 6.805981159210205, 19.079572677612305, 0.5999009013175964], step: 45200, lr: 8.509643128979703e-05, reference_loss: 31.4727840423584
2024-01-02 03:04:46,419	44k	INFO	====> Epoch: 1292, cost 26.92 s
2024-01-02 03:05:12,954	44k	INFO	====> Epoch: 1293, cost 26.53 s
2024-01-02 03:05:39,101	44k	INFO	====> Epoch: 1294, cost 26.15 s
2024-01-02 03:06:05,405	44k	INFO	====> Epoch: 1295, cost 26.30 s
2024-01-02 03:06:31,808	44k	INFO	====> Epoch: 1296, cost 26.40 s
2024-01-02 03:06:58,011	44k	INFO	====> Epoch: 1297, cost 26.20 s
2024-01-02 03:07:01,774	44k	INFO	Train Epoch: 1298 [11%]
2024-01-02 03:07:01,775	44k	INFO	Losses: [2.509962558746338, 2.292008876800537, 6.021495819091797, 17.73609161376953, 0.4597984552383423], step: 45400, lr: 8.5032628907482e-05, reference_loss: 29.019357681274414
2024-01-02 03:07:24,843	44k	INFO	====> Epoch: 1298, cost 26.83 s
2024-01-02 03:07:51,214	44k	INFO	====> Epoch: 1299, cost 26.37 s
2024-01-02 03:08:17,837	44k	INFO	====> Epoch: 1300, cost 26.62 s
2024-01-02 03:08:44,113	44k	INFO	====> Epoch: 1301, cost 26.28 s
2024-01-02 03:09:10,444	44k	INFO	====> Epoch: 1302, cost 26.33 s
2024-01-02 03:09:32,983	44k	INFO	Train Epoch: 1303 [83%]
2024-01-02 03:09:32,984	44k	INFO	Losses: [2.4573426246643066, 2.2641406059265137, 6.056303977966309, 15.874372482299805, 0.7225424647331238], step: 45600, lr: 8.497949679910239e-05, reference_loss: 27.37470245361328
2024-01-02 03:09:40,336	44k	INFO	Saving model and optimizer state at iteration 1303 to ./logs/44k/G_45600.pth
2024-01-02 03:09:41,230	44k	INFO	Saving model and optimizer state at iteration 1303 to ./logs/44k/D_45600.pth
2024-01-02 03:09:41,986	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_43200.pth
2024-01-02 03:09:42,042	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_43200.pth
2024-01-02 03:09:45,801	44k	INFO	====> Epoch: 1303, cost 35.36 s
2024-01-02 03:10:12,079	44k	INFO	====> Epoch: 1304, cost 26.28 s
2024-01-02 03:10:38,235	44k	INFO	====> Epoch: 1305, cost 26.16 s
2024-01-02 03:11:04,723	44k	INFO	====> Epoch: 1306, cost 26.49 s
2024-01-02 03:11:31,020	44k	INFO	====> Epoch: 1307, cost 26.30 s
2024-01-02 03:11:57,334	44k	INFO	====> Epoch: 1308, cost 26.31 s
2024-01-02 03:12:12,288	44k	INFO	Train Epoch: 1309 [54%]
2024-01-02 03:12:12,289	44k	INFO	Losses: [2.535820722579956, 2.339967727661133, 6.21136999130249, 16.792816162109375, 0.40809449553489685], step: 45800, lr: 8.49157820902534e-05, reference_loss: 28.288068771362305
2024-01-02 03:12:24,064	44k	INFO	====> Epoch: 1309, cost 26.73 s
2024-01-02 03:12:50,399	44k	INFO	====> Epoch: 1310, cost 26.34 s
2024-01-02 03:13:16,648	44k	INFO	====> Epoch: 1311, cost 26.25 s
2024-01-02 03:13:43,004	44k	INFO	====> Epoch: 1312, cost 26.36 s
2024-01-02 03:14:09,384	44k	INFO	====> Epoch: 1313, cost 26.38 s
2024-01-02 03:14:36,063	44k	INFO	====> Epoch: 1314, cost 26.68 s
2024-01-02 03:14:43,566	44k	INFO	Train Epoch: 1315 [26%]
2024-01-02 03:14:43,566	44k	INFO	Losses: [2.4420933723449707, 2.331083297729492, 7.307851791381836, 19.705615997314453, 0.836384654045105], step: 46000, lr: 8.48521151525054e-05, reference_loss: 32.62302780151367
2024-01-02 03:15:02,904	44k	INFO	====> Epoch: 1315, cost 26.84 s
2024-01-02 03:15:29,358	44k	INFO	====> Epoch: 1316, cost 26.45 s
2024-01-02 03:15:55,721	44k	INFO	====> Epoch: 1317, cost 26.36 s
2024-01-02 03:16:21,997	44k	INFO	====> Epoch: 1318, cost 26.28 s
2024-01-02 03:16:48,325	44k	INFO	====> Epoch: 1319, cost 26.33 s
2024-01-02 03:17:14,699	44k	INFO	Train Epoch: 1320 [97%]
2024-01-02 03:17:14,700	44k	INFO	Losses: [2.207566261291504, 2.8972833156585693, 7.982451438903809, 17.984607696533203, 0.6736124753952026], step: 46200, lr: 8.479909583702088e-05, reference_loss: 31.745521545410156
2024-01-02 03:17:15,506	44k	INFO	====> Epoch: 1320, cost 27.18 s
2024-01-02 03:17:41,650	44k	INFO	====> Epoch: 1321, cost 26.14 s
2024-01-02 03:18:07,883	44k	INFO	====> Epoch: 1322, cost 26.23 s
2024-01-02 03:18:34,138	44k	INFO	====> Epoch: 1323, cost 26.25 s
2024-01-02 03:19:00,352	44k	INFO	====> Epoch: 1324, cost 26.21 s
2024-01-02 03:19:26,519	44k	INFO	====> Epoch: 1325, cost 26.17 s
2024-01-02 03:19:45,175	44k	INFO	Train Epoch: 1326 [69%]
2024-01-02 03:19:45,176	44k	INFO	Losses: [2.5128633975982666, 2.572977066040039, 6.238681316375732, 14.771732330322266, 0.6458221673965454], step: 46400, lr: 8.473551638661902e-05, reference_loss: 26.742076873779297
2024-01-02 03:19:52,687	44k	INFO	Saving model and optimizer state at iteration 1326 to ./logs/44k/G_46400.pth
2024-01-02 03:19:53,907	44k	INFO	Saving model and optimizer state at iteration 1326 to ./logs/44k/D_46400.pth
2024-01-02 03:19:54,673	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_44000.pth
2024-01-02 03:19:54,730	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_44000.pth
2024-01-02 03:20:02,288	44k	INFO	====> Epoch: 1326, cost 35.77 s
2024-01-02 03:20:28,621	44k	INFO	====> Epoch: 1327, cost 26.33 s
2024-01-02 03:20:54,994	44k	INFO	====> Epoch: 1328, cost 26.37 s
2024-01-02 03:21:21,281	44k	INFO	====> Epoch: 1329, cost 26.29 s
2024-01-02 03:21:47,553	44k	INFO	====> Epoch: 1330, cost 26.27 s
2024-01-02 03:22:13,914	44k	INFO	====> Epoch: 1331, cost 26.36 s
2024-01-02 03:22:25,090	44k	INFO	Train Epoch: 1332 [40%]
2024-01-02 03:22:25,091	44k	INFO	Losses: [2.5540921688079834, 2.2826988697052, 6.74753999710083, 18.867502212524414, 0.5225557684898376], step: 46600, lr: 8.467198460590602e-05, reference_loss: 30.974390029907227
2024-01-02 03:22:40,634	44k	INFO	====> Epoch: 1332, cost 26.72 s
2024-01-02 03:23:07,285	44k	INFO	====> Epoch: 1333, cost 26.65 s
2024-01-02 03:23:33,594	44k	INFO	====> Epoch: 1334, cost 26.31 s
2024-01-02 03:23:59,856	44k	INFO	====> Epoch: 1335, cost 26.26 s
2024-01-02 03:24:26,206	44k	INFO	====> Epoch: 1336, cost 26.35 s
2024-01-02 03:24:52,526	44k	INFO	====> Epoch: 1337, cost 26.32 s
2024-01-02 03:24:56,284	44k	INFO	Train Epoch: 1338 [11%]
2024-01-02 03:24:56,285	44k	INFO	Losses: [2.2689850330352783, 2.345294713973999, 6.513031005859375, 18.062740325927734, 0.526132345199585], step: 46800, lr: 8.460850045914078e-05, reference_loss: 29.716184616088867
2024-01-02 03:25:19,445	44k	INFO	====> Epoch: 1338, cost 26.92 s
2024-01-02 03:25:45,770	44k	INFO	====> Epoch: 1339, cost 26.32 s
2024-01-02 03:26:12,396	44k	INFO	====> Epoch: 1340, cost 26.63 s
2024-01-02 03:26:38,763	44k	INFO	====> Epoch: 1341, cost 26.37 s
2024-01-02 03:27:05,060	44k	INFO	====> Epoch: 1342, cost 26.30 s
2024-01-02 03:27:27,626	44k	INFO	Train Epoch: 1343 [83%]
2024-01-02 03:27:27,627	44k	INFO	Losses: [2.5631675720214844, 2.4399163722991943, 6.728296756744385, 17.213224411010742, 0.7476419806480408], step: 47000, lr: 8.455563336477959e-05, reference_loss: 29.69224739074707
2024-01-02 03:27:31,854	44k	INFO	====> Epoch: 1343, cost 26.79 s
2024-01-02 03:27:58,085	44k	INFO	====> Epoch: 1344, cost 26.23 s
2024-01-02 03:28:24,248	44k	INFO	====> Epoch: 1345, cost 26.16 s
2024-01-02 03:28:50,443	44k	INFO	====> Epoch: 1346, cost 26.19 s
2024-01-02 03:29:17,025	44k	INFO	====> Epoch: 1347, cost 26.58 s
2024-01-02 03:29:43,347	44k	INFO	====> Epoch: 1348, cost 26.32 s
2024-01-02 03:29:58,256	44k	INFO	Train Epoch: 1349 [54%]
2024-01-02 03:29:58,257	44k	INFO	Losses: [2.189419746398926, 2.724430561065674, 8.591224670410156, 17.736940383911133, 0.7450602650642395], step: 47200, lr: 8.44922364541799e-05, reference_loss: 31.987075805664062
2024-01-02 03:30:05,558	44k	INFO	Saving model and optimizer state at iteration 1349 to ./logs/44k/G_47200.pth
2024-01-02 03:30:06,453	44k	INFO	Saving model and optimizer state at iteration 1349 to ./logs/44k/D_47200.pth
2024-01-02 03:30:07,222	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_44800.pth
2024-01-02 03:30:07,281	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_44800.pth
2024-01-02 03:30:18,642	44k	INFO	====> Epoch: 1349, cost 35.29 s
2024-01-02 03:30:44,829	44k	INFO	====> Epoch: 1350, cost 26.19 s
2024-01-02 03:31:11,132	44k	INFO	====> Epoch: 1351, cost 26.30 s
2024-01-02 03:31:37,369	44k	INFO	====> Epoch: 1352, cost 26.24 s
2024-01-02 03:32:03,971	44k	INFO	====> Epoch: 1353, cost 26.60 s
2024-01-02 03:32:30,215	44k	INFO	====> Epoch: 1354, cost 26.24 s
2024-01-02 03:32:37,725	44k	INFO	Train Epoch: 1355 [26%]
2024-01-02 03:32:37,726	44k	INFO	Losses: [2.3712222576141357, 2.337120771408081, 7.257176876068115, 17.97173309326172, 0.7169824838638306], step: 47400, lr: 8.4428887076407e-05, reference_loss: 30.654233932495117
2024-01-02 03:32:57,090	44k	INFO	====> Epoch: 1355, cost 26.88 s
2024-01-02 03:33:23,392	44k	INFO	====> Epoch: 1356, cost 26.30 s
2024-01-02 03:33:49,713	44k	INFO	====> Epoch: 1357, cost 26.32 s
2024-01-02 03:34:15,990	44k	INFO	====> Epoch: 1358, cost 26.28 s
2024-01-02 03:34:42,166	44k	INFO	====> Epoch: 1359, cost 26.18 s
2024-01-02 03:35:08,418	44k	INFO	Train Epoch: 1360 [97%]
2024-01-02 03:35:08,418	44k	INFO	Losses: [2.365203857421875, 2.3676493167877197, 6.356500148773193, 17.228927612304688, 0.45752087235450745], step: 47600, lr: 8.437613221234893e-05, reference_loss: 28.775802612304688
2024-01-02 03:35:09,199	44k	INFO	====> Epoch: 1360, cost 27.03 s
2024-01-02 03:35:35,365	44k	INFO	====> Epoch: 1361, cost 26.17 s
2024-01-02 03:36:01,566	44k	INFO	====> Epoch: 1362, cost 26.20 s
2024-01-02 03:36:27,892	44k	INFO	====> Epoch: 1363, cost 26.33 s
2024-01-02 03:36:54,233	44k	INFO	====> Epoch: 1364, cost 26.34 s
2024-01-02 03:37:20,542	44k	INFO	====> Epoch: 1365, cost 26.31 s
2024-01-02 03:37:39,267	44k	INFO	Train Epoch: 1366 [69%]
2024-01-02 03:37:39,268	44k	INFO	Losses: [2.503998279571533, 2.307353973388672, 6.081277847290039, 17.14365577697754, 0.6099910140037537], step: 47800, lr: 8.431286988554999e-05, reference_loss: 28.646276473999023
2024-01-02 03:37:47,458	44k	INFO	====> Epoch: 1366, cost 26.92 s
2024-01-02 03:38:14,102	44k	INFO	====> Epoch: 1367, cost 26.64 s
2024-01-02 03:38:40,424	44k	INFO	====> Epoch: 1368, cost 26.32 s
2024-01-02 03:39:06,740	44k	INFO	====> Epoch: 1369, cost 26.32 s
2024-01-02 03:39:33,027	44k	INFO	====> Epoch: 1370, cost 26.29 s
2024-01-02 03:39:59,305	44k	INFO	====> Epoch: 1371, cost 26.28 s
2024-01-02 03:40:10,373	44k	INFO	Train Epoch: 1372 [40%]
2024-01-02 03:40:10,373	44k	INFO	Losses: [2.0885720252990723, 2.865018844604492, 9.512585639953613, 19.9224910736084, 0.6062391400337219], step: 48000, lr: 8.424965499067151e-05, reference_loss: 34.99490737915039
2024-01-02 03:40:17,773	44k	INFO	Saving model and optimizer state at iteration 1372 to ./logs/44k/G_48000.pth
2024-01-02 03:40:18,681	44k	INFO	Saving model and optimizer state at iteration 1372 to ./logs/44k/D_48000.pth
2024-01-02 03:40:19,473	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_45600.pth
2024-01-02 03:40:19,530	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_45600.pth
2024-01-02 03:40:34,884	44k	INFO	====> Epoch: 1372, cost 35.58 s
2024-01-02 03:41:01,077	44k	INFO	====> Epoch: 1373, cost 26.19 s
2024-01-02 03:41:27,455	44k	INFO	====> Epoch: 1374, cost 26.38 s
2024-01-02 03:41:53,734	44k	INFO	====> Epoch: 1375, cost 26.28 s
2024-01-02 03:42:20,039	44k	INFO	====> Epoch: 1376, cost 26.31 s
2024-01-02 03:42:46,301	44k	INFO	====> Epoch: 1377, cost 26.26 s
2024-01-02 03:42:50,037	44k	INFO	Train Epoch: 1378 [11%]
2024-01-02 03:42:50,038	44k	INFO	Losses: [2.6544618606567383, 2.057581901550293, 5.849662780761719, 17.33159828186035, 0.6506852507591248], step: 48200, lr: 8.418648749215067e-05, reference_loss: 28.543989181518555
2024-01-02 03:43:12,976	44k	INFO	====> Epoch: 1378, cost 26.67 s
2024-01-02 03:43:39,396	44k	INFO	====> Epoch: 1379, cost 26.42 s
2024-01-02 03:44:05,759	44k	INFO	====> Epoch: 1380, cost 26.36 s
2024-01-02 03:44:32,218	44k	INFO	====> Epoch: 1381, cost 26.46 s
2024-01-02 03:44:58,395	44k	INFO	====> Epoch: 1382, cost 26.18 s
2024-01-02 03:45:20,845	44k	INFO	Train Epoch: 1383 [83%]
2024-01-02 03:45:20,846	44k	INFO	Losses: [2.2928695678710938, 2.8316240310668945, 6.640199184417725, 17.971853256225586, 0.6342437267303467], step: 48400, lr: 8.413388408996258e-05, reference_loss: 30.37078857421875
2024-01-02 03:45:25,063	44k	INFO	====> Epoch: 1383, cost 26.67 s
2024-01-02 03:45:51,359	44k	INFO	====> Epoch: 1384, cost 26.30 s
2024-01-02 03:46:17,660	44k	INFO	====> Epoch: 1385, cost 26.30 s
2024-01-02 03:46:44,039	44k	INFO	====> Epoch: 1386, cost 26.38 s
2024-01-02 03:47:10,302	44k	INFO	====> Epoch: 1387, cost 26.26 s
2024-01-02 03:47:36,684	44k	INFO	====> Epoch: 1388, cost 26.38 s
2024-01-02 03:47:51,962	44k	INFO	Train Epoch: 1389 [54%]
2024-01-02 03:47:51,962	44k	INFO	Losses: [2.2733168601989746, 2.456709861755371, 8.40543270111084, 18.52289390563965, 0.5550978779792786], step: 48600, lr: 8.4070803392488e-05, reference_loss: 32.21345138549805
2024-01-02 03:48:03,751	44k	INFO	====> Epoch: 1389, cost 27.07 s
2024-01-02 03:48:29,942	44k	INFO	====> Epoch: 1390, cost 26.19 s
2024-01-02 03:48:56,140	44k	INFO	====> Epoch: 1391, cost 26.20 s
2024-01-02 03:49:22,425	44k	INFO	====> Epoch: 1392, cost 26.28 s
2024-01-02 03:49:48,608	44k	INFO	====> Epoch: 1393, cost 26.18 s
2024-01-02 03:50:14,885	44k	INFO	====> Epoch: 1394, cost 26.28 s
2024-01-02 03:50:22,385	44k	INFO	Train Epoch: 1395 [26%]
2024-01-02 03:50:22,386	44k	INFO	Losses: [2.3935487270355225, 2.4923746585845947, 6.55225944519043, 18.15967559814453, 0.6201827526092529], step: 48800, lr: 8.400776999075448e-05, reference_loss: 30.218040466308594
2024-01-02 03:50:29,970	44k	INFO	Saving model and optimizer state at iteration 1395 to ./logs/44k/G_48800.pth
2024-01-02 03:50:30,882	44k	INFO	Saving model and optimizer state at iteration 1395 to ./logs/44k/D_48800.pth
2024-01-02 03:50:31,661	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_46400.pth
2024-01-02 03:50:31,719	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_46400.pth
2024-01-02 03:50:50,517	44k	INFO	====> Epoch: 1395, cost 35.63 s
2024-01-02 03:51:16,824	44k	INFO	====> Epoch: 1396, cost 26.31 s
2024-01-02 03:51:43,182	44k	INFO	====> Epoch: 1397, cost 26.36 s
2024-01-02 03:52:09,526	44k	INFO	====> Epoch: 1398, cost 26.34 s
2024-01-02 03:52:35,877	44k	INFO	====> Epoch: 1399, cost 26.35 s
2024-01-02 03:53:02,243	44k	INFO	Train Epoch: 1400 [97%]
2024-01-02 03:53:02,244	44k	INFO	Losses: [2.1320369243621826, 2.7579681873321533, 8.931816101074219, 19.665082931518555, 0.5319629907608032], step: 49000, lr: 8.395527825908361e-05, reference_loss: 34.01886749267578
2024-01-02 03:53:03,029	44k	INFO	====> Epoch: 1400, cost 27.15 s
2024-01-02 03:53:29,254	44k	INFO	====> Epoch: 1401, cost 26.23 s
2024-01-02 03:53:55,390	44k	INFO	====> Epoch: 1402, cost 26.14 s
2024-01-02 03:54:21,594	44k	INFO	====> Epoch: 1403, cost 26.20 s
2024-01-02 03:54:47,833	44k	INFO	====> Epoch: 1404, cost 26.24 s
2024-01-02 03:55:14,066	44k	INFO	====> Epoch: 1405, cost 26.23 s
2024-01-02 03:55:32,707	44k	INFO	Train Epoch: 1406 [69%]
2024-01-02 03:55:32,707	44k	INFO	Losses: [2.390275716781616, 2.4444284439086914, 6.941610813140869, 15.520538330078125, 0.786389946937561], step: 49200, lr: 8.389233147412843e-05, reference_loss: 28.08324432373047
2024-01-02 03:55:40,706	44k	INFO	====> Epoch: 1406, cost 26.64 s
2024-01-02 03:56:07,196	44k	INFO	====> Epoch: 1407, cost 26.49 s
2024-01-02 03:56:33,281	44k	INFO	====> Epoch: 1408, cost 26.09 s
2024-01-02 03:56:59,501	44k	INFO	====> Epoch: 1409, cost 26.22 s
2024-01-02 03:57:25,693	44k	INFO	====> Epoch: 1410, cost 26.19 s
2024-01-02 03:57:51,873	44k	INFO	====> Epoch: 1411, cost 26.18 s
2024-01-02 03:58:03,044	44k	INFO	Train Epoch: 1412 [40%]
2024-01-02 03:58:03,045	44k	INFO	Losses: [2.6067616939544678, 2.0102181434631348, 6.003690719604492, 17.154888153076172, 0.7954431176185608], step: 49400, lr: 8.382943188451128e-05, reference_loss: 28.571001052856445
2024-01-02 03:58:18,777	44k	INFO	====> Epoch: 1412, cost 26.90 s
2024-01-02 03:58:45,080	44k	INFO	====> Epoch: 1413, cost 26.30 s
2024-01-02 03:59:11,382	44k	INFO	====> Epoch: 1414, cost 26.30 s
2024-01-02 03:59:38,006	44k	INFO	====> Epoch: 1415, cost 26.62 s
2024-01-02 04:00:04,224	44k	INFO	====> Epoch: 1416, cost 26.22 s
2024-01-02 04:00:30,401	44k	INFO	====> Epoch: 1417, cost 26.18 s
2024-01-02 04:00:34,138	44k	INFO	Train Epoch: 1418 [11%]
2024-01-02 04:00:34,139	44k	INFO	Losses: [2.5402042865753174, 2.3500523567199707, 6.6365180015563965, 17.305662155151367, 0.8733891844749451], step: 49600, lr: 8.376657945484669e-05, reference_loss: 29.705825805664062
2024-01-02 04:00:41,384	44k	INFO	Saving model and optimizer state at iteration 1418 to ./logs/44k/G_49600.pth
2024-01-02 04:00:42,289	44k	INFO	Saving model and optimizer state at iteration 1418 to ./logs/44k/D_49600.pth
2024-01-02 04:00:43,061	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_47200.pth
2024-01-02 04:00:43,117	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_47200.pth
2024-01-02 04:01:05,565	44k	INFO	====> Epoch: 1418, cost 35.16 s
2024-01-02 04:01:31,805	44k	INFO	====> Epoch: 1419, cost 26.24 s
2024-01-02 04:01:58,470	44k	INFO	====> Epoch: 1420, cost 26.66 s
2024-01-02 04:02:24,654	44k	INFO	====> Epoch: 1421, cost 26.18 s
2024-01-02 04:02:50,690	44k	INFO	====> Epoch: 1422, cost 26.04 s
2024-01-02 04:03:13,111	44k	INFO	Train Epoch: 1423 [83%]
2024-01-02 04:03:13,112	44k	INFO	Losses: [2.1797614097595215, 2.588223695755005, 7.611542701721191, 15.48776912689209, 0.6035239100456238], step: 49800, lr: 8.371423842957948e-05, reference_loss: 28.470821380615234
2024-01-02 04:03:17,494	44k	INFO	====> Epoch: 1423, cost 26.80 s
2024-01-02 04:03:43,722	44k	INFO	====> Epoch: 1424, cost 26.23 s
2024-01-02 04:04:09,899	44k	INFO	====> Epoch: 1425, cost 26.18 s
2024-01-02 04:04:36,073	44k	INFO	====> Epoch: 1426, cost 26.17 s
2024-01-02 04:05:02,403	44k	INFO	====> Epoch: 1427, cost 26.33 s
2024-01-02 04:05:28,906	44k	INFO	====> Epoch: 1428, cost 26.50 s
2024-01-02 04:05:43,832	44k	INFO	Train Epoch: 1429 [54%]
2024-01-02 04:05:43,833	44k	INFO	Losses: [2.6043598651885986, 2.0386672019958496, 6.2018537521362305, 16.9371280670166, 0.6992340087890625], step: 50000, lr: 8.365147236801214e-05, reference_loss: 28.481243133544922
2024-01-02 04:05:55,621	44k	INFO	====> Epoch: 1429, cost 26.71 s
2024-01-02 04:06:21,836	44k	INFO	====> Epoch: 1430, cost 26.22 s
2024-01-02 04:06:48,050	44k	INFO	====> Epoch: 1431, cost 26.21 s
2024-01-02 04:07:14,422	44k	INFO	====> Epoch: 1432, cost 26.37 s
2024-01-02 04:07:40,703	44k	INFO	====> Epoch: 1433, cost 26.28 s
2024-01-02 04:08:07,045	44k	INFO	====> Epoch: 1434, cost 26.34 s
2024-01-02 04:08:14,530	44k	INFO	Train Epoch: 1435 [26%]
2024-01-02 04:08:14,530	44k	INFO	Losses: [2.9743542671203613, 2.002432346343994, 6.293323040008545, 17.127742767333984, 0.6079035401344299], step: 50200, lr: 8.35887533662826e-05, reference_loss: 29.005756378173828
2024-01-02 04:08:34,189	44k	INFO	====> Epoch: 1435, cost 27.14 s
2024-01-02 04:09:00,463	44k	INFO	====> Epoch: 1436, cost 26.27 s
2024-01-02 04:09:26,720	44k	INFO	====> Epoch: 1437, cost 26.26 s
2024-01-02 04:09:52,886	44k	INFO	====> Epoch: 1438, cost 26.17 s
2024-01-02 04:10:18,989	44k	INFO	====> Epoch: 1439, cost 26.10 s
2024-01-02 04:10:45,126	44k	INFO	Train Epoch: 1440 [97%]
2024-01-02 04:10:45,126	44k	INFO	Losses: [2.177791118621826, 2.809589147567749, 6.417105674743652, 15.20392894744873, 0.5575556755065918], step: 50400, lr: 8.353652345453889e-05, reference_loss: 27.165969848632812
2024-01-02 04:10:52,665	44k	INFO	Saving model and optimizer state at iteration 1440 to ./logs/44k/G_50400.pth
2024-01-02 04:10:53,912	44k	INFO	Saving model and optimizer state at iteration 1440 to ./logs/44k/D_50400.pth
2024-01-02 04:10:54,680	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_48000.pth
2024-01-02 04:10:54,737	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_48000.pth
2024-01-02 04:10:54,738	44k	INFO	====> Epoch: 1440, cost 35.75 s
2024-01-02 04:11:20,979	44k	INFO	====> Epoch: 1441, cost 26.24 s
2024-01-02 04:11:47,144	44k	INFO	====> Epoch: 1442, cost 26.16 s
2024-01-02 04:12:13,481	44k	INFO	====> Epoch: 1443, cost 26.34 s
2024-01-02 04:12:39,779	44k	INFO	====> Epoch: 1444, cost 26.30 s
2024-01-02 04:13:06,107	44k	INFO	====> Epoch: 1445, cost 26.33 s
2024-01-02 04:13:24,805	44k	INFO	Train Epoch: 1446 [69%]
2024-01-02 04:13:24,805	44k	INFO	Losses: [2.0431203842163086, 2.656493902206421, 7.9921183586120605, 16.234344482421875, 0.6806817054748535], step: 50600, lr: 8.347389063755781e-05, reference_loss: 29.60675811767578
2024-01-02 04:13:32,846	44k	INFO	====> Epoch: 1446, cost 26.74 s
2024-01-02 04:13:59,378	44k	INFO	====> Epoch: 1447, cost 26.53 s
2024-01-02 04:14:25,605	44k	INFO	====> Epoch: 1448, cost 26.23 s
2024-01-02 04:14:51,791	44k	INFO	====> Epoch: 1449, cost 26.19 s
2024-01-02 04:15:18,126	44k	INFO	====> Epoch: 1450, cost 26.33 s
2024-01-02 04:15:44,470	44k	INFO	====> Epoch: 1451, cost 26.34 s
2024-01-02 04:15:55,652	44k	INFO	Train Epoch: 1452 [40%]
2024-01-02 04:15:55,652	44k	INFO	Losses: [2.2174370288848877, 2.5731260776519775, 7.610847473144531, 18.36032485961914, 0.5488818883895874], step: 50800, lr: 8.341130478051234e-05, reference_loss: 31.310617446899414
2024-01-02 04:16:11,289	44k	INFO	====> Epoch: 1452, cost 26.82 s
2024-01-02 04:16:37,608	44k	INFO	====> Epoch: 1453, cost 26.32 s
2024-01-02 04:17:03,964	44k	INFO	====> Epoch: 1454, cost 26.36 s
2024-01-02 04:17:30,512	44k	INFO	====> Epoch: 1455, cost 26.55 s
2024-01-02 04:17:56,828	44k	INFO	====> Epoch: 1456, cost 26.32 s
2024-01-02 04:18:23,014	44k	INFO	====> Epoch: 1457, cost 26.19 s
2024-01-02 04:18:26,758	44k	INFO	Train Epoch: 1458 [11%]
2024-01-02 04:18:26,758	44k	INFO	Losses: [2.0937657356262207, 2.9614346027374268, 8.124402046203613, 17.799137115478516, 0.4504404664039612], step: 51000, lr: 8.334876584819357e-05, reference_loss: 31.429182052612305
2024-01-02 04:18:49,750	44k	INFO	====> Epoch: 1458, cost 26.74 s
2024-01-02 04:19:16,120	44k	INFO	====> Epoch: 1459, cost 26.37 s
2024-01-02 04:19:42,411	44k	INFO	====> Epoch: 1460, cost 26.29 s
2024-01-02 04:20:08,743	44k	INFO	====> Epoch: 1461, cost 26.33 s
2024-01-02 04:20:35,453	44k	INFO	====> Epoch: 1462, cost 26.71 s
2024-01-02 04:20:57,903	44k	INFO	Train Epoch: 1463 [83%]
2024-01-02 04:20:57,904	44k	INFO	Losses: [2.3121917247772217, 2.4374184608459473, 7.385948181152344, 16.223026275634766, 0.6309831738471985], step: 51200, lr: 8.329668589115528e-05, reference_loss: 28.98956871032715
2024-01-02 04:21:05,386	44k	INFO	Saving model and optimizer state at iteration 1463 to ./logs/44k/G_51200.pth
2024-01-02 04:21:06,293	44k	INFO	Saving model and optimizer state at iteration 1463 to ./logs/44k/D_51200.pth
2024-01-02 04:21:07,062	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_48800.pth
2024-01-02 04:21:07,118	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_48800.pth
2024-01-02 04:21:10,892	44k	INFO	====> Epoch: 1463, cost 35.44 s
2024-01-02 04:21:37,180	44k	INFO	====> Epoch: 1464, cost 26.29 s
2024-01-02 04:22:03,470	44k	INFO	====> Epoch: 1465, cost 26.29 s
2024-01-02 04:22:29,811	44k	INFO	====> Epoch: 1466, cost 26.34 s
2024-01-02 04:22:56,456	44k	INFO	====> Epoch: 1467, cost 26.64 s
2024-01-02 04:23:22,750	44k	INFO	====> Epoch: 1468, cost 26.29 s
2024-01-02 04:23:37,723	44k	INFO	Train Epoch: 1469 [54%]
2024-01-02 04:23:37,724	44k	INFO	Losses: [2.5178849697113037, 2.1397504806518555, 6.243957042694092, 16.56102180480957, 0.3987278938293457], step: 51400, lr: 8.323423289614418e-05, reference_loss: 27.86134147644043
2024-01-02 04:23:49,676	44k	INFO	====> Epoch: 1469, cost 26.93 s
2024-01-02 04:24:15,960	44k	INFO	====> Epoch: 1470, cost 26.28 s
2024-01-02 04:24:42,248	44k	INFO	====> Epoch: 1471, cost 26.29 s
2024-01-02 04:25:08,511	44k	INFO	====> Epoch: 1472, cost 26.26 s
2024-01-02 04:25:34,868	44k	INFO	====> Epoch: 1473, cost 26.36 s
2024-01-02 04:26:01,091	44k	INFO	====> Epoch: 1474, cost 26.22 s
2024-01-02 04:26:08,548	44k	INFO	Train Epoch: 1475 [26%]
2024-01-02 04:26:08,549	44k	INFO	Losses: [2.2614362239837646, 2.6475636959075928, 7.695768356323242, 18.694116592407227, 0.854649007320404], step: 51600, lr: 8.317182672624434e-05, reference_loss: 32.153533935546875
2024-01-02 04:26:28,059	44k	INFO	====> Epoch: 1475, cost 26.97 s
2024-01-02 04:26:54,347	44k	INFO	====> Epoch: 1476, cost 26.29 s
2024-01-02 04:27:20,660	44k	INFO	====> Epoch: 1477, cost 26.31 s
2024-01-02 04:27:46,949	44k	INFO	====> Epoch: 1478, cost 26.29 s
2024-01-02 04:28:13,147	44k	INFO	====> Epoch: 1479, cost 26.20 s
2024-01-02 04:28:39,448	44k	INFO	Train Epoch: 1480 [97%]
2024-01-02 04:28:39,449	44k	INFO	Losses: [2.521228551864624, 2.165815830230713, 6.954115390777588, 17.944873809814453, 0.6375175714492798], step: 51800, lr: 8.3119857328514e-05, reference_loss: 30.22355079650879
2024-01-02 04:28:39,935	44k	INFO	====> Epoch: 1480, cost 26.79 s
2024-01-02 04:29:06,609	44k	INFO	====> Epoch: 1481, cost 26.67 s
2024-01-02 04:29:32,984	44k	INFO	====> Epoch: 1482, cost 26.38 s
2024-01-02 04:29:59,362	44k	INFO	====> Epoch: 1483, cost 26.38 s
2024-01-02 04:30:25,679	44k	INFO	====> Epoch: 1484, cost 26.32 s
2024-01-02 04:30:52,038	44k	INFO	====> Epoch: 1485, cost 26.36 s
2024-01-02 04:31:10,836	44k	INFO	Train Epoch: 1486 [69%]
2024-01-02 04:31:10,837	44k	INFO	Losses: [1.886946201324463, 3.130089282989502, 8.286942481994629, 14.384296417236328, 0.6046398282051086], step: 52000, lr: 8.305753691348759e-05, reference_loss: 28.29291343688965
2024-01-02 04:31:18,080	44k	INFO	Saving model and optimizer state at iteration 1486 to ./logs/44k/G_52000.pth
2024-01-02 04:31:18,983	44k	INFO	Saving model and optimizer state at iteration 1486 to ./logs/44k/D_52000.pth
2024-01-02 04:31:19,756	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_49600.pth
2024-01-02 04:31:19,812	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_49600.pth
2024-01-02 04:31:27,329	44k	INFO	====> Epoch: 1486, cost 35.29 s
2024-01-02 04:31:53,807	44k	INFO	====> Epoch: 1487, cost 26.48 s
2024-01-02 04:32:20,099	44k	INFO	====> Epoch: 1488, cost 26.29 s
2024-01-02 04:32:46,287	44k	INFO	====> Epoch: 1489, cost 26.19 s
2024-01-02 04:33:12,555	44k	INFO	====> Epoch: 1490, cost 26.27 s
2024-01-02 04:33:38,786	44k	INFO	====> Epoch: 1491, cost 26.23 s
2024-01-02 04:33:49,958	44k	INFO	Train Epoch: 1492 [40%]
2024-01-02 04:33:49,958	44k	INFO	Losses: [2.3878726959228516, 2.5052876472473145, 7.396986484527588, 18.539133071899414, 0.42347294092178345], step: 52200, lr: 8.299526322416852e-05, reference_loss: 31.25275421142578
2024-01-02 04:34:05,447	44k	INFO	====> Epoch: 1492, cost 26.66 s
2024-01-02 04:34:31,634	44k	INFO	====> Epoch: 1493, cost 26.19 s
2024-01-02 04:34:57,943	44k	INFO	====> Epoch: 1494, cost 26.31 s
2024-01-02 04:35:24,322	44k	INFO	====> Epoch: 1495, cost 26.38 s
2024-01-02 04:35:50,976	44k	INFO	====> Epoch: 1496, cost 26.65 s
2024-01-02 04:36:17,364	44k	INFO	====> Epoch: 1497, cost 26.39 s
2024-01-02 04:36:21,122	44k	INFO	Train Epoch: 1498 [11%]
2024-01-02 04:36:21,123	44k	INFO	Losses: [2.2554147243499756, 2.3641555309295654, 7.855308532714844, 18.92351722717285, 0.5448203682899475], step: 52400, lr: 8.293303622552349e-05, reference_loss: 31.94321632385254
2024-01-02 04:36:44,179	44k	INFO	====> Epoch: 1498, cost 26.81 s
2024-01-02 04:37:10,588	44k	INFO	====> Epoch: 1499, cost 26.41 s
2024-01-02 04:37:36,962	44k	INFO	====> Epoch: 1500, cost 26.37 s
2024-01-02 04:38:03,273	44k	INFO	====> Epoch: 1501, cost 26.31 s
2024-01-02 04:38:29,603	44k	INFO	====> Epoch: 1502, cost 26.33 s
2024-01-02 04:38:52,512	44k	INFO	Train Epoch: 1503 [83%]
2024-01-02 04:38:52,512	44k	INFO	Losses: [2.193749189376831, 2.54841685295105, 7.200942039489746, 15.504653930664062, 0.6721690893173218], step: 52600, lr: 8.288121603454975e-05, reference_loss: 28.119930267333984
2024-01-02 04:38:56,787	44k	INFO	====> Epoch: 1503, cost 27.18 s
2024-01-02 04:39:23,044	44k	INFO	====> Epoch: 1504, cost 26.26 s
2024-01-02 04:39:49,148	44k	INFO	====> Epoch: 1505, cost 26.10 s
2024-01-02 04:40:15,338	44k	INFO	====> Epoch: 1506, cost 26.19 s
2024-01-02 04:40:41,538	44k	INFO	====> Epoch: 1507, cost 26.20 s
2024-01-02 04:41:07,840	44k	INFO	====> Epoch: 1508, cost 26.30 s
2024-01-02 04:41:22,776	44k	INFO	Train Epoch: 1509 [54%]
2024-01-02 04:41:22,776	44k	INFO	Losses: [2.664454698562622, 2.4540250301361084, 8.644343376159668, 17.70314598083496, 0.6959304213523865], step: 52800, lr: 8.281907454457157e-05, reference_loss: 32.16189956665039
2024-01-02 04:41:30,523	44k	INFO	Saving model and optimizer state at iteration 1509 to ./logs/44k/G_52800.pth
2024-01-02 04:41:31,418	44k	INFO	Saving model and optimizer state at iteration 1509 to ./logs/44k/D_52800.pth
2024-01-02 04:41:32,189	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_50400.pth
2024-01-02 04:41:32,246	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_50400.pth
2024-01-02 04:41:43,538	44k	INFO	====> Epoch: 1509, cost 35.70 s
2024-01-02 04:42:09,664	44k	INFO	====> Epoch: 1510, cost 26.13 s
2024-01-02 04:42:35,826	44k	INFO	====> Epoch: 1511, cost 26.16 s
2024-01-02 04:43:02,046	44k	INFO	====> Epoch: 1512, cost 26.22 s
2024-01-02 04:43:28,381	44k	INFO	====> Epoch: 1513, cost 26.34 s
2024-01-02 04:43:54,557	44k	INFO	====> Epoch: 1514, cost 26.18 s
2024-01-02 04:44:02,012	44k	INFO	Train Epoch: 1515 [26%]
2024-01-02 04:44:02,012	44k	INFO	Losses: [2.420274496078491, 2.465590476989746, 7.213554859161377, 17.130399703979492, 0.8108921647071838], step: 53000, lr: 8.275697964614889e-05, reference_loss: 30.040712356567383
2024-01-02 04:44:21,702	44k	INFO	====> Epoch: 1515, cost 27.14 s
2024-01-02 04:44:47,866	44k	INFO	====> Epoch: 1516, cost 26.16 s
2024-01-02 04:45:13,961	44k	INFO	====> Epoch: 1517, cost 26.09 s
2024-01-02 04:45:40,044	44k	INFO	====> Epoch: 1518, cost 26.08 s
2024-01-02 04:46:06,288	44k	INFO	====> Epoch: 1519, cost 26.24 s
2024-01-02 04:46:32,435	44k	INFO	Train Epoch: 1520 [97%]
2024-01-02 04:46:32,435	44k	INFO	Losses: [2.419727325439453, 2.3353123664855957, 6.624082088470459, 17.470237731933594, 0.44669365882873535], step: 53200, lr: 8.270526946303185e-05, reference_loss: 29.296052932739258
2024-01-02 04:46:32,919	44k	INFO	====> Epoch: 1520, cost 26.63 s
2024-01-02 04:46:59,132	44k	INFO	====> Epoch: 1521, cost 26.21 s
2024-01-02 04:47:25,712	44k	INFO	====> Epoch: 1522, cost 26.58 s
2024-01-02 04:47:51,923	44k	INFO	====> Epoch: 1523, cost 26.21 s
2024-01-02 04:48:18,151	44k	INFO	====> Epoch: 1524, cost 26.23 s
2024-01-02 04:48:44,536	44k	INFO	====> Epoch: 1525, cost 26.38 s
2024-01-02 04:49:03,226	44k	INFO	Train Epoch: 1526 [69%]
2024-01-02 04:49:03,226	44k	INFO	Losses: [2.0957388877868652, 3.0061187744140625, 7.886066436767578, 17.01921844482422, 0.5895813703536987], step: 53400, lr: 8.26432598917517e-05, reference_loss: 30.596723556518555
2024-01-02 04:49:11,271	44k	INFO	====> Epoch: 1526, cost 26.73 s
2024-01-02 04:49:37,588	44k	INFO	====> Epoch: 1527, cost 26.32 s
2024-01-02 04:50:03,929	44k	INFO	====> Epoch: 1528, cost 26.34 s
2024-01-02 04:50:30,439	44k	INFO	====> Epoch: 1529, cost 26.51 s
2024-01-02 04:50:56,656	44k	INFO	====> Epoch: 1530, cost 26.22 s
2024-01-02 04:51:22,963	44k	INFO	====> Epoch: 1531, cost 26.31 s
2024-01-02 04:51:34,191	44k	INFO	Train Epoch: 1532 [40%]
2024-01-02 04:51:34,191	44k	INFO	Losses: [2.4262919425964355, 2.552640199661255, 8.11855411529541, 19.545427322387695, 0.5750871300697327], step: 53600, lr: 8.258129681311897e-05, reference_loss: 33.21800231933594
2024-01-02 04:51:41,506	44k	INFO	Saving model and optimizer state at iteration 1532 to ./logs/44k/G_53600.pth
2024-01-02 04:51:42,390	44k	INFO	Saving model and optimizer state at iteration 1532 to ./logs/44k/D_53600.pth
2024-01-02 04:51:43,155	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_51200.pth
2024-01-02 04:51:43,212	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_51200.pth
2024-01-02 04:51:58,319	44k	INFO	====> Epoch: 1532, cost 35.36 s
2024-01-02 04:52:24,677	44k	INFO	====> Epoch: 1533, cost 26.36 s
2024-01-02 04:52:51,265	44k	INFO	====> Epoch: 1534, cost 26.59 s
2024-01-02 04:53:17,564	44k	INFO	====> Epoch: 1535, cost 26.30 s
2024-01-02 04:53:43,804	44k	INFO	====> Epoch: 1536, cost 26.24 s
2024-01-02 04:54:10,010	44k	INFO	====> Epoch: 1537, cost 26.21 s
2024-01-02 04:54:13,744	44k	INFO	Train Epoch: 1538 [11%]
2024-01-02 04:54:13,745	44k	INFO	Losses: [2.521170139312744, 2.3689234256744385, 5.985722064971924, 16.255313873291016, 0.5588945746421814], step: 53800, lr: 8.2519380192275e-05, reference_loss: 27.690025329589844
2024-01-02 04:54:36,854	44k	INFO	====> Epoch: 1538, cost 26.84 s
2024-01-02 04:55:03,214	44k	INFO	====> Epoch: 1539, cost 26.36 s
2024-01-02 04:55:29,548	44k	INFO	====> Epoch: 1540, cost 26.33 s
2024-01-02 04:55:55,891	44k	INFO	====> Epoch: 1541, cost 26.34 s
2024-01-02 04:56:22,233	44k	INFO	====> Epoch: 1542, cost 26.34 s
2024-01-02 04:56:45,126	44k	INFO	Train Epoch: 1543 [83%]
2024-01-02 04:56:45,126	44k	INFO	Losses: [2.696694850921631, 2.0817360877990723, 5.751802444458008, 17.7615966796875, 0.7211875319480896], step: 54000, lr: 8.246781847169636e-05, reference_loss: 29.013017654418945
2024-01-02 04:56:49,367	44k	INFO	====> Epoch: 1543, cost 27.13 s
2024-01-02 04:57:15,472	44k	INFO	====> Epoch: 1544, cost 26.10 s
2024-01-02 04:57:41,850	44k	INFO	====> Epoch: 1545, cost 26.38 s
2024-01-02 04:58:08,178	44k	INFO	====> Epoch: 1546, cost 26.33 s
2024-01-02 04:58:34,376	44k	INFO	====> Epoch: 1547, cost 26.20 s
2024-01-02 04:59:00,577	44k	INFO	====> Epoch: 1548, cost 26.20 s
2024-01-02 04:59:15,459	44k	INFO	Train Epoch: 1549 [54%]
2024-01-02 04:59:15,459	44k	INFO	Losses: [2.389943838119507, 2.767242670059204, 8.954561233520508, 18.074607849121094, 0.5531874895095825], step: 54200, lr: 8.240598693301641e-05, reference_loss: 32.73954391479492
2024-01-02 04:59:27,593	44k	INFO	====> Epoch: 1549, cost 27.02 s
2024-01-02 04:59:53,869	44k	INFO	====> Epoch: 1550, cost 26.28 s
2024-01-02 05:00:20,063	44k	INFO	====> Epoch: 1551, cost 26.19 s
2024-01-02 05:00:46,229	44k	INFO	====> Epoch: 1552, cost 26.17 s
2024-01-02 05:01:12,531	44k	INFO	====> Epoch: 1553, cost 26.30 s
2024-01-02 05:01:38,850	44k	INFO	====> Epoch: 1554, cost 26.32 s
2024-01-02 05:01:46,286	44k	INFO	Train Epoch: 1555 [26%]
2024-01-02 05:01:46,287	44k	INFO	Losses: [2.5229837894439697, 2.2606143951416016, 6.192291259765625, 18.04401206970215, 0.6563615202903748], step: 54400, lr: 8.234420175350112e-05, reference_loss: 29.67626190185547
2024-01-02 05:01:53,553	44k	INFO	Saving model and optimizer state at iteration 1555 to ./logs/44k/G_54400.pth
2024-01-02 05:01:54,797	44k	INFO	Saving model and optimizer state at iteration 1555 to ./logs/44k/D_54400.pth
2024-01-02 05:01:55,556	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_52000.pth
2024-01-02 05:01:55,613	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_52000.pth
2024-01-02 05:02:14,354	44k	INFO	====> Epoch: 1555, cost 35.50 s
2024-01-02 05:02:40,642	44k	INFO	====> Epoch: 1556, cost 26.29 s
2024-01-02 05:03:06,934	44k	INFO	====> Epoch: 1557, cost 26.29 s
2024-01-02 05:03:33,124	44k	INFO	====> Epoch: 1558, cost 26.19 s
2024-01-02 05:03:59,413	44k	INFO	====> Epoch: 1559, cost 26.29 s
2024-01-02 05:04:25,625	44k	INFO	Train Epoch: 1560 [97%]
2024-01-02 05:04:25,626	44k	INFO	Losses: [2.2773079872131348, 2.7684786319732666, 9.014497756958008, 19.38042640686035, 0.5087707042694092], step: 54600, lr: 8.22927494920785e-05, reference_loss: 33.94948196411133
2024-01-02 05:04:26,108	44k	INFO	====> Epoch: 1560, cost 26.69 s
2024-01-02 05:04:52,414	44k	INFO	====> Epoch: 1561, cost 26.31 s
2024-01-02 05:05:18,910	44k	INFO	====> Epoch: 1562, cost 26.50 s
2024-01-02 05:05:45,133	44k	INFO	====> Epoch: 1563, cost 26.22 s
2024-01-02 05:06:11,525	44k	INFO	====> Epoch: 1564, cost 26.39 s
2024-01-02 05:06:37,887	44k	INFO	====> Epoch: 1565, cost 26.36 s
2024-01-02 05:06:56,706	44k	INFO	Train Epoch: 1566 [69%]
2024-01-02 05:06:56,707	44k	INFO	Losses: [2.2385103702545166, 2.681809425354004, 8.157387733459473, 16.373952865600586, 0.6942306756973267], step: 54800, lr: 8.223104921410833e-05, reference_loss: 30.145891189575195
2024-01-02 05:07:04,909	44k	INFO	====> Epoch: 1566, cost 27.02 s
2024-01-02 05:07:31,273	44k	INFO	====> Epoch: 1567, cost 26.36 s
2024-01-02 05:07:57,641	44k	INFO	====> Epoch: 1568, cost 26.37 s
2024-01-02 05:08:24,099	44k	INFO	====> Epoch: 1569, cost 26.46 s
2024-01-02 05:08:50,324	44k	INFO	====> Epoch: 1570, cost 26.22 s
2024-01-02 05:09:16,685	44k	INFO	====> Epoch: 1571, cost 26.36 s
2024-01-02 05:09:27,907	44k	INFO	Train Epoch: 1572 [40%]
2024-01-02 05:09:27,908	44k	INFO	Losses: [2.218533754348755, 3.0637407302856445, 8.015028953552246, 16.859819412231445, 0.7323734164237976], step: 55000, lr: 8.216939519688802e-05, reference_loss: 30.889497756958008
2024-01-02 05:09:43,665	44k	INFO	====> Epoch: 1572, cost 26.98 s
2024-01-02 05:10:09,963	44k	INFO	====> Epoch: 1573, cost 26.30 s
2024-01-02 05:10:36,300	44k	INFO	====> Epoch: 1574, cost 26.34 s
2024-01-02 05:11:02,697	44k	INFO	====> Epoch: 1575, cost 26.40 s
2024-01-02 05:11:29,332	44k	INFO	====> Epoch: 1576, cost 26.64 s
2024-01-02 05:11:55,652	44k	INFO	====> Epoch: 1577, cost 26.32 s
2024-01-02 05:11:59,407	44k	INFO	Train Epoch: 1578 [11%]
2024-01-02 05:11:59,408	44k	INFO	Losses: [2.467923402786255, 2.29536509513855, 7.34886360168457, 17.29944610595703, 0.8365914225578308], step: 55200, lr: 8.210778740573289e-05, reference_loss: 30.24818992614746
2024-01-02 05:12:06,740	44k	INFO	Saving model and optimizer state at iteration 1578 to ./logs/44k/G_55200.pth
2024-01-02 05:12:07,633	44k	INFO	Saving model and optimizer state at iteration 1578 to ./logs/44k/D_55200.pth
2024-01-02 05:12:08,404	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_52800.pth
2024-01-02 05:12:08,461	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_52800.pth
2024-01-02 05:12:30,986	44k	INFO	====> Epoch: 1578, cost 35.33 s
2024-01-02 05:12:57,251	44k	INFO	====> Epoch: 1579, cost 26.27 s
2024-01-02 05:13:23,422	44k	INFO	====> Epoch: 1580, cost 26.17 s
2024-01-02 05:13:49,936	44k	INFO	====> Epoch: 1581, cost 26.51 s
2024-01-02 05:14:16,093	44k	INFO	====> Epoch: 1582, cost 26.16 s
2024-01-02 05:14:38,553	44k	INFO	Train Epoch: 1583 [83%]
2024-01-02 05:14:38,554	44k	INFO	Losses: [2.5460386276245117, 2.3051366806030273, 6.637210845947266, 16.181665420532227, 0.4595261216163635], step: 55400, lr: 8.205648286634251e-05, reference_loss: 28.12957763671875
2024-01-02 05:14:42,952	44k	INFO	====> Epoch: 1583, cost 26.86 s
2024-01-02 05:15:09,312	44k	INFO	====> Epoch: 1584, cost 26.36 s
2024-01-02 05:15:35,572	44k	INFO	====> Epoch: 1585, cost 26.26 s
2024-01-02 05:16:01,893	44k	INFO	====> Epoch: 1586, cost 26.32 s
2024-01-02 05:16:28,139	44k	INFO	====> Epoch: 1587, cost 26.25 s
2024-01-02 05:16:54,374	44k	INFO	====> Epoch: 1588, cost 26.24 s
2024-01-02 05:17:09,341	44k	INFO	Train Epoch: 1589 [54%]
2024-01-02 05:17:09,341	44k	INFO	Losses: [2.648700714111328, 2.1504974365234375, 6.410637855529785, 17.248306274414062, 0.6670554876327515], step: 55600, lr: 8.199495973297586e-05, reference_loss: 29.12519645690918
2024-01-02 05:17:21,501	44k	INFO	====> Epoch: 1589, cost 27.13 s
2024-01-02 05:17:47,732	44k	INFO	====> Epoch: 1590, cost 26.23 s
2024-01-02 05:18:13,903	44k	INFO	====> Epoch: 1591, cost 26.17 s
2024-01-02 05:18:40,092	44k	INFO	====> Epoch: 1592, cost 26.19 s
2024-01-02 05:19:06,413	44k	INFO	====> Epoch: 1593, cost 26.32 s
2024-01-02 05:19:32,617	44k	INFO	====> Epoch: 1594, cost 26.20 s
2024-01-02 05:19:40,104	44k	INFO	Train Epoch: 1595 [26%]
2024-01-02 05:19:40,104	44k	INFO	Losses: [2.1645407676696777, 2.8811962604522705, 7.881852149963379, 16.704648971557617, 0.6168414950370789], step: 55800, lr: 8.193348272754219e-05, reference_loss: 30.249080657958984
2024-01-02 05:19:59,594	44k	INFO	====> Epoch: 1595, cost 26.98 s
2024-01-02 05:20:25,802	44k	INFO	====> Epoch: 1596, cost 26.21 s
2024-01-02 05:20:52,008	44k	INFO	====> Epoch: 1597, cost 26.21 s
2024-01-02 05:21:18,202	44k	INFO	====> Epoch: 1598, cost 26.19 s
2024-01-02 05:21:44,513	44k	INFO	====> Epoch: 1599, cost 26.31 s
2024-01-02 05:22:10,841	44k	INFO	Train Epoch: 1600 [97%]
2024-01-02 05:22:10,842	44k	INFO	Losses: [2.2595438957214355, 2.802927017211914, 7.095034122467041, 15.807933807373047, 0.5520266890525818], step: 56000, lr: 8.188228710134397e-05, reference_loss: 28.517465591430664
2024-01-02 05:22:18,121	44k	INFO	Saving model and optimizer state at iteration 1600 to ./logs/44k/G_56000.pth
2024-01-02 05:22:19,018	44k	INFO	Saving model and optimizer state at iteration 1600 to ./logs/44k/D_56000.pth
2024-01-02 05:22:19,789	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_53600.pth
2024-01-02 05:22:19,846	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_53600.pth
2024-01-02 05:22:19,846	44k	INFO	====> Epoch: 1600, cost 35.33 s
2024-01-02 05:22:46,454	44k	INFO	====> Epoch: 1601, cost 26.61 s
2024-01-02 05:23:12,789	44k	INFO	====> Epoch: 1602, cost 26.34 s
2024-01-02 05:23:39,160	44k	INFO	====> Epoch: 1603, cost 26.37 s
2024-01-02 05:24:05,520	44k	INFO	====> Epoch: 1604, cost 26.36 s
2024-01-02 05:24:31,693	44k	INFO	====> Epoch: 1605, cost 26.17 s
2024-01-02 05:24:50,347	44k	INFO	Train Epoch: 1606 [69%]
2024-01-02 05:24:50,347	44k	INFO	Losses: [2.4029312133789062, 2.2793920040130615, 7.237554550170898, 16.21624183654785, 0.647689938545227], step: 56200, lr: 8.182089457398074e-05, reference_loss: 28.783809661865234
2024-01-02 05:24:58,327	44k	INFO	====> Epoch: 1606, cost 26.63 s
2024-01-02 05:25:24,565	44k	INFO	====> Epoch: 1607, cost 26.24 s
2024-01-02 05:25:50,925	44k	INFO	====> Epoch: 1608, cost 26.36 s
2024-01-02 05:26:17,226	44k	INFO	====> Epoch: 1609, cost 26.30 s
2024-01-02 05:26:43,799	44k	INFO	====> Epoch: 1610, cost 26.57 s
2024-01-02 05:27:09,966	44k	INFO	====> Epoch: 1611, cost 26.17 s
2024-01-02 05:27:21,155	44k	INFO	Train Epoch: 1612 [40%]
2024-01-02 05:27:21,156	44k	INFO	Losses: [2.3454017639160156, 2.3926186561584473, 7.712711811065674, 17.785099029541016, 0.5173267126083374], step: 56400, lr: 8.175954807662658e-05, reference_loss: 30.753158569335938
2024-01-02 05:27:36,718	44k	INFO	====> Epoch: 1612, cost 26.75 s
2024-01-02 05:28:02,928	44k	INFO	====> Epoch: 1613, cost 26.21 s
2024-01-02 05:28:29,263	44k	INFO	====> Epoch: 1614, cost 26.33 s
2024-01-02 05:28:55,532	44k	INFO	====> Epoch: 1615, cost 26.27 s
2024-01-02 05:29:21,841	44k	INFO	====> Epoch: 1616, cost 26.31 s
2024-01-02 05:29:48,362	44k	INFO	====> Epoch: 1617, cost 26.52 s
2024-01-02 05:29:52,121	44k	INFO	Train Epoch: 1618 [11%]
2024-01-02 05:29:52,121	44k	INFO	Losses: [2.675550937652588, 2.195561408996582, 5.3600850105285645, 16.25872039794922, 0.4543112516403198], step: 56600, lr: 8.169824757476974e-05, reference_loss: 26.944229125976562
2024-01-02 05:30:15,227	44k	INFO	====> Epoch: 1618, cost 26.87 s
2024-01-02 05:30:41,523	44k	INFO	====> Epoch: 1619, cost 26.30 s
2024-01-02 05:31:07,752	44k	INFO	====> Epoch: 1620, cost 26.23 s
2024-01-02 05:31:34,034	44k	INFO	====> Epoch: 1621, cost 26.28 s
2024-01-02 05:32:00,274	44k	INFO	====> Epoch: 1622, cost 26.24 s
2024-01-02 05:32:22,826	44k	INFO	Train Epoch: 1623 [83%]
2024-01-02 05:32:22,826	44k	INFO	Losses: [2.3575477600097656, 2.4215621948242188, 7.627779960632324, 15.4406099319458, 0.6302966475486755], step: 56800, lr: 8.164719893379112e-05, reference_loss: 28.47779655456543
2024-01-02 05:32:30,454	44k	INFO	Saving model and optimizer state at iteration 1623 to ./logs/44k/G_56800.pth
2024-01-02 05:32:31,350	44k	INFO	Saving model and optimizer state at iteration 1623 to ./logs/44k/D_56800.pth
2024-01-02 05:32:32,134	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_54400.pth
2024-01-02 05:32:32,193	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_54400.pth
2024-01-02 05:32:35,967	44k	INFO	====> Epoch: 1623, cost 35.69 s
2024-01-02 05:33:02,304	44k	INFO	====> Epoch: 1624, cost 26.34 s
2024-01-02 05:33:28,525	44k	INFO	====> Epoch: 1625, cost 26.22 s
2024-01-02 05:33:54,781	44k	INFO	====> Epoch: 1626, cost 26.26 s
2024-01-02 05:34:21,087	44k	INFO	====> Epoch: 1627, cost 26.31 s
2024-01-02 05:34:47,408	44k	INFO	====> Epoch: 1628, cost 26.32 s
2024-01-02 05:35:02,415	44k	INFO	Train Epoch: 1629 [54%]
2024-01-02 05:35:02,416	44k	INFO	Losses: [2.1588709354400635, 2.4873709678649902, 7.307340145111084, 16.173385620117188, 0.430978924036026], step: 57000, lr: 8.158598266746396e-05, reference_loss: 28.557947158813477
2024-01-02 05:35:14,553	44k	INFO	====> Epoch: 1629, cost 27.15 s
2024-01-02 05:35:40,774	44k	INFO	====> Epoch: 1630, cost 26.22 s
2024-01-02 05:36:07,086	44k	INFO	====> Epoch: 1631, cost 26.31 s
2024-01-02 05:36:33,301	44k	INFO	====> Epoch: 1632, cost 26.22 s
2024-01-02 05:36:59,486	44k	INFO	====> Epoch: 1633, cost 26.18 s
2024-01-02 05:37:25,677	44k	INFO	====> Epoch: 1634, cost 26.19 s
2024-01-02 05:37:33,152	44k	INFO	Train Epoch: 1635 [26%]
2024-01-02 05:37:33,152	44k	INFO	Losses: [2.281367778778076, 2.4056906700134277, 8.391830444335938, 19.345561981201172, 0.8815484642982483], step: 57200, lr: 8.152481229899136e-05, reference_loss: 33.305999755859375
2024-01-02 05:37:52,476	44k	INFO	====> Epoch: 1635, cost 26.80 s
2024-01-02 05:38:19,091	44k	INFO	====> Epoch: 1636, cost 26.62 s
2024-01-02 05:38:45,384	44k	INFO	====> Epoch: 1637, cost 26.29 s
2024-01-02 05:39:11,604	44k	INFO	====> Epoch: 1638, cost 26.22 s
2024-01-02 05:39:37,997	44k	INFO	====> Epoch: 1639, cost 26.39 s
2024-01-02 05:40:04,429	44k	INFO	Train Epoch: 1640 [97%]
2024-01-02 05:40:04,430	44k	INFO	Losses: [2.395888328552246, 2.3788695335388184, 7.988965034484863, 19.263751983642578, 0.6508563160896301], step: 57400, lr: 8.147387202796423e-05, reference_loss: 32.67832946777344
2024-01-02 05:40:05,075	44k	INFO	====> Epoch: 1640, cost 27.08 s
2024-01-02 05:40:31,343	44k	INFO	====> Epoch: 1641, cost 26.27 s
2024-01-02 05:40:57,780	44k	INFO	====> Epoch: 1642, cost 26.44 s
2024-01-02 05:41:24,481	44k	INFO	====> Epoch: 1643, cost 26.70 s
2024-01-02 05:41:50,844	44k	INFO	====> Epoch: 1644, cost 26.36 s
2024-01-02 05:42:17,183	44k	INFO	====> Epoch: 1645, cost 26.34 s
2024-01-02 05:42:35,988	44k	INFO	Train Epoch: 1646 [69%]
2024-01-02 05:42:35,989	44k	INFO	Losses: [2.3923373222351074, 2.347811222076416, 7.189377307891846, 15.166626930236816, 0.5959601998329163], step: 57600, lr: 8.141278571619972e-05, reference_loss: 27.692113876342773
2024-01-02 05:42:43,734	44k	INFO	Saving model and optimizer state at iteration 1646 to ./logs/44k/G_57600.pth
2024-01-02 05:42:44,635	44k	INFO	Saving model and optimizer state at iteration 1646 to ./logs/44k/D_57600.pth
2024-01-02 05:42:45,402	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_55200.pth
2024-01-02 05:42:45,458	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_55200.pth
2024-01-02 05:42:53,051	44k	INFO	====> Epoch: 1646, cost 35.87 s
2024-01-02 05:43:19,269	44k	INFO	====> Epoch: 1647, cost 26.22 s
2024-01-02 05:43:45,908	44k	INFO	====> Epoch: 1648, cost 26.64 s
2024-01-02 05:44:12,300	44k	INFO	====> Epoch: 1649, cost 26.39 s
2024-01-02 05:44:38,546	44k	INFO	====> Epoch: 1650, cost 26.25 s
2024-01-02 05:45:05,078	44k	INFO	====> Epoch: 1651, cost 26.53 s
2024-01-02 05:45:16,285	44k	INFO	Train Epoch: 1652 [40%]
2024-01-02 05:45:16,286	44k	INFO	Losses: [2.0415279865264893, 2.8999829292297363, 9.363151550292969, 18.529619216918945, 0.45098981261253357], step: 57800, lr: 8.135174520485431e-05, reference_loss: 33.28527069091797
2024-01-02 05:45:31,898	44k	INFO	====> Epoch: 1652, cost 26.82 s
2024-01-02 05:45:58,456	44k	INFO	====> Epoch: 1653, cost 26.56 s
2024-01-02 05:46:24,743	44k	INFO	====> Epoch: 1654, cost 26.29 s
2024-01-02 05:46:50,922	44k	INFO	====> Epoch: 1655, cost 26.18 s
2024-01-02 05:47:17,221	44k	INFO	====> Epoch: 1656, cost 26.30 s
2024-01-02 05:47:43,877	44k	INFO	====> Epoch: 1657, cost 26.66 s
2024-01-02 05:47:47,646	44k	INFO	Train Epoch: 1658 [11%]
2024-01-02 05:47:47,647	44k	INFO	Losses: [2.3229472637176514, 2.3382880687713623, 7.512724876403809, 18.23263168334961, 0.473906546831131], step: 58000, lr: 8.129075045958844e-05, reference_loss: 30.8804988861084
2024-01-02 05:48:10,788	44k	INFO	====> Epoch: 1658, cost 26.91 s
2024-01-02 05:48:37,220	44k	INFO	====> Epoch: 1659, cost 26.43 s
2024-01-02 05:49:03,625	44k	INFO	====> Epoch: 1660, cost 26.41 s
2024-01-02 05:49:29,982	44k	INFO	====> Epoch: 1661, cost 26.36 s
2024-01-02 05:49:56,255	44k	INFO	====> Epoch: 1662, cost 26.27 s
2024-01-02 05:50:18,665	44k	INFO	Train Epoch: 1663 [83%]
2024-01-02 05:50:18,666	44k	INFO	Losses: [2.1616051197052, 2.751833200454712, 8.586668014526367, 18.153724670410156, 0.6050186157226562], step: 58200, lr: 8.123995644064333e-05, reference_loss: 32.25885009765625
2024-01-02 05:50:23,351	44k	INFO	====> Epoch: 1663, cost 27.10 s
2024-01-02 05:50:49,518	44k	INFO	====> Epoch: 1664, cost 26.17 s
2024-01-02 05:51:15,820	44k	INFO	====> Epoch: 1665, cost 26.30 s
2024-01-02 05:51:42,136	44k	INFO	====> Epoch: 1666, cost 26.32 s
2024-01-02 05:52:08,371	44k	INFO	====> Epoch: 1667, cost 26.23 s
2024-01-02 05:52:34,649	44k	INFO	====> Epoch: 1668, cost 26.28 s
2024-01-02 05:52:49,614	44k	INFO	Train Epoch: 1669 [54%]
2024-01-02 05:52:49,615	44k	INFO	Losses: [2.350152015686035, 2.244527816772461, 8.974254608154297, 17.35508918762207, 0.7271928191184998], step: 58400, lr: 8.117904551075448e-05, reference_loss: 31.651214599609375
2024-01-02 05:52:56,966	44k	INFO	Saving model and optimizer state at iteration 1669 to ./logs/44k/G_58400.pth
2024-01-02 05:52:58,219	44k	INFO	Saving model and optimizer state at iteration 1669 to ./logs/44k/D_58400.pth
2024-01-02 05:52:59,010	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_56000.pth
2024-01-02 05:52:59,066	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_56000.pth
2024-01-02 05:53:10,437	44k	INFO	====> Epoch: 1669, cost 35.79 s
2024-01-02 05:53:36,796	44k	INFO	====> Epoch: 1670, cost 26.36 s
2024-01-02 05:54:03,109	44k	INFO	====> Epoch: 1671, cost 26.31 s
2024-01-02 05:54:29,345	44k	INFO	====> Epoch: 1672, cost 26.24 s
2024-01-02 05:54:55,562	44k	INFO	====> Epoch: 1673, cost 26.22 s
2024-01-02 05:55:21,852	44k	INFO	====> Epoch: 1674, cost 26.29 s
2024-01-02 05:55:29,344	44k	INFO	Train Epoch: 1675 [26%]
2024-01-02 05:55:29,345	44k	INFO	Losses: [2.4184751510620117, 2.303527593612671, 6.616701126098633, 16.28652000427246, 0.7377756237983704], step: 58600, lr: 8.111818024978944e-05, reference_loss: 28.363000869750977
2024-01-02 05:55:48,762	44k	INFO	====> Epoch: 1675, cost 26.91 s
2024-01-02 05:56:15,435	44k	INFO	====> Epoch: 1676, cost 26.67 s
2024-01-02 05:56:41,805	44k	INFO	====> Epoch: 1677, cost 26.37 s
2024-01-02 05:57:08,031	44k	INFO	====> Epoch: 1678, cost 26.23 s
2024-01-02 05:57:34,231	44k	INFO	====> Epoch: 1679, cost 26.20 s
2024-01-02 05:58:00,495	44k	INFO	Train Epoch: 1680 [97%]
2024-01-02 05:58:00,496	44k	INFO	Losses: [2.30914306640625, 2.7089943885803223, 7.485376358032227, 16.636043548583984, 0.4493086338043213], step: 58800, lr: 8.106749406026473e-05, reference_loss: 29.588865280151367
2024-01-02 05:58:00,983	44k	INFO	====> Epoch: 1680, cost 26.75 s
2024-01-02 05:58:27,159	44k	INFO	====> Epoch: 1681, cost 26.18 s
2024-01-02 05:58:53,370	44k	INFO	====> Epoch: 1682, cost 26.21 s
2024-01-02 05:59:19,896	44k	INFO	====> Epoch: 1683, cost 26.53 s
2024-01-02 05:59:46,217	44k	INFO	====> Epoch: 1684, cost 26.32 s
2024-01-02 06:00:12,551	44k	INFO	====> Epoch: 1685, cost 26.33 s
2024-01-02 06:00:31,291	44k	INFO	Train Epoch: 1686 [69%]
2024-01-02 06:00:31,292	44k	INFO	Losses: [2.554952383041382, 2.308227062225342, 7.1999735832214355, 17.434528350830078, 0.5667007565498352], step: 59000, lr: 8.100671243674704e-05, reference_loss: 30.064380645751953
2024-01-02 06:00:39,335	44k	INFO	====> Epoch: 1686, cost 26.78 s
2024-01-02 06:01:05,695	44k	INFO	====> Epoch: 1687, cost 26.36 s
2024-01-02 06:01:31,909	44k	INFO	====> Epoch: 1688, cost 26.21 s
2024-01-02 06:01:58,286	44k	INFO	====> Epoch: 1689, cost 26.38 s
2024-01-02 06:02:24,977	44k	INFO	====> Epoch: 1690, cost 26.69 s
2024-01-02 06:02:51,277	44k	INFO	====> Epoch: 1691, cost 26.30 s
2024-01-02 06:03:02,417	44k	INFO	Train Epoch: 1692 [40%]
2024-01-02 06:03:02,418	44k	INFO	Losses: [2.2433207035064697, 2.5128817558288574, 8.601921081542969, 19.222124099731445, 0.6006432175636292], step: 59200, lr: 8.094597638520365e-05, reference_loss: 33.18088912963867
2024-01-02 06:03:09,702	44k	INFO	Saving model and optimizer state at iteration 1692 to ./logs/44k/G_59200.pth
2024-01-02 06:03:10,587	44k	INFO	Saving model and optimizer state at iteration 1692 to ./logs/44k/D_59200.pth
2024-01-02 06:03:11,362	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_56800.pth
2024-01-02 06:03:11,418	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_56800.pth
2024-01-02 06:03:26,562	44k	INFO	====> Epoch: 1692, cost 35.28 s
2024-01-02 06:03:52,783	44k	INFO	====> Epoch: 1693, cost 26.22 s
2024-01-02 06:04:19,009	44k	INFO	====> Epoch: 1694, cost 26.23 s
2024-01-02 06:04:45,332	44k	INFO	====> Epoch: 1695, cost 26.32 s
2024-01-02 06:05:11,985	44k	INFO	====> Epoch: 1696, cost 26.65 s
2024-01-02 06:05:38,339	44k	INFO	====> Epoch: 1697, cost 26.35 s
2024-01-02 06:05:42,095	44k	INFO	Train Epoch: 1698 [11%]
2024-01-02 06:05:42,095	44k	INFO	Losses: [1.9412851333618164, 3.200648069381714, 8.136456489562988, 16.073989868164062, 0.5618836283683777], step: 59400, lr: 8.088528587146629e-05, reference_loss: 29.914262771606445
2024-01-02 06:06:05,179	44k	INFO	====> Epoch: 1698, cost 26.84 s
2024-01-02 06:06:31,434	44k	INFO	====> Epoch: 1699, cost 26.26 s
2024-01-02 06:06:57,689	44k	INFO	====> Epoch: 1700, cost 26.25 s
2024-01-02 06:07:23,962	44k	INFO	====> Epoch: 1701, cost 26.27 s
2024-01-02 06:07:50,173	44k	INFO	====> Epoch: 1702, cost 26.21 s
2024-01-02 06:08:12,623	44k	INFO	Train Epoch: 1703 [83%]
2024-01-02 06:08:12,623	44k	INFO	Losses: [2.0861124992370605, 2.891674757003784, 8.627915382385254, 18.88357925415039, 0.5936815142631531], step: 59600, lr: 8.083474520454283e-05, reference_loss: 33.08296203613281
2024-01-02 06:08:17,124	44k	INFO	====> Epoch: 1703, cost 26.95 s
2024-01-02 06:08:43,432	44k	INFO	====> Epoch: 1704, cost 26.31 s
2024-01-02 06:09:09,634	44k	INFO	====> Epoch: 1705, cost 26.20 s
2024-01-02 06:09:35,840	44k	INFO	====> Epoch: 1706, cost 26.21 s
2024-01-02 06:10:02,022	44k	INFO	====> Epoch: 1707, cost 26.18 s
2024-01-02 06:10:28,308	44k	INFO	====> Epoch: 1708, cost 26.29 s
2024-01-02 06:10:43,293	44k	INFO	Train Epoch: 1709 [54%]
2024-01-02 06:10:43,293	44k	INFO	Losses: [2.414182424545288, 2.27512526512146, 8.192687034606934, 18.147201538085938, 0.5314083099365234], step: 59800, lr: 8.077413808812551e-05, reference_loss: 31.560604095458984
2024-01-02 06:10:55,252	44k	INFO	====> Epoch: 1709, cost 26.94 s
2024-01-02 06:11:21,762	44k	INFO	====> Epoch: 1710, cost 26.51 s
2024-01-02 06:11:48,013	44k	INFO	====> Epoch: 1711, cost 26.25 s
2024-01-02 06:12:14,337	44k	INFO	====> Epoch: 1712, cost 26.32 s
2024-01-02 06:12:40,562	44k	INFO	====> Epoch: 1713, cost 26.22 s
2024-01-02 06:13:06,794	44k	INFO	====> Epoch: 1714, cost 26.23 s
2024-01-02 06:13:14,241	44k	INFO	Train Epoch: 1715 [26%]
2024-01-02 06:13:14,242	44k	INFO	Losses: [2.3248250484466553, 2.60568904876709, 7.933876037597656, 17.889158248901367, 0.5060279369354248], step: 60000, lr: 8.071357641284309e-05, reference_loss: 31.25957489013672
2024-01-02 06:13:21,615	44k	INFO	Saving model and optimizer state at iteration 1715 to ./logs/44k/G_60000.pth
2024-01-02 06:13:22,496	44k	INFO	Saving model and optimizer state at iteration 1715 to ./logs/44k/D_60000.pth
2024-01-02 06:13:23,262	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_57600.pth
2024-01-02 06:13:23,320	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_57600.pth
2024-01-02 06:13:42,461	44k	INFO	====> Epoch: 1715, cost 35.67 s
2024-01-02 06:14:08,794	44k	INFO	====> Epoch: 1716, cost 26.33 s
2024-01-02 06:14:35,110	44k	INFO	====> Epoch: 1717, cost 26.32 s
2024-01-02 06:15:01,409	44k	INFO	====> Epoch: 1718, cost 26.30 s
2024-01-02 06:15:27,701	44k	INFO	====> Epoch: 1719, cost 26.29 s
2024-01-02 06:15:53,946	44k	INFO	Train Epoch: 1720 [97%]
2024-01-02 06:15:53,947	44k	INFO	Losses: [2.57161808013916, 2.376368999481201, 8.222090721130371, 17.702180862426758, 0.518161952495575], step: 60200, lr: 8.066314303750501e-05, reference_loss: 31.39042091369629
2024-01-02 06:15:54,429	44k	INFO	====> Epoch: 1720, cost 26.73 s
2024-01-02 06:16:20,694	44k	INFO	====> Epoch: 1721, cost 26.27 s
2024-01-02 06:16:46,834	44k	INFO	====> Epoch: 1722, cost 26.14 s
2024-01-02 06:17:13,098	44k	INFO	====> Epoch: 1723, cost 26.26 s
2024-01-02 06:17:39,628	44k	INFO	====> Epoch: 1724, cost 26.53 s
2024-01-02 06:18:05,811	44k	INFO	====> Epoch: 1725, cost 26.18 s
2024-01-02 06:18:24,536	44k	INFO	Train Epoch: 1726 [69%]
2024-01-02 06:18:24,536	44k	INFO	Losses: [2.7320199012756348, 2.200862407684326, 6.7730183601379395, 14.765327453613281, 0.7344905138015747], step: 60400, lr: 8.060266458250043e-05, reference_loss: 27.205718994140625
2024-01-02 06:18:32,594	44k	INFO	====> Epoch: 1726, cost 26.78 s
2024-01-02 06:18:58,831	44k	INFO	====> Epoch: 1727, cost 26.24 s
2024-01-02 06:19:25,206	44k	INFO	====> Epoch: 1728, cost 26.37 s
2024-01-02 06:19:51,422	44k	INFO	====> Epoch: 1729, cost 26.22 s
2024-01-02 06:20:17,645	44k	INFO	====> Epoch: 1730, cost 26.22 s
2024-01-02 06:20:44,188	44k	INFO	====> Epoch: 1731, cost 26.54 s
2024-01-02 06:20:55,342	44k	INFO	Train Epoch: 1732 [40%]
2024-01-02 06:20:55,343	44k	INFO	Losses: [2.459876298904419, 2.2269794940948486, 7.092833518981934, 16.58108139038086, 0.741381049156189], step: 60600, lr: 8.05422314721648e-05, reference_loss: 29.10215187072754
2024-01-02 06:21:10,956	44k	INFO	====> Epoch: 1732, cost 26.77 s
2024-01-02 06:21:37,276	44k	INFO	====> Epoch: 1733, cost 26.32 s
2024-01-02 06:22:03,623	44k	INFO	====> Epoch: 1734, cost 26.35 s
2024-01-02 06:22:29,960	44k	INFO	====> Epoch: 1735, cost 26.34 s
2024-01-02 06:22:56,170	44k	INFO	====> Epoch: 1736, cost 26.21 s
2024-01-02 06:23:22,417	44k	INFO	====> Epoch: 1737, cost 26.25 s
2024-01-02 06:23:26,152	44k	INFO	Train Epoch: 1738 [11%]
2024-01-02 06:23:26,152	44k	INFO	Losses: [2.543945789337158, 1.9948674440383911, 7.0748820304870605, 16.415592193603516, 0.76417475938797], step: 60800, lr: 8.048184367250029e-05, reference_loss: 28.7934627532959
2024-01-02 06:23:33,756	44k	INFO	Saving model and optimizer state at iteration 1738 to ./logs/44k/G_60800.pth
2024-01-02 06:23:34,641	44k	INFO	Saving model and optimizer state at iteration 1738 to ./logs/44k/D_60800.pth
2024-01-02 06:23:35,417	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_58400.pth
2024-01-02 06:23:35,474	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_58400.pth
2024-01-02 06:23:57,722	44k	INFO	====> Epoch: 1738, cost 35.30 s
2024-01-02 06:24:23,935	44k	INFO	====> Epoch: 1739, cost 26.21 s
2024-01-02 06:24:50,123	44k	INFO	====> Epoch: 1740, cost 26.19 s
2024-01-02 06:25:16,354	44k	INFO	====> Epoch: 1741, cost 26.23 s
2024-01-02 06:25:42,564	44k	INFO	====> Epoch: 1742, cost 26.21 s
2024-01-02 06:26:05,169	44k	INFO	Train Epoch: 1743 [83%]
2024-01-02 06:26:05,169	44k	INFO	Losses: [2.215007781982422, 2.906926393508911, 8.167529106140137, 15.828115463256836, 0.5117800235748291], step: 61000, lr: 8.043155509392122e-05, reference_loss: 29.629358291625977
2024-01-02 06:26:09,719	44k	INFO	====> Epoch: 1743, cost 27.15 s
2024-01-02 06:26:35,853	44k	INFO	====> Epoch: 1744, cost 26.13 s
2024-01-02 06:27:02,104	44k	INFO	====> Epoch: 1745, cost 26.25 s
2024-01-02 06:27:28,439	44k	INFO	====> Epoch: 1746, cost 26.34 s
2024-01-02 06:27:54,811	44k	INFO	====> Epoch: 1747, cost 26.37 s
2024-01-02 06:28:21,148	44k	INFO	====> Epoch: 1748, cost 26.34 s
2024-01-02 06:28:36,054	44k	INFO	Train Epoch: 1749 [54%]
2024-01-02 06:28:36,054	44k	INFO	Losses: [2.00584077835083, 2.809788703918457, 8.15687370300293, 16.973363876342773, 0.6381685137748718], step: 61200, lr: 8.037125027560492e-05, reference_loss: 30.584035873413086
2024-01-02 06:28:47,891	44k	INFO	====> Epoch: 1749, cost 26.74 s
2024-01-02 06:29:14,540	44k	INFO	====> Epoch: 1750, cost 26.65 s
2024-01-02 06:29:40,859	44k	INFO	====> Epoch: 1751, cost 26.32 s
2024-01-02 06:30:07,237	44k	INFO	====> Epoch: 1752, cost 26.38 s
2024-01-02 06:30:33,694	44k	INFO	====> Epoch: 1753, cost 26.46 s
2024-01-02 06:30:59,948	44k	INFO	====> Epoch: 1754, cost 26.25 s
2024-01-02 06:31:07,432	44k	INFO	Train Epoch: 1755 [26%]
2024-01-02 06:31:07,433	44k	INFO	Losses: [2.3258919715881348, 2.7590646743774414, 8.287129402160645, 17.015703201293945, 0.5457162261009216], step: 61400, lr: 8.031099067177077e-05, reference_loss: 30.933504104614258
2024-01-02 06:31:26,663	44k	INFO	====> Epoch: 1755, cost 26.72 s
2024-01-02 06:31:52,910	44k	INFO	====> Epoch: 1756, cost 26.25 s
2024-01-02 06:32:19,449	44k	INFO	====> Epoch: 1757, cost 26.54 s
2024-01-02 06:32:45,610	44k	INFO	====> Epoch: 1758, cost 26.16 s
2024-01-02 06:33:11,837	44k	INFO	====> Epoch: 1759, cost 26.23 s
2024-01-02 06:33:38,065	44k	INFO	Train Epoch: 1760 [97%]
2024-01-02 06:33:38,065	44k	INFO	Losses: [2.461376667022705, 2.3439176082611084, 6.395811557769775, 16.504159927368164, 0.5166898965835571], step: 61600, lr: 8.026080884962472e-05, reference_loss: 28.221954345703125
2024-01-02 06:33:45,418	44k	INFO	Saving model and optimizer state at iteration 1760 to ./logs/44k/G_61600.pth
2024-01-02 06:33:46,331	44k	INFO	Saving model and optimizer state at iteration 1760 to ./logs/44k/D_61600.pth
2024-01-02 06:33:47,121	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_59200.pth
2024-01-02 06:33:47,178	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_59200.pth
2024-01-02 06:33:47,178	44k	INFO	====> Epoch: 1760, cost 35.34 s
2024-01-02 06:34:13,369	44k	INFO	====> Epoch: 1761, cost 26.19 s
2024-01-02 06:34:39,742	44k	INFO	====> Epoch: 1762, cost 26.37 s
2024-01-02 06:35:06,339	44k	INFO	====> Epoch: 1763, cost 26.60 s
2024-01-02 06:35:32,690	44k	INFO	====> Epoch: 1764, cost 26.35 s
2024-01-02 06:35:58,912	44k	INFO	====> Epoch: 1765, cost 26.22 s
2024-01-02 06:36:17,623	44k	INFO	Train Epoch: 1766 [69%]
2024-01-02 06:36:17,623	44k	INFO	Losses: [2.247729778289795, 2.4304122924804688, 8.606956481933594, 17.321645736694336, 0.6462894678115845], step: 61800, lr: 8.020063205097967e-05, reference_loss: 31.253034591674805
2024-01-02 06:36:25,819	44k	INFO	====> Epoch: 1766, cost 26.91 s
2024-01-02 06:36:52,170	44k	INFO	====> Epoch: 1767, cost 26.35 s
2024-01-02 06:37:18,534	44k	INFO	====> Epoch: 1768, cost 26.36 s
2024-01-02 06:37:44,708	44k	INFO	====> Epoch: 1769, cost 26.17 s
2024-01-02 06:38:10,891	44k	INFO	====> Epoch: 1770, cost 26.18 s
2024-01-02 06:38:37,438	44k	INFO	====> Epoch: 1771, cost 26.55 s
2024-01-02 06:38:48,613	44k	INFO	Train Epoch: 1772 [40%]
2024-01-02 06:38:48,614	44k	INFO	Losses: [2.375530242919922, 2.4503679275512695, 7.868833541870117, 17.860301971435547, 0.4798247814178467], step: 62000, lr: 8.014050037083201e-05, reference_loss: 31.03485870361328
2024-01-02 06:39:04,076	44k	INFO	====> Epoch: 1772, cost 26.64 s
2024-01-02 06:39:30,427	44k	INFO	====> Epoch: 1773, cost 26.35 s
2024-01-02 06:39:56,774	44k	INFO	====> Epoch: 1774, cost 26.35 s
2024-01-02 06:40:23,077	44k	INFO	====> Epoch: 1775, cost 26.30 s
2024-01-02 06:40:49,409	44k	INFO	====> Epoch: 1776, cost 26.33 s
2024-01-02 06:41:15,742	44k	INFO	====> Epoch: 1777, cost 26.33 s
2024-01-02 06:41:19,479	44k	INFO	Train Epoch: 1778 [11%]
2024-01-02 06:41:19,479	44k	INFO	Losses: [2.2265372276306152, 2.651672601699829, 7.802733898162842, 17.233612060546875, 0.475429505109787], step: 62200, lr: 8.008041377535345e-05, reference_loss: 30.389986038208008
2024-01-02 06:41:42,975	44k	INFO	====> Epoch: 1778, cost 27.23 s
2024-01-02 06:42:09,316	44k	INFO	====> Epoch: 1779, cost 26.34 s
2024-01-02 06:42:35,551	44k	INFO	====> Epoch: 1780, cost 26.24 s
2024-01-02 06:43:01,738	44k	INFO	====> Epoch: 1781, cost 26.19 s
2024-01-02 06:43:27,897	44k	INFO	====> Epoch: 1782, cost 26.16 s
2024-01-02 06:43:50,439	44k	INFO	Train Epoch: 1783 [83%]
2024-01-02 06:43:50,440	44k	INFO	Losses: [2.533353328704834, 2.1292803287506104, 7.333818435668945, 14.684364318847656, 0.5824963450431824], step: 62400, lr: 8.003037602774452e-05, reference_loss: 27.26331329345703
2024-01-02 06:43:57,700	44k	INFO	Saving model and optimizer state at iteration 1783 to ./logs/44k/G_62400.pth
2024-01-02 06:43:58,932	44k	INFO	Saving model and optimizer state at iteration 1783 to ./logs/44k/D_62400.pth
2024-01-02 06:43:59,693	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_60000.pth
2024-01-02 06:43:59,750	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_60000.pth
2024-01-02 06:44:03,519	44k	INFO	====> Epoch: 1783, cost 35.62 s
2024-01-02 06:44:29,872	44k	INFO	====> Epoch: 1784, cost 26.35 s
2024-01-02 06:44:56,110	44k	INFO	====> Epoch: 1785, cost 26.24 s
2024-01-02 06:45:22,502	44k	INFO	====> Epoch: 1786, cost 26.39 s
2024-01-02 06:45:48,809	44k	INFO	====> Epoch: 1787, cost 26.31 s
2024-01-02 06:46:15,053	44k	INFO	====> Epoch: 1788, cost 26.24 s
2024-01-02 06:46:29,941	44k	INFO	Train Epoch: 1789 [54%]
2024-01-02 06:46:29,942	44k	INFO	Losses: [1.7818200588226318, 3.1828441619873047, 8.800994873046875, 16.380151748657227, 0.4100591540336609], step: 62600, lr: 7.997037199971719e-05, reference_loss: 30.555870056152344
2024-01-02 06:46:41,730	44k	INFO	====> Epoch: 1789, cost 26.68 s
2024-01-02 06:47:08,145	44k	INFO	====> Epoch: 1790, cost 26.42 s
2024-01-02 06:47:34,362	44k	INFO	====> Epoch: 1791, cost 26.22 s
2024-01-02 06:48:00,695	44k	INFO	====> Epoch: 1792, cost 26.33 s
2024-01-02 06:48:27,027	44k	INFO	====> Epoch: 1793, cost 26.33 s
2024-01-02 06:48:53,240	44k	INFO	====> Epoch: 1794, cost 26.21 s
2024-01-02 06:49:00,719	44k	INFO	Train Epoch: 1795 [26%]
2024-01-02 06:49:00,720	44k	INFO	Losses: [1.9266808032989502, 3.1485085487365723, 9.812642097473145, 18.964733123779297, 0.8473096489906311], step: 62800, lr: 7.991041296064977e-05, reference_loss: 34.69987487792969
2024-01-02 06:49:20,100	44k	INFO	====> Epoch: 1795, cost 26.86 s
2024-01-02 06:49:46,353	44k	INFO	====> Epoch: 1796, cost 26.25 s
2024-01-02 06:50:12,853	44k	INFO	====> Epoch: 1797, cost 26.50 s
2024-01-02 06:50:39,179	44k	INFO	====> Epoch: 1798, cost 26.33 s
2024-01-02 06:51:05,491	44k	INFO	====> Epoch: 1799, cost 26.31 s
2024-01-02 06:51:31,752	44k	INFO	Train Epoch: 1800 [97%]
2024-01-02 06:51:31,753	44k	INFO	Losses: [2.1820783615112305, 2.656707286834717, 8.862383842468262, 18.87948989868164, 0.6049413681030273], step: 63000, lr: 7.986048143699072e-05, reference_loss: 33.18560028076172
2024-01-02 06:51:32,235	44k	INFO	====> Epoch: 1800, cost 26.74 s
2024-01-02 06:51:58,496	44k	INFO	====> Epoch: 1801, cost 26.26 s
2024-01-02 06:52:24,746	44k	INFO	====> Epoch: 1802, cost 26.25 s
2024-01-02 06:52:51,157	44k	INFO	====> Epoch: 1803, cost 26.41 s
2024-01-02 06:53:17,648	44k	INFO	====> Epoch: 1804, cost 26.49 s
2024-01-02 06:53:43,978	44k	INFO	====> Epoch: 1805, cost 26.33 s
2024-01-02 06:54:02,760	44k	INFO	Train Epoch: 1806 [69%]
2024-01-02 06:54:02,761	44k	INFO	Losses: [1.7903225421905518, 3.087167739868164, 9.199624061584473, 15.596961975097656, 0.606126606464386], step: 63200, lr: 7.980060479009402e-05, reference_loss: 30.280202865600586
2024-01-02 06:54:10,022	44k	INFO	Saving model and optimizer state at iteration 1806 to ./logs/44k/G_63200.pth
2024-01-02 06:54:10,903	44k	INFO	Saving model and optimizer state at iteration 1806 to ./logs/44k/D_63200.pth
2024-01-02 06:54:11,672	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_60800.pth
2024-01-02 06:54:11,730	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_60800.pth
2024-01-02 06:54:19,302	44k	INFO	====> Epoch: 1806, cost 35.32 s
2024-01-02 06:54:45,551	44k	INFO	====> Epoch: 1807, cost 26.25 s
2024-01-02 06:55:11,894	44k	INFO	====> Epoch: 1808, cost 26.34 s
2024-01-02 06:55:38,238	44k	INFO	====> Epoch: 1809, cost 26.34 s
2024-01-02 06:56:04,918	44k	INFO	====> Epoch: 1810, cost 26.68 s
2024-01-02 06:56:31,224	44k	INFO	====> Epoch: 1811, cost 26.31 s
2024-01-02 06:56:42,406	44k	INFO	Train Epoch: 1812 [40%]
2024-01-02 06:56:42,406	44k	INFO	Losses: [2.337533473968506, 2.3023927211761475, 8.449151039123535, 17.971607208251953, 0.44171714782714844], step: 63400, lr: 7.974077303665127e-05, reference_loss: 31.50240135192871
2024-01-02 06:56:57,995	44k	INFO	====> Epoch: 1812, cost 26.77 s
2024-01-02 06:57:24,355	44k	INFO	====> Epoch: 1813, cost 26.36 s
2024-01-02 06:57:50,560	44k	INFO	====> Epoch: 1814, cost 26.20 s
2024-01-02 06:58:16,761	44k	INFO	====> Epoch: 1815, cost 26.20 s
2024-01-02 06:58:43,104	44k	INFO	====> Epoch: 1816, cost 26.34 s
2024-01-02 06:59:09,452	44k	INFO	====> Epoch: 1817, cost 26.35 s
2024-01-02 06:59:13,190	44k	INFO	Train Epoch: 1818 [11%]
2024-01-02 06:59:13,191	44k	INFO	Losses: [1.9957194328308105, 3.231076717376709, 9.068098068237305, 18.190776824951172, 0.47369515895843506], step: 63600, lr: 7.968098614300285e-05, reference_loss: 32.95936584472656
2024-01-02 06:59:36,400	44k	INFO	====> Epoch: 1818, cost 26.95 s
2024-01-02 07:00:02,597	44k	INFO	====> Epoch: 1819, cost 26.20 s
2024-01-02 07:00:28,921	44k	INFO	====> Epoch: 1820, cost 26.32 s
2024-01-02 07:00:55,299	44k	INFO	====> Epoch: 1821, cost 26.38 s
2024-01-02 07:01:21,555	44k	INFO	====> Epoch: 1822, cost 26.26 s
2024-01-02 07:01:44,013	44k	INFO	Train Epoch: 1823 [83%]
2024-01-02 07:01:44,013	44k	INFO	Losses: [2.455404758453369, 2.401848554611206, 7.624815940856934, 16.259057998657227, 0.6377938389778137], step: 63800, lr: 7.963119797526136e-05, reference_loss: 29.378921508789062
2024-01-02 07:01:48,224	44k	INFO	====> Epoch: 1823, cost 26.67 s
2024-01-02 07:02:14,916	44k	INFO	====> Epoch: 1824, cost 26.69 s
2024-01-02 07:02:41,106	44k	INFO	====> Epoch: 1825, cost 26.19 s
2024-01-02 07:03:07,254	44k	INFO	====> Epoch: 1826, cost 26.15 s
2024-01-02 07:03:33,398	44k	INFO	====> Epoch: 1827, cost 26.14 s
2024-01-02 07:03:59,500	44k	INFO	====> Epoch: 1828, cost 26.10 s
2024-01-02 07:04:14,481	44k	INFO	Train Epoch: 1829 [54%]
2024-01-02 07:04:14,482	44k	INFO	Losses: [2.128844976425171, 2.6047940254211426, 10.154948234558105, 17.228652954101562, 0.5869224667549133], step: 64000, lr: 7.95714932372316e-05, reference_loss: 32.70416259765625
2024-01-02 07:04:21,934	44k	INFO	Saving model and optimizer state at iteration 1829 to ./logs/44k/G_64000.pth
2024-01-02 07:04:22,858	44k	INFO	Saving model and optimizer state at iteration 1829 to ./logs/44k/D_64000.pth
2024-01-02 07:04:23,640	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_61600.pth
2024-01-02 07:04:23,697	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_61600.pth
2024-01-02 07:04:35,370	44k	INFO	====> Epoch: 1829, cost 35.87 s
2024-01-02 07:05:01,596	44k	INFO	====> Epoch: 1830, cost 26.23 s
2024-01-02 07:05:27,845	44k	INFO	====> Epoch: 1831, cost 26.25 s
2024-01-02 07:05:54,219	44k	INFO	====> Epoch: 1832, cost 26.37 s
2024-01-02 07:06:20,525	44k	INFO	====> Epoch: 1833, cost 26.31 s
2024-01-02 07:06:46,863	44k	INFO	====> Epoch: 1834, cost 26.34 s
2024-01-02 07:06:54,272	44k	INFO	Train Epoch: 1835 [26%]
2024-01-02 07:06:54,273	44k	INFO	Losses: [2.2575483322143555, 2.670351982116699, 8.264944076538086, 17.229604721069336, 0.6406522989273071], step: 64200, lr: 7.951183326376442e-05, reference_loss: 31.063100814819336
2024-01-02 07:07:13,537	44k	INFO	====> Epoch: 1835, cost 26.67 s
2024-01-02 07:07:39,965	44k	INFO	====> Epoch: 1836, cost 26.43 s
2024-01-02 07:08:06,293	44k	INFO	====> Epoch: 1837, cost 26.33 s
2024-01-02 07:08:32,905	44k	INFO	====> Epoch: 1838, cost 26.61 s
2024-01-02 07:08:59,207	44k	INFO	====> Epoch: 1839, cost 26.30 s
2024-01-02 07:09:25,534	44k	INFO	Train Epoch: 1840 [97%]
2024-01-02 07:09:25,535	44k	INFO	Losses: [2.440192937850952, 2.2456486225128174, 6.83465051651001, 16.426912307739258, 0.42081713676452637], step: 64400, lr: 7.946215079014563e-05, reference_loss: 28.368221282958984
2024-01-02 07:09:26,014	44k	INFO	====> Epoch: 1840, cost 26.81 s
2024-01-02 07:09:52,302	44k	INFO	====> Epoch: 1841, cost 26.29 s
2024-01-02 07:10:18,627	44k	INFO	====> Epoch: 1842, cost 26.32 s
2024-01-02 07:10:44,989	44k	INFO	====> Epoch: 1843, cost 26.36 s
2024-01-02 07:11:11,159	44k	INFO	====> Epoch: 1844, cost 26.17 s
2024-01-02 07:11:37,353	44k	INFO	====> Epoch: 1845, cost 26.19 s
2024-01-02 07:11:56,292	44k	INFO	Train Epoch: 1846 [69%]
2024-01-02 07:11:56,292	44k	INFO	Losses: [2.046894073486328, 2.8632946014404297, 8.203256607055664, 15.89745807647705, 0.5564479827880859], step: 64600, lr: 7.94025727978909e-05, reference_loss: 29.567350387573242
2024-01-02 07:12:04,475	44k	INFO	====> Epoch: 1846, cost 27.12 s
2024-01-02 07:12:30,745	44k	INFO	====> Epoch: 1847, cost 26.27 s
2024-01-02 07:12:57,116	44k	INFO	====> Epoch: 1848, cost 26.37 s
2024-01-02 07:13:23,489	44k	INFO	====> Epoch: 1849, cost 26.37 s
2024-01-02 07:13:49,851	44k	INFO	====> Epoch: 1850, cost 26.36 s
2024-01-02 07:14:16,199	44k	INFO	====> Epoch: 1851, cost 26.35 s
2024-01-02 07:14:27,420	44k	INFO	Train Epoch: 1852 [40%]
2024-01-02 07:14:27,421	44k	INFO	Losses: [2.1476364135742188, 2.7790322303771973, 9.05853271484375, 18.625930786132812, 0.5376872420310974], step: 64800, lr: 7.93430394751691e-05, reference_loss: 33.1488151550293
2024-01-02 07:14:34,967	44k	INFO	Saving model and optimizer state at iteration 1852 to ./logs/44k/G_64800.pth
2024-01-02 07:14:35,872	44k	INFO	Saving model and optimizer state at iteration 1852 to ./logs/44k/D_64800.pth
2024-01-02 07:14:36,642	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_62400.pth
2024-01-02 07:14:36,698	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_62400.pth
2024-01-02 07:14:51,709	44k	INFO	====> Epoch: 1852, cost 35.51 s
2024-01-02 07:15:17,860	44k	INFO	====> Epoch: 1853, cost 26.15 s
2024-01-02 07:15:44,097	44k	INFO	====> Epoch: 1854, cost 26.24 s
2024-01-02 07:16:10,387	44k	INFO	====> Epoch: 1855, cost 26.29 s
2024-01-02 07:16:36,719	44k	INFO	====> Epoch: 1856, cost 26.33 s
2024-01-02 07:17:03,001	44k	INFO	====> Epoch: 1857, cost 26.28 s
2024-01-02 07:17:06,711	44k	INFO	Train Epoch: 1858 [11%]
2024-01-02 07:17:06,712	44k	INFO	Losses: [2.1744582653045654, 2.9227654933929443, 8.16497802734375, 16.343994140625, 0.5548714399337769], step: 65000, lr: 7.928355078848854e-05, reference_loss: 30.16106605529785
2024-01-02 07:17:30,138	44k	INFO	====> Epoch: 1858, cost 27.14 s
2024-01-02 07:17:56,456	44k	INFO	====> Epoch: 1859, cost 26.32 s
2024-01-02 07:18:22,616	44k	INFO	====> Epoch: 1860, cost 26.16 s
2024-01-02 07:18:48,832	44k	INFO	====> Epoch: 1861, cost 26.22 s
2024-01-02 07:19:14,850	44k	INFO	====> Epoch: 1862, cost 26.02 s
2024-01-02 07:19:37,185	44k	INFO	Train Epoch: 1863 [83%]
2024-01-02 07:19:37,185	44k	INFO	Losses: [2.29071044921875, 2.6123299598693848, 7.75923490524292, 17.917306900024414, 0.593426525592804], step: 65200, lr: 7.923401095575211e-05, reference_loss: 31.17300796508789
2024-01-02 07:19:41,551	44k	INFO	====> Epoch: 1863, cost 26.70 s
2024-01-02 07:20:08,014	44k	INFO	====> Epoch: 1864, cost 26.46 s
2024-01-02 07:20:34,355	44k	INFO	====> Epoch: 1865, cost 26.34 s
2024-01-02 07:21:00,637	44k	INFO	====> Epoch: 1866, cost 26.28 s
2024-01-02 07:21:26,891	44k	INFO	====> Epoch: 1867, cost 26.25 s
2024-01-02 07:21:53,042	44k	INFO	====> Epoch: 1868, cost 26.15 s
2024-01-02 07:22:07,990	44k	INFO	Train Epoch: 1869 [54%]
2024-01-02 07:22:07,990	44k	INFO	Losses: [2.5467584133148193, 2.198368787765503, 8.265589714050293, 17.742841720581055, 0.5045353174209595], step: 65400, lr: 7.917460401491182e-05, reference_loss: 31.258094787597656
2024-01-02 07:22:19,803	44k	INFO	====> Epoch: 1869, cost 26.76 s
2024-01-02 07:22:46,132	44k	INFO	====> Epoch: 1870, cost 26.33 s
2024-01-02 07:23:12,754	44k	INFO	====> Epoch: 1871, cost 26.62 s
2024-01-02 07:23:39,021	44k	INFO	====> Epoch: 1872, cost 26.27 s
2024-01-02 07:24:05,307	44k	INFO	====> Epoch: 1873, cost 26.29 s
2024-01-02 07:24:31,575	44k	INFO	====> Epoch: 1874, cost 26.27 s
2024-01-02 07:24:39,027	44k	INFO	Train Epoch: 1875 [26%]
2024-01-02 07:24:39,028	44k	INFO	Losses: [2.558178424835205, 2.2591004371643066, 7.376940727233887, 18.279605865478516, 0.5434949398040771], step: 65600, lr: 7.911524161535595e-05, reference_loss: 31.01732063293457
2024-01-02 07:24:46,360	44k	INFO	Saving model and optimizer state at iteration 1875 to ./logs/44k/G_65600.pth
2024-01-02 07:24:47,253	44k	INFO	Saving model and optimizer state at iteration 1875 to ./logs/44k/D_65600.pth
2024-01-02 07:24:48,037	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_63200.pth
2024-01-02 07:24:48,094	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_63200.pth
2024-01-02 07:25:06,832	44k	INFO	====> Epoch: 1875, cost 35.26 s
2024-01-02 07:25:33,161	44k	INFO	====> Epoch: 1876, cost 26.33 s
2024-01-02 07:25:59,759	44k	INFO	====> Epoch: 1877, cost 26.60 s
2024-01-02 07:26:26,086	44k	INFO	====> Epoch: 1878, cost 26.33 s
2024-01-02 07:26:52,336	44k	INFO	====> Epoch: 1879, cost 26.25 s
2024-01-02 07:27:18,561	44k	INFO	Train Epoch: 1880 [97%]
2024-01-02 07:27:18,562	44k	INFO	Losses: [2.4300570487976074, 2.4359612464904785, 9.184114456176758, 19.535932540893555, 0.423828125], step: 65800, lr: 7.906580694955773e-05, reference_loss: 34.00989532470703
2024-01-02 07:27:19,188	44k	INFO	====> Epoch: 1880, cost 26.85 s
2024-01-02 07:27:45,368	44k	INFO	====> Epoch: 1881, cost 26.18 s
2024-01-02 07:28:11,619	44k	INFO	====> Epoch: 1882, cost 26.25 s
2024-01-02 07:28:37,980	44k	INFO	====> Epoch: 1883, cost 26.36 s
2024-01-02 07:29:04,285	44k	INFO	====> Epoch: 1884, cost 26.30 s
2024-01-02 07:29:30,840	44k	INFO	====> Epoch: 1885, cost 26.55 s
2024-01-02 07:29:49,496	44k	INFO	Train Epoch: 1886 [69%]
2024-01-02 07:29:49,497	44k	INFO	Losses: [2.2859597206115723, 2.4872050285339355, 8.532445907592773, 16.997108459472656, 0.7141350507736206], step: 66000, lr: 7.900652612230582e-05, reference_loss: 31.01685333251953
2024-01-02 07:29:57,703	44k	INFO	====> Epoch: 1886, cost 26.86 s
2024-01-02 07:30:23,998	44k	INFO	====> Epoch: 1887, cost 26.30 s
2024-01-02 07:30:50,338	44k	INFO	====> Epoch: 1888, cost 26.34 s
2024-01-02 07:31:16,583	44k	INFO	====> Epoch: 1889, cost 26.25 s
2024-01-02 07:31:42,757	44k	INFO	====> Epoch: 1890, cost 26.17 s
2024-01-02 07:32:09,098	44k	INFO	====> Epoch: 1891, cost 26.34 s
2024-01-02 07:32:20,327	44k	INFO	Train Epoch: 1892 [40%]
2024-01-02 07:32:20,328	44k	INFO	Losses: [2.523015260696411, 2.4776768684387207, 7.570281028747559, 16.472686767578125, 0.6849782466888428], step: 66200, lr: 7.894728974178272e-05, reference_loss: 29.7286376953125
2024-01-02 07:32:36,174	44k	INFO	====> Epoch: 1892, cost 27.08 s
2024-01-02 07:33:02,424	44k	INFO	====> Epoch: 1893, cost 26.25 s
2024-01-02 07:33:28,688	44k	INFO	====> Epoch: 1894, cost 26.26 s
2024-01-02 07:33:54,985	44k	INFO	====> Epoch: 1895, cost 26.30 s
2024-01-02 07:34:21,361	44k	INFO	====> Epoch: 1896, cost 26.38 s
2024-01-02 07:34:47,607	44k	INFO	====> Epoch: 1897, cost 26.25 s
2024-01-02 07:34:51,339	44k	INFO	Train Epoch: 1898 [11%]
2024-01-02 07:34:51,340	44k	INFO	Losses: [2.4093191623687744, 2.0089733600616455, 6.671293258666992, 16.039997100830078, 0.7827358841896057], step: 66400, lr: 7.888809777466381e-05, reference_loss: 27.91231918334961
2024-01-02 07:34:58,631	44k	INFO	Saving model and optimizer state at iteration 1898 to ./logs/44k/G_66400.pth
2024-01-02 07:34:59,836	44k	INFO	Saving model and optimizer state at iteration 1898 to ./logs/44k/D_66400.pth
2024-01-02 07:35:00,615	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_64000.pth
2024-01-02 07:35:00,672	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_64000.pth
2024-01-02 07:35:23,218	44k	INFO	====> Epoch: 1898, cost 35.61 s
2024-01-02 07:35:49,602	44k	INFO	====> Epoch: 1899, cost 26.38 s
2024-01-02 07:36:15,911	44k	INFO	====> Epoch: 1900, cost 26.31 s
2024-01-02 07:36:42,086	44k	INFO	====> Epoch: 1901, cost 26.18 s
2024-01-02 07:37:08,294	44k	INFO	====> Epoch: 1902, cost 26.21 s
2024-01-02 07:37:30,805	44k	INFO	Train Epoch: 1903 [83%]
2024-01-02 07:37:30,805	44k	INFO	Losses: [2.0563862323760986, 3.4794700145721436, 8.501751899719238, 15.707294464111328, 0.4689972400665283], step: 66600, lr: 7.883880503827922e-05, reference_loss: 30.21390151977539
2024-01-02 07:37:35,037	44k	INFO	====> Epoch: 1903, cost 26.74 s
2024-01-02 07:38:01,508	44k	INFO	====> Epoch: 1904, cost 26.47 s
2024-01-02 07:38:27,665	44k	INFO	====> Epoch: 1905, cost 26.16 s
2024-01-02 07:38:53,890	44k	INFO	====> Epoch: 1906, cost 26.23 s
2024-01-02 07:39:20,184	44k	INFO	====> Epoch: 1907, cost 26.29 s
2024-01-02 07:39:46,513	44k	INFO	====> Epoch: 1908, cost 26.33 s
2024-01-02 07:40:01,472	44k	INFO	Train Epoch: 1909 [54%]
2024-01-02 07:40:01,472	44k	INFO	Losses: [2.0836081504821777, 2.760941743850708, 8.135037422180176, 16.777759552001953, 0.6276483535766602], step: 66800, lr: 7.877969440926608e-05, reference_loss: 30.384994506835938
2024-01-02 07:40:13,258	44k	INFO	====> Epoch: 1909, cost 26.74 s
2024-01-02 07:40:39,400	44k	INFO	====> Epoch: 1910, cost 26.14 s
2024-01-02 07:41:05,907	44k	INFO	====> Epoch: 1911, cost 26.51 s
2024-01-02 07:41:32,248	44k	INFO	====> Epoch: 1912, cost 26.34 s
2024-01-02 07:41:58,631	44k	INFO	====> Epoch: 1913, cost 26.38 s
2024-01-02 07:42:24,947	44k	INFO	====> Epoch: 1914, cost 26.32 s
2024-01-02 07:42:32,434	44k	INFO	Train Epoch: 1915 [26%]
2024-01-02 07:42:32,434	44k	INFO	Losses: [2.4252638816833496, 2.5412492752075195, 7.239447116851807, 15.994597434997559, 0.6252196431159973], step: 67000, lr: 7.872062809937293e-05, reference_loss: 28.825777053833008
2024-01-02 07:42:51,860	44k	INFO	====> Epoch: 1915, cost 26.91 s
2024-01-02 07:43:18,142	44k	INFO	====> Epoch: 1916, cost 26.28 s
2024-01-02 07:43:44,337	44k	INFO	====> Epoch: 1917, cost 26.20 s
2024-01-02 07:44:10,777	44k	INFO	====> Epoch: 1918, cost 26.44 s
2024-01-02 07:44:37,172	44k	INFO	====> Epoch: 1919, cost 26.40 s
2024-01-02 07:45:03,600	44k	INFO	Train Epoch: 1920 [97%]
2024-01-02 07:45:03,600	44k	INFO	Losses: [2.6322951316833496, 2.3432810306549072, 6.359282493591309, 16.190380096435547, 0.5069097280502319], step: 67200, lr: 7.867144000537153e-05, reference_loss: 28.032148361206055
2024-01-02 07:45:10,967	44k	INFO	Saving model and optimizer state at iteration 1920 to ./logs/44k/G_67200.pth
2024-01-02 07:45:11,881	44k	INFO	Saving model and optimizer state at iteration 1920 to ./logs/44k/D_67200.pth
2024-01-02 07:45:12,664	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_64800.pth
2024-01-02 07:45:12,721	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_64800.pth
2024-01-02 07:45:12,721	44k	INFO	====> Epoch: 1920, cost 35.55 s
2024-01-02 07:45:39,014	44k	INFO	====> Epoch: 1921, cost 26.29 s
2024-01-02 07:46:05,388	44k	INFO	====> Epoch: 1922, cost 26.37 s
2024-01-02 07:46:31,637	44k	INFO	====> Epoch: 1923, cost 26.25 s
2024-01-02 07:46:58,150	44k	INFO	====> Epoch: 1924, cost 26.51 s
2024-01-02 07:47:24,329	44k	INFO	====> Epoch: 1925, cost 26.18 s
2024-01-02 07:47:43,041	44k	INFO	Train Epoch: 1926 [69%]
2024-01-02 07:47:43,041	44k	INFO	Losses: [2.2895359992980957, 2.2592005729675293, 7.448023319244385, 14.913543701171875, 0.6266216039657593], step: 67400, lr: 7.86124548609134e-05, reference_loss: 27.536924362182617
2024-01-02 07:47:51,071	44k	INFO	====> Epoch: 1926, cost 26.74 s
2024-01-02 07:48:17,246	44k	INFO	====> Epoch: 1927, cost 26.18 s
2024-01-02 07:48:43,610	44k	INFO	====> Epoch: 1928, cost 26.36 s
2024-01-02 07:49:09,832	44k	INFO	====> Epoch: 1929, cost 26.22 s
2024-01-02 07:49:36,040	44k	INFO	====> Epoch: 1930, cost 26.21 s
2024-01-02 07:50:02,195	44k	INFO	====> Epoch: 1931, cost 26.16 s
2024-01-02 07:50:13,404	44k	INFO	Train Epoch: 1932 [40%]
2024-01-02 07:50:13,404	44k	INFO	Losses: [2.2266886234283447, 2.4871275424957275, 8.675671577453613, 17.63977813720703, 0.5219396948814392], step: 67600, lr: 7.855351394149128e-05, reference_loss: 31.551206588745117
2024-01-02 07:50:29,407	44k	INFO	====> Epoch: 1932, cost 27.21 s
2024-01-02 07:50:55,683	44k	INFO	====> Epoch: 1933, cost 26.28 s
2024-01-02 07:51:21,895	44k	INFO	====> Epoch: 1934, cost 26.21 s
2024-01-02 07:51:48,116	44k	INFO	====> Epoch: 1935, cost 26.22 s
2024-01-02 07:52:14,381	44k	INFO	====> Epoch: 1936, cost 26.26 s
2024-01-02 07:52:40,748	44k	INFO	====> Epoch: 1937, cost 26.37 s
2024-01-02 07:52:44,501	44k	INFO	Train Epoch: 1938 [11%]
2024-01-02 07:52:44,501	44k	INFO	Losses: [2.035736560821533, 3.073807716369629, 8.829957008361816, 17.0290584564209, 0.41127556562423706], step: 67800, lr: 7.849461721394677e-05, reference_loss: 31.37983512878418
2024-01-02 07:53:08,022	44k	INFO	====> Epoch: 1938, cost 27.27 s
2024-01-02 07:53:34,224	44k	INFO	====> Epoch: 1939, cost 26.20 s
2024-01-02 07:54:00,436	44k	INFO	====> Epoch: 1940, cost 26.21 s
2024-01-02 07:54:26,668	44k	INFO	====> Epoch: 1941, cost 26.23 s
2024-01-02 07:54:52,862	44k	INFO	====> Epoch: 1942, cost 26.19 s
2024-01-02 07:55:15,381	44k	INFO	Train Epoch: 1943 [83%]
2024-01-02 07:55:15,381	44k	INFO	Losses: [2.2963759899139404, 2.2643802165985107, 8.182265281677246, 15.49494457244873, 0.6050631403923035], step: 68000, lr: 7.844557034143897e-05, reference_loss: 28.843027114868164
2024-01-02 07:55:22,970	44k	INFO	Saving model and optimizer state at iteration 1943 to ./logs/44k/G_68000.pth
2024-01-02 07:55:24,195	44k	INFO	Saving model and optimizer state at iteration 1943 to ./logs/44k/D_68000.pth
2024-01-02 07:55:24,967	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_65600.pth
2024-01-02 07:55:25,025	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_65600.pth
2024-01-02 07:55:28,799	44k	INFO	====> Epoch: 1943, cost 35.94 s
2024-01-02 07:55:55,143	44k	INFO	====> Epoch: 1944, cost 26.34 s
2024-01-02 07:56:21,447	44k	INFO	====> Epoch: 1945, cost 26.30 s
2024-01-02 07:56:47,699	44k	INFO	====> Epoch: 1946, cost 26.25 s
2024-01-02 07:57:14,012	44k	INFO	====> Epoch: 1947, cost 26.31 s
2024-01-02 07:57:40,264	44k	INFO	====> Epoch: 1948, cost 26.25 s
2024-01-02 07:57:55,133	44k	INFO	Train Epoch: 1949 [54%]
2024-01-02 07:57:55,134	44k	INFO	Losses: [2.444302558898926, 2.0830917358398438, 7.003211975097656, 15.692827224731445, 0.3165733814239502], step: 68200, lr: 7.83867545462994e-05, reference_loss: 27.540008544921875
2024-01-02 07:58:06,918	44k	INFO	====> Epoch: 1949, cost 26.65 s
2024-01-02 07:58:33,098	44k	INFO	====> Epoch: 1950, cost 26.18 s
2024-01-02 07:58:59,697	44k	INFO	====> Epoch: 1951, cost 26.60 s
2024-01-02 07:59:26,029	44k	INFO	====> Epoch: 1952, cost 26.33 s
2024-01-02 07:59:52,255	44k	INFO	====> Epoch: 1953, cost 26.23 s
2024-01-02 08:00:18,533	44k	INFO	====> Epoch: 1954, cost 26.28 s
2024-01-02 08:00:26,007	44k	INFO	Train Epoch: 1955 [26%]
2024-01-02 08:00:26,008	44k	INFO	Losses: [1.969545841217041, 3.191946029663086, 10.678779602050781, 19.1914005279541, 0.8151988387107849], step: 68400, lr: 7.832798284922357e-05, reference_loss: 35.846866607666016
2024-01-02 08:00:45,321	44k	INFO	====> Epoch: 1955, cost 26.79 s
2024-01-02 08:01:11,602	44k	INFO	====> Epoch: 1956, cost 26.28 s
2024-01-02 08:01:37,934	44k	INFO	====> Epoch: 1957, cost 26.33 s
2024-01-02 08:02:04,519	44k	INFO	====> Epoch: 1958, cost 26.58 s
2024-01-02 08:02:30,712	44k	INFO	====> Epoch: 1959, cost 26.19 s
2024-01-02 08:02:56,809	44k	INFO	Train Epoch: 1960 [97%]
2024-01-02 08:02:56,810	44k	INFO	Losses: [1.837665319442749, 3.2051494121551514, 10.411588668823242, 17.307941436767578, 0.6471662521362305], step: 68600, lr: 7.827904009716035e-05, reference_loss: 33.40951156616211
2024-01-02 08:02:57,299	44k	INFO	====> Epoch: 1960, cost 26.59 s
2024-01-02 08:03:23,592	44k	INFO	====> Epoch: 1961, cost 26.29 s
2024-01-02 08:03:49,791	44k	INFO	====> Epoch: 1962, cost 26.20 s
2024-01-02 08:04:16,141	44k	INFO	====> Epoch: 1963, cost 26.35 s
2024-01-02 08:04:42,406	44k	INFO	====> Epoch: 1964, cost 26.27 s
2024-01-02 08:05:08,879	44k	INFO	====> Epoch: 1965, cost 26.47 s
2024-01-02 08:05:27,425	44k	INFO	Train Epoch: 1966 [69%]
2024-01-02 08:05:27,425	44k	INFO	Losses: [2.503223419189453, 2.1427977085113525, 6.584618091583252, 14.180893898010254, 0.5585610866546631], step: 68800, lr: 7.822034916067999e-05, reference_loss: 25.970094680786133
2024-01-02 08:05:34,645	44k	INFO	Saving model and optimizer state at iteration 1966 to ./logs/44k/G_68800.pth
2024-01-02 08:05:35,539	44k	INFO	Saving model and optimizer state at iteration 1966 to ./logs/44k/D_68800.pth
2024-01-02 08:05:36,297	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_66400.pth
2024-01-02 08:05:36,353	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_66400.pth
2024-01-02 08:05:43,858	44k	INFO	====> Epoch: 1966, cost 34.98 s
2024-01-02 08:06:10,052	44k	INFO	====> Epoch: 1967, cost 26.19 s
2024-01-02 08:06:36,326	44k	INFO	====> Epoch: 1968, cost 26.27 s
2024-01-02 08:07:02,579	44k	INFO	====> Epoch: 1969, cost 26.25 s
2024-01-02 08:07:28,752	44k	INFO	====> Epoch: 1970, cost 26.17 s
2024-01-02 08:07:55,305	44k	INFO	====> Epoch: 1971, cost 26.55 s
2024-01-02 08:08:06,515	44k	INFO	Train Epoch: 1972 [40%]
2024-01-02 08:08:06,516	44k	INFO	Losses: [2.3430511951446533, 2.6015524864196777, 9.166549682617188, 17.63608169555664, 0.4573339521884918], step: 69000, lr: 7.81617022286486e-05, reference_loss: 32.204566955566406
2024-01-02 08:08:22,075	44k	INFO	====> Epoch: 1972, cost 26.77 s
2024-01-02 08:08:48,431	44k	INFO	====> Epoch: 1973, cost 26.36 s
2024-01-02 08:09:14,692	44k	INFO	====> Epoch: 1974, cost 26.26 s
2024-01-02 08:09:41,042	44k	INFO	====> Epoch: 1975, cost 26.35 s
2024-01-02 08:10:07,364	44k	INFO	====> Epoch: 1976, cost 26.32 s
2024-01-02 08:10:33,682	44k	INFO	====> Epoch: 1977, cost 26.32 s
2024-01-02 08:10:37,439	44k	INFO	Train Epoch: 1978 [11%]
2024-01-02 08:10:37,440	44k	INFO	Losses: [2.0226502418518066, 2.8489768505096436, 8.97586727142334, 18.01753044128418, 0.42184746265411377], step: 69200, lr: 7.810309926807314e-05, reference_loss: 32.28687286376953
2024-01-02 08:11:00,624	44k	INFO	====> Epoch: 1978, cost 26.94 s
2024-01-02 08:11:26,841	44k	INFO	====> Epoch: 1979, cost 26.22 s
2024-01-02 08:11:53,201	44k	INFO	====> Epoch: 1980, cost 26.36 s
2024-01-02 08:12:19,574	44k	INFO	====> Epoch: 1981, cost 26.37 s
2024-01-02 08:12:46,029	44k	INFO	====> Epoch: 1982, cost 26.46 s
2024-01-02 08:13:08,628	44k	INFO	Train Epoch: 1983 [83%]
2024-01-02 08:13:08,629	44k	INFO	Losses: [2.072688579559326, 2.7367136478424072, 8.560752868652344, 16.16366958618164, 0.6065222024917603], step: 69400, lr: 7.805429703311449e-05, reference_loss: 30.14034652709961
2024-01-02 08:13:12,864	44k	INFO	====> Epoch: 1983, cost 26.83 s
2024-01-02 08:13:39,512	44k	INFO	====> Epoch: 1984, cost 26.65 s
2024-01-02 08:14:05,844	44k	INFO	====> Epoch: 1985, cost 26.33 s
2024-01-02 08:14:32,022	44k	INFO	====> Epoch: 1986, cost 26.18 s
2024-01-02 08:14:58,236	44k	INFO	====> Epoch: 1987, cost 26.21 s
2024-01-02 08:15:24,520	44k	INFO	====> Epoch: 1988, cost 26.28 s
2024-01-02 08:15:39,386	44k	INFO	Train Epoch: 1989 [54%]
2024-01-02 08:15:39,386	44k	INFO	Losses: [2.2305314540863037, 2.485191822052002, 10.03479290008545, 16.864280700683594, 0.5916256308555603], step: 69600, lr: 7.79957746012668e-05, reference_loss: 32.2064208984375
2024-01-02 08:15:46,837	44k	INFO	Saving model and optimizer state at iteration 1989 to ./logs/44k/G_69600.pth
2024-01-02 08:15:47,732	44k	INFO	Saving model and optimizer state at iteration 1989 to ./logs/44k/D_69600.pth
2024-01-02 08:15:48,529	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_67200.pth
2024-01-02 08:15:48,587	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_67200.pth
2024-01-02 08:15:59,916	44k	INFO	====> Epoch: 1989, cost 35.40 s
2024-01-02 08:16:26,542	44k	INFO	====> Epoch: 1990, cost 26.63 s
2024-01-02 08:16:52,823	44k	INFO	====> Epoch: 1991, cost 26.28 s
2024-01-02 08:17:19,086	44k	INFO	====> Epoch: 1992, cost 26.26 s
2024-01-02 08:17:45,361	44k	INFO	====> Epoch: 1993, cost 26.27 s
2024-01-02 08:18:11,638	44k	INFO	====> Epoch: 1994, cost 26.28 s
2024-01-02 08:18:19,141	44k	INFO	Train Epoch: 1995 [26%]
2024-01-02 08:18:19,141	44k	INFO	Losses: [2.352047920227051, 2.5994765758514404, 7.518458366394043, 16.539697647094727, 0.6525954604148865], step: 69800, lr: 7.793729604752907e-05, reference_loss: 29.662277221679688
2024-01-02 08:18:38,454	44k	INFO	====> Epoch: 1995, cost 26.82 s
2024-01-02 08:19:04,776	44k	INFO	====> Epoch: 1996, cost 26.32 s
2024-01-02 08:19:31,040	44k	INFO	====> Epoch: 1997, cost 26.26 s
2024-01-02 08:19:57,378	44k	INFO	====> Epoch: 1998, cost 26.34 s
2024-01-02 08:20:24,014	44k	INFO	====> Epoch: 1999, cost 26.64 s
2024-01-02 08:20:50,307	44k	INFO	Train Epoch: 2000 [97%]
2024-01-02 08:20:50,307	44k	INFO	Losses: [1.8567222356796265, 3.07415771484375, 8.955702781677246, 16.854494094848633, 0.3794749081134796], step: 70000, lr: 7.788859741367973e-05, reference_loss: 31.12055206298828
2024-01-02 08:20:50,786	44k	INFO	====> Epoch: 2000, cost 26.77 s
2024-01-02 08:21:17,085	44k	INFO	====> Epoch: 2001, cost 26.30 s
2024-01-02 08:21:43,464	44k	INFO	====> Epoch: 2002, cost 26.38 s
2024-01-02 08:22:09,897	44k	INFO	====> Epoch: 2003, cost 26.43 s
2024-01-02 08:22:36,278	44k	INFO	====> Epoch: 2004, cost 26.38 s
2024-01-02 08:23:02,495	44k	INFO	====> Epoch: 2005, cost 26.22 s
2024-01-02 08:23:21,550	44k	INFO	Train Epoch: 2006 [69%]
2024-01-02 08:23:21,550	44k	INFO	Losses: [1.877634882926941, 3.2351627349853516, 8.69296932220459, 16.260290145874023, 0.5452446341514587], step: 70200, lr: 7.783019921771725e-05, reference_loss: 30.61130142211914
2024-01-02 08:23:29,593	44k	INFO	====> Epoch: 2006, cost 27.10 s
2024-01-02 08:23:55,907	44k	INFO	====> Epoch: 2007, cost 26.31 s
2024-01-02 08:24:22,144	44k	INFO	====> Epoch: 2008, cost 26.24 s
2024-01-02 08:24:48,495	44k	INFO	====> Epoch: 2009, cost 26.35 s
2024-01-02 08:25:14,780	44k	INFO	====> Epoch: 2010, cost 26.29 s
2024-01-02 08:25:41,107	44k	INFO	====> Epoch: 2011, cost 26.33 s
2024-01-02 08:25:52,250	44k	INFO	Train Epoch: 2012 [40%]
2024-01-02 08:25:52,251	44k	INFO	Losses: [2.289574384689331, 2.707479953765869, 9.744011878967285, 18.776039123535156, 0.6141837239265442], step: 70400, lr: 7.777184480671692e-05, reference_loss: 34.131290435791016
2024-01-02 08:25:59,974	44k	INFO	Saving model and optimizer state at iteration 2012 to ./logs/44k/G_70400.pth
2024-01-02 08:26:00,871	44k	INFO	Saving model and optimizer state at iteration 2012 to ./logs/44k/D_70400.pth
2024-01-02 08:26:01,652	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_68000.pth
2024-01-02 08:26:01,709	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_68000.pth
2024-01-02 08:26:16,720	44k	INFO	====> Epoch: 2012, cost 35.61 s
2024-01-02 08:26:42,886	44k	INFO	====> Epoch: 2013, cost 26.17 s
2024-01-02 08:27:09,197	44k	INFO	====> Epoch: 2014, cost 26.31 s
2024-01-02 08:27:35,374	44k	INFO	====> Epoch: 2015, cost 26.18 s
2024-01-02 08:28:01,642	44k	INFO	====> Epoch: 2016, cost 26.27 s
2024-01-02 08:28:27,915	44k	INFO	====> Epoch: 2017, cost 26.27 s
2024-01-02 08:28:31,662	44k	INFO	Train Epoch: 2018 [11%]
2024-01-02 08:28:31,663	44k	INFO	Losses: [2.647322177886963, 2.3453335762023926, 6.876278400421143, 15.558165550231934, 0.5501917004585266], step: 70600, lr: 7.77135341478503e-05, reference_loss: 27.977293014526367
2024-01-02 08:28:55,095	44k	INFO	====> Epoch: 2018, cost 27.18 s
2024-01-02 08:29:21,384	44k	INFO	====> Epoch: 2019, cost 26.29 s
2024-01-02 08:29:47,792	44k	INFO	====> Epoch: 2020, cost 26.41 s
2024-01-02 08:30:14,153	44k	INFO	====> Epoch: 2021, cost 26.36 s
2024-01-02 08:30:40,470	44k	INFO	====> Epoch: 2022, cost 26.32 s
2024-01-02 08:31:02,938	44k	INFO	Train Epoch: 2023 [83%]
2024-01-02 08:31:02,938	44k	INFO	Losses: [2.372664213180542, 2.3490054607391357, 7.4151153564453125, 17.78279685974121, 0.5985960364341736], step: 70800, lr: 7.766497533022985e-05, reference_loss: 30.518178939819336
2024-01-02 08:31:07,136	44k	INFO	====> Epoch: 2023, cost 26.67 s
2024-01-02 08:31:33,345	44k	INFO	====> Epoch: 2024, cost 26.21 s
2024-01-02 08:31:59,830	44k	INFO	====> Epoch: 2025, cost 26.49 s
2024-01-02 08:32:26,039	44k	INFO	====> Epoch: 2026, cost 26.21 s
2024-01-02 08:32:52,374	44k	INFO	====> Epoch: 2027, cost 26.34 s
2024-01-02 08:33:18,514	44k	INFO	====> Epoch: 2028, cost 26.14 s
2024-01-02 08:33:33,402	44k	INFO	Train Epoch: 2029 [54%]
2024-01-02 08:33:33,402	44k	INFO	Losses: [2.3982903957366943, 2.5400402545928955, 8.26012897491455, 17.641529083251953, 0.5547427535057068], step: 71000, lr: 7.760674479842725e-05, reference_loss: 31.394731521606445
2024-01-02 08:33:45,257	44k	INFO	====> Epoch: 2029, cost 26.74 s
2024-01-02 08:34:11,596	44k	INFO	====> Epoch: 2030, cost 26.34 s
2024-01-02 08:34:37,894	44k	INFO	====> Epoch: 2031, cost 26.30 s
2024-01-02 08:35:04,514	44k	INFO	====> Epoch: 2032, cost 26.62 s
2024-01-02 08:35:30,788	44k	INFO	====> Epoch: 2033, cost 26.27 s
2024-01-02 08:35:57,087	44k	INFO	====> Epoch: 2034, cost 26.30 s
2024-01-02 08:36:04,535	44k	INFO	Train Epoch: 2035 [26%]
2024-01-02 08:36:04,535	44k	INFO	Losses: [2.543593168258667, 2.389702081680298, 7.609584808349609, 17.08518409729004, 0.46231505274772644], step: 71200, lr: 7.7548557925878e-05, reference_loss: 30.090377807617188
2024-01-02 08:36:11,792	44k	INFO	Saving model and optimizer state at iteration 2035 to ./logs/44k/G_71200.pth
2024-01-02 08:36:12,690	44k	INFO	Saving model and optimizer state at iteration 2035 to ./logs/44k/D_71200.pth
2024-01-02 08:36:13,462	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_68800.pth
2024-01-02 08:36:13,519	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_68800.pth
2024-01-02 08:36:32,208	44k	INFO	====> Epoch: 2035, cost 35.12 s
2024-01-02 08:36:58,426	44k	INFO	====> Epoch: 2036, cost 26.22 s
2024-01-02 08:37:24,971	44k	INFO	====> Epoch: 2037, cost 26.55 s
2024-01-02 08:37:51,151	44k	INFO	====> Epoch: 2038, cost 26.18 s
2024-01-02 08:38:17,438	44k	INFO	====> Epoch: 2039, cost 26.29 s
2024-01-02 08:38:43,793	44k	INFO	Train Epoch: 2040 [97%]
2024-01-02 08:38:43,793	44k	INFO	Losses: [2.342618942260742, 2.66672420501709, 9.399023056030273, 18.319631576538086, 0.451671838760376], step: 71400, lr: 7.750010219262196e-05, reference_loss: 33.17966842651367
2024-01-02 08:38:44,274	44k	INFO	====> Epoch: 2040, cost 26.84 s
2024-01-02 08:39:10,641	44k	INFO	====> Epoch: 2041, cost 26.37 s
2024-01-02 08:39:36,952	44k	INFO	====> Epoch: 2042, cost 26.31 s
2024-01-02 08:40:03,200	44k	INFO	====> Epoch: 2043, cost 26.25 s
2024-01-02 08:40:29,626	44k	INFO	====> Epoch: 2044, cost 26.43 s
2024-01-02 08:40:55,941	44k	INFO	====> Epoch: 2045, cost 26.32 s
2024-01-02 08:41:14,991	44k	INFO	Train Epoch: 2046 [69%]
2024-01-02 08:41:14,992	44k	INFO	Losses: [2.190061330795288, 2.901201009750366, 9.807663917541504, 15.759956359863281, 0.7502179145812988], step: 71600, lr: 7.744199527703687e-05, reference_loss: 31.409099578857422
2024-01-02 08:41:23,025	44k	INFO	====> Epoch: 2046, cost 27.08 s
2024-01-02 08:41:49,209	44k	INFO	====> Epoch: 2047, cost 26.18 s
2024-01-02 08:42:15,519	44k	INFO	====> Epoch: 2048, cost 26.31 s
2024-01-02 08:42:41,756	44k	INFO	====> Epoch: 2049, cost 26.24 s
2024-01-02 08:43:08,106	44k	INFO	====> Epoch: 2050, cost 26.35 s
2024-01-02 08:43:34,355	44k	INFO	====> Epoch: 2051, cost 26.25 s
2024-01-02 08:43:45,504	44k	INFO	Train Epoch: 2052 [40%]
2024-01-02 08:43:45,505	44k	INFO	Losses: [2.4169247150421143, 2.682631731033325, 8.312422752380371, 16.600826263427734, 0.6861239075660706], step: 71800, lr: 7.738393192802191e-05, reference_loss: 30.698930740356445
2024-01-02 08:44:01,396	44k	INFO	====> Epoch: 2052, cost 27.04 s
2024-01-02 08:44:27,720	44k	INFO	====> Epoch: 2053, cost 26.32 s
2024-01-02 08:44:54,057	44k	INFO	====> Epoch: 2054, cost 26.34 s
2024-01-02 08:45:20,322	44k	INFO	====> Epoch: 2055, cost 26.27 s
2024-01-02 08:45:46,562	44k	INFO	====> Epoch: 2056, cost 26.24 s
2024-01-02 08:46:12,942	44k	INFO	====> Epoch: 2057, cost 26.38 s
2024-01-02 08:46:16,673	44k	INFO	Train Epoch: 2058 [11%]
2024-01-02 08:46:16,674	44k	INFO	Losses: [2.1600687503814697, 2.4719152450561523, 8.23677921295166, 16.330177307128906, 0.7821943759918213], step: 72000, lr: 7.732591211291238e-05, reference_loss: 29.98113441467285
2024-01-02 08:46:23,987	44k	INFO	Saving model and optimizer state at iteration 2058 to ./logs/44k/G_72000.pth
2024-01-02 08:46:25,217	44k	INFO	Saving model and optimizer state at iteration 2058 to ./logs/44k/D_72000.pth
2024-01-02 08:46:25,990	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_69600.pth
2024-01-02 08:46:26,048	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_69600.pth
2024-01-02 08:46:48,588	44k	INFO	====> Epoch: 2058, cost 35.65 s
2024-01-02 08:47:14,845	44k	INFO	====> Epoch: 2059, cost 26.26 s
2024-01-02 08:47:41,065	44k	INFO	====> Epoch: 2060, cost 26.22 s
2024-01-02 08:48:07,264	44k	INFO	====> Epoch: 2061, cost 26.20 s
2024-01-02 08:48:33,450	44k	INFO	====> Epoch: 2062, cost 26.19 s
2024-01-02 08:48:55,904	44k	INFO	Train Epoch: 2063 [83%]
2024-01-02 08:48:55,904	44k	INFO	Losses: [1.7724215984344482, 3.2904205322265625, 9.12729263305664, 14.19565200805664, 0.45979613065719604], step: 72200, lr: 7.727759549850538e-05, reference_loss: 28.845584869384766
2024-01-02 08:49:00,134	44k	INFO	====> Epoch: 2063, cost 26.68 s
2024-01-02 08:49:26,300	44k	INFO	====> Epoch: 2064, cost 26.17 s
2024-01-02 08:49:52,955	44k	INFO	====> Epoch: 2065, cost 26.66 s
2024-01-02 08:50:19,272	44k	INFO	====> Epoch: 2066, cost 26.32 s
2024-01-02 08:50:45,625	44k	INFO	====> Epoch: 2067, cost 26.35 s
2024-01-02 08:51:11,925	44k	INFO	====> Epoch: 2068, cost 26.30 s
2024-01-02 08:51:26,832	44k	INFO	Train Epoch: 2069 [54%]
2024-01-02 08:51:26,833	44k	INFO	Losses: [2.0221378803253174, 2.8912339210510254, 8.853283882141113, 16.549301147460938, 0.6010547876358032], step: 72400, lr: 7.721965541079953e-05, reference_loss: 30.917011260986328
2024-01-02 08:51:38,691	44k	INFO	====> Epoch: 2069, cost 26.77 s
2024-01-02 08:52:05,029	44k	INFO	====> Epoch: 2070, cost 26.34 s
2024-01-02 08:52:31,275	44k	INFO	====> Epoch: 2071, cost 26.25 s
2024-01-02 08:52:57,826	44k	INFO	====> Epoch: 2072, cost 26.55 s
2024-01-02 08:53:24,107	44k	INFO	====> Epoch: 2073, cost 26.28 s
2024-01-02 08:53:50,293	44k	INFO	====> Epoch: 2074, cost 26.19 s
2024-01-02 08:53:57,746	44k	INFO	Train Epoch: 2075 [26%]
2024-01-02 08:53:57,747	44k	INFO	Losses: [2.4537811279296875, 2.354789972305298, 7.523135662078857, 16.109844207763672, 0.5634928941726685], step: 72600, lr: 7.716175876458204e-05, reference_loss: 29.00504493713379
2024-01-02 08:54:17,121	44k	INFO	====> Epoch: 2075, cost 26.83 s
2024-01-02 08:54:43,352	44k	INFO	====> Epoch: 2076, cost 26.23 s
2024-01-02 08:55:09,699	44k	INFO	====> Epoch: 2077, cost 26.35 s
2024-01-02 08:55:35,997	44k	INFO	====> Epoch: 2078, cost 26.30 s
2024-01-02 08:56:02,682	44k	INFO	====> Epoch: 2079, cost 26.68 s
2024-01-02 08:56:29,029	44k	INFO	Train Epoch: 2080 [97%]
2024-01-02 08:56:29,029	44k	INFO	Losses: [1.8130396604537964, 3.927753210067749, 9.463460922241211, 15.082910537719727, 0.5002843141555786], step: 72800, lr: 7.7113544720372e-05, reference_loss: 30.78744888305664
2024-01-02 08:56:36,557	44k	INFO	Saving model and optimizer state at iteration 2080 to ./logs/44k/G_72800.pth
2024-01-02 08:56:37,452	44k	INFO	Saving model and optimizer state at iteration 2080 to ./logs/44k/D_72800.pth
2024-01-02 08:56:38,249	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_70400.pth
2024-01-02 08:56:38,306	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_70400.pth
2024-01-02 08:56:38,307	44k	INFO	====> Epoch: 2080, cost 35.62 s
2024-01-02 08:57:04,591	44k	INFO	====> Epoch: 2081, cost 26.28 s
2024-01-02 08:57:30,849	44k	INFO	====> Epoch: 2082, cost 26.26 s
2024-01-02 08:57:57,037	44k	INFO	====> Epoch: 2083, cost 26.19 s
2024-01-02 08:58:23,591	44k	INFO	====> Epoch: 2084, cost 26.55 s
2024-01-02 08:58:49,901	44k	INFO	====> Epoch: 2085, cost 26.31 s
2024-01-02 08:59:08,739	44k	INFO	Train Epoch: 2086 [69%]
2024-01-02 08:59:08,739	44k	INFO	Losses: [2.1323294639587402, 2.564220905303955, 8.581404685974121, 15.300882339477539, 0.6860891580581665], step: 73000, lr: 7.705572763230678e-05, reference_loss: 29.26492691040039
2024-01-02 08:59:16,965	44k	INFO	====> Epoch: 2086, cost 27.06 s
2024-01-02 08:59:43,184	44k	INFO	====> Epoch: 2087, cost 26.22 s
2024-01-02 09:00:09,357	44k	INFO	====> Epoch: 2088, cost 26.17 s
2024-01-02 09:00:35,633	44k	INFO	====> Epoch: 2089, cost 26.28 s
2024-01-02 09:01:02,031	44k	INFO	====> Epoch: 2090, cost 26.40 s
2024-01-02 09:01:28,381	44k	INFO	====> Epoch: 2091, cost 26.35 s
2024-01-02 09:01:39,602	44k	INFO	Train Epoch: 2092 [40%]
2024-01-02 09:01:39,603	44k	INFO	Losses: [2.4040591716766357, 2.269786834716797, 8.196990013122559, 17.49516487121582, 0.4373461902141571], step: 73200, lr: 7.699795389350898e-05, reference_loss: 30.803346633911133
2024-01-02 09:01:55,670	44k	INFO	====> Epoch: 2092, cost 27.29 s
2024-01-02 09:02:22,036	44k	INFO	====> Epoch: 2093, cost 26.37 s
2024-01-02 09:02:48,342	44k	INFO	====> Epoch: 2094, cost 26.31 s
2024-01-02 09:03:14,618	44k	INFO	====> Epoch: 2095, cost 26.28 s
2024-01-02 09:03:40,974	44k	INFO	====> Epoch: 2096, cost 26.36 s
2024-01-02 09:04:07,338	44k	INFO	====> Epoch: 2097, cost 26.36 s
2024-01-02 09:04:11,090	44k	INFO	Train Epoch: 2098 [11%]
2024-01-02 09:04:11,090	44k	INFO	Losses: [1.723620057106018, 3.460022449493408, 9.366092681884766, 16.440725326538086, 0.3856108784675598], step: 73400, lr: 7.694022347147682e-05, reference_loss: 31.376070022583008
2024-01-02 09:04:34,312	44k	INFO	====> Epoch: 2098, cost 26.97 s
2024-01-02 09:05:00,594	44k	INFO	====> Epoch: 2099, cost 26.28 s
2024-01-02 09:05:26,794	44k	INFO	====> Epoch: 2100, cost 26.20 s
2024-01-02 09:05:53,019	44k	INFO	====> Epoch: 2101, cost 26.23 s
2024-01-02 09:06:19,357	44k	INFO	====> Epoch: 2102, cost 26.34 s
2024-01-02 09:06:41,977	44k	INFO	Train Epoch: 2103 [83%]
2024-01-02 09:06:41,977	44k	INFO	Losses: [2.4192631244659424, 2.327307939529419, 8.036903381347656, 14.183728218078613, 0.5439406633377075], step: 73600, lr: 7.689214785221441e-05, reference_loss: 27.51114273071289
2024-01-02 09:06:49,295	44k	INFO	Saving model and optimizer state at iteration 2103 to ./logs/44k/G_73600.pth
2024-01-02 09:06:50,194	44k	INFO	Saving model and optimizer state at iteration 2103 to ./logs/44k/D_73600.pth
2024-01-02 09:06:50,968	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_71200.pth
2024-01-02 09:06:51,026	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_71200.pth
2024-01-02 09:06:54,769	44k	INFO	====> Epoch: 2103, cost 35.41 s
2024-01-02 09:07:21,328	44k	INFO	====> Epoch: 2104, cost 26.56 s
2024-01-02 09:07:47,674	44k	INFO	====> Epoch: 2105, cost 26.35 s
2024-01-02 09:08:14,082	44k	INFO	====> Epoch: 2106, cost 26.41 s
2024-01-02 09:08:40,463	44k	INFO	====> Epoch: 2107, cost 26.38 s
2024-01-02 09:09:06,702	44k	INFO	====> Epoch: 2108, cost 26.24 s
2024-01-02 09:09:21,643	44k	INFO	Train Epoch: 2109 [54%]
2024-01-02 09:09:21,644	44k	INFO	Losses: [2.5321359634399414, 2.1046361923217773, 7.173503875732422, 15.4926118850708, 0.34342119097709656], step: 73800, lr: 7.683449675991908e-05, reference_loss: 27.64630889892578
2024-01-02 09:09:33,528	44k	INFO	====> Epoch: 2109, cost 26.83 s
2024-01-02 09:09:59,856	44k	INFO	====> Epoch: 2110, cost 26.33 s
2024-01-02 09:10:26,139	44k	INFO	====> Epoch: 2111, cost 26.28 s
2024-01-02 09:10:52,450	44k	INFO	====> Epoch: 2112, cost 26.31 s
2024-01-02 09:11:19,008	44k	INFO	====> Epoch: 2113, cost 26.56 s
2024-01-02 09:11:45,151	44k	INFO	====> Epoch: 2114, cost 26.14 s
2024-01-02 09:11:52,621	44k	INFO	Train Epoch: 2115 [26%]
2024-01-02 09:11:52,621	44k	INFO	Losses: [2.154284954071045, 2.54229736328125, 8.859883308410645, 18.24709701538086, 0.8077239394187927], step: 74000, lr: 7.677688889243324e-05, reference_loss: 32.61128616333008
2024-01-02 09:12:11,883	44k	INFO	====> Epoch: 2115, cost 26.73 s
2024-01-02 09:12:38,061	44k	INFO	====> Epoch: 2116, cost 26.18 s
2024-01-02 09:13:04,298	44k	INFO	====> Epoch: 2117, cost 26.24 s
2024-01-02 09:13:30,652	44k	INFO	====> Epoch: 2118, cost 26.35 s
2024-01-02 09:13:57,053	44k	INFO	====> Epoch: 2119, cost 26.40 s
2024-01-02 09:14:23,741	44k	INFO	Train Epoch: 2120 [97%]
2024-01-02 09:14:23,741	44k	INFO	Losses: [2.191290855407715, 2.752147912979126, 9.822068214416504, 18.84314727783203, 0.5994507074356079], step: 74200, lr: 7.67289153317649e-05, reference_loss: 34.20810317993164
2024-01-02 09:14:24,242	44k	INFO	====> Epoch: 2120, cost 27.19 s
2024-01-02 09:14:50,561	44k	INFO	====> Epoch: 2121, cost 26.32 s
2024-01-02 09:15:16,781	44k	INFO	====> Epoch: 2122, cost 26.22 s
2024-01-02 09:15:43,069	44k	INFO	====> Epoch: 2123, cost 26.29 s
2024-01-02 09:16:09,425	44k	INFO	====> Epoch: 2124, cost 26.36 s
2024-01-02 09:16:35,791	44k	INFO	====> Epoch: 2125, cost 26.37 s
2024-01-02 09:16:54,598	44k	INFO	Train Epoch: 2126 [69%]
2024-01-02 09:16:54,598	44k	INFO	Losses: [2.2246181964874268, 2.592540979385376, 8.059072494506836, 13.99144172668457, 0.6574717164039612], step: 74400, lr: 7.667138662560864e-05, reference_loss: 27.525146484375
2024-01-02 09:17:02,335	44k	INFO	Saving model and optimizer state at iteration 2126 to ./logs/44k/G_74400.pth
2024-01-02 09:17:03,228	44k	INFO	Saving model and optimizer state at iteration 2126 to ./logs/44k/D_74400.pth
2024-01-02 09:17:03,986	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_72000.pth
2024-01-02 09:17:04,042	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_72000.pth
2024-01-02 09:17:11,629	44k	INFO	====> Epoch: 2126, cost 35.84 s
2024-01-02 09:17:38,007	44k	INFO	====> Epoch: 2127, cost 26.38 s
2024-01-02 09:18:04,392	44k	INFO	====> Epoch: 2128, cost 26.39 s
2024-01-02 09:18:30,738	44k	INFO	====> Epoch: 2129, cost 26.35 s
2024-01-02 09:18:56,968	44k	INFO	====> Epoch: 2130, cost 26.23 s
2024-01-02 09:19:23,224	44k	INFO	====> Epoch: 2131, cost 26.26 s
2024-01-02 09:19:34,370	44k	INFO	Train Epoch: 2132 [40%]
2024-01-02 09:19:34,371	44k	INFO	Losses: [2.3530049324035645, 2.433368682861328, 9.237543106079102, 17.664382934570312, 0.41096988320350647], step: 74600, lr: 7.661390105250096e-05, reference_loss: 32.09926986694336
2024-01-02 09:19:50,294	44k	INFO	====> Epoch: 2132, cost 27.07 s
2024-01-02 09:20:16,752	44k	INFO	====> Epoch: 2133, cost 26.46 s
2024-01-02 09:20:43,098	44k	INFO	====> Epoch: 2134, cost 26.35 s
2024-01-02 09:21:09,255	44k	INFO	====> Epoch: 2135, cost 26.16 s
2024-01-02 09:21:35,617	44k	INFO	====> Epoch: 2136, cost 26.36 s
2024-01-02 09:22:01,866	44k	INFO	====> Epoch: 2137, cost 26.25 s
2024-01-02 09:22:05,631	44k	INFO	Train Epoch: 2138 [11%]
2024-01-02 09:22:05,631	44k	INFO	Losses: [2.317927122116089, 2.4672298431396484, 8.260212898254395, 17.861650466918945, 0.4166127145290375], step: 74800, lr: 7.655645858010219e-05, reference_loss: 31.323633193969727
2024-01-02 09:22:28,597	44k	INFO	====> Epoch: 2138, cost 26.73 s
2024-01-02 09:22:55,075	44k	INFO	====> Epoch: 2139, cost 26.48 s
2024-01-02 09:23:21,339	44k	INFO	====> Epoch: 2140, cost 26.26 s
2024-01-02 09:23:47,705	44k	INFO	====> Epoch: 2141, cost 26.37 s
2024-01-02 09:24:14,000	44k	INFO	====> Epoch: 2142, cost 26.30 s
2024-01-02 09:24:36,482	44k	INFO	Train Epoch: 2143 [83%]
2024-01-02 09:24:36,483	44k	INFO	Losses: [2.0585520267486572, 3.084506034851074, 9.512011528015137, 15.876943588256836, 0.5838738083839417], step: 75000, lr: 7.65086227539411e-05, reference_loss: 31.115886688232422
2024-01-02 09:24:40,740	44k	INFO	====> Epoch: 2143, cost 26.74 s
2024-01-02 09:25:06,961	44k	INFO	====> Epoch: 2144, cost 26.22 s
2024-01-02 09:25:33,201	44k	INFO	====> Epoch: 2145, cost 26.24 s
2024-01-02 09:25:59,816	44k	INFO	====> Epoch: 2146, cost 26.61 s
2024-01-02 09:26:26,092	44k	INFO	====> Epoch: 2147, cost 26.28 s
2024-01-02 09:26:52,357	44k	INFO	====> Epoch: 2148, cost 26.26 s
2024-01-02 09:27:07,298	44k	INFO	Train Epoch: 2149 [54%]
2024-01-02 09:27:07,299	44k	INFO	Losses: [2.155527353286743, 2.617459774017334, 10.505061149597168, 17.015390396118164, 0.5917929410934448], step: 75200, lr: 7.645125921559574e-05, reference_loss: 32.885231018066406
2024-01-02 09:27:14,603	44k	INFO	Saving model and optimizer state at iteration 2149 to ./logs/44k/G_75200.pth
2024-01-02 09:27:15,490	44k	INFO	Saving model and optimizer state at iteration 2149 to ./logs/44k/D_75200.pth
2024-01-02 09:27:16,265	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_72800.pth
2024-01-02 09:27:16,322	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_72800.pth
2024-01-02 09:27:27,693	44k	INFO	====> Epoch: 2149, cost 35.34 s
2024-01-02 09:27:53,979	44k	INFO	====> Epoch: 2150, cost 26.29 s
2024-01-02 09:28:20,489	44k	INFO	====> Epoch: 2151, cost 26.51 s
2024-01-02 09:28:46,801	44k	INFO	====> Epoch: 2152, cost 26.31 s
2024-01-02 09:29:13,223	44k	INFO	====> Epoch: 2153, cost 26.42 s
2024-01-02 09:29:39,490	44k	INFO	====> Epoch: 2154, cost 26.27 s
2024-01-02 09:29:46,927	44k	INFO	Train Epoch: 2155 [26%]
2024-01-02 09:29:46,927	44k	INFO	Losses: [2.5508599281311035, 2.529752254486084, 8.020624160766602, 16.997777938842773, 0.677490234375], step: 75400, lr: 7.63939386864618e-05, reference_loss: 30.776504516601562
2024-01-02 09:30:06,379	44k	INFO	====> Epoch: 2155, cost 26.89 s
2024-01-02 09:30:32,593	44k	INFO	====> Epoch: 2156, cost 26.21 s
2024-01-02 09:30:58,938	44k	INFO	====> Epoch: 2157, cost 26.34 s
2024-01-02 09:31:25,304	44k	INFO	====> Epoch: 2158, cost 26.37 s
2024-01-02 09:31:51,662	44k	INFO	====> Epoch: 2159, cost 26.36 s
2024-01-02 09:32:18,193	44k	INFO	Train Epoch: 2160 [97%]
2024-01-02 09:32:18,194	44k	INFO	Losses: [2.3056750297546387, 2.809098720550537, 7.871992111206055, 16.352529525756836, 0.4144509732723236], step: 75600, lr: 7.63462044098437e-05, reference_loss: 29.753746032714844
2024-01-02 09:32:18,675	44k	INFO	====> Epoch: 2160, cost 27.01 s
2024-01-02 09:32:44,989	44k	INFO	====> Epoch: 2161, cost 26.31 s
2024-01-02 09:33:11,224	44k	INFO	====> Epoch: 2162, cost 26.24 s
2024-01-02 09:33:37,531	44k	INFO	====> Epoch: 2163, cost 26.31 s
2024-01-02 09:34:03,853	44k	INFO	====> Epoch: 2164, cost 26.32 s
2024-01-02 09:34:30,167	44k	INFO	====> Epoch: 2165, cost 26.31 s
2024-01-02 09:34:48,888	44k	INFO	Train Epoch: 2166 [69%]
2024-01-02 09:34:48,889	44k	INFO	Losses: [1.7916641235351562, 3.1656064987182617, 9.632636070251465, 16.002685546875, 0.6167416572570801], step: 75800, lr: 7.628896264719596e-05, reference_loss: 31.209333419799805
2024-01-02 09:34:57,252	44k	INFO	====> Epoch: 2166, cost 27.09 s
2024-01-02 09:35:23,448	44k	INFO	====> Epoch: 2167, cost 26.20 s
2024-01-02 09:35:49,665	44k	INFO	====> Epoch: 2168, cost 26.22 s
2024-01-02 09:36:15,831	44k	INFO	====> Epoch: 2169, cost 26.17 s
2024-01-02 09:36:42,082	44k	INFO	====> Epoch: 2170, cost 26.25 s
2024-01-02 09:37:08,251	44k	INFO	====> Epoch: 2171, cost 26.17 s
2024-01-02 09:37:19,498	44k	INFO	Train Epoch: 2172 [40%]
2024-01-02 09:37:19,499	44k	INFO	Losses: [2.258310317993164, 2.6545615196228027, 9.42168140411377, 18.37230682373047, 0.5131022334098816], step: 76000, lr: 7.623176380245642e-05, reference_loss: 33.21996307373047
2024-01-02 09:37:26,799	44k	INFO	Saving model and optimizer state at iteration 2172 to ./logs/44k/G_76000.pth
2024-01-02 09:37:28,024	44k	INFO	Saving model and optimizer state at iteration 2172 to ./logs/44k/D_76000.pth
2024-01-02 09:37:28,788	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_73600.pth
2024-01-02 09:37:28,845	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_73600.pth
2024-01-02 09:37:44,038	44k	INFO	====> Epoch: 2172, cost 35.79 s
2024-01-02 09:38:10,337	44k	INFO	====> Epoch: 2173, cost 26.30 s
2024-01-02 09:38:36,752	44k	INFO	====> Epoch: 2174, cost 26.41 s
2024-01-02 09:39:03,127	44k	INFO	====> Epoch: 2175, cost 26.38 s
2024-01-02 09:39:29,374	44k	INFO	====> Epoch: 2176, cost 26.25 s
2024-01-02 09:39:55,522	44k	INFO	====> Epoch: 2177, cost 26.15 s
2024-01-02 09:39:59,250	44k	INFO	Train Epoch: 2178 [11%]
2024-01-02 09:39:59,251	44k	INFO	Losses: [1.996372938156128, 3.206813335418701, 8.354178428649902, 15.51607894897461, 0.5575636029243469], step: 76200, lr: 7.617460784344667e-05, reference_loss: 29.63100814819336
2024-01-02 09:40:22,461	44k	INFO	====> Epoch: 2178, cost 26.94 s
2024-01-02 09:40:49,159	44k	INFO	====> Epoch: 2179, cost 26.70 s
2024-01-02 09:41:15,510	44k	INFO	====> Epoch: 2180, cost 26.35 s
2024-01-02 09:41:41,928	44k	INFO	====> Epoch: 2181, cost 26.42 s
2024-01-02 09:42:08,449	44k	INFO	====> Epoch: 2182, cost 26.52 s
2024-01-02 09:42:30,959	44k	INFO	Train Epoch: 2183 [83%]
2024-01-02 09:42:30,960	44k	INFO	Losses: [2.4370033740997314, 2.355306625366211, 7.083032131195068, 17.6225643157959, 0.5476577877998352], step: 76400, lr: 7.612701061433928e-05, reference_loss: 30.045562744140625
2024-01-02 09:42:35,309	44k	INFO	====> Epoch: 2183, cost 26.86 s
2024-01-02 09:43:01,637	44k	INFO	====> Epoch: 2184, cost 26.33 s
2024-01-02 09:43:28,007	44k	INFO	====> Epoch: 2185, cost 26.37 s
2024-01-02 09:43:54,544	44k	INFO	====> Epoch: 2186, cost 26.54 s
2024-01-02 09:44:20,889	44k	INFO	====> Epoch: 2187, cost 26.35 s
2024-01-02 09:44:47,246	44k	INFO	====> Epoch: 2188, cost 26.36 s
2024-01-02 09:45:02,178	44k	INFO	Train Epoch: 2189 [54%]
2024-01-02 09:45:02,179	44k	INFO	Losses: [2.1380724906921387, 2.700732707977295, 9.475407600402832, 17.66875457763672, 0.499950110912323], step: 76600, lr: 7.606993319567318e-05, reference_loss: 32.48291778564453
2024-01-02 09:45:14,008	44k	INFO	====> Epoch: 2189, cost 26.76 s
2024-01-02 09:45:40,336	44k	INFO	====> Epoch: 2190, cost 26.33 s
2024-01-02 09:46:06,594	44k	INFO	====> Epoch: 2191, cost 26.26 s
2024-01-02 09:46:32,918	44k	INFO	====> Epoch: 2192, cost 26.32 s
2024-01-02 09:46:59,489	44k	INFO	====> Epoch: 2193, cost 26.57 s
2024-01-02 09:47:25,804	44k	INFO	====> Epoch: 2194, cost 26.31 s
2024-01-02 09:47:33,309	44k	INFO	Train Epoch: 2195 [26%]
2024-01-02 09:47:33,310	44k	INFO	Losses: [2.419630765914917, 2.356846809387207, 8.346877098083496, 16.63852882385254, 0.5013987421989441], step: 76800, lr: 7.601289857169579e-05, reference_loss: 30.263280868530273
2024-01-02 09:47:40,847	44k	INFO	Saving model and optimizer state at iteration 2195 to ./logs/44k/G_76800.pth
2024-01-02 09:47:41,750	44k	INFO	Saving model and optimizer state at iteration 2195 to ./logs/44k/D_76800.pth
2024-01-02 09:47:42,525	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_74400.pth
2024-01-02 09:47:42,582	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_74400.pth
2024-01-02 09:48:01,389	44k	INFO	====> Epoch: 2195, cost 35.59 s
2024-01-02 09:48:27,656	44k	INFO	====> Epoch: 2196, cost 26.27 s
2024-01-02 09:48:53,940	44k	INFO	====> Epoch: 2197, cost 26.28 s
2024-01-02 09:49:20,300	44k	INFO	====> Epoch: 2198, cost 26.36 s
2024-01-02 09:49:46,992	44k	INFO	====> Epoch: 2199, cost 26.69 s
2024-01-02 09:50:13,292	44k	INFO	Train Epoch: 2200 [97%]
2024-01-02 09:50:13,293	44k	INFO	Losses: [1.9738404750823975, 3.2391655445098877, 10.332050323486328, 17.169736862182617, 0.42311355471611023], step: 77000, lr: 7.596540238561933e-05, reference_loss: 33.137908935546875
2024-01-02 09:50:13,775	44k	INFO	====> Epoch: 2200, cost 26.78 s
2024-01-02 09:50:40,176	44k	INFO	====> Epoch: 2201, cost 26.40 s
2024-01-02 09:51:06,548	44k	INFO	====> Epoch: 2202, cost 26.37 s
2024-01-02 09:51:32,955	44k	INFO	====> Epoch: 2203, cost 26.41 s
2024-01-02 09:51:59,359	44k	INFO	====> Epoch: 2204, cost 26.40 s
2024-01-02 09:52:25,633	44k	INFO	====> Epoch: 2205, cost 26.27 s
2024-01-02 09:52:44,396	44k	INFO	Train Epoch: 2206 [69%]
2024-01-02 09:52:44,396	44k	INFO	Losses: [2.2658889293670654, 2.8689754009246826, 8.637492179870605, 14.259761810302734, 0.6983634233474731], step: 77200, lr: 7.590844613525417e-05, reference_loss: 28.73048210144043
2024-01-02 09:52:52,743	44k	INFO	====> Epoch: 2206, cost 27.11 s
2024-01-02 09:53:19,000	44k	INFO	====> Epoch: 2207, cost 26.26 s
2024-01-02 09:53:45,239	44k	INFO	====> Epoch: 2208, cost 26.24 s
2024-01-02 09:54:11,524	44k	INFO	====> Epoch: 2209, cost 26.29 s
2024-01-02 09:54:37,791	44k	INFO	====> Epoch: 2210, cost 26.27 s
2024-01-02 09:55:04,124	44k	INFO	====> Epoch: 2211, cost 26.33 s
2024-01-02 09:55:15,358	44k	INFO	Train Epoch: 2212 [40%]
2024-01-02 09:55:15,358	44k	INFO	Losses: [2.7110342979431152, 2.5115673542022705, 7.5543599128723145, 16.25979995727539, 0.7101023197174072], step: 77400, lr: 7.585153258872988e-05, reference_loss: 29.746864318847656
2024-01-02 09:55:30,996	44k	INFO	====> Epoch: 2212, cost 26.87 s
2024-01-02 09:55:57,592	44k	INFO	====> Epoch: 2213, cost 26.60 s
2024-01-02 09:56:23,857	44k	INFO	====> Epoch: 2214, cost 26.27 s
2024-01-02 09:56:50,123	44k	INFO	====> Epoch: 2215, cost 26.27 s
2024-01-02 09:57:16,420	44k	INFO	====> Epoch: 2216, cost 26.30 s
2024-01-02 09:57:42,636	44k	INFO	====> Epoch: 2217, cost 26.22 s
2024-01-02 09:57:46,398	44k	INFO	Train Epoch: 2218 [11%]
2024-01-02 09:57:46,398	44k	INFO	Losses: [2.428903102874756, 2.2486603260040283, 7.644161224365234, 16.04660987854004, 0.721725583076477], step: 77600, lr: 7.579466171402858e-05, reference_loss: 29.09006118774414
2024-01-02 09:57:53,875	44k	INFO	Saving model and optimizer state at iteration 2218 to ./logs/44k/G_77600.pth
2024-01-02 09:57:54,779	44k	INFO	Saving model and optimizer state at iteration 2218 to ./logs/44k/D_77600.pth
2024-01-02 09:57:55,551	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_75200.pth
2024-01-02 09:57:55,608	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_75200.pth
2024-01-02 09:58:18,468	44k	INFO	====> Epoch: 2218, cost 35.83 s
2024-01-02 09:58:44,641	44k	INFO	====> Epoch: 2219, cost 26.17 s
2024-01-02 09:59:10,885	44k	INFO	====> Epoch: 2220, cost 26.24 s
2024-01-02 09:59:37,230	44k	INFO	====> Epoch: 2221, cost 26.34 s
2024-01-02 10:00:03,584	44k	INFO	====> Epoch: 2222, cost 26.35 s
2024-01-02 10:00:26,220	44k	INFO	Train Epoch: 2223 [83%]
2024-01-02 10:00:26,221	44k	INFO	Losses: [2.4417200088500977, 2.3547146320343018, 6.982302188873291, 15.559287071228027, 0.4215281307697296], step: 77800, lr: 7.574730189189292e-05, reference_loss: 27.759552001953125
2024-01-02 10:00:30,474	44k	INFO	====> Epoch: 2223, cost 26.89 s
2024-01-02 10:00:56,817	44k	INFO	====> Epoch: 2224, cost 26.34 s
2024-01-02 10:01:23,243	44k	INFO	====> Epoch: 2225, cost 26.43 s
2024-01-02 10:01:49,611	44k	INFO	====> Epoch: 2226, cost 26.37 s
2024-01-02 10:02:16,179	44k	INFO	====> Epoch: 2227, cost 26.57 s
2024-01-02 10:02:42,475	44k	INFO	====> Epoch: 2228, cost 26.30 s
2024-01-02 10:02:57,487	44k	INFO	Train Epoch: 2229 [54%]
2024-01-02 10:02:57,488	44k	INFO	Losses: [1.7431933879852295, 3.525543212890625, 9.677982330322266, 16.514020919799805, 0.6019300222396851], step: 78000, lr: 7.569050916578924e-05, reference_loss: 32.06266784667969
2024-01-02 10:03:09,485	44k	INFO	====> Epoch: 2229, cost 27.01 s
2024-01-02 10:03:35,798	44k	INFO	====> Epoch: 2230, cost 26.31 s
2024-01-02 10:04:02,201	44k	INFO	====> Epoch: 2231, cost 26.40 s
2024-01-02 10:04:28,596	44k	INFO	====> Epoch: 2232, cost 26.39 s
2024-01-02 10:04:54,891	44k	INFO	====> Epoch: 2233, cost 26.30 s
2024-01-02 10:05:21,405	44k	INFO	====> Epoch: 2234, cost 26.51 s
2024-01-02 10:05:28,856	44k	INFO	Train Epoch: 2235 [26%]
2024-01-02 10:05:28,857	44k	INFO	Losses: [1.819091558456421, 3.289569854736328, 9.331127166748047, 16.134906768798828, 0.5259706974029541], step: 78200, lr: 7.563375902092158e-05, reference_loss: 31.100666046142578
2024-01-02 10:05:48,205	44k	INFO	====> Epoch: 2235, cost 26.80 s
2024-01-02 10:06:14,381	44k	INFO	====> Epoch: 2236, cost 26.18 s
2024-01-02 10:06:40,678	44k	INFO	====> Epoch: 2237, cost 26.30 s
2024-01-02 10:07:07,035	44k	INFO	====> Epoch: 2238, cost 26.36 s
2024-01-02 10:07:33,342	44k	INFO	====> Epoch: 2239, cost 26.31 s
2024-01-02 10:07:59,663	44k	INFO	Train Epoch: 2240 [97%]
2024-01-02 10:07:59,664	44k	INFO	Losses: [1.913712501525879, 3.2932722568511963, 8.148674011230469, 14.859199523925781, 0.49428462982177734], step: 78400, lr: 7.558649973783121e-05, reference_loss: 28.709144592285156
2024-01-02 10:08:07,513	44k	INFO	Saving model and optimizer state at iteration 2240 to ./logs/44k/G_78400.pth
2024-01-02 10:08:08,412	44k	INFO	Saving model and optimizer state at iteration 2240 to ./logs/44k/D_78400.pth
2024-01-02 10:08:09,205	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_76000.pth
2024-01-02 10:08:09,265	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_76000.pth
2024-01-02 10:08:09,265	44k	INFO	====> Epoch: 2240, cost 35.92 s
2024-01-02 10:08:35,574	44k	INFO	====> Epoch: 2241, cost 26.31 s
2024-01-02 10:09:01,916	44k	INFO	====> Epoch: 2242, cost 26.34 s
2024-01-02 10:09:28,170	44k	INFO	====> Epoch: 2243, cost 26.25 s
2024-01-02 10:09:54,353	44k	INFO	====> Epoch: 2244, cost 26.18 s
2024-01-02 10:10:20,626	44k	INFO	====> Epoch: 2245, cost 26.27 s
2024-01-02 10:10:39,384	44k	INFO	Train Epoch: 2246 [69%]
2024-01-02 10:10:39,385	44k	INFO	Losses: [2.227799892425537, 2.63853120803833, 8.66894817352295, 14.895991325378418, 0.6459088325500488], step: 78600, lr: 7.552982757566138e-05, reference_loss: 29.077178955078125
2024-01-02 10:10:47,713	44k	INFO	====> Epoch: 2246, cost 27.09 s
2024-01-02 10:11:13,931	44k	INFO	====> Epoch: 2247, cost 26.22 s
2024-01-02 10:11:40,228	44k	INFO	====> Epoch: 2248, cost 26.30 s
2024-01-02 10:12:06,567	44k	INFO	====> Epoch: 2249, cost 26.34 s
2024-01-02 10:12:32,980	44k	INFO	====> Epoch: 2250, cost 26.41 s
2024-01-02 10:12:59,295	44k	INFO	====> Epoch: 2251, cost 26.31 s
2024-01-02 10:13:10,511	44k	INFO	Train Epoch: 2252 [40%]
2024-01-02 10:13:10,512	44k	INFO	Losses: [2.500930070877075, 2.326106071472168, 8.219125747680664, 17.416501998901367, 0.46525728702545166], step: 78800, lr: 7.547319790433284e-05, reference_loss: 30.927921295166016
2024-01-02 10:13:26,047	44k	INFO	====> Epoch: 2252, cost 26.75 s
2024-01-02 10:13:52,768	44k	INFO	====> Epoch: 2253, cost 26.72 s
2024-01-02 10:14:19,059	44k	INFO	====> Epoch: 2254, cost 26.29 s
2024-01-02 10:14:45,335	44k	INFO	====> Epoch: 2255, cost 26.28 s
2024-01-02 10:15:11,690	44k	INFO	====> Epoch: 2256, cost 26.35 s
2024-01-02 10:15:38,051	44k	INFO	====> Epoch: 2257, cost 26.36 s
2024-01-02 10:15:41,805	44k	INFO	Train Epoch: 2258 [11%]
2024-01-02 10:15:41,805	44k	INFO	Losses: [2.1822681427001953, 2.9652719497680664, 8.03189468383789, 16.045846939086914, 0.3700801730155945], step: 79000, lr: 7.541661069198744e-05, reference_loss: 29.595361709594727
2024-01-02 10:16:04,825	44k	INFO	====> Epoch: 2258, cost 26.77 s
2024-01-02 10:16:31,050	44k	INFO	====> Epoch: 2259, cost 26.23 s
2024-01-02 10:16:57,510	44k	INFO	====> Epoch: 2260, cost 26.46 s
2024-01-02 10:17:23,714	44k	INFO	====> Epoch: 2261, cost 26.20 s
2024-01-02 10:17:50,042	44k	INFO	====> Epoch: 2262, cost 26.33 s
2024-01-02 10:18:12,653	44k	INFO	Train Epoch: 2263 [83%]
2024-01-02 10:18:12,654	44k	INFO	Losses: [1.8721851110458374, 2.9354283809661865, 9.728507995605469, 14.877785682678223, 0.6013903617858887], step: 79200, lr: 7.536948709267746e-05, reference_loss: 30.015296936035156
2024-01-02 10:18:19,950	44k	INFO	Saving model and optimizer state at iteration 2263 to ./logs/44k/G_79200.pth
2024-01-02 10:18:20,853	44k	INFO	Saving model and optimizer state at iteration 2263 to ./logs/44k/D_79200.pth
2024-01-02 10:18:21,620	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_76800.pth
2024-01-02 10:18:21,678	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_76800.pth
2024-01-02 10:18:25,389	44k	INFO	====> Epoch: 2263, cost 35.35 s
2024-01-02 10:18:51,758	44k	INFO	====> Epoch: 2264, cost 26.37 s
2024-01-02 10:19:18,059	44k	INFO	====> Epoch: 2265, cost 26.30 s
2024-01-02 10:19:44,742	44k	INFO	====> Epoch: 2266, cost 26.68 s
2024-01-02 10:20:11,171	44k	INFO	====> Epoch: 2267, cost 26.43 s
2024-01-02 10:20:37,533	44k	INFO	====> Epoch: 2268, cost 26.36 s
2024-01-02 10:20:52,467	44k	INFO	Train Epoch: 2269 [54%]
2024-01-02 10:20:52,467	44k	INFO	Losses: [2.975865364074707, 2.347445249557495, 7.055736064910889, 15.410736083984375, 0.28448012471199036], step: 79400, lr: 7.531297763913763e-05, reference_loss: 28.074264526367188
2024-01-02 10:21:04,320	44k	INFO	====> Epoch: 2269, cost 26.79 s
2024-01-02 10:21:30,498	44k	INFO	====> Epoch: 2270, cost 26.18 s
2024-01-02 10:21:56,728	44k	INFO	====> Epoch: 2271, cost 26.23 s
2024-01-02 10:22:23,064	44k	INFO	====> Epoch: 2272, cost 26.34 s
2024-01-02 10:22:49,569	44k	INFO	====> Epoch: 2273, cost 26.50 s
2024-01-02 10:23:16,385	44k	INFO	====> Epoch: 2274, cost 26.82 s
2024-01-02 10:23:23,917	44k	INFO	Train Epoch: 2275 [26%]
2024-01-02 10:23:23,917	44k	INFO	Losses: [2.1023435592651367, 2.629349946975708, 10.44734001159668, 18.94991683959961, 0.7775505781173706], step: 79600, lr: 7.525651055444575e-05, reference_loss: 34.90650177001953
2024-01-02 10:23:43,309	44k	INFO	====> Epoch: 2275, cost 26.92 s
2024-01-02 10:24:09,692	44k	INFO	====> Epoch: 2276, cost 26.38 s
2024-01-02 10:24:36,122	44k	INFO	====> Epoch: 2277, cost 26.43 s
2024-01-02 10:25:02,596	44k	INFO	====> Epoch: 2278, cost 26.47 s
2024-01-02 10:25:28,993	44k	INFO	====> Epoch: 2279, cost 26.40 s
2024-01-02 10:25:55,468	44k	INFO	Train Epoch: 2280 [97%]
2024-01-02 10:25:55,469	44k	INFO	Losses: [2.3892741203308105, 2.358792781829834, 8.475781440734863, 17.501638412475586, 0.5981302261352539], step: 79800, lr: 7.520948699270922e-05, reference_loss: 31.32361602783203
2024-01-02 10:25:56,305	44k	INFO	====> Epoch: 2280, cost 27.31 s
2024-01-02 10:26:22,739	44k	INFO	====> Epoch: 2281, cost 26.43 s
2024-01-02 10:26:49,220	44k	INFO	====> Epoch: 2282, cost 26.48 s
2024-01-02 10:27:15,638	44k	INFO	====> Epoch: 2283, cost 26.42 s
2024-01-02 10:27:42,099	44k	INFO	====> Epoch: 2284, cost 26.46 s
2024-01-02 10:28:08,484	44k	INFO	====> Epoch: 2285, cost 26.38 s
2024-01-02 10:28:27,267	44k	INFO	Train Epoch: 2286 [69%]
2024-01-02 10:28:27,267	44k	INFO	Losses: [2.6562693119049072, 2.445289134979248, 7.995814323425293, 12.961265563964844, 0.5284465551376343], step: 80000, lr: 7.51530975017506e-05, reference_loss: 26.587085723876953
2024-01-02 10:28:34,861	44k	INFO	Saving model and optimizer state at iteration 2286 to ./logs/44k/G_80000.pth
2024-01-02 10:28:36,091	44k	INFO	Saving model and optimizer state at iteration 2286 to ./logs/44k/D_80000.pth
2024-01-02 10:28:36,870	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_77600.pth
2024-01-02 10:28:36,927	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_77600.pth
2024-01-02 10:28:44,529	44k	INFO	====> Epoch: 2286, cost 36.05 s
2024-01-02 10:29:10,924	44k	INFO	====> Epoch: 2287, cost 26.40 s
2024-01-02 10:29:37,202	44k	INFO	====> Epoch: 2288, cost 26.28 s
2024-01-02 10:30:03,480	44k	INFO	====> Epoch: 2289, cost 26.28 s
2024-01-02 10:30:29,908	44k	INFO	====> Epoch: 2290, cost 26.43 s
2024-01-02 10:30:56,267	44k	INFO	====> Epoch: 2291, cost 26.36 s
2024-01-02 10:31:07,466	44k	INFO	Train Epoch: 2292 [40%]
2024-01-02 10:31:07,467	44k	INFO	Losses: [2.069003105163574, 2.8115615844726562, 9.94782543182373, 17.879322052001953, 0.40986159443855286], step: 80200, lr: 7.50967502896961e-05, reference_loss: 33.11757278442383
2024-01-02 10:31:23,076	44k	INFO	====> Epoch: 2292, cost 26.81 s
2024-01-02 10:31:49,711	44k	INFO	====> Epoch: 2293, cost 26.64 s
2024-01-02 10:32:16,053	44k	INFO	====> Epoch: 2294, cost 26.34 s
2024-01-02 10:32:42,387	44k	INFO	====> Epoch: 2295, cost 26.33 s
2024-01-02 10:33:08,724	44k	INFO	====> Epoch: 2296, cost 26.34 s
2024-01-02 10:33:35,014	44k	INFO	====> Epoch: 2297, cost 26.29 s
2024-01-02 10:33:38,794	44k	INFO	Train Epoch: 2298 [11%]
2024-01-02 10:33:38,795	44k	INFO	Losses: [2.3110246658325195, 2.2220094203948975, 7.82120418548584, 17.516111373901367, 0.49727869033813477], step: 80400, lr: 7.504044532484646e-05, reference_loss: 30.36762809753418
2024-01-02 10:34:02,136	44k	INFO	====> Epoch: 2298, cost 27.12 s
2024-01-02 10:34:28,587	44k	INFO	====> Epoch: 2299, cost 26.45 s
2024-01-02 10:34:55,299	44k	INFO	====> Epoch: 2300, cost 26.71 s
2024-01-02 10:35:21,658	44k	INFO	====> Epoch: 2301, cost 26.36 s
2024-01-02 10:35:48,132	44k	INFO	====> Epoch: 2302, cost 26.47 s
2024-01-02 10:36:10,732	44k	INFO	Train Epoch: 2303 [83%]
2024-01-02 10:36:10,733	44k	INFO	Losses: [2.171396255493164, 2.6517841815948486, 9.080252647399902, 16.633878707885742, 0.6354624629020691], step: 80600, lr: 7.499355677012246e-05, reference_loss: 31.172773361206055
2024-01-02 10:36:15,167	44k	INFO	====> Epoch: 2303, cost 27.03 s
2024-01-02 10:36:41,574	44k	INFO	====> Epoch: 2304, cost 26.41 s
2024-01-02 10:37:08,038	44k	INFO	====> Epoch: 2305, cost 26.46 s
2024-01-02 10:37:34,505	44k	INFO	====> Epoch: 2306, cost 26.47 s
2024-01-02 10:38:01,225	44k	INFO	====> Epoch: 2307, cost 26.72 s
2024-01-02 10:38:27,639	44k	INFO	====> Epoch: 2308, cost 26.41 s
2024-01-02 10:38:42,663	44k	INFO	Train Epoch: 2309 [54%]
2024-01-02 10:38:42,664	44k	INFO	Losses: [2.04571533203125, 2.7381839752197266, 10.805068969726562, 16.867265701293945, 0.6165539026260376], step: 80800, lr: 7.493732917623055e-05, reference_loss: 33.07278823852539
2024-01-02 10:38:50,179	44k	INFO	Saving model and optimizer state at iteration 2309 to ./logs/44k/G_80800.pth
2024-01-02 10:38:51,082	44k	INFO	Saving model and optimizer state at iteration 2309 to ./logs/44k/D_80800.pth
2024-01-02 10:38:51,862	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_78400.pth
2024-01-02 10:38:51,918	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_78400.pth
2024-01-02 10:39:03,266	44k	INFO	====> Epoch: 2309, cost 35.63 s
2024-01-02 10:39:29,617	44k	INFO	====> Epoch: 2310, cost 26.35 s
2024-01-02 10:39:55,855	44k	INFO	====> Epoch: 2311, cost 26.24 s
2024-01-02 10:40:22,292	44k	INFO	====> Epoch: 2312, cost 26.44 s
2024-01-02 10:40:49,032	44k	INFO	====> Epoch: 2313, cost 26.74 s
2024-01-02 10:41:15,452	44k	INFO	====> Epoch: 2314, cost 26.42 s
2024-01-02 10:41:22,970	44k	INFO	Train Epoch: 2315 [26%]
2024-01-02 10:41:22,971	44k	INFO	Losses: [2.349623203277588, 2.65718412399292, 7.978773593902588, 16.60211944580078, 0.6733703017234802], step: 81000, lr: 7.488114373985791e-05, reference_loss: 30.261070251464844
2024-01-02 10:41:42,432	44k	INFO	====> Epoch: 2315, cost 26.98 s
2024-01-02 10:42:08,782	44k	INFO	====> Epoch: 2316, cost 26.35 s
2024-01-02 10:42:35,156	44k	INFO	====> Epoch: 2317, cost 26.37 s
2024-01-02 10:43:01,462	44k	INFO	====> Epoch: 2318, cost 26.31 s
2024-01-02 10:43:27,929	44k	INFO	====> Epoch: 2319, cost 26.47 s
2024-01-02 10:43:54,254	44k	INFO	Train Epoch: 2320 [97%]
2024-01-02 10:43:54,254	44k	INFO	Losses: [2.467587471008301, 2.5308852195739746, 8.473848342895508, 17.42719268798828, 0.4241487979888916], step: 81200, lr: 7.483435472373676e-05, reference_loss: 31.32366180419922
2024-01-02 10:43:55,078	44k	INFO	====> Epoch: 2320, cost 27.15 s
2024-01-02 10:44:21,344	44k	INFO	====> Epoch: 2321, cost 26.27 s
2024-01-02 10:44:47,542	44k	INFO	====> Epoch: 2322, cost 26.20 s
2024-01-02 10:45:13,795	44k	INFO	====> Epoch: 2323, cost 26.25 s
2024-01-02 10:45:40,104	44k	INFO	====> Epoch: 2324, cost 26.31 s
2024-01-02 10:46:06,453	44k	INFO	====> Epoch: 2325, cost 26.35 s
2024-01-02 10:46:25,244	44k	INFO	Train Epoch: 2326 [69%]
2024-01-02 10:46:25,245	44k	INFO	Losses: [1.7827489376068115, 3.420433282852173, 10.02173900604248, 16.488222122192383, 0.6327648758888245], step: 81400, lr: 7.47782464940729e-05, reference_loss: 32.345909118652344
2024-01-02 10:46:33,250	44k	INFO	====> Epoch: 2326, cost 26.80 s
2024-01-02 10:47:00,003	44k	INFO	====> Epoch: 2327, cost 26.75 s
2024-01-02 10:47:26,374	44k	INFO	====> Epoch: 2328, cost 26.37 s
2024-01-02 10:47:52,766	44k	INFO	====> Epoch: 2329, cost 26.39 s
2024-01-02 10:48:19,249	44k	INFO	====> Epoch: 2330, cost 26.48 s
2024-01-02 10:48:45,655	44k	INFO	====> Epoch: 2331, cost 26.41 s
2024-01-02 10:48:56,913	44k	INFO	Train Epoch: 2332 [40%]
2024-01-02 10:48:56,913	44k	INFO	Losses: [2.335069417953491, 2.542804718017578, 9.671018600463867, 18.200815200805664, 0.4851115643978119], step: 81600, lr: 7.472218033243309e-05, reference_loss: 33.23482131958008
2024-01-02 10:49:04,503	44k	INFO	Saving model and optimizer state at iteration 2332 to ./logs/44k/G_81600.pth
2024-01-02 10:49:05,418	44k	INFO	Saving model and optimizer state at iteration 2332 to ./logs/44k/D_81600.pth
2024-01-02 10:49:06,199	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_79200.pth
2024-01-02 10:49:06,255	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_79200.pth
2024-01-02 10:49:21,725	44k	INFO	====> Epoch: 2332, cost 36.07 s
2024-01-02 10:49:48,029	44k	INFO	====> Epoch: 2333, cost 26.30 s
2024-01-02 10:50:14,473	44k	INFO	====> Epoch: 2334, cost 26.44 s
2024-01-02 10:50:40,955	44k	INFO	====> Epoch: 2335, cost 26.48 s
2024-01-02 10:51:07,404	44k	INFO	====> Epoch: 2336, cost 26.45 s
2024-01-02 10:51:33,829	44k	INFO	====> Epoch: 2337, cost 26.42 s
2024-01-02 10:51:37,594	44k	INFO	Train Epoch: 2338 [11%]
2024-01-02 10:51:37,594	44k	INFO	Losses: [1.8379747867584229, 3.674038887023926, 9.617044448852539, 15.866783142089844, 0.5255788564682007], step: 81800, lr: 7.466615620727619e-05, reference_loss: 31.521421432495117
2024-01-02 10:52:00,737	44k	INFO	====> Epoch: 2338, cost 26.91 s
2024-01-02 10:52:27,149	44k	INFO	====> Epoch: 2339, cost 26.41 s
2024-01-02 10:52:53,575	44k	INFO	====> Epoch: 2340, cost 26.43 s
2024-01-02 10:53:20,280	44k	INFO	====> Epoch: 2341, cost 26.71 s
2024-01-02 10:53:46,675	44k	INFO	====> Epoch: 2342, cost 26.39 s
2024-01-02 10:54:09,299	44k	INFO	Train Epoch: 2343 [83%]
2024-01-02 10:54:09,300	44k	INFO	Losses: [2.2626044750213623, 2.609600782394409, 7.453399658203125, 16.959735870361328, 0.6052003502845764], step: 82000, lr: 7.46195015247753e-05, reference_loss: 29.890541076660156
2024-01-02 10:54:13,662	44k	INFO	====> Epoch: 2343, cost 26.99 s
2024-01-02 10:54:40,001	44k	INFO	====> Epoch: 2344, cost 26.34 s
2024-01-02 10:55:06,439	44k	INFO	====> Epoch: 2345, cost 26.44 s
2024-01-02 10:55:32,799	44k	INFO	====> Epoch: 2346, cost 26.36 s
2024-01-02 10:55:59,074	44k	INFO	====> Epoch: 2347, cost 26.28 s
2024-01-02 10:56:25,421	44k	INFO	====> Epoch: 2348, cost 26.35 s
2024-01-02 10:56:40,717	44k	INFO	Train Epoch: 2349 [54%]
2024-01-02 10:56:40,717	44k	INFO	Losses: [2.4693667888641357, 2.479055166244507, 9.358779907226562, 17.46886444091797, 0.49159759283065796], step: 82200, lr: 7.456355438466281e-05, reference_loss: 32.267662048339844
2024-01-02 10:56:52,558	44k	INFO	====> Epoch: 2349, cost 27.14 s
2024-01-02 10:57:19,026	44k	INFO	====> Epoch: 2350, cost 26.47 s
2024-01-02 10:57:45,492	44k	INFO	====> Epoch: 2351, cost 26.47 s
2024-01-02 10:58:11,876	44k	INFO	====> Epoch: 2352, cost 26.38 s
2024-01-02 10:58:38,283	44k	INFO	====> Epoch: 2353, cost 26.41 s
2024-01-02 10:59:04,661	44k	INFO	====> Epoch: 2354, cost 26.38 s
2024-01-02 10:59:12,146	44k	INFO	Train Epoch: 2355 [26%]
2024-01-02 10:59:12,147	44k	INFO	Losses: [2.125680923461914, 2.7056336402893066, 9.002615928649902, 16.855052947998047, 0.48038947582244873], step: 82400, lr: 7.450764919179499e-05, reference_loss: 31.16937255859375
2024-01-02 10:59:19,887	44k	INFO	Saving model and optimizer state at iteration 2355 to ./logs/44k/G_82400.pth
2024-01-02 10:59:20,785	44k	INFO	Saving model and optimizer state at iteration 2355 to ./logs/44k/D_82400.pth
2024-01-02 10:59:21,573	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_80000.pth
2024-01-02 10:59:21,630	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_80000.pth
2024-01-02 10:59:40,445	44k	INFO	====> Epoch: 2355, cost 35.78 s
2024-01-02 11:00:06,824	44k	INFO	====> Epoch: 2356, cost 26.38 s
2024-01-02 11:00:33,241	44k	INFO	====> Epoch: 2357, cost 26.42 s
2024-01-02 11:00:59,540	44k	INFO	====> Epoch: 2358, cost 26.30 s
2024-01-02 11:01:25,976	44k	INFO	====> Epoch: 2359, cost 26.44 s
2024-01-02 11:01:52,380	44k	INFO	Train Epoch: 2360 [97%]
2024-01-02 11:01:52,380	44k	INFO	Losses: [2.237041473388672, 2.517214059829712, 10.018265724182129, 18.7366886138916, 0.3900914192199707], step: 82600, lr: 7.446109355141515e-05, reference_loss: 33.89929962158203
2024-01-02 11:01:53,321	44k	INFO	====> Epoch: 2360, cost 27.34 s
2024-01-02 11:02:19,671	44k	INFO	====> Epoch: 2361, cost 26.35 s
2024-01-02 11:02:45,949	44k	INFO	====> Epoch: 2362, cost 26.28 s
2024-01-02 11:03:12,207	44k	INFO	====> Epoch: 2363, cost 26.26 s
2024-01-02 11:03:38,516	44k	INFO	====> Epoch: 2364, cost 26.31 s
2024-01-02 11:04:04,922	44k	INFO	====> Epoch: 2365, cost 26.41 s
2024-01-02 11:04:23,712	44k	INFO	Train Epoch: 2366 [69%]
2024-01-02 11:04:23,712	44k	INFO	Losses: [2.320098638534546, 2.607088088989258, 9.25316047668457, 16.156761169433594, 0.694121241569519], step: 82800, lr: 7.440526518016201e-05, reference_loss: 31.03122901916504
2024-01-02 11:04:31,691	44k	INFO	====> Epoch: 2366, cost 26.77 s
2024-01-02 11:04:58,397	44k	INFO	====> Epoch: 2367, cost 26.71 s
2024-01-02 11:05:24,805	44k	INFO	====> Epoch: 2368, cost 26.41 s
2024-01-02 11:05:51,174	44k	INFO	====> Epoch: 2369, cost 26.37 s
2024-01-02 11:06:17,580	44k	INFO	====> Epoch: 2370, cost 26.41 s
2024-01-02 11:06:43,848	44k	INFO	====> Epoch: 2371, cost 26.27 s
2024-01-02 11:06:55,096	44k	INFO	Train Epoch: 2372 [40%]
2024-01-02 11:06:55,097	44k	INFO	Losses: [2.5906853675842285, 2.003371477127075, 7.269975662231445, 15.719891548156738, 0.6704327464103699], step: 83000, lr: 7.434947866710472e-05, reference_loss: 28.254356384277344
2024-01-02 11:07:10,832	44k	INFO	====> Epoch: 2372, cost 26.98 s
2024-01-02 11:07:37,145	44k	INFO	====> Epoch: 2373, cost 26.31 s
2024-01-02 11:08:03,420	44k	INFO	====> Epoch: 2374, cost 26.28 s
2024-01-02 11:08:30,062	44k	INFO	====> Epoch: 2375, cost 26.64 s
2024-01-02 11:08:56,554	44k	INFO	====> Epoch: 2376, cost 26.49 s
2024-01-02 11:09:23,002	44k	INFO	====> Epoch: 2377, cost 26.45 s
2024-01-02 11:09:26,781	44k	INFO	Train Epoch: 2378 [11%]
2024-01-02 11:09:26,782	44k	INFO	Losses: [2.6108787059783936, 2.307098865509033, 7.2242751121521, 16.012901306152344, 0.70670485496521], step: 83200, lr: 7.429373398085944e-05, reference_loss: 28.861858367919922
2024-01-02 11:09:34,339	44k	INFO	Saving model and optimizer state at iteration 2378 to ./logs/44k/G_83200.pth
2024-01-02 11:09:35,246	44k	INFO	Saving model and optimizer state at iteration 2378 to ./logs/44k/D_83200.pth
2024-01-02 11:09:36,016	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_80800.pth
2024-01-02 11:09:36,072	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_80800.pth
2024-01-02 11:09:58,675	44k	INFO	====> Epoch: 2378, cost 35.67 s
2024-01-02 11:10:25,132	44k	INFO	====> Epoch: 2379, cost 26.46 s
2024-01-02 11:10:51,917	44k	INFO	====> Epoch: 2380, cost 26.78 s
2024-01-02 11:11:18,301	44k	INFO	====> Epoch: 2381, cost 26.38 s
2024-01-02 11:11:44,738	44k	INFO	====> Epoch: 2382, cost 26.44 s
2024-01-02 11:12:07,402	44k	INFO	Train Epoch: 2383 [83%]
2024-01-02 11:12:07,402	44k	INFO	Losses: [2.184124708175659, 3.1798617839813232, 7.941161632537842, 14.642416000366211, 0.40898334980010986], step: 83400, lr: 7.424731200406636e-05, reference_loss: 28.35654640197754
2024-01-02 11:12:11,676	44k	INFO	====> Epoch: 2383, cost 26.94 s
2024-01-02 11:12:38,093	44k	INFO	====> Epoch: 2384, cost 26.42 s
2024-01-02 11:13:04,430	44k	INFO	====> Epoch: 2385, cost 26.34 s
2024-01-02 11:13:30,738	44k	INFO	====> Epoch: 2386, cost 26.31 s
2024-01-02 11:13:57,170	44k	INFO	====> Epoch: 2387, cost 26.43 s
2024-01-02 11:14:23,932	44k	INFO	====> Epoch: 2388, cost 26.76 s
2024-01-02 11:14:38,855	44k	INFO	Train Epoch: 2389 [54%]
2024-01-02 11:14:38,856	44k	INFO	Losses: [2.0162878036499023, 2.8798325061798096, 8.73275375366211, 16.053264617919922, 0.5949251651763916], step: 83600, lr: 7.419164391887705e-05, reference_loss: 30.277063369750977
2024-01-02 11:14:50,757	44k	INFO	====> Epoch: 2389, cost 26.83 s
2024-01-02 11:15:17,245	44k	INFO	====> Epoch: 2390, cost 26.49 s
2024-01-02 11:15:43,582	44k	INFO	====> Epoch: 2391, cost 26.34 s
2024-01-02 11:16:09,749	44k	INFO	====> Epoch: 2392, cost 26.17 s
2024-01-02 11:16:36,122	44k	INFO	====> Epoch: 2393, cost 26.37 s
2024-01-02 11:17:02,602	44k	INFO	====> Epoch: 2394, cost 26.48 s
2024-01-02 11:17:10,141	44k	INFO	Train Epoch: 2395 [26%]
2024-01-02 11:17:10,141	44k	INFO	Losses: [2.6863248348236084, 2.560889720916748, 7.491023063659668, 15.118094444274902, 0.5495245456695557], step: 83800, lr: 7.413601757170658e-05, reference_loss: 28.405855178833008
2024-01-02 11:17:29,928	44k	INFO	====> Epoch: 2395, cost 27.33 s
2024-01-02 11:17:56,320	44k	INFO	====> Epoch: 2396, cost 26.39 s
2024-01-02 11:18:22,802	44k	INFO	====> Epoch: 2397, cost 26.48 s
2024-01-02 11:18:49,146	44k	INFO	====> Epoch: 2398, cost 26.34 s
2024-01-02 11:19:15,549	44k	INFO	====> Epoch: 2399, cost 26.40 s
2024-01-02 11:19:41,983	44k	INFO	Train Epoch: 2400 [97%]
2024-01-02 11:19:41,983	44k	INFO	Losses: [1.7010986804962158, 3.552626132965088, 9.639476776123047, 14.932116508483887, 0.5330019593238831], step: 84000, lr: 7.408969414302911e-05, reference_loss: 30.358320236206055
2024-01-02 11:19:49,578	44k	INFO	Saving model and optimizer state at iteration 2400 to ./logs/44k/G_84000.pth
2024-01-02 11:19:50,817	44k	INFO	Saving model and optimizer state at iteration 2400 to ./logs/44k/D_84000.pth
2024-01-02 11:19:51,606	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_81600.pth
2024-01-02 11:19:51,663	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_81600.pth
2024-01-02 11:19:51,663	44k	INFO	====> Epoch: 2400, cost 36.11 s
2024-01-02 11:20:17,922	44k	INFO	====> Epoch: 2401, cost 26.26 s
2024-01-02 11:20:44,238	44k	INFO	====> Epoch: 2402, cost 26.32 s
2024-01-02 11:21:10,559	44k	INFO	====> Epoch: 2403, cost 26.32 s
2024-01-02 11:21:36,895	44k	INFO	====> Epoch: 2404, cost 26.34 s
2024-01-02 11:22:03,305	44k	INFO	====> Epoch: 2405, cost 26.41 s
2024-01-02 11:22:22,155	44k	INFO	Train Epoch: 2406 [69%]
2024-01-02 11:22:22,155	44k	INFO	Losses: [2.216946840286255, 2.662693977355957, 9.467087745666504, 16.46759605407715, 0.5820448994636536], step: 84200, lr: 7.403414423430003e-05, reference_loss: 31.3963680267334
2024-01-02 11:22:30,372	44k	INFO	====> Epoch: 2406, cost 27.07 s
2024-01-02 11:22:56,979	44k	INFO	====> Epoch: 2407, cost 26.61 s
2024-01-02 11:23:23,261	44k	INFO	====> Epoch: 2408, cost 26.28 s
2024-01-02 11:23:49,614	44k	INFO	====> Epoch: 2409, cost 26.35 s
2024-01-02 11:24:16,034	44k	INFO	====> Epoch: 2410, cost 26.42 s
2024-01-02 11:24:42,489	44k	INFO	====> Epoch: 2411, cost 26.45 s
2024-01-02 11:24:53,765	44k	INFO	Train Epoch: 2412 [40%]
2024-01-02 11:24:53,765	44k	INFO	Losses: [2.049560308456421, 3.018522024154663, 9.773673057556152, 17.350875854492188, 0.4579685628414154], step: 84400, lr: 7.397863597498516e-05, reference_loss: 32.65060043334961
2024-01-02 11:25:09,603	44k	INFO	====> Epoch: 2412, cost 27.11 s
2024-01-02 11:25:36,056	44k	INFO	====> Epoch: 2413, cost 26.45 s
2024-01-02 11:26:02,439	44k	INFO	====> Epoch: 2414, cost 26.38 s
2024-01-02 11:26:29,194	44k	INFO	====> Epoch: 2415, cost 26.76 s
2024-01-02 11:26:55,617	44k	INFO	====> Epoch: 2416, cost 26.42 s
2024-01-02 11:27:22,065	44k	INFO	====> Epoch: 2417, cost 26.45 s
2024-01-02 11:27:25,844	44k	INFO	Train Epoch: 2418 [11%]
2024-01-02 11:27:25,844	44k	INFO	Losses: [2.0498220920562744, 2.968532085418701, 9.269100189208984, 15.873543739318848, 0.3410722315311432], step: 84600, lr: 7.392316933385719e-05, reference_loss: 30.502071380615234
2024-01-02 11:27:49,018	44k	INFO	====> Epoch: 2418, cost 26.95 s
2024-01-02 11:28:15,491	44k	INFO	====> Epoch: 2419, cost 26.47 s
2024-01-02 11:28:41,930	44k	INFO	====> Epoch: 2420, cost 26.44 s
2024-01-02 11:29:08,398	44k	INFO	====> Epoch: 2421, cost 26.47 s
2024-01-02 11:29:35,123	44k	INFO	====> Epoch: 2422, cost 26.73 s
2024-01-02 11:29:57,747	44k	INFO	Train Epoch: 2423 [83%]
2024-01-02 11:29:57,748	44k	INFO	Losses: [2.282238483428955, 2.2946839332580566, 8.656975746154785, 14.687604904174805, 0.572238564491272], step: 84800, lr: 7.3876978902075e-05, reference_loss: 28.493741989135742
2024-01-02 11:30:05,187	44k	INFO	Saving model and optimizer state at iteration 2423 to ./logs/44k/G_84800.pth
2024-01-02 11:30:06,074	44k	INFO	Saving model and optimizer state at iteration 2423 to ./logs/44k/D_84800.pth
2024-01-02 11:30:06,842	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_82400.pth
2024-01-02 11:30:06,900	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_82400.pth
2024-01-02 11:30:10,647	44k	INFO	====> Epoch: 2423, cost 35.52 s
2024-01-02 11:30:37,064	44k	INFO	====> Epoch: 2424, cost 26.42 s
2024-01-02 11:31:03,517	44k	INFO	====> Epoch: 2425, cost 26.45 s
2024-01-02 11:31:29,961	44k	INFO	====> Epoch: 2426, cost 26.44 s
2024-01-02 11:31:56,578	44k	INFO	====> Epoch: 2427, cost 26.62 s
2024-01-02 11:32:22,961	44k	INFO	====> Epoch: 2428, cost 26.38 s
2024-01-02 11:32:37,990	44k	INFO	Train Epoch: 2429 [54%]
2024-01-02 11:32:37,991	44k	INFO	Losses: [2.1635944843292236, 2.6938605308532715, 8.192704200744629, 15.497079849243164, 0.30258846282958984], step: 85000, lr: 7.382158847992981e-05, reference_loss: 28.84982681274414
2024-01-02 11:32:49,811	44k	INFO	====> Epoch: 2429, cost 26.85 s
2024-01-02 11:33:16,098	44k	INFO	====> Epoch: 2430, cost 26.29 s
2024-01-02 11:33:42,366	44k	INFO	====> Epoch: 2431, cost 26.27 s
2024-01-02 11:34:08,633	44k	INFO	====> Epoch: 2432, cost 26.27 s
2024-01-02 11:34:35,004	44k	INFO	====> Epoch: 2433, cost 26.37 s
2024-01-02 11:35:01,393	44k	INFO	====> Epoch: 2434, cost 26.39 s
2024-01-02 11:35:08,906	44k	INFO	Train Epoch: 2435 [26%]
2024-01-02 11:35:08,907	44k	INFO	Losses: [2.390033483505249, 2.4714417457580566, 8.879197120666504, 17.74140167236328, 0.7968793511390686], step: 85200, lr: 7.376623958762127e-05, reference_loss: 32.278953552246094
2024-01-02 11:35:28,591	44k	INFO	====> Epoch: 2435, cost 27.20 s
2024-01-02 11:35:54,994	44k	INFO	====> Epoch: 2436, cost 26.40 s
2024-01-02 11:36:21,371	44k	INFO	====> Epoch: 2437, cost 26.38 s
2024-01-02 11:36:47,728	44k	INFO	====> Epoch: 2438, cost 26.36 s
2024-01-02 11:37:14,240	44k	INFO	====> Epoch: 2439, cost 26.51 s
2024-01-02 11:37:40,678	44k	INFO	Train Epoch: 2440 [97%]
2024-01-02 11:37:40,678	44k	INFO	Losses: [2.5060105323791504, 2.270292282104492, 7.859692096710205, 16.328815460205078, 0.5809065103530884], step: 85400, lr: 7.372014721241325e-05, reference_loss: 29.54571533203125
2024-01-02 11:37:41,171	44k	INFO	====> Epoch: 2440, cost 26.93 s
2024-01-02 11:38:07,858	44k	INFO	====> Epoch: 2441, cost 26.69 s
2024-01-02 11:38:34,258	44k	INFO	====> Epoch: 2442, cost 26.40 s
2024-01-02 11:39:00,559	44k	INFO	====> Epoch: 2443, cost 26.30 s
2024-01-02 11:39:26,950	44k	INFO	====> Epoch: 2444, cost 26.39 s
2024-01-02 11:39:53,201	44k	INFO	====> Epoch: 2445, cost 26.25 s
2024-01-02 11:40:11,914	44k	INFO	Train Epoch: 2446 [69%]
2024-01-02 11:40:11,914	44k	INFO	Losses: [1.6612801551818848, 3.5262529850006104, 10.508515357971191, 14.776344299316406, 0.567165732383728], step: 85600, lr: 7.3664874377284e-05, reference_loss: 31.03955841064453
2024-01-02 11:40:19,359	44k	INFO	Saving model and optimizer state at iteration 2446 to ./logs/44k/G_85600.pth
2024-01-02 11:40:20,248	44k	INFO	Saving model and optimizer state at iteration 2446 to ./logs/44k/D_85600.pth
2024-01-02 11:40:21,031	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_83200.pth
2024-01-02 11:40:21,087	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_83200.pth
2024-01-02 11:40:28,675	44k	INFO	====> Epoch: 2446, cost 35.47 s
2024-01-02 11:40:55,319	44k	INFO	====> Epoch: 2447, cost 26.64 s
2024-01-02 11:41:21,568	44k	INFO	====> Epoch: 2448, cost 26.25 s
2024-01-02 11:41:47,777	44k	INFO	====> Epoch: 2449, cost 26.21 s
2024-01-02 11:42:14,129	44k	INFO	====> Epoch: 2450, cost 26.35 s
2024-01-02 11:42:40,473	44k	INFO	====> Epoch: 2451, cost 26.34 s
2024-01-02 11:42:51,719	44k	INFO	Train Epoch: 2452 [40%]
2024-01-02 11:42:51,720	44k	INFO	Losses: [2.3792307376861572, 2.681330442428589, 8.953316688537598, 17.338356018066406, 0.3857065737247467], step: 85800, lr: 7.360964298382869e-05, reference_loss: 31.737939834594727
2024-01-02 11:43:07,439	44k	INFO	====> Epoch: 2452, cost 26.97 s
2024-01-02 11:43:33,731	44k	INFO	====> Epoch: 2453, cost 26.29 s
2024-01-02 11:44:00,096	44k	INFO	====> Epoch: 2454, cost 26.36 s
2024-01-02 11:44:26,456	44k	INFO	====> Epoch: 2455, cost 26.36 s
2024-01-02 11:44:53,170	44k	INFO	====> Epoch: 2456, cost 26.71 s
2024-01-02 11:45:19,648	44k	INFO	====> Epoch: 2457, cost 26.48 s
2024-01-02 11:45:23,423	44k	INFO	Train Epoch: 2458 [11%]
2024-01-02 11:45:23,423	44k	INFO	Losses: [1.8877575397491455, 3.1774697303771973, 9.988669395446777, 17.603437423706055, 0.3978211581707001], step: 86000, lr: 7.355445300097575e-05, reference_loss: 33.055152893066406
2024-01-02 11:45:46,599	44k	INFO	====> Epoch: 2458, cost 26.95 s
2024-01-02 11:46:13,108	44k	INFO	====> Epoch: 2459, cost 26.51 s
2024-01-02 11:46:39,550	44k	INFO	====> Epoch: 2460, cost 26.44 s
2024-01-02 11:47:06,007	44k	INFO	====> Epoch: 2461, cost 26.46 s
2024-01-02 11:47:32,491	44k	INFO	====> Epoch: 2462, cost 26.48 s
2024-01-02 11:47:55,466	44k	INFO	Train Epoch: 2463 [83%]
2024-01-02 11:47:55,467	44k	INFO	Losses: [2.1680214405059814, 2.941946029663086, 9.077919006347656, 15.875665664672852, 0.56744784116745], step: 86200, lr: 7.350849295929688e-05, reference_loss: 30.631000518798828
2024-01-02 11:47:59,739	44k	INFO	====> Epoch: 2463, cost 27.25 s
2024-01-02 11:48:26,261	44k	INFO	====> Epoch: 2464, cost 26.52 s
2024-01-02 11:48:52,688	44k	INFO	====> Epoch: 2465, cost 26.43 s
2024-01-02 11:49:19,120	44k	INFO	====> Epoch: 2466, cost 26.43 s
2024-01-02 11:49:45,612	44k	INFO	====> Epoch: 2467, cost 26.49 s
2024-01-02 11:50:11,992	44k	INFO	====> Epoch: 2468, cost 26.38 s
2024-01-02 11:50:27,018	44k	INFO	Train Epoch: 2469 [54%]
2024-01-02 11:50:27,019	44k	INFO	Losses: [2.238414764404297, 2.3492748737335205, 10.219422340393066, 16.494754791259766, 0.6180458664894104], step: 86400, lr: 7.345337881525929e-05, reference_loss: 31.919912338256836
2024-01-02 11:50:34,905	44k	INFO	Saving model and optimizer state at iteration 2469 to ./logs/44k/G_86400.pth
2024-01-02 11:50:35,797	44k	INFO	Saving model and optimizer state at iteration 2469 to ./logs/44k/D_86400.pth
2024-01-02 11:50:36,582	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_84000.pth
2024-01-02 11:50:36,640	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_84000.pth
2024-01-02 11:50:48,109	44k	INFO	====> Epoch: 2469, cost 36.12 s
2024-01-02 11:51:14,361	44k	INFO	====> Epoch: 2470, cost 26.25 s
2024-01-02 11:51:40,832	44k	INFO	====> Epoch: 2471, cost 26.47 s
2024-01-02 11:52:07,317	44k	INFO	====> Epoch: 2472, cost 26.48 s
2024-01-02 11:52:33,753	44k	INFO	====> Epoch: 2473, cost 26.44 s
2024-01-02 11:53:00,091	44k	INFO	====> Epoch: 2474, cost 26.34 s
2024-01-02 11:53:07,599	44k	INFO	Train Epoch: 2475 [26%]
2024-01-02 11:53:07,599	44k	INFO	Losses: [2.1082584857940674, 2.8505730628967285, 8.22716236114502, 15.726082801818848, 0.6157160997390747], step: 86600, lr: 7.33983059939145e-05, reference_loss: 29.527793884277344
2024-01-02 11:53:27,326	44k	INFO	====> Epoch: 2475, cost 27.24 s
2024-01-02 11:53:53,553	44k	INFO	====> Epoch: 2476, cost 26.23 s
2024-01-02 11:54:19,804	44k	INFO	====> Epoch: 2477, cost 26.25 s
2024-01-02 11:54:46,146	44k	INFO	====> Epoch: 2478, cost 26.34 s
2024-01-02 11:55:12,427	44k	INFO	====> Epoch: 2479, cost 26.28 s
2024-01-02 11:55:38,873	44k	INFO	Train Epoch: 2480 [97%]
2024-01-02 11:55:38,873	44k	INFO	Losses: [2.4861059188842773, 2.5013070106506348, 7.411763668060303, 15.759313583374023, 0.3867892324924469], step: 86800, lr: 7.335244351972012e-05, reference_loss: 28.545278549194336
2024-01-02 11:55:39,365	44k	INFO	====> Epoch: 2480, cost 26.94 s
2024-01-02 11:56:05,795	44k	INFO	====> Epoch: 2481, cost 26.43 s
2024-01-02 11:56:32,414	44k	INFO	====> Epoch: 2482, cost 26.62 s
2024-01-02 11:56:58,857	44k	INFO	====> Epoch: 2483, cost 26.44 s
2024-01-02 11:57:25,242	44k	INFO	====> Epoch: 2484, cost 26.39 s
2024-01-02 11:57:51,614	44k	INFO	====> Epoch: 2485, cost 26.37 s
2024-01-02 11:58:10,458	44k	INFO	Train Epoch: 2486 [69%]
2024-01-02 11:58:10,459	44k	INFO	Losses: [2.5692992210388184, 2.1588923931121826, 7.737953186035156, 15.974255561828613, 0.5340882539749146], step: 87000, lr: 7.32974463761942e-05, reference_loss: 28.9744873046875
2024-01-02 11:58:18,658	44k	INFO	====> Epoch: 2486, cost 27.04 s
2024-01-02 11:58:45,072	44k	INFO	====> Epoch: 2487, cost 26.41 s
2024-01-02 11:59:11,499	44k	INFO	====> Epoch: 2488, cost 26.43 s
2024-01-02 11:59:38,123	44k	INFO	====> Epoch: 2489, cost 26.62 s
2024-01-02 12:00:04,493	44k	INFO	====> Epoch: 2490, cost 26.37 s
2024-01-02 12:00:30,810	44k	INFO	====> Epoch: 2491, cost 26.32 s
2024-01-02 12:00:41,997	44k	INFO	Train Epoch: 2492 [40%]
2024-01-02 12:00:41,998	44k	INFO	Losses: [2.403604745864868, 2.5156428813934326, 9.560064315795898, 18.486604690551758, 0.5798099040985107], step: 87200, lr: 7.324249046763813e-05, reference_loss: 33.54572677612305
2024-01-02 12:00:49,775	44k	INFO	Saving model and optimizer state at iteration 2492 to ./logs/44k/G_87200.pth
2024-01-02 12:00:50,671	44k	INFO	Saving model and optimizer state at iteration 2492 to ./logs/44k/D_87200.pth
2024-01-02 12:00:51,447	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_84800.pth
2024-01-02 12:00:51,503	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_84800.pth
2024-01-02 12:01:06,632	44k	INFO	====> Epoch: 2492, cost 35.82 s
2024-01-02 12:01:33,043	44k	INFO	====> Epoch: 2493, cost 26.41 s
2024-01-02 12:01:59,698	44k	INFO	====> Epoch: 2494, cost 26.65 s
2024-01-02 12:02:26,145	44k	INFO	====> Epoch: 2495, cost 26.45 s
2024-01-02 12:02:52,589	44k	INFO	====> Epoch: 2496, cost 26.44 s
2024-01-02 12:03:18,990	44k	INFO	====> Epoch: 2497, cost 26.40 s
2024-01-02 12:03:22,770	44k	INFO	Train Epoch: 2498 [11%]
2024-01-02 12:03:22,771	44k	INFO	Losses: [2.5712778568267822, 2.3095622062683105, 7.564208030700684, 15.765360832214355, 0.49333152174949646], step: 87400, lr: 7.31875757631353e-05, reference_loss: 28.7037410736084
2024-01-02 12:03:45,842	44k	INFO	====> Epoch: 2498, cost 26.85 s
2024-01-02 12:04:12,141	44k	INFO	====> Epoch: 2499, cost 26.30 s
2024-01-02 12:04:38,441	44k	INFO	====> Epoch: 2500, cost 26.30 s
2024-01-02 12:05:04,810	44k	INFO	====> Epoch: 2501, cost 26.37 s
2024-01-02 12:05:31,152	44k	INFO	====> Epoch: 2502, cost 26.34 s
2024-01-02 12:05:53,931	44k	INFO	Train Epoch: 2503 [83%]
2024-01-02 12:05:53,932	44k	INFO	Losses: [2.309028148651123, 2.418006181716919, 7.714252471923828, 17.378864288330078, 0.5536737442016602], step: 87600, lr: 7.314184496241268e-05, reference_loss: 30.373825073242188
2024-01-02 12:05:58,184	44k	INFO	====> Epoch: 2503, cost 27.03 s
2024-01-02 12:06:24,543	44k	INFO	====> Epoch: 2504, cost 26.36 s
2024-01-02 12:06:50,823	44k	INFO	====> Epoch: 2505, cost 26.28 s
2024-01-02 12:07:17,109	44k	INFO	====> Epoch: 2506, cost 26.29 s
2024-01-02 12:07:43,381	44k	INFO	====> Epoch: 2507, cost 26.27 s
2024-01-02 12:08:09,596	44k	INFO	====> Epoch: 2508, cost 26.21 s
2024-01-02 12:08:24,586	44k	INFO	Train Epoch: 2509 [54%]
2024-01-02 12:08:24,587	44k	INFO	Losses: [2.057318925857544, 2.9482483863830566, 10.346465110778809, 17.46082305908203, 0.48106229305267334], step: 87800, lr: 7.308700571845392e-05, reference_loss: 33.29391860961914
2024-01-02 12:08:36,832	44k	INFO	====> Epoch: 2509, cost 27.24 s
2024-01-02 12:09:03,241	44k	INFO	====> Epoch: 2510, cost 26.41 s
2024-01-02 12:09:29,705	44k	INFO	====> Epoch: 2511, cost 26.46 s
2024-01-02 12:09:56,117	44k	INFO	====> Epoch: 2512, cost 26.41 s
2024-01-02 12:10:22,528	44k	INFO	====> Epoch: 2513, cost 26.41 s
2024-01-02 12:10:48,916	44k	INFO	====> Epoch: 2514, cost 26.39 s
2024-01-02 12:10:56,397	44k	INFO	Train Epoch: 2515 [26%]
2024-01-02 12:10:56,398	44k	INFO	Losses: [2.2618894577026367, 3.16731595993042, 10.28637981414795, 18.56989097595215, 0.4941027760505676], step: 88000, lr: 7.303220759107733e-05, reference_loss: 34.779579162597656
2024-01-02 12:11:04,019	44k	INFO	Saving model and optimizer state at iteration 2515 to ./logs/44k/G_88000.pth
2024-01-02 12:11:05,238	44k	INFO	Saving model and optimizer state at iteration 2515 to ./logs/44k/D_88000.pth
2024-01-02 12:11:06,014	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_85600.pth
2024-01-02 12:11:06,072	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_85600.pth
2024-01-02 12:11:24,996	44k	INFO	====> Epoch: 2515, cost 36.08 s
2024-01-02 12:11:51,361	44k	INFO	====> Epoch: 2516, cost 26.37 s
2024-01-02 12:12:17,744	44k	INFO	====> Epoch: 2517, cost 26.38 s
2024-01-02 12:12:44,100	44k	INFO	====> Epoch: 2518, cost 26.36 s
2024-01-02 12:13:10,476	44k	INFO	====> Epoch: 2519, cost 26.38 s
2024-01-02 12:13:36,584	44k	INFO	Train Epoch: 2520 [97%]
2024-01-02 12:13:36,585	44k	INFO	Losses: [2.127969264984131, 2.755525588989258, 10.326568603515625, 18.203060150146484, 0.39356327056884766], step: 88200, lr: 7.298657387118901e-05, reference_loss: 33.80668640136719
2024-01-02 12:13:37,069	44k	INFO	====> Epoch: 2520, cost 26.59 s
2024-01-02 12:14:03,423	44k	INFO	====> Epoch: 2521, cost 26.35 s
2024-01-02 12:14:30,125	44k	INFO	====> Epoch: 2522, cost 26.70 s
2024-01-02 12:14:56,398	44k	INFO	====> Epoch: 2523, cost 26.27 s
2024-01-02 12:15:22,573	44k	INFO	====> Epoch: 2524, cost 26.17 s
2024-01-02 12:15:48,937	44k	INFO	====> Epoch: 2525, cost 26.36 s
2024-01-02 12:16:07,698	44k	INFO	Train Epoch: 2526 [69%]
2024-01-02 12:16:07,698	44k	INFO	Losses: [2.232609748840332, 2.7239246368408203, 9.477970123291016, 16.24640464782715, 0.6661241054534912], step: 88400, lr: 7.293185104416308e-05, reference_loss: 31.34703254699707
2024-01-02 12:16:15,786	44k	INFO	====> Epoch: 2526, cost 26.85 s
2024-01-02 12:16:42,052	44k	INFO	====> Epoch: 2527, cost 26.27 s
2024-01-02 12:17:08,424	44k	INFO	====> Epoch: 2528, cost 26.37 s
2024-01-02 12:17:35,075	44k	INFO	====> Epoch: 2529, cost 26.65 s
2024-01-02 12:18:01,289	44k	INFO	====> Epoch: 2530, cost 26.21 s
2024-01-02 12:18:27,463	44k	INFO	====> Epoch: 2531, cost 26.17 s
2024-01-02 12:18:38,642	44k	INFO	Train Epoch: 2532 [40%]
2024-01-02 12:18:38,642	44k	INFO	Losses: [2.3683676719665527, 2.465510368347168, 8.358590126037598, 15.96263599395752, 0.7013952732086182], step: 88600, lr: 7.287716924643387e-05, reference_loss: 29.85650062561035
2024-01-02 12:18:54,215	44k	INFO	====> Epoch: 2532, cost 26.75 s
2024-01-02 12:19:20,640	44k	INFO	====> Epoch: 2533, cost 26.42 s
2024-01-02 12:19:47,028	44k	INFO	====> Epoch: 2534, cost 26.39 s
2024-01-02 12:20:13,443	44k	INFO	====> Epoch: 2535, cost 26.41 s
2024-01-02 12:20:39,937	44k	INFO	====> Epoch: 2536, cost 26.49 s
2024-01-02 12:21:06,201	44k	INFO	====> Epoch: 2537, cost 26.26 s
2024-01-02 12:21:09,944	44k	INFO	Train Epoch: 2538 [11%]
2024-01-02 12:21:09,945	44k	INFO	Losses: [1.693896770477295, 3.5073423385620117, 10.336505889892578, 15.863574028015137, 0.7536447644233704], step: 88800, lr: 7.282252844723908e-05, reference_loss: 32.15496063232422
2024-01-02 12:21:17,463	44k	INFO	Saving model and optimizer state at iteration 2538 to ./logs/44k/G_88800.pth
2024-01-02 12:21:18,362	44k	INFO	Saving model and optimizer state at iteration 2538 to ./logs/44k/D_88800.pth
2024-01-02 12:21:19,147	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_86400.pth
2024-01-02 12:21:19,205	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_86400.pth
2024-01-02 12:21:41,756	44k	INFO	====> Epoch: 2538, cost 35.56 s
2024-01-02 12:22:07,990	44k	INFO	====> Epoch: 2539, cost 26.23 s
2024-01-02 12:22:34,345	44k	INFO	====> Epoch: 2540, cost 26.35 s
2024-01-02 12:23:00,955	44k	INFO	====> Epoch: 2541, cost 26.61 s
2024-01-02 12:23:27,284	44k	INFO	====> Epoch: 2542, cost 26.33 s
2024-01-02 12:23:49,802	44k	INFO	Train Epoch: 2543 [83%]
2024-01-02 12:23:49,803	44k	INFO	Losses: [2.279785394668579, 2.531254768371582, 7.997579097747803, 14.752525329589844, 0.43979182839393616], step: 89000, lr: 7.277702574405738e-05, reference_loss: 28.00093650817871
2024-01-02 12:23:54,062	44k	INFO	====> Epoch: 2543, cost 26.78 s
2024-01-02 12:24:20,415	44k	INFO	====> Epoch: 2544, cost 26.35 s
2024-01-02 12:24:46,826	44k	INFO	====> Epoch: 2545, cost 26.41 s
2024-01-02 12:25:13,094	44k	INFO	====> Epoch: 2546, cost 26.27 s
2024-01-02 12:25:39,497	44k	INFO	====> Epoch: 2547, cost 26.40 s
2024-01-02 12:26:05,809	44k	INFO	====> Epoch: 2548, cost 26.31 s
2024-01-02 12:26:20,727	44k	INFO	Train Epoch: 2549 [54%]
2024-01-02 12:26:20,728	44k	INFO	Losses: [2.1820597648620605, 2.728706121444702, 8.396029472351074, 16.235624313354492, 0.5826416611671448], step: 89200, lr: 7.272246002902214e-05, reference_loss: 30.12506103515625
2024-01-02 12:26:32,895	44k	INFO	====> Epoch: 2549, cost 27.09 s
2024-01-02 12:26:59,197	44k	INFO	====> Epoch: 2550, cost 26.30 s
2024-01-02 12:27:25,458	44k	INFO	====> Epoch: 2551, cost 26.26 s
2024-01-02 12:27:51,722	44k	INFO	====> Epoch: 2552, cost 26.26 s
2024-01-02 12:28:17,958	44k	INFO	====> Epoch: 2553, cost 26.24 s
2024-01-02 12:28:44,216	44k	INFO	====> Epoch: 2554, cost 26.26 s
2024-01-02 12:28:51,676	44k	INFO	Train Epoch: 2555 [26%]
2024-01-02 12:28:51,676	44k	INFO	Losses: [2.208658456802368, 2.5262057781219482, 8.339893341064453, 15.078985214233398, 0.5314610004425049], step: 89400, lr: 7.266793522548648e-05, reference_loss: 28.685205459594727
2024-01-02 12:29:11,373	44k	INFO	====> Epoch: 2555, cost 27.16 s
2024-01-02 12:29:37,572	44k	INFO	====> Epoch: 2556, cost 26.20 s
2024-01-02 12:30:03,949	44k	INFO	====> Epoch: 2557, cost 26.38 s
2024-01-02 12:30:30,280	44k	INFO	====> Epoch: 2558, cost 26.33 s
2024-01-02 12:30:56,588	44k	INFO	====> Epoch: 2559, cost 26.31 s
2024-01-02 12:31:22,789	44k	INFO	Train Epoch: 2560 [97%]
2024-01-02 12:31:22,790	44k	INFO	Losses: [2.2658801078796387, 2.7691404819488525, 7.849410057067871, 15.446024894714355, 0.5030127763748169], step: 89600, lr: 7.26225291189162e-05, reference_loss: 28.83346939086914
2024-01-02 12:31:30,212	44k	INFO	Saving model and optimizer state at iteration 2560 to ./logs/44k/G_89600.pth
2024-01-02 12:31:31,108	44k	INFO	Saving model and optimizer state at iteration 2560 to ./logs/44k/D_89600.pth
2024-01-02 12:31:31,895	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_87200.pth
2024-01-02 12:31:31,952	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_87200.pth
2024-01-02 12:31:31,952	44k	INFO	====> Epoch: 2560, cost 35.36 s
2024-01-02 12:31:58,386	44k	INFO	====> Epoch: 2561, cost 26.43 s
2024-01-02 12:32:24,500	44k	INFO	====> Epoch: 2562, cost 26.11 s
2024-01-02 12:32:50,666	44k	INFO	====> Epoch: 2563, cost 26.17 s
2024-01-02 12:33:17,061	44k	INFO	====> Epoch: 2564, cost 26.40 s
2024-01-02 12:33:43,337	44k	INFO	====> Epoch: 2565, cost 26.28 s
2024-01-02 12:34:02,011	44k	INFO	Train Epoch: 2566 [69%]
2024-01-02 12:34:02,011	44k	INFO	Losses: [2.1829354763031006, 2.9228875637054443, 10.046843528747559, 16.487350463867188, 0.6271452307701111], step: 89800, lr: 7.256807924014571e-05, reference_loss: 32.26716232299805
2024-01-02 12:34:10,192	44k	INFO	====> Epoch: 2566, cost 26.86 s
2024-01-02 12:34:36,513	44k	INFO	====> Epoch: 2567, cost 26.32 s
2024-01-02 12:35:02,794	44k	INFO	====> Epoch: 2568, cost 26.28 s
2024-01-02 12:35:28,961	44k	INFO	====> Epoch: 2569, cost 26.17 s
2024-01-02 12:35:55,552	44k	INFO	====> Epoch: 2570, cost 26.59 s
2024-01-02 12:36:21,722	44k	INFO	====> Epoch: 2571, cost 26.17 s
2024-01-02 12:36:32,880	44k	INFO	Train Epoch: 2572 [40%]
2024-01-02 12:36:32,881	44k	INFO	Losses: [2.205404043197632, 2.658781051635742, 9.795856475830078, 17.259275436401367, 0.4678727388381958], step: 90000, lr: 7.251367018602473e-05, reference_loss: 32.38719177246094
2024-01-02 12:36:48,646	44k	INFO	====> Epoch: 2572, cost 26.92 s
2024-01-02 12:37:15,019	44k	INFO	====> Epoch: 2573, cost 26.37 s
2024-01-02 12:37:41,382	44k	INFO	====> Epoch: 2574, cost 26.36 s
2024-01-02 12:38:07,708	44k	INFO	====> Epoch: 2575, cost 26.33 s
2024-01-02 12:38:34,097	44k	INFO	====> Epoch: 2576, cost 26.39 s
2024-01-02 12:39:00,803	44k	INFO	====> Epoch: 2577, cost 26.71 s
2024-01-02 12:39:04,559	44k	INFO	Train Epoch: 2578 [11%]
2024-01-02 12:39:04,559	44k	INFO	Losses: [1.9983429908752441, 2.98689866065979, 8.707385063171387, 15.67199993133545, 0.319976270198822], step: 90200, lr: 7.245930192594435e-05, reference_loss: 29.68460464477539
2024-01-02 12:39:27,550	44k	INFO	====> Epoch: 2578, cost 26.75 s
2024-01-02 12:39:53,799	44k	INFO	====> Epoch: 2579, cost 26.25 s
2024-01-02 12:40:20,040	44k	INFO	====> Epoch: 2580, cost 26.24 s
2024-01-02 12:40:46,373	44k	INFO	====> Epoch: 2581, cost 26.33 s
2024-01-02 12:41:12,717	44k	INFO	====> Epoch: 2582, cost 26.34 s
2024-01-02 12:41:35,317	44k	INFO	Train Epoch: 2583 [83%]
2024-01-02 12:41:35,318	44k	INFO	Losses: [1.931229829788208, 2.8180477619171143, 9.948787689208984, 15.171759605407715, 0.5922236442565918], step: 90400, lr: 7.24140261825914e-05, reference_loss: 30.462047576904297
2024-01-02 12:41:43,214	44k	INFO	Saving model and optimizer state at iteration 2583 to ./logs/44k/G_90400.pth
2024-01-02 12:41:44,106	44k	INFO	Saving model and optimizer state at iteration 2583 to ./logs/44k/D_90400.pth
2024-01-02 12:41:44,866	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_88000.pth
2024-01-02 12:41:44,923	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_88000.pth
2024-01-02 12:41:48,670	44k	INFO	====> Epoch: 2583, cost 35.95 s
2024-01-02 12:42:15,011	44k	INFO	====> Epoch: 2584, cost 26.34 s
2024-01-02 12:42:41,345	44k	INFO	====> Epoch: 2585, cost 26.33 s
2024-01-02 12:43:07,516	44k	INFO	====> Epoch: 2586, cost 26.17 s
2024-01-02 12:43:33,803	44k	INFO	====> Epoch: 2587, cost 26.29 s
2024-01-02 12:44:00,050	44k	INFO	====> Epoch: 2588, cost 26.25 s
2024-01-02 12:44:15,049	44k	INFO	Train Epoch: 2589 [54%]
2024-01-02 12:44:15,050	44k	INFO	Losses: [2.4010725021362305, 2.7191238403320312, 8.369795799255371, 15.410491943359375, 0.2622603178024292], step: 90600, lr: 7.235973263216342e-05, reference_loss: 29.162744522094727
2024-01-02 12:44:27,257	44k	INFO	====> Epoch: 2589, cost 27.21 s
2024-01-02 12:44:53,617	44k	INFO	====> Epoch: 2590, cost 26.36 s
2024-01-02 12:45:19,933	44k	INFO	====> Epoch: 2591, cost 26.32 s
2024-01-02 12:45:46,268	44k	INFO	====> Epoch: 2592, cost 26.34 s
2024-01-02 12:46:12,477	44k	INFO	====> Epoch: 2593, cost 26.21 s
2024-01-02 12:46:38,659	44k	INFO	====> Epoch: 2594, cost 26.18 s
2024-01-02 12:46:46,133	44k	INFO	Train Epoch: 2595 [26%]
2024-01-02 12:46:46,133	44k	INFO	Losses: [2.007359504699707, 2.6710593700408936, 9.846345901489258, 17.48383331298828, 0.8056240677833557], step: 90800, lr: 7.230547978917533e-05, reference_loss: 32.81422424316406
2024-01-02 12:47:05,502	44k	INFO	====> Epoch: 2595, cost 26.84 s
2024-01-02 12:47:32,060	44k	INFO	====> Epoch: 2596, cost 26.56 s
2024-01-02 12:47:58,408	44k	INFO	====> Epoch: 2597, cost 26.35 s
2024-01-02 12:48:24,646	44k	INFO	====> Epoch: 2598, cost 26.24 s
2024-01-02 12:48:50,896	44k	INFO	====> Epoch: 2599, cost 26.25 s
2024-01-02 12:49:17,162	44k	INFO	Train Epoch: 2600 [97%]
2024-01-02 12:49:17,163	44k	INFO	Losses: [2.135775566101074, 3.049117088317871, 9.64816665649414, 16.891626358032227, 0.6188982129096985], step: 91000, lr: 7.226030016062616e-05, reference_loss: 32.34358215332031
2024-01-02 12:49:17,680	44k	INFO	====> Epoch: 2600, cost 26.78 s
2024-01-02 12:49:43,890	44k	INFO	====> Epoch: 2601, cost 26.21 s
2024-01-02 12:50:10,204	44k	INFO	====> Epoch: 2602, cost 26.31 s
2024-01-02 12:50:36,922	44k	INFO	====> Epoch: 2603, cost 26.72 s
2024-01-02 12:51:03,365	44k	INFO	====> Epoch: 2604, cost 26.44 s
2024-01-02 12:51:29,650	44k	INFO	====> Epoch: 2605, cost 26.29 s
2024-01-02 12:51:48,359	44k	INFO	Train Epoch: 2606 [69%]
2024-01-02 12:51:48,360	44k	INFO	Losses: [2.176398277282715, 3.0626440048217773, 8.97493839263916, 13.687703132629395, 0.6083840131759644], step: 91200, lr: 7.220612186869113e-05, reference_loss: 28.510066986083984
2024-01-02 12:51:55,808	44k	INFO	Saving model and optimizer state at iteration 2606 to ./logs/44k/G_91200.pth
2024-01-02 12:51:56,707	44k	INFO	Saving model and optimizer state at iteration 2606 to ./logs/44k/D_91200.pth
2024-01-02 12:51:57,479	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_88800.pth
2024-01-02 12:51:57,538	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_88800.pth
2024-01-02 12:52:05,071	44k	INFO	====> Epoch: 2606, cost 35.42 s
2024-01-02 12:52:31,456	44k	INFO	====> Epoch: 2607, cost 26.39 s
2024-01-02 12:52:58,210	44k	INFO	====> Epoch: 2608, cost 26.75 s
2024-01-02 12:53:24,458	44k	INFO	====> Epoch: 2609, cost 26.25 s
2024-01-02 12:53:50,836	44k	INFO	====> Epoch: 2610, cost 26.38 s
2024-01-02 12:54:17,231	44k	INFO	====> Epoch: 2611, cost 26.40 s
2024-01-02 12:54:28,412	44k	INFO	Train Epoch: 2612 [40%]
2024-01-02 12:54:28,412	44k	INFO	Losses: [2.369298219680786, 2.6875052452087402, 9.37350082397461, 17.378833770751953, 0.3724815249443054], step: 91400, lr: 7.215198419777912e-05, reference_loss: 32.18162155151367
2024-01-02 12:54:44,045	44k	INFO	====> Epoch: 2612, cost 26.81 s
2024-01-02 12:55:10,363	44k	INFO	====> Epoch: 2613, cost 26.32 s
2024-01-02 12:55:36,814	44k	INFO	====> Epoch: 2614, cost 26.45 s
2024-01-02 12:56:03,195	44k	INFO	====> Epoch: 2615, cost 26.38 s
2024-01-02 12:56:29,577	44k	INFO	====> Epoch: 2616, cost 26.38 s
2024-01-02 12:56:56,318	44k	INFO	====> Epoch: 2617, cost 26.74 s
2024-01-02 12:57:00,089	44k	INFO	Train Epoch: 2618 [11%]
2024-01-02 12:57:00,090	44k	INFO	Losses: [2.3158912658691406, 2.4199039936065674, 8.592340469360352, 16.944217681884766, 0.3931131958961487], step: 91600, lr: 7.20978871174339e-05, reference_loss: 30.665468215942383
2024-01-02 12:57:23,413	44k	INFO	====> Epoch: 2618, cost 27.10 s
2024-01-02 12:57:49,849	44k	INFO	====> Epoch: 2619, cost 26.44 s
2024-01-02 12:58:16,255	44k	INFO	====> Epoch: 2620, cost 26.41 s
2024-01-02 12:58:42,561	44k	INFO	====> Epoch: 2621, cost 26.31 s
2024-01-02 12:59:08,943	44k	INFO	====> Epoch: 2622, cost 26.38 s
2024-01-02 12:59:31,577	44k	INFO	Train Epoch: 2623 [83%]
2024-01-02 12:59:31,577	44k	INFO	Losses: [2.0782244205474854, 2.8506195545196533, 9.906523704528809, 15.932868957519531, 0.6077229976654053], step: 91800, lr: 7.205283720187227e-05, reference_loss: 31.375959396362305
2024-01-02 12:59:36,145	44k	INFO	====> Epoch: 2623, cost 27.20 s
2024-01-02 13:00:02,402	44k	INFO	====> Epoch: 2624, cost 26.26 s
2024-01-02 13:00:28,795	44k	INFO	====> Epoch: 2625, cost 26.39 s
2024-01-02 13:00:55,085	44k	INFO	====> Epoch: 2626, cost 26.29 s
2024-01-02 13:01:21,515	44k	INFO	====> Epoch: 2627, cost 26.43 s
2024-01-02 13:01:47,866	44k	INFO	====> Epoch: 2628, cost 26.35 s
2024-01-02 13:02:02,778	44k	INFO	Train Epoch: 2629 [54%]
2024-01-02 13:02:02,778	44k	INFO	Losses: [2.114314556121826, 2.6397740840911865, 10.886799812316895, 16.432039260864258, 0.6169477105140686], step: 92000, lr: 7.199881445854027e-05, reference_loss: 32.689876556396484
2024-01-02 13:02:10,142	44k	INFO	Saving model and optimizer state at iteration 2629 to ./logs/44k/G_92000.pth
2024-01-02 13:02:11,377	44k	INFO	Saving model and optimizer state at iteration 2629 to ./logs/44k/D_92000.pth
2024-01-02 13:02:12,180	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_89600.pth
2024-01-02 13:02:12,238	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_89600.pth
2024-01-02 13:02:23,582	44k	INFO	====> Epoch: 2629, cost 35.72 s
2024-01-02 13:02:49,900	44k	INFO	====> Epoch: 2630, cost 26.32 s
2024-01-02 13:03:16,300	44k	INFO	====> Epoch: 2631, cost 26.40 s
2024-01-02 13:03:42,700	44k	INFO	====> Epoch: 2632, cost 26.40 s
2024-01-02 13:04:08,990	44k	INFO	====> Epoch: 2633, cost 26.29 s
2024-01-02 13:04:35,469	44k	INFO	====> Epoch: 2634, cost 26.48 s
2024-01-02 13:04:42,993	44k	INFO	Train Epoch: 2635 [26%]
2024-01-02 13:04:42,993	44k	INFO	Losses: [2.334134340286255, 2.5857982635498047, 8.538322448730469, 16.23841094970703, 0.5732855200767517], step: 92200, lr: 7.19448322196063e-05, reference_loss: 30.26995277404785
2024-01-02 13:05:02,813	44k	INFO	====> Epoch: 2635, cost 27.34 s
2024-01-02 13:05:29,236	44k	INFO	====> Epoch: 2636, cost 26.42 s
2024-01-02 13:05:55,509	44k	INFO	====> Epoch: 2637, cost 26.27 s
2024-01-02 13:06:21,799	44k	INFO	====> Epoch: 2638, cost 26.29 s
2024-01-02 13:06:48,252	44k	INFO	====> Epoch: 2639, cost 26.45 s
2024-01-02 13:07:14,595	44k	INFO	Train Epoch: 2640 [97%]
2024-01-02 13:07:14,596	44k	INFO	Losses: [2.1046059131622314, 2.906515598297119, 8.587024688720703, 14.892935752868652, 0.426652193069458], step: 92400, lr: 7.189987793944396e-05, reference_loss: 28.917734146118164
2024-01-02 13:07:15,245	44k	INFO	====> Epoch: 2640, cost 26.99 s
2024-01-02 13:07:41,675	44k	INFO	====> Epoch: 2641, cost 26.43 s
2024-01-02 13:08:08,114	44k	INFO	====> Epoch: 2642, cost 26.44 s
2024-01-02 13:08:34,873	44k	INFO	====> Epoch: 2643, cost 26.76 s
2024-01-02 13:09:01,228	44k	INFO	====> Epoch: 2644, cost 26.36 s
2024-01-02 13:09:27,579	44k	INFO	====> Epoch: 2645, cost 26.35 s
2024-01-02 13:09:46,318	44k	INFO	Train Epoch: 2646 [69%]
2024-01-02 13:09:46,319	44k	INFO	Losses: [2.391284942626953, 2.1993024349212646, 7.532459259033203, 15.53908920288086, 0.5284744501113892], step: 92600, lr: 7.184596987971493e-05, reference_loss: 28.190610885620117
2024-01-02 13:09:54,529	44k	INFO	====> Epoch: 2646, cost 26.95 s
2024-01-02 13:10:20,965	44k	INFO	====> Epoch: 2647, cost 26.44 s
2024-01-02 13:10:47,214	44k	INFO	====> Epoch: 2648, cost 26.25 s
2024-01-02 13:11:13,595	44k	INFO	====> Epoch: 2649, cost 26.38 s
2024-01-02 13:11:40,370	44k	INFO	====> Epoch: 2650, cost 26.78 s
2024-01-02 13:12:06,805	44k	INFO	====> Epoch: 2651, cost 26.43 s
2024-01-02 13:12:18,088	44k	INFO	Train Epoch: 2652 [40%]
2024-01-02 13:12:18,088	44k	INFO	Losses: [2.2725653648376465, 2.4116945266723633, 9.861693382263184, 18.049705505371094, 0.47537827491760254], step: 92800, lr: 7.17921022383981e-05, reference_loss: 33.07103729248047
2024-01-02 13:12:25,665	44k	INFO	Saving model and optimizer state at iteration 2652 to ./logs/44k/G_92800.pth
2024-01-02 13:12:26,570	44k	INFO	Saving model and optimizer state at iteration 2652 to ./logs/44k/D_92800.pth
2024-01-02 13:12:27,349	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_90400.pth
2024-01-02 13:12:27,406	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_90400.pth
2024-01-02 13:12:42,492	44k	INFO	====> Epoch: 2652, cost 35.69 s
2024-01-02 13:13:08,821	44k	INFO	====> Epoch: 2653, cost 26.33 s
2024-01-02 13:13:35,042	44k	INFO	====> Epoch: 2654, cost 26.22 s
2024-01-02 13:14:01,764	44k	INFO	====> Epoch: 2655, cost 26.72 s
2024-01-02 13:14:28,179	44k	INFO	====> Epoch: 2656, cost 26.42 s
2024-01-02 13:14:54,544	44k	INFO	====> Epoch: 2657, cost 26.36 s
2024-01-02 13:14:58,287	44k	INFO	Train Epoch: 2658 [11%]
2024-01-02 13:14:58,287	44k	INFO	Losses: [2.344378709793091, 2.6765177249908447, 8.068313598632812, 15.580848693847656, 0.44678235054016113], step: 93000, lr: 7.173827498518913e-05, reference_loss: 29.11684226989746
2024-01-02 13:15:21,404	44k	INFO	====> Epoch: 2658, cost 26.86 s
2024-01-02 13:15:47,769	44k	INFO	====> Epoch: 2659, cost 26.37 s
2024-01-02 13:16:14,217	44k	INFO	====> Epoch: 2660, cost 26.45 s
2024-01-02 13:16:40,666	44k	INFO	====> Epoch: 2661, cost 26.45 s
2024-01-02 13:17:06,945	44k	INFO	====> Epoch: 2662, cost 26.28 s
2024-01-02 13:17:29,451	44k	INFO	Train Epoch: 2663 [83%]
2024-01-02 13:17:29,452	44k	INFO	Losses: [2.09236741065979, 2.873095989227295, 9.130180358886719, 17.251819610595703, 0.5783743858337402], step: 93200, lr: 7.169344977102779e-05, reference_loss: 31.925838470458984
2024-01-02 13:17:34,009	44k	INFO	====> Epoch: 2663, cost 27.06 s
2024-01-02 13:18:00,402	44k	INFO	====> Epoch: 2664, cost 26.39 s
2024-01-02 13:18:26,747	44k	INFO	====> Epoch: 2665, cost 26.34 s
2024-01-02 13:18:53,168	44k	INFO	====> Epoch: 2666, cost 26.42 s
2024-01-02 13:19:19,512	44k	INFO	====> Epoch: 2667, cost 26.34 s
2024-01-02 13:19:45,817	44k	INFO	====> Epoch: 2668, cost 26.30 s
2024-01-02 13:20:00,777	44k	INFO	Train Epoch: 2669 [54%]
2024-01-02 13:20:00,778	44k	INFO	Losses: [2.342237949371338, 2.5524985790252686, 9.650911331176758, 17.26453399658203, 0.48076626658439636], step: 93400, lr: 7.163969648405153e-05, reference_loss: 32.29094696044922
2024-01-02 13:20:12,948	44k	INFO	====> Epoch: 2669, cost 27.13 s
2024-01-02 13:20:39,316	44k	INFO	====> Epoch: 2670, cost 26.37 s
2024-01-02 13:21:05,749	44k	INFO	====> Epoch: 2671, cost 26.43 s
2024-01-02 13:21:32,169	44k	INFO	====> Epoch: 2672, cost 26.42 s
2024-01-02 13:21:58,478	44k	INFO	====> Epoch: 2673, cost 26.31 s
2024-01-02 13:22:24,832	44k	INFO	====> Epoch: 2674, cost 26.35 s
2024-01-02 13:22:32,296	44k	INFO	Train Epoch: 2675 [26%]
2024-01-02 13:22:32,297	44k	INFO	Losses: [1.936643123626709, 3.2730369567871094, 10.762497901916504, 16.26961326599121, 0.4702364206314087], step: 93600, lr: 7.158598349944418e-05, reference_loss: 32.71202850341797
2024-01-02 13:22:39,831	44k	INFO	Saving model and optimizer state at iteration 2675 to ./logs/44k/G_93600.pth
2024-01-02 13:22:40,724	44k	INFO	Saving model and optimizer state at iteration 2675 to ./logs/44k/D_93600.pth
2024-01-02 13:22:41,506	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_91200.pth
2024-01-02 13:22:41,563	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_91200.pth
2024-01-02 13:23:00,742	44k	INFO	====> Epoch: 2675, cost 35.91 s
2024-01-02 13:23:27,198	44k	INFO	====> Epoch: 2676, cost 26.46 s
2024-01-02 13:23:53,643	44k	INFO	====> Epoch: 2677, cost 26.44 s
2024-01-02 13:24:20,099	44k	INFO	====> Epoch: 2678, cost 26.46 s
2024-01-02 13:24:46,518	44k	INFO	====> Epoch: 2679, cost 26.42 s
2024-01-02 13:25:12,990	44k	INFO	Train Epoch: 2680 [97%]
2024-01-02 13:25:12,991	44k	INFO	Losses: [2.278752088546753, 2.4318628311157227, 9.27456283569336, 17.30777359008789, 0.4311651885509491], step: 93800, lr: 7.154125344366885e-05, reference_loss: 31.724117279052734
2024-01-02 13:25:13,480	44k	INFO	====> Epoch: 2680, cost 26.96 s
2024-01-02 13:25:39,890	44k	INFO	====> Epoch: 2681, cost 26.41 s
2024-01-02 13:26:06,323	44k	INFO	====> Epoch: 2682, cost 26.43 s
2024-01-02 13:26:32,576	44k	INFO	====> Epoch: 2683, cost 26.25 s
2024-01-02 13:26:59,266	44k	INFO	====> Epoch: 2684, cost 26.69 s
2024-01-02 13:27:25,605	44k	INFO	====> Epoch: 2685, cost 26.34 s
2024-01-02 13:27:44,150	44k	INFO	Train Epoch: 2686 [69%]
2024-01-02 13:27:44,151	44k	INFO	Losses: [1.9369776248931885, 3.2602877616882324, 9.8538179397583, 14.057565689086914, 0.6761012673377991], step: 94000, lr: 7.148761426827304e-05, reference_loss: 29.784751892089844
2024-01-02 13:27:52,301	44k	INFO	====> Epoch: 2686, cost 26.70 s
2024-01-02 13:28:18,615	44k	INFO	====> Epoch: 2687, cost 26.31 s
2024-01-02 13:28:45,086	44k	INFO	====> Epoch: 2688, cost 26.47 s
2024-01-02 13:29:11,445	44k	INFO	====> Epoch: 2689, cost 26.36 s
2024-01-02 13:29:37,834	44k	INFO	====> Epoch: 2690, cost 26.39 s
2024-01-02 13:30:04,619	44k	INFO	====> Epoch: 2691, cost 26.78 s
2024-01-02 13:30:15,862	44k	INFO	Train Epoch: 2692 [40%]
2024-01-02 13:30:15,862	44k	INFO	Losses: [2.045753002166748, 2.946470260620117, 9.499968528747559, 15.928505897521973, 0.6829312443733215], step: 94200, lr: 7.143401530968918e-05, reference_loss: 31.103628158569336
2024-01-02 13:30:31,541	44k	INFO	====> Epoch: 2692, cost 26.92 s
2024-01-02 13:30:57,894	44k	INFO	====> Epoch: 2693, cost 26.35 s
2024-01-02 13:31:24,310	44k	INFO	====> Epoch: 2694, cost 26.42 s
2024-01-02 13:31:50,741	44k	INFO	====> Epoch: 2695, cost 26.43 s
2024-01-02 13:32:17,039	44k	INFO	====> Epoch: 2696, cost 26.30 s
2024-01-02 13:32:43,313	44k	INFO	====> Epoch: 2697, cost 26.27 s
2024-01-02 13:32:47,080	44k	INFO	Train Epoch: 2698 [11%]
2024-01-02 13:32:47,081	44k	INFO	Losses: [1.8758130073547363, 2.7937674522399902, 8.878262519836426, 15.47471809387207, 0.7193186283111572], step: 94400, lr: 7.13804565377641e-05, reference_loss: 29.741878509521484
2024-01-02 13:32:54,992	44k	INFO	Saving model and optimizer state at iteration 2698 to ./logs/44k/G_94400.pth
2024-01-02 13:32:55,902	44k	INFO	Saving model and optimizer state at iteration 2698 to ./logs/44k/D_94400.pth
2024-01-02 13:32:56,686	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_92000.pth
2024-01-02 13:32:56,743	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_92000.pth
2024-01-02 13:33:19,369	44k	INFO	====> Epoch: 2698, cost 36.06 s
2024-01-02 13:33:45,676	44k	INFO	====> Epoch: 2699, cost 26.31 s
2024-01-02 13:34:11,910	44k	INFO	====> Epoch: 2700, cost 26.23 s
2024-01-02 13:34:38,176	44k	INFO	====> Epoch: 2701, cost 26.27 s
2024-01-02 13:35:04,335	44k	INFO	====> Epoch: 2702, cost 26.16 s
2024-01-02 13:35:27,031	44k	INFO	Train Epoch: 2703 [83%]
2024-01-02 13:35:27,032	44k	INFO	Losses: [2.698349952697754, 2.2805395126342773, 7.886199474334717, 14.108759880065918, 0.3399030864238739], step: 94600, lr: 7.133585490423026e-05, reference_loss: 27.313753128051758
2024-01-02 13:35:31,761	44k	INFO	====> Epoch: 2703, cost 27.43 s
2024-01-02 13:35:58,187	44k	INFO	====> Epoch: 2704, cost 26.43 s
2024-01-02 13:36:24,541	44k	INFO	====> Epoch: 2705, cost 26.35 s
2024-01-02 13:36:50,931	44k	INFO	====> Epoch: 2706, cost 26.39 s
2024-01-02 13:37:17,369	44k	INFO	====> Epoch: 2707, cost 26.44 s
2024-01-02 13:37:43,803	44k	INFO	====> Epoch: 2708, cost 26.43 s
2024-01-02 13:37:58,785	44k	INFO	Train Epoch: 2709 [54%]
2024-01-02 13:37:58,785	44k	INFO	Losses: [2.194304943084717, 2.642800807952881, 8.627729415893555, 16.079975128173828, 0.5493320226669312], step: 94800, lr: 7.128236972960677e-05, reference_loss: 30.09414291381836
2024-01-02 13:38:10,836	44k	INFO	====> Epoch: 2709, cost 27.03 s
2024-01-02 13:38:37,562	44k	INFO	====> Epoch: 2710, cost 26.73 s
2024-01-02 13:39:03,958	44k	INFO	====> Epoch: 2711, cost 26.40 s
2024-01-02 13:39:30,162	44k	INFO	====> Epoch: 2712, cost 26.20 s
2024-01-02 13:39:56,381	44k	INFO	====> Epoch: 2713, cost 26.22 s
2024-01-02 13:40:22,667	44k	INFO	====> Epoch: 2714, cost 26.29 s
2024-01-02 13:40:30,145	44k	INFO	Train Epoch: 2715 [26%]
2024-01-02 13:40:30,146	44k	INFO	Losses: [2.0621232986450195, 2.819518566131592, 8.907292366027832, 15.424643516540527, 0.5332289338111877], step: 95000, lr: 7.122892465633075e-05, reference_loss: 29.746807098388672
2024-01-02 13:40:49,582	44k	INFO	====> Epoch: 2715, cost 26.92 s
2024-01-02 13:41:15,924	44k	INFO	====> Epoch: 2716, cost 26.34 s
2024-01-02 13:41:42,556	44k	INFO	====> Epoch: 2717, cost 26.63 s
2024-01-02 13:42:08,929	44k	INFO	====> Epoch: 2718, cost 26.37 s
2024-01-02 13:42:35,342	44k	INFO	====> Epoch: 2719, cost 26.41 s
2024-01-02 13:43:01,729	44k	INFO	Train Epoch: 2720 [97%]
2024-01-02 13:43:01,730	44k	INFO	Losses: [2.3025362491607666, 2.820380687713623, 7.544321060180664, 13.641398429870605, 0.4799959361553192], step: 95200, lr: 7.118441770654889e-05, reference_loss: 26.788631439208984
2024-01-02 13:43:09,186	44k	INFO	Saving model and optimizer state at iteration 2720 to ./logs/44k/G_95200.pth
2024-01-02 13:43:10,103	44k	INFO	Saving model and optimizer state at iteration 2720 to ./logs/44k/D_95200.pth
2024-01-02 13:43:10,890	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_92800.pth
2024-01-02 13:43:10,949	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_92800.pth
2024-01-02 13:43:10,949	44k	INFO	====> Epoch: 2720, cost 35.61 s
2024-01-02 13:43:37,321	44k	INFO	====> Epoch: 2721, cost 26.37 s
2024-01-02 13:44:03,716	44k	INFO	====> Epoch: 2722, cost 26.40 s
2024-01-02 13:44:30,505	44k	INFO	====> Epoch: 2723, cost 26.79 s
2024-01-02 13:44:56,864	44k	INFO	====> Epoch: 2724, cost 26.36 s
2024-01-02 13:45:23,158	44k	INFO	====> Epoch: 2725, cost 26.29 s
2024-01-02 13:45:41,840	44k	INFO	Train Epoch: 2726 [69%]
2024-01-02 13:45:41,840	44k	INFO	Losses: [2.365002393722534, 2.2380716800689697, 8.720501899719238, 16.180803298950195, 0.5762032866477966], step: 95400, lr: 7.113104607433648e-05, reference_loss: 30.080581665039062
2024-01-02 13:45:50,015	44k	INFO	====> Epoch: 2726, cost 26.86 s
2024-01-02 13:46:16,360	44k	INFO	====> Epoch: 2727, cost 26.35 s
2024-01-02 13:46:42,616	44k	INFO	====> Epoch: 2728, cost 26.26 s
2024-01-02 13:47:09,042	44k	INFO	====> Epoch: 2729, cost 26.43 s
2024-01-02 13:47:35,362	44k	INFO	====> Epoch: 2730, cost 26.32 s
2024-01-02 13:48:02,035	44k	INFO	====> Epoch: 2731, cost 26.67 s
2024-01-02 13:48:13,288	44k	INFO	Train Epoch: 2732 [40%]
2024-01-02 13:48:13,289	44k	INFO	Losses: [1.8947277069091797, 3.317725658416748, 11.301016807556152, 17.21224021911621, 0.4227965474128723], step: 95600, lr: 7.107771445834135e-05, reference_loss: 34.14850616455078
2024-01-02 13:48:28,852	44k	INFO	====> Epoch: 2732, cost 26.82 s
2024-01-02 13:48:55,254	44k	INFO	====> Epoch: 2733, cost 26.40 s
2024-01-02 13:49:21,613	44k	INFO	====> Epoch: 2734, cost 26.36 s
2024-01-02 13:49:48,004	44k	INFO	====> Epoch: 2735, cost 26.39 s
2024-01-02 13:50:14,333	44k	INFO	====> Epoch: 2736, cost 26.33 s
2024-01-02 13:50:40,716	44k	INFO	====> Epoch: 2737, cost 26.38 s
2024-01-02 13:50:44,467	44k	INFO	Train Epoch: 2738 [11%]
2024-01-02 13:50:44,468	44k	INFO	Losses: [1.9257173538208008, 3.326653003692627, 10.104039192199707, 16.41766357421875, 0.31575125455856323], step: 95800, lr: 7.10244228285607e-05, reference_loss: 32.08982467651367
2024-01-02 13:51:08,078	44k	INFO	====> Epoch: 2738, cost 27.36 s
2024-01-02 13:51:34,578	44k	INFO	====> Epoch: 2739, cost 26.50 s
2024-01-02 13:52:00,902	44k	INFO	====> Epoch: 2740, cost 26.32 s
2024-01-02 13:52:27,314	44k	INFO	====> Epoch: 2741, cost 26.41 s
2024-01-02 13:52:53,666	44k	INFO	====> Epoch: 2742, cost 26.35 s
2024-01-02 13:53:16,281	44k	INFO	Train Epoch: 2743 [83%]
2024-01-02 13:53:16,282	44k	INFO	Losses: [2.2444491386413574, 2.6113381385803223, 9.593249320983887, 15.186436653137207, 0.5540090799331665], step: 96000, lr: 7.09800436604718e-05, reference_loss: 30.189481735229492
2024-01-02 13:53:23,899	44k	INFO	Saving model and optimizer state at iteration 2743 to ./logs/44k/G_96000.pth
2024-01-02 13:53:25,143	44k	INFO	Saving model and optimizer state at iteration 2743 to ./logs/44k/D_96000.pth
2024-01-02 13:53:25,898	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_93600.pth
2024-01-02 13:53:25,955	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_93600.pth
2024-01-02 13:53:29,714	44k	INFO	====> Epoch: 2743, cost 36.05 s
2024-01-02 13:53:55,956	44k	INFO	====> Epoch: 2744, cost 26.24 s
2024-01-02 13:54:22,343	44k	INFO	====> Epoch: 2745, cost 26.39 s
2024-01-02 13:54:48,682	44k	INFO	====> Epoch: 2746, cost 26.34 s
2024-01-02 13:55:15,069	44k	INFO	====> Epoch: 2747, cost 26.39 s
2024-01-02 13:55:41,393	44k	INFO	====> Epoch: 2748, cost 26.32 s
2024-01-02 13:55:56,407	44k	INFO	Train Epoch: 2749 [54%]
2024-01-02 13:55:56,407	44k	INFO	Losses: [1.9504563808441162, 3.1111369132995605, 10.011351585388184, 15.449019432067871, 0.3691069185733795], step: 96200, lr: 7.092682526090176e-05, reference_loss: 30.891071319580078
2024-01-02 13:56:08,259	44k	INFO	====> Epoch: 2749, cost 26.87 s
2024-01-02 13:56:34,882	44k	INFO	====> Epoch: 2750, cost 26.62 s
2024-01-02 13:57:01,143	44k	INFO	====> Epoch: 2751, cost 26.26 s
2024-01-02 13:57:27,560	44k	INFO	====> Epoch: 2752, cost 26.42 s
2024-01-02 13:57:54,005	44k	INFO	====> Epoch: 2753, cost 26.44 s
2024-01-02 13:58:20,444	44k	INFO	====> Epoch: 2754, cost 26.44 s
2024-01-02 13:58:27,976	44k	INFO	Train Epoch: 2755 [26%]
2024-01-02 13:58:27,976	44k	INFO	Losses: [2.1920299530029297, 2.5485897064208984, 9.60616683959961, 17.329856872558594, 0.799663782119751], step: 96400, lr: 7.08736467626604e-05, reference_loss: 32.4763069152832
2024-01-02 13:58:47,372	44k	INFO	====> Epoch: 2755, cost 26.93 s
2024-01-02 13:59:13,767	44k	INFO	====> Epoch: 2756, cost 26.40 s
2024-01-02 13:59:40,526	44k	INFO	====> Epoch: 2757, cost 26.76 s
2024-01-02 14:00:06,951	44k	INFO	====> Epoch: 2758, cost 26.43 s
2024-01-02 14:00:33,408	44k	INFO	====> Epoch: 2759, cost 26.46 s
2024-01-02 14:00:59,835	44k	INFO	Train Epoch: 2760 [97%]
2024-01-02 14:00:59,835	44k	INFO	Losses: [2.0063493251800537, 2.9500200748443604, 9.940079689025879, 17.050230026245117, 0.6270841956138611], step: 96600, lr: 7.082936180605687e-05, reference_loss: 32.573760986328125
2024-01-02 14:01:00,336	44k	INFO	====> Epoch: 2760, cost 26.93 s
2024-01-02 14:01:26,638	44k	INFO	====> Epoch: 2761, cost 26.30 s
2024-01-02 14:01:53,046	44k	INFO	====> Epoch: 2762, cost 26.41 s
2024-01-02 14:02:19,397	44k	INFO	====> Epoch: 2763, cost 26.35 s
2024-01-02 14:02:46,005	44k	INFO	====> Epoch: 2764, cost 26.61 s
2024-01-02 14:03:12,206	44k	INFO	====> Epoch: 2765, cost 26.20 s
2024-01-02 14:03:30,916	44k	INFO	Train Epoch: 2766 [69%]
2024-01-02 14:03:30,917	44k	INFO	Losses: [1.9883495569229126, 3.431819438934326, 9.754889488220215, 14.519594192504883, 0.5711849331855774], step: 96800, lr: 7.077625638256748e-05, reference_loss: 30.265836715698242
2024-01-02 14:03:38,349	44k	INFO	Saving model and optimizer state at iteration 2766 to ./logs/44k/G_96800.pth
2024-01-02 14:03:39,226	44k	INFO	Saving model and optimizer state at iteration 2766 to ./logs/44k/D_96800.pth
2024-01-02 14:03:40,008	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_94400.pth
2024-01-02 14:03:40,066	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_94400.pth
2024-01-02 14:03:47,610	44k	INFO	====> Epoch: 2766, cost 35.40 s
2024-01-02 14:04:13,954	44k	INFO	====> Epoch: 2767, cost 26.34 s
2024-01-02 14:04:40,233	44k	INFO	====> Epoch: 2768, cost 26.28 s
2024-01-02 14:05:06,596	44k	INFO	====> Epoch: 2769, cost 26.36 s
2024-01-02 14:05:33,314	44k	INFO	====> Epoch: 2770, cost 26.72 s
2024-01-02 14:05:59,743	44k	INFO	====> Epoch: 2771, cost 26.43 s
2024-01-02 14:06:10,988	44k	INFO	Train Epoch: 2772 [40%]
2024-01-02 14:06:10,989	44k	INFO	Losses: [2.156789779663086, 2.930227756500244, 10.583059310913086, 17.602436065673828, 0.37880760431289673], step: 97000, lr: 7.07231907757012e-05, reference_loss: 33.65132141113281
2024-01-02 14:06:26,552	44k	INFO	====> Epoch: 2772, cost 26.81 s
2024-01-02 14:06:52,925	44k	INFO	====> Epoch: 2773, cost 26.37 s
2024-01-02 14:07:19,326	44k	INFO	====> Epoch: 2774, cost 26.40 s
2024-01-02 14:07:45,710	44k	INFO	====> Epoch: 2775, cost 26.38 s
2024-01-02 14:08:12,107	44k	INFO	====> Epoch: 2776, cost 26.40 s
2024-01-02 14:08:38,461	44k	INFO	====> Epoch: 2777, cost 26.35 s
2024-01-02 14:08:42,229	44k	INFO	Train Epoch: 2778 [11%]
2024-01-02 14:08:42,229	44k	INFO	Losses: [2.146394968032837, 2.7045278549194336, 9.331254005432129, 17.61905288696289, 0.40729671716690063], step: 97200, lr: 7.067016495560489e-05, reference_loss: 32.208526611328125
2024-01-02 14:09:05,655	44k	INFO	====> Epoch: 2778, cost 27.19 s
2024-01-02 14:09:31,970	44k	INFO	====> Epoch: 2779, cost 26.32 s
2024-01-02 14:09:58,338	44k	INFO	====> Epoch: 2780, cost 26.37 s
2024-01-02 14:10:24,739	44k	INFO	====> Epoch: 2781, cost 26.40 s
2024-01-02 14:10:51,089	44k	INFO	====> Epoch: 2782, cost 26.35 s
2024-01-02 14:11:13,601	44k	INFO	Train Epoch: 2783 [83%]
2024-01-02 14:11:13,602	44k	INFO	Losses: [2.337855815887451, 2.6910667419433594, 9.350046157836914, 15.444637298583984, 0.5219372510910034], step: 97400, lr: 7.06260071433407e-05, reference_loss: 30.345542907714844
2024-01-02 14:11:17,831	44k	INFO	====> Epoch: 2783, cost 26.74 s
2024-01-02 14:11:44,465	44k	INFO	====> Epoch: 2784, cost 26.63 s
2024-01-02 14:12:10,859	44k	INFO	====> Epoch: 2785, cost 26.39 s
2024-01-02 14:12:37,099	44k	INFO	====> Epoch: 2786, cost 26.24 s
2024-01-02 14:13:03,251	44k	INFO	====> Epoch: 2787, cost 26.15 s
2024-01-02 14:13:29,684	44k	INFO	====> Epoch: 2788, cost 26.43 s
2024-01-02 14:13:44,712	44k	INFO	Train Epoch: 2789 [54%]
2024-01-02 14:13:44,712	44k	INFO	Losses: [2.2619874477386475, 2.4425880908966064, 10.99601936340332, 16.45935821533203, 0.5952783226966858], step: 97600, lr: 7.057305418819503e-05, reference_loss: 32.75523376464844
2024-01-02 14:13:52,173	44k	INFO	Saving model and optimizer state at iteration 2789 to ./logs/44k/G_97600.pth
2024-01-02 14:13:53,072	44k	INFO	Saving model and optimizer state at iteration 2789 to ./logs/44k/D_97600.pth
2024-01-02 14:13:53,835	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_95200.pth
2024-01-02 14:13:53,892	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_95200.pth
2024-01-02 14:14:05,603	44k	INFO	====> Epoch: 2789, cost 35.92 s
2024-01-02 14:14:31,862	44k	INFO	====> Epoch: 2790, cost 26.26 s
2024-01-02 14:14:58,325	44k	INFO	====> Epoch: 2791, cost 26.46 s
2024-01-02 14:15:24,615	44k	INFO	====> Epoch: 2792, cost 26.29 s
2024-01-02 14:15:50,924	44k	INFO	====> Epoch: 2793, cost 26.31 s
2024-01-02 14:16:17,338	44k	INFO	====> Epoch: 2794, cost 26.41 s
2024-01-02 14:16:24,829	44k	INFO	Train Epoch: 2795 [26%]
2024-01-02 14:16:24,830	44k	INFO	Losses: [1.9661595821380615, 3.3717782497406006, 10.338947296142578, 17.380029678344727, 0.6434264183044434], step: 97800, lr: 7.052014093535694e-05, reference_loss: 33.700340270996094
2024-01-02 14:16:44,159	44k	INFO	====> Epoch: 2795, cost 26.82 s
2024-01-02 14:17:10,499	44k	INFO	====> Epoch: 2796, cost 26.34 s
2024-01-02 14:17:36,898	44k	INFO	====> Epoch: 2797, cost 26.40 s
2024-01-02 14:18:03,636	44k	INFO	====> Epoch: 2798, cost 26.74 s
2024-01-02 14:18:30,053	44k	INFO	====> Epoch: 2799, cost 26.42 s
2024-01-02 14:18:56,485	44k	INFO	Train Epoch: 2800 [97%]
2024-01-02 14:18:56,485	44k	INFO	Losses: [1.7391172647476196, 3.250977039337158, 10.136099815368652, 16.475893020629883, 0.4109230041503906], step: 98000, lr: 7.04760768646671e-05, reference_loss: 32.01300811767578
2024-01-02 14:18:56,966	44k	INFO	====> Epoch: 2800, cost 26.91 s
2024-01-02 14:19:23,389	44k	INFO	====> Epoch: 2801, cost 26.42 s
2024-01-02 14:19:49,728	44k	INFO	====> Epoch: 2802, cost 26.34 s
2024-01-02 14:20:16,168	44k	INFO	====> Epoch: 2803, cost 26.44 s
2024-01-02 14:20:42,529	44k	INFO	====> Epoch: 2804, cost 26.36 s
2024-01-02 14:21:08,830	44k	INFO	====> Epoch: 2805, cost 26.30 s
2024-01-02 14:21:27,988	44k	INFO	Train Epoch: 2806 [69%]
2024-01-02 14:21:27,989	44k	INFO	Losses: [1.9082437753677368, 3.247683525085449, 9.355986595153809, 16.23969268798828, 0.5707929134368896], step: 98200, lr: 7.042323632209639e-05, reference_loss: 31.322399139404297
2024-01-02 14:21:36,047	44k	INFO	====> Epoch: 2806, cost 27.22 s
2024-01-02 14:22:02,472	44k	INFO	====> Epoch: 2807, cost 26.42 s
2024-01-02 14:22:28,779	44k	INFO	====> Epoch: 2808, cost 26.31 s
2024-01-02 14:22:55,070	44k	INFO	====> Epoch: 2809, cost 26.29 s
2024-01-02 14:23:21,392	44k	INFO	====> Epoch: 2810, cost 26.32 s
2024-01-02 14:23:47,784	44k	INFO	====> Epoch: 2811, cost 26.39 s
2024-01-02 14:23:59,029	44k	INFO	Train Epoch: 2812 [40%]
2024-01-02 14:23:59,029	44k	INFO	Losses: [2.1838302612304688, 2.6545538902282715, 10.39307975769043, 18.042461395263672, 0.47944748401641846], step: 98400, lr: 7.037043539755017e-05, reference_loss: 33.75337219238281
2024-01-02 14:24:06,963	44k	INFO	Saving model and optimizer state at iteration 2812 to ./logs/44k/G_98400.pth
2024-01-02 14:24:07,861	44k	INFO	Saving model and optimizer state at iteration 2812 to ./logs/44k/D_98400.pth
2024-01-02 14:24:08,646	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_96000.pth
2024-01-02 14:24:08,703	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_96000.pth
2024-01-02 14:24:23,913	44k	INFO	====> Epoch: 2812, cost 36.13 s
2024-01-02 14:24:50,332	44k	INFO	====> Epoch: 2813, cost 26.42 s
2024-01-02 14:25:16,799	44k	INFO	====> Epoch: 2814, cost 26.47 s
2024-01-02 14:25:43,192	44k	INFO	====> Epoch: 2815, cost 26.39 s
2024-01-02 14:26:09,638	44k	INFO	====> Epoch: 2816, cost 26.45 s
2024-01-02 14:26:35,971	44k	INFO	====> Epoch: 2817, cost 26.33 s
2024-01-02 14:26:39,739	44k	INFO	Train Epoch: 2818 [11%]
2024-01-02 14:26:39,740	44k	INFO	Losses: [2.4792001247406006, 2.5552992820739746, 8.319828033447266, 15.461037635803223, 0.5203716158866882], step: 98600, lr: 7.03176740613242e-05, reference_loss: 29.335737228393555
2024-01-02 14:27:03,148	44k	INFO	====> Epoch: 2818, cost 27.18 s
2024-01-02 14:27:29,483	44k	INFO	====> Epoch: 2819, cost 26.34 s
2024-01-02 14:27:55,885	44k	INFO	====> Epoch: 2820, cost 26.40 s
2024-01-02 14:28:22,333	44k	INFO	====> Epoch: 2821, cost 26.45 s
2024-01-02 14:28:48,760	44k	INFO	====> Epoch: 2822, cost 26.43 s
2024-01-02 14:29:11,420	44k	INFO	Train Epoch: 2823 [83%]
2024-01-02 14:29:11,420	44k	INFO	Losses: [2.083902359008789, 2.7842321395874023, 9.159822463989258, 17.51715087890625, 0.5390973091125488], step: 98800, lr: 7.02737365007991e-05, reference_loss: 32.084205627441406
2024-01-02 14:29:15,807	44k	INFO	====> Epoch: 2823, cost 27.05 s
2024-01-02 14:29:42,386	44k	INFO	====> Epoch: 2824, cost 26.58 s
2024-01-02 14:30:08,654	44k	INFO	====> Epoch: 2825, cost 26.27 s
2024-01-02 14:30:34,908	44k	INFO	====> Epoch: 2826, cost 26.25 s
2024-01-02 14:31:01,142	44k	INFO	====> Epoch: 2827, cost 26.23 s
2024-01-02 14:31:27,470	44k	INFO	====> Epoch: 2828, cost 26.33 s
2024-01-02 14:31:42,389	44k	INFO	Train Epoch: 2829 [54%]
2024-01-02 14:31:42,389	44k	INFO	Losses: [2.448502540588379, 2.484959125518799, 9.762356758117676, 17.012117385864258, 0.49559950828552246], step: 99000, lr: 7.022104766608568e-05, reference_loss: 32.20353317260742
2024-01-02 14:31:54,240	44k	INFO	====> Epoch: 2829, cost 26.77 s
2024-01-02 14:32:20,526	44k	INFO	====> Epoch: 2830, cost 26.29 s
2024-01-02 14:32:47,068	44k	INFO	====> Epoch: 2831, cost 26.54 s
2024-01-02 14:33:13,368	44k	INFO	====> Epoch: 2832, cost 26.30 s
2024-01-02 14:33:39,699	44k	INFO	====> Epoch: 2833, cost 26.33 s
2024-01-02 14:34:06,088	44k	INFO	====> Epoch: 2834, cost 26.39 s
2024-01-02 14:34:13,611	44k	INFO	Train Epoch: 2835 [26%]
2024-01-02 14:34:13,611	44k	INFO	Losses: [2.4827890396118164, 2.4204046726226807, 8.171318054199219, 16.460660934448242, 0.4611551761627197], step: 99200, lr: 7.01683983356514e-05, reference_loss: 29.996326446533203
2024-01-02 14:34:21,202	44k	INFO	Saving model and optimizer state at iteration 2835 to ./logs/44k/G_99200.pth
2024-01-02 14:34:22,102	44k	INFO	Saving model and optimizer state at iteration 2835 to ./logs/44k/D_99200.pth
2024-01-02 14:34:22,879	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_96800.pth
2024-01-02 14:34:22,936	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_96800.pth
2024-01-02 14:34:41,667	44k	INFO	====> Epoch: 2835, cost 35.58 s
2024-01-02 14:35:07,892	44k	INFO	====> Epoch: 2836, cost 26.22 s
2024-01-02 14:35:34,444	44k	INFO	====> Epoch: 2837, cost 26.55 s
2024-01-02 14:36:00,663	44k	INFO	====> Epoch: 2838, cost 26.22 s
2024-01-02 14:36:26,882	44k	INFO	====> Epoch: 2839, cost 26.22 s
2024-01-02 14:36:53,126	44k	INFO	Train Epoch: 2840 [97%]
2024-01-02 14:36:53,126	44k	INFO	Losses: [2.030952215194702, 3.0648727416992188, 11.756353378295898, 17.63730812072754, 0.40848270058631897], step: 99400, lr: 7.012455404913344e-05, reference_loss: 34.89796829223633
2024-01-02 14:36:53,618	44k	INFO	====> Epoch: 2840, cost 26.74 s
2024-01-02 14:37:19,892	44k	INFO	====> Epoch: 2841, cost 26.27 s
2024-01-02 14:37:46,171	44k	INFO	====> Epoch: 2842, cost 26.28 s
2024-01-02 14:38:12,511	44k	INFO	====> Epoch: 2843, cost 26.34 s
2024-01-02 14:38:38,888	44k	INFO	====> Epoch: 2844, cost 26.38 s
2024-01-02 14:39:05,579	44k	INFO	====> Epoch: 2845, cost 26.69 s
2024-01-02 14:39:24,362	44k	INFO	Train Epoch: 2846 [69%]
2024-01-02 14:39:24,362	44k	INFO	Losses: [2.417171001434326, 2.499077796936035, 9.062237739562988, 14.4139404296875, 0.6750543117523193], step: 99600, lr: 7.007197706629994e-05, reference_loss: 29.067481994628906
2024-01-02 14:39:32,412	44k	INFO	====> Epoch: 2846, cost 26.83 s
2024-01-02 14:39:58,765	44k	INFO	====> Epoch: 2847, cost 26.35 s
2024-01-02 14:40:25,150	44k	INFO	====> Epoch: 2848, cost 26.38 s
2024-01-02 14:40:51,468	44k	INFO	====> Epoch: 2849, cost 26.32 s
2024-01-02 14:41:17,789	44k	INFO	====> Epoch: 2850, cost 26.32 s
2024-01-02 14:41:44,164	44k	INFO	====> Epoch: 2851, cost 26.38 s
2024-01-02 14:41:55,350	44k	INFO	Train Epoch: 2852 [40%]
2024-01-02 14:41:55,351	44k	INFO	Losses: [2.3976082801818848, 2.2797622680664062, 7.872519493103027, 15.699541091918945, 0.6792991757392883], step: 99800, lr: 7.00194395038829e-05, reference_loss: 28.928730010986328
2024-01-02 14:42:11,220	44k	INFO	====> Epoch: 2852, cost 27.06 s
2024-01-02 14:42:37,513	44k	INFO	====> Epoch: 2853, cost 26.29 s
2024-01-02 14:43:03,862	44k	INFO	====> Epoch: 2854, cost 26.35 s
2024-01-02 14:43:30,195	44k	INFO	====> Epoch: 2855, cost 26.33 s
2024-01-02 14:43:56,622	44k	INFO	====> Epoch: 2856, cost 26.43 s
2024-01-02 14:44:22,834	44k	INFO	====> Epoch: 2857, cost 26.21 s
2024-01-02 14:44:26,608	44k	INFO	Train Epoch: 2858 [11%]
2024-01-02 14:44:26,609	44k	INFO	Losses: [2.420088768005371, 2.5029234886169434, 7.630228519439697, 14.72214412689209, 0.7008241415023804], step: 100000, lr: 6.996694133232622e-05, reference_loss: 27.97620964050293
2024-01-02 14:44:34,136	44k	INFO	Saving model and optimizer state at iteration 2858 to ./logs/44k/G_100000.pth
2024-01-02 14:44:35,365	44k	INFO	Saving model and optimizer state at iteration 2858 to ./logs/44k/D_100000.pth
2024-01-02 14:44:36,121	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_97600.pth
2024-01-02 14:44:36,178	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_97600.pth
2024-01-02 14:44:58,803	44k	INFO	====> Epoch: 2858, cost 35.97 s
2024-01-02 14:45:25,113	44k	INFO	====> Epoch: 2859, cost 26.31 s
2024-01-02 14:45:51,479	44k	INFO	====> Epoch: 2860, cost 26.37 s
2024-01-02 14:46:17,868	44k	INFO	====> Epoch: 2861, cost 26.39 s
2024-01-02 14:46:44,324	44k	INFO	====> Epoch: 2862, cost 26.46 s
2024-01-02 14:47:07,001	44k	INFO	Train Epoch: 2863 [83%]
2024-01-02 14:47:07,001	44k	INFO	Losses: [2.21283221244812, 2.9404332637786865, 8.123745918273926, 14.29798698425293, 0.38583844900131226], step: 100200, lr: 6.992322292496161e-05, reference_loss: 27.96083641052246
2024-01-02 14:47:11,424	44k	INFO	====> Epoch: 2863, cost 27.10 s
2024-01-02 14:47:38,155	44k	INFO	====> Epoch: 2864, cost 26.73 s
2024-01-02 14:48:04,480	44k	INFO	====> Epoch: 2865, cost 26.32 s
2024-01-02 14:48:30,874	44k	INFO	====> Epoch: 2866, cost 26.39 s
2024-01-02 14:48:57,205	44k	INFO	====> Epoch: 2867, cost 26.33 s
2024-01-02 14:49:23,512	44k	INFO	====> Epoch: 2868, cost 26.31 s
2024-01-02 14:49:38,517	44k	INFO	Train Epoch: 2869 [54%]
2024-01-02 14:49:38,518	44k	INFO	Losses: [2.230921745300293, 2.6246418952941895, 8.645783424377441, 15.856082916259766, 0.5687293410301208], step: 100400, lr: 6.987079689329212e-05, reference_loss: 29.926158905029297
2024-01-02 14:49:50,344	44k	INFO	====> Epoch: 2869, cost 26.83 s
2024-01-02 14:50:16,730	44k	INFO	====> Epoch: 2870, cost 26.39 s
2024-01-02 14:50:43,341	44k	INFO	====> Epoch: 2871, cost 26.61 s
2024-01-02 14:51:09,757	44k	INFO	====> Epoch: 2872, cost 26.42 s
2024-01-02 14:51:36,152	44k	INFO	====> Epoch: 2873, cost 26.39 s
2024-01-02 14:52:02,385	44k	INFO	====> Epoch: 2874, cost 26.23 s
2024-01-02 14:52:09,878	44k	INFO	Train Epoch: 2875 [26%]
2024-01-02 14:52:09,879	44k	INFO	Losses: [1.9083911180496216, 3.0497307777404785, 9.42575454711914, 15.498186111450195, 0.5632619261741638], step: 100600, lr: 6.981841016886109e-05, reference_loss: 30.445323944091797
2024-01-02 14:52:29,357	44k	INFO	====> Epoch: 2875, cost 26.97 s
2024-01-02 14:52:55,777	44k	INFO	====> Epoch: 2876, cost 26.42 s
2024-01-02 14:53:22,125	44k	INFO	====> Epoch: 2877, cost 26.35 s
2024-01-02 14:53:48,820	44k	INFO	====> Epoch: 2878, cost 26.70 s
2024-01-02 14:54:15,191	44k	INFO	====> Epoch: 2879, cost 26.37 s
2024-01-02 14:54:41,544	44k	INFO	Train Epoch: 2880 [97%]
2024-01-02 14:54:41,544	44k	INFO	Losses: [2.0261669158935547, 2.8383162021636963, 8.499295234680176, 14.448014259338379, 0.47551634907722473], step: 100800, lr: 6.977478457026858e-05, reference_loss: 28.287309646606445
2024-01-02 14:54:48,938	44k	INFO	Saving model and optimizer state at iteration 2880 to ./logs/44k/G_100800.pth
2024-01-02 14:54:49,838	44k	INFO	Saving model and optimizer state at iteration 2880 to ./logs/44k/D_100800.pth
2024-01-02 14:54:50,613	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_98400.pth
2024-01-02 14:54:50,670	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_98400.pth
2024-01-02 14:54:50,670	44k	INFO	====> Epoch: 2880, cost 35.48 s
2024-01-02 14:55:17,117	44k	INFO	====> Epoch: 2881, cost 26.45 s
2024-01-02 14:55:43,529	44k	INFO	====> Epoch: 2882, cost 26.41 s
2024-01-02 14:56:09,694	44k	INFO	====> Epoch: 2883, cost 26.17 s
2024-01-02 14:56:36,397	44k	INFO	====> Epoch: 2884, cost 26.70 s
2024-01-02 14:57:02,675	44k	INFO	====> Epoch: 2885, cost 26.28 s
2024-01-02 14:57:21,426	44k	INFO	Train Epoch: 2886 [69%]
2024-01-02 14:57:21,427	44k	INFO	Losses: [2.4255073070526123, 2.2299277782440186, 7.903802394866943, 14.677800178527832, 0.5542982220649719], step: 101000, lr: 6.972246983258066e-05, reference_loss: 27.791336059570312
2024-01-02 14:57:29,606	44k	INFO	====> Epoch: 2886, cost 26.93 s
2024-01-02 14:57:55,938	44k	INFO	====> Epoch: 2887, cost 26.33 s
2024-01-02 14:58:22,354	44k	INFO	====> Epoch: 2888, cost 26.42 s
2024-01-02 14:58:48,660	44k	INFO	====> Epoch: 2889, cost 26.31 s
2024-01-02 14:59:14,978	44k	INFO	====> Epoch: 2890, cost 26.32 s
2024-01-02 14:59:41,379	44k	INFO	====> Epoch: 2891, cost 26.40 s
2024-01-02 14:59:52,916	44k	INFO	Train Epoch: 2892 [40%]
2024-01-02 14:59:52,917	44k	INFO	Losses: [2.2078914642333984, 2.861104726791382, 10.243049621582031, 17.06637954711914, 0.4170481860637665], step: 101200, lr: 6.96701943186868e-05, reference_loss: 32.795475006103516
2024-01-02 15:00:08,580	44k	INFO	====> Epoch: 2892, cost 27.20 s
2024-01-02 15:00:34,986	44k	INFO	====> Epoch: 2893, cost 26.41 s
2024-01-02 15:01:01,331	44k	INFO	====> Epoch: 2894, cost 26.35 s
2024-01-02 15:01:27,729	44k	INFO	====> Epoch: 2895, cost 26.40 s
2024-01-02 15:01:54,076	44k	INFO	====> Epoch: 2896, cost 26.35 s
2024-01-02 15:02:20,289	44k	INFO	====> Epoch: 2897, cost 26.21 s
2024-01-02 15:02:24,060	44k	INFO	Train Epoch: 2898 [11%]
2024-01-02 15:02:24,060	44k	INFO	Losses: [1.825491189956665, 3.21911883354187, 10.314583778381348, 16.104293823242188, 0.3614480495452881], step: 101400, lr: 6.961795799917833e-05, reference_loss: 31.824935913085938
2024-01-02 15:02:47,575	44k	INFO	====> Epoch: 2898, cost 27.29 s
2024-01-02 15:03:13,904	44k	INFO	====> Epoch: 2899, cost 26.33 s
2024-01-02 15:03:40,134	44k	INFO	====> Epoch: 2900, cost 26.23 s
2024-01-02 15:04:06,484	44k	INFO	====> Epoch: 2901, cost 26.35 s
2024-01-02 15:04:32,642	44k	INFO	====> Epoch: 2902, cost 26.16 s
2024-01-02 15:04:55,109	44k	INFO	Train Epoch: 2903 [83%]
2024-01-02 15:04:55,110	44k	INFO	Losses: [2.052676200866699, 2.763962507247925, 10.00927734375, 14.883499145507812, 0.5871715545654297], step: 101600, lr: 6.957445765187512e-05, reference_loss: 30.296586990356445
2024-01-02 15:05:02,559	44k	INFO	Saving model and optimizer state at iteration 2903 to ./logs/44k/G_101600.pth
2024-01-02 15:05:03,802	44k	INFO	Saving model and optimizer state at iteration 2903 to ./logs/44k/D_101600.pth
2024-01-02 15:05:04,566	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_99200.pth
2024-01-02 15:05:04,624	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_99200.pth
2024-01-02 15:05:08,366	44k	INFO	====> Epoch: 2903, cost 35.72 s
2024-01-02 15:05:34,771	44k	INFO	====> Epoch: 2904, cost 26.41 s
2024-01-02 15:06:01,058	44k	INFO	====> Epoch: 2905, cost 26.29 s
2024-01-02 15:06:27,173	44k	INFO	====> Epoch: 2906, cost 26.11 s
2024-01-02 15:06:53,517	44k	INFO	====> Epoch: 2907, cost 26.34 s
2024-01-02 15:07:19,695	44k	INFO	====> Epoch: 2908, cost 26.18 s
2024-01-02 15:07:34,599	44k	INFO	Train Epoch: 2909 [54%]
2024-01-02 15:07:34,599	44k	INFO	Losses: [2.3145458698272705, 2.1896727085113525, 7.741026401519775, 14.96873950958252, 0.25171148777008057], step: 101800, lr: 6.95222931124322e-05, reference_loss: 27.465696334838867
2024-01-02 15:07:46,418	44k	INFO	====> Epoch: 2909, cost 26.72 s
2024-01-02 15:08:12,763	44k	INFO	====> Epoch: 2910, cost 26.35 s
2024-01-02 15:08:39,383	44k	INFO	====> Epoch: 2911, cost 26.62 s
2024-01-02 15:09:05,598	44k	INFO	====> Epoch: 2912, cost 26.22 s
2024-01-02 15:09:31,874	44k	INFO	====> Epoch: 2913, cost 26.28 s
2024-01-02 15:09:58,182	44k	INFO	====> Epoch: 2914, cost 26.31 s
2024-01-02 15:10:05,592	44k	INFO	Train Epoch: 2915 [26%]
2024-01-02 15:10:05,593	44k	INFO	Losses: [1.995314598083496, 2.9492287635803223, 11.013378143310547, 17.936227798461914, 0.7127881050109863], step: 102000, lr: 6.947016768416984e-05, reference_loss: 34.606937408447266
2024-01-02 15:10:24,790	44k	INFO	====> Epoch: 2915, cost 26.61 s
2024-01-02 15:10:51,158	44k	INFO	====> Epoch: 2916, cost 26.37 s
2024-01-02 15:11:17,399	44k	INFO	====> Epoch: 2917, cost 26.24 s
2024-01-02 15:11:44,021	44k	INFO	====> Epoch: 2918, cost 26.62 s
2024-01-02 15:12:10,440	44k	INFO	====> Epoch: 2919, cost 26.42 s
2024-01-02 15:12:36,864	44k	INFO	Train Epoch: 2920 [97%]
2024-01-02 15:12:36,864	44k	INFO	Losses: [2.038620948791504, 3.0866198539733887, 9.997031211853027, 16.555932998657227, 0.5889408588409424], step: 102200, lr: 6.942675968272417e-05, reference_loss: 32.267147064208984
2024-01-02 15:12:37,373	44k	INFO	====> Epoch: 2920, cost 26.93 s
2024-01-02 15:13:03,840	44k	INFO	====> Epoch: 2921, cost 26.47 s
2024-01-02 15:13:30,288	44k	INFO	====> Epoch: 2922, cost 26.45 s
2024-01-02 15:13:56,883	44k	INFO	====> Epoch: 2923, cost 26.59 s
2024-01-02 15:14:23,418	44k	INFO	====> Epoch: 2924, cost 26.54 s
2024-01-02 15:14:50,316	44k	INFO	====> Epoch: 2925, cost 26.90 s
2024-01-02 15:15:09,285	44k	INFO	Train Epoch: 2926 [69%]
2024-01-02 15:15:09,285	44k	INFO	Losses: [2.1688852310180664, 2.6100070476531982, 8.709260940551758, 13.678329467773438, 0.5379273295402527], step: 102400, lr: 6.937470588214718e-05, reference_loss: 27.704410552978516
2024-01-02 15:15:17,330	44k	INFO	Saving model and optimizer state at iteration 2926 to ./logs/44k/G_102400.pth
2024-01-02 15:15:18,261	44k	INFO	Saving model and optimizer state at iteration 2926 to ./logs/44k/D_102400.pth
2024-01-02 15:15:19,056	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_100000.pth
2024-01-02 15:15:19,113	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_100000.pth
2024-01-02 15:15:26,752	44k	INFO	====> Epoch: 2926, cost 36.44 s
2024-01-02 15:15:53,304	44k	INFO	====> Epoch: 2927, cost 26.55 s
2024-01-02 15:16:19,762	44k	INFO	====> Epoch: 2928, cost 26.46 s
2024-01-02 15:16:46,464	44k	INFO	====> Epoch: 2929, cost 26.70 s
2024-01-02 15:17:12,989	44k	INFO	====> Epoch: 2930, cost 26.53 s
2024-01-02 15:17:39,918	44k	INFO	====> Epoch: 2931, cost 26.93 s
2024-01-02 15:17:51,182	44k	INFO	Train Epoch: 2932 [40%]
2024-01-02 15:17:51,183	44k	INFO	Losses: [2.18249249458313, 2.952385187149048, 10.442363739013672, 17.570377349853516, 0.40552955865859985], step: 102600, lr: 6.932269110972256e-05, reference_loss: 33.55315017700195
2024-01-02 15:18:06,848	44k	INFO	====> Epoch: 2932, cost 26.93 s
2024-01-02 15:18:33,245	44k	INFO	====> Epoch: 2933, cost 26.40 s
2024-01-02 15:18:59,612	44k	INFO	====> Epoch: 2934, cost 26.37 s
2024-01-02 15:19:25,879	44k	INFO	====> Epoch: 2935, cost 26.27 s
2024-01-02 15:19:52,312	44k	INFO	====> Epoch: 2936, cost 26.43 s
2024-01-02 15:20:18,795	44k	INFO	====> Epoch: 2937, cost 26.48 s
2024-01-02 15:20:22,578	44k	INFO	Train Epoch: 2938 [11%]
2024-01-02 15:20:22,579	44k	INFO	Losses: [1.9493021965026855, 3.070929527282715, 10.41418170928955, 17.472190856933594, 0.37613537907600403], step: 102800, lr: 6.927071533618831e-05, reference_loss: 33.28274154663086
2024-01-02 15:20:46,114	44k	INFO	====> Epoch: 2938, cost 27.32 s
2024-01-02 15:21:12,519	44k	INFO	====> Epoch: 2939, cost 26.40 s
2024-01-02 15:21:38,845	44k	INFO	====> Epoch: 2940, cost 26.33 s
2024-01-02 15:22:05,201	44k	INFO	====> Epoch: 2941, cost 26.36 s
2024-01-02 15:22:31,616	44k	INFO	====> Epoch: 2942, cost 26.41 s
2024-01-02 15:22:54,208	44k	INFO	Train Epoch: 2943 [83%]
2024-01-02 15:22:54,209	44k	INFO	Losses: [2.0937106609344482, 2.907132387161255, 8.825983047485352, 15.16501522064209, 0.5227735042572021], step: 103000, lr: 6.922743196129958e-05, reference_loss: 29.51461410522461
2024-01-02 15:22:58,609	44k	INFO	====> Epoch: 2943, cost 26.99 s
2024-01-02 15:23:25,222	44k	INFO	====> Epoch: 2944, cost 26.61 s
2024-01-02 15:23:51,627	44k	INFO	====> Epoch: 2945, cost 26.40 s
2024-01-02 15:24:18,038	44k	INFO	====> Epoch: 2946, cost 26.41 s
2024-01-02 15:24:44,423	44k	INFO	====> Epoch: 2947, cost 26.39 s
2024-01-02 15:25:10,679	44k	INFO	====> Epoch: 2948, cost 26.26 s
2024-01-02 15:25:25,582	44k	INFO	Train Epoch: 2949 [54%]
2024-01-02 15:25:25,582	44k	INFO	Losses: [2.213463306427002, 2.727342367172241, 11.650382041931152, 16.465124130249023, 0.5782998204231262], step: 103200, lr: 6.917552760980402e-05, reference_loss: 33.634613037109375
2024-01-02 15:25:33,128	44k	INFO	Saving model and optimizer state at iteration 2949 to ./logs/44k/G_103200.pth
2024-01-02 15:25:34,035	44k	INFO	Saving model and optimizer state at iteration 2949 to ./logs/44k/D_103200.pth
2024-01-02 15:25:34,813	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_100800.pth
2024-01-02 15:25:34,870	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_100800.pth
2024-01-02 15:25:46,228	44k	INFO	====> Epoch: 2949, cost 35.55 s
2024-01-02 15:26:12,855	44k	INFO	====> Epoch: 2950, cost 26.63 s
2024-01-02 15:26:39,188	44k	INFO	====> Epoch: 2951, cost 26.33 s
2024-01-02 15:27:05,572	44k	INFO	====> Epoch: 2952, cost 26.38 s
2024-01-02 15:27:31,946	44k	INFO	====> Epoch: 2953, cost 26.37 s
2024-01-02 15:27:58,163	44k	INFO	====> Epoch: 2954, cost 26.22 s
2024-01-02 15:28:05,644	44k	INFO	Train Epoch: 2955 [26%]
2024-01-02 15:28:05,645	44k	INFO	Losses: [2.550595760345459, 2.313326835632324, 8.174613952636719, 15.005316734313965, 0.564883291721344], step: 103400, lr: 6.912366217440901e-05, reference_loss: 28.60873794555664
2024-01-02 15:28:24,998	44k	INFO	====> Epoch: 2955, cost 26.83 s
2024-01-02 15:28:51,409	44k	INFO	====> Epoch: 2956, cost 26.41 s
2024-01-02 15:29:17,901	44k	INFO	====> Epoch: 2957, cost 26.49 s
2024-01-02 15:29:44,363	44k	INFO	====> Epoch: 2958, cost 26.46 s
2024-01-02 15:30:11,087	44k	INFO	====> Epoch: 2959, cost 26.72 s
2024-01-02 15:30:37,492	44k	INFO	Train Epoch: 2960 [97%]
2024-01-02 15:30:37,493	44k	INFO	Losses: [1.7923016548156738, 3.479177713394165, 10.666486740112305, 17.1258602142334, 0.3350748121738434], step: 103600, lr: 6.908047068477221e-05, reference_loss: 33.398902893066406
2024-01-02 15:30:37,996	44k	INFO	====> Epoch: 2960, cost 26.91 s
2024-01-02 15:31:04,449	44k	INFO	====> Epoch: 2961, cost 26.45 s
2024-01-02 15:31:30,887	44k	INFO	====> Epoch: 2962, cost 26.44 s
2024-01-02 15:31:57,136	44k	INFO	====> Epoch: 2963, cost 26.25 s
2024-01-02 15:32:23,342	44k	INFO	====> Epoch: 2964, cost 26.21 s
2024-01-02 15:32:49,632	44k	INFO	====> Epoch: 2965, cost 26.29 s
2024-01-02 15:33:08,674	44k	INFO	Train Epoch: 2966 [69%]
2024-01-02 15:33:08,675	44k	INFO	Losses: [1.5824878215789795, 3.6034579277038574, 9.740423202514648, 14.476358413696289, 0.5784339308738708], step: 103800, lr: 6.902867651979573e-05, reference_loss: 29.98116111755371
2024-01-02 15:33:16,754	44k	INFO	====> Epoch: 2966, cost 27.12 s
2024-01-02 15:33:43,090	44k	INFO	====> Epoch: 2967, cost 26.34 s
2024-01-02 15:34:09,509	44k	INFO	====> Epoch: 2968, cost 26.42 s
2024-01-02 15:34:36,009	44k	INFO	====> Epoch: 2969, cost 26.50 s
2024-01-02 15:35:02,360	44k	INFO	====> Epoch: 2970, cost 26.35 s
2024-01-02 15:35:28,681	44k	INFO	====> Epoch: 2971, cost 26.32 s
2024-01-02 15:35:39,874	44k	INFO	Train Epoch: 2972 [40%]
2024-01-02 15:35:39,875	44k	INFO	Losses: [2.2983834743499756, 2.4731876850128174, 10.084321022033691, 17.771020889282227, 0.46882227063179016], step: 104000, lr: 6.897692118830576e-05, reference_loss: 33.09573745727539
2024-01-02 15:35:47,619	44k	INFO	Saving model and optimizer state at iteration 2972 to ./logs/44k/G_104000.pth
2024-01-02 15:35:48,533	44k	INFO	Saving model and optimizer state at iteration 2972 to ./logs/44k/D_104000.pth
2024-01-02 15:35:49,307	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_101600.pth
2024-01-02 15:35:49,364	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_101600.pth
2024-01-02 15:36:04,415	44k	INFO	====> Epoch: 2972, cost 35.73 s
2024-01-02 15:36:30,781	44k	INFO	====> Epoch: 2973, cost 26.37 s
2024-01-02 15:36:57,163	44k	INFO	====> Epoch: 2974, cost 26.38 s
2024-01-02 15:37:23,535	44k	INFO	====> Epoch: 2975, cost 26.37 s
2024-01-02 15:37:49,860	44k	INFO	====> Epoch: 2976, cost 26.32 s
2024-01-02 15:38:16,285	44k	INFO	====> Epoch: 2977, cost 26.42 s
2024-01-02 15:38:20,078	44k	INFO	Train Epoch: 2978 [11%]
2024-01-02 15:38:20,079	44k	INFO	Losses: [1.9187607765197754, 3.0643091201782227, 9.889080047607422, 15.656208038330078, 0.5007896423339844], step: 104200, lr: 6.892520466118625e-05, reference_loss: 31.02914810180664
2024-01-02 15:38:43,794	44k	INFO	====> Epoch: 2978, cost 27.51 s
2024-01-02 15:39:10,181	44k	INFO	====> Epoch: 2979, cost 26.39 s
2024-01-02 15:39:36,570	44k	INFO	====> Epoch: 2980, cost 26.39 s
2024-01-02 15:40:02,915	44k	INFO	====> Epoch: 2981, cost 26.35 s
2024-01-02 15:40:29,277	44k	INFO	====> Epoch: 2982, cost 26.36 s
2024-01-02 15:40:51,825	44k	INFO	Train Epoch: 2983 [83%]
2024-01-02 15:40:51,825	44k	INFO	Losses: [2.291135787963867, 2.5899558067321777, 8.087278366088867, 15.947649002075195, 0.550357460975647], step: 104400, lr: 6.88821371764901e-05, reference_loss: 29.46637725830078
2024-01-02 15:40:56,080	44k	INFO	====> Epoch: 2983, cost 26.80 s
2024-01-02 15:41:22,506	44k	INFO	====> Epoch: 2984, cost 26.43 s
2024-01-02 15:41:49,244	44k	INFO	====> Epoch: 2985, cost 26.74 s
2024-01-02 15:42:15,668	44k	INFO	====> Epoch: 2986, cost 26.42 s
2024-01-02 15:42:42,012	44k	INFO	====> Epoch: 2987, cost 26.34 s
2024-01-02 15:43:08,567	44k	INFO	====> Epoch: 2988, cost 26.56 s
2024-01-02 15:43:23,669	44k	INFO	Train Epoch: 2989 [54%]
2024-01-02 15:43:23,670	44k	INFO	Losses: [2.301283836364746, 3.030756950378418, 10.68111515045166, 17.215740203857422, 0.49151453375816345], step: 104600, lr: 6.883049171516815e-05, reference_loss: 33.72041320800781
2024-01-02 15:43:35,674	44k	INFO	====> Epoch: 2989, cost 27.11 s
2024-01-02 15:44:02,313	44k	INFO	====> Epoch: 2990, cost 26.64 s
2024-01-02 15:44:28,868	44k	INFO	====> Epoch: 2991, cost 26.56 s
2024-01-02 15:44:55,834	44k	INFO	====> Epoch: 2992, cost 26.97 s
2024-01-02 15:45:22,369	44k	INFO	====> Epoch: 2993, cost 26.53 s
2024-01-02 15:45:48,936	44k	INFO	====> Epoch: 2994, cost 26.57 s
2024-01-02 15:45:56,540	44k	INFO	Train Epoch: 2995 [26%]
2024-01-02 15:45:56,541	44k	INFO	Losses: [2.6170430183410645, 2.3818368911743164, 7.956607818603516, 15.281566619873047, 0.43732526898384094], step: 104800, lr: 6.877888497583981e-05, reference_loss: 28.674379348754883
2024-01-02 15:46:04,577	44k	INFO	Saving model and optimizer state at iteration 2995 to ./logs/44k/G_104800.pth
2024-01-02 15:46:05,499	44k	INFO	Saving model and optimizer state at iteration 2995 to ./logs/44k/D_104800.pth
2024-01-02 15:46:06,301	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_102400.pth
2024-01-02 15:46:06,358	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_102400.pth
2024-01-02 15:46:25,304	44k	INFO	====> Epoch: 2995, cost 36.37 s
2024-01-02 15:46:51,805	44k	INFO	====> Epoch: 2996, cost 26.50 s
2024-01-02 15:47:18,679	44k	INFO	====> Epoch: 2997, cost 26.87 s
2024-01-02 15:47:45,284	44k	INFO	====> Epoch: 2998, cost 26.60 s
2024-01-02 15:48:11,715	44k	INFO	====> Epoch: 2999, cost 26.43 s
2024-01-02 15:48:38,123	44k	INFO	Train Epoch: 3000 [97%]
2024-01-02 15:48:38,123	44k	INFO	Losses: [2.283942222595215, 2.745758295059204, 10.664128303527832, 18.34991455078125, 0.4140377640724182], step: 105000, lr: 6.873590891808743e-05, reference_loss: 34.45778274536133
2024-01-02 15:48:38,609	44k	INFO	====> Epoch: 3000, cost 26.89 s
2024-01-02 15:49:04,921	44k	INFO	====> Epoch: 3001, cost 26.31 s
2024-01-02 15:49:31,121	44k	INFO	====> Epoch: 3002, cost 26.20 s
2024-01-02 15:49:57,397	44k	INFO	====> Epoch: 3003, cost 26.28 s
2024-01-02 15:50:23,785	44k	INFO	====> Epoch: 3004, cost 26.39 s
2024-01-02 15:50:50,055	44k	INFO	====> Epoch: 3005, cost 26.27 s
2024-01-02 15:51:09,163	44k	INFO	Train Epoch: 3006 [69%]
2024-01-02 15:51:09,164	44k	INFO	Losses: [2.067060947418213, 3.2336297035217285, 10.27567195892334, 14.050064086914062, 0.6668282151222229], step: 105200, lr: 6.868437309369275e-05, reference_loss: 30.293254852294922
2024-01-02 15:51:17,146	44k	INFO	====> Epoch: 3006, cost 27.09 s
2024-01-02 15:51:43,528	44k	INFO	====> Epoch: 3007, cost 26.38 s
2024-01-02 15:52:09,907	44k	INFO	====> Epoch: 3008, cost 26.38 s
2024-01-02 15:52:36,329	44k	INFO	====> Epoch: 3009, cost 26.42 s
2024-01-02 15:53:02,731	44k	INFO	====> Epoch: 3010, cost 26.40 s
2024-01-02 15:53:29,129	44k	INFO	====> Epoch: 3011, cost 26.40 s
2024-01-02 15:53:40,355	44k	INFO	Train Epoch: 3012 [40%]
2024-01-02 15:53:40,356	44k	INFO	Losses: [1.9966768026351929, 3.1894659996032715, 9.8131742477417, 15.788901329040527, 0.6741933822631836], step: 105400, lr: 6.863287590908969e-05, reference_loss: 31.462413787841797
2024-01-02 15:53:56,502	44k	INFO	====> Epoch: 3012, cost 27.37 s
2024-01-02 15:54:22,779	44k	INFO	====> Epoch: 3013, cost 26.28 s
2024-01-02 15:54:49,070	44k	INFO	====> Epoch: 3014, cost 26.29 s
2024-01-02 15:55:15,335	44k	INFO	====> Epoch: 3015, cost 26.26 s
2024-01-02 15:55:41,592	44k	INFO	====> Epoch: 3016, cost 26.26 s
2024-01-02 15:56:08,095	44k	INFO	====> Epoch: 3017, cost 26.50 s
2024-01-02 15:56:11,864	44k	INFO	Train Epoch: 3018 [11%]
2024-01-02 15:56:11,864	44k	INFO	Losses: [2.8071138858795166, 1.8984695672988892, 8.132970809936523, 15.79298210144043, 0.7376184463500977], step: 105600, lr: 6.858141733530744e-05, reference_loss: 29.369155883789062
2024-01-02 15:56:19,291	44k	INFO	Saving model and optimizer state at iteration 3018 to ./logs/44k/G_105600.pth
2024-01-02 15:56:20,524	44k	INFO	Saving model and optimizer state at iteration 3018 to ./logs/44k/D_105600.pth
2024-01-02 15:56:21,303	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_103200.pth
2024-01-02 15:56:21,361	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_103200.pth
2024-01-02 15:56:43,836	44k	INFO	====> Epoch: 3018, cost 35.74 s
2024-01-02 15:57:10,165	44k	INFO	====> Epoch: 3019, cost 26.33 s
2024-01-02 15:57:36,505	44k	INFO	====> Epoch: 3020, cost 26.34 s
2024-01-02 15:58:02,977	44k	INFO	====> Epoch: 3021, cost 26.47 s
2024-01-02 15:58:29,228	44k	INFO	====> Epoch: 3022, cost 26.25 s
2024-01-02 15:58:51,784	44k	INFO	Train Epoch: 3023 [83%]
2024-01-02 15:58:51,785	44k	INFO	Losses: [1.8490266799926758, 3.495199680328369, 9.623499870300293, 14.369410514831543, 0.3953157663345337], step: 105800, lr: 6.853856466397991e-05, reference_loss: 29.732450485229492
2024-01-02 15:58:56,205	44k	INFO	====> Epoch: 3023, cost 26.98 s
2024-01-02 15:59:22,612	44k	INFO	====> Epoch: 3024, cost 26.41 s
2024-01-02 15:59:49,262	44k	INFO	====> Epoch: 3025, cost 26.65 s
2024-01-02 16:00:15,675	44k	INFO	====> Epoch: 3026, cost 26.41 s
2024-01-02 16:00:42,158	44k	INFO	====> Epoch: 3027, cost 26.48 s
2024-01-02 16:01:08,565	44k	INFO	====> Epoch: 3028, cost 26.41 s
2024-01-02 16:01:23,484	44k	INFO	Train Epoch: 3029 [54%]
2024-01-02 16:01:23,484	44k	INFO	Losses: [2.21000075340271, 2.4685685634613037, 8.43867015838623, 15.520516395568848, 0.5664382576942444], step: 106000, lr: 6.848717680153097e-05, reference_loss: 29.204195022583008
2024-01-02 16:01:35,342	44k	INFO	====> Epoch: 3029, cost 26.78 s
2024-01-02 16:02:01,852	44k	INFO	====> Epoch: 3030, cost 26.51 s
2024-01-02 16:02:28,468	44k	INFO	====> Epoch: 3031, cost 26.62 s
2024-01-02 16:02:55,297	44k	INFO	====> Epoch: 3032, cost 26.83 s
2024-01-02 16:03:21,898	44k	INFO	====> Epoch: 3033, cost 26.60 s
2024-01-02 16:03:48,503	44k	INFO	====> Epoch: 3034, cost 26.60 s
2024-01-02 16:03:56,109	44k	INFO	Train Epoch: 3035 [26%]
2024-01-02 16:03:56,110	44k	INFO	Losses: [1.9042842388153076, 3.0779354572296143, 9.892373085021973, 15.557262420654297, 0.5101902484893799], step: 106200, lr: 6.843582746793683e-05, reference_loss: 30.942045211791992
2024-01-02 16:04:15,549	44k	INFO	====> Epoch: 3035, cost 27.05 s
2024-01-02 16:04:42,049	44k	INFO	====> Epoch: 3036, cost 26.50 s
2024-01-02 16:05:08,700	44k	INFO	====> Epoch: 3037, cost 26.65 s
2024-01-02 16:05:35,359	44k	INFO	====> Epoch: 3038, cost 26.66 s
2024-01-02 16:06:02,290	44k	INFO	====> Epoch: 3039, cost 26.93 s
2024-01-02 16:06:28,798	44k	INFO	Train Epoch: 3040 [97%]
2024-01-02 16:06:28,799	44k	INFO	Losses: [2.2823708057403564, 2.7185049057006836, 7.909708499908447, 14.017666816711426, 0.5176633596420288], step: 106400, lr: 6.839306576753085e-05, reference_loss: 27.445913314819336
2024-01-02 16:06:36,520	44k	INFO	Saving model and optimizer state at iteration 3040 to ./logs/44k/G_106400.pth
2024-01-02 16:06:37,427	44k	INFO	Saving model and optimizer state at iteration 3040 to ./logs/44k/D_106400.pth
2024-01-02 16:06:38,208	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_104000.pth
2024-01-02 16:06:38,265	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_104000.pth
2024-01-02 16:06:38,266	44k	INFO	====> Epoch: 3040, cost 35.98 s
2024-01-02 16:07:04,651	44k	INFO	====> Epoch: 3041, cost 26.39 s
2024-01-02 16:07:31,030	44k	INFO	====> Epoch: 3042, cost 26.38 s
2024-01-02 16:07:57,434	44k	INFO	====> Epoch: 3043, cost 26.40 s
2024-01-02 16:08:24,136	44k	INFO	====> Epoch: 3044, cost 26.70 s
2024-01-02 16:08:50,514	44k	INFO	====> Epoch: 3045, cost 26.38 s
2024-01-02 16:09:09,252	44k	INFO	Train Epoch: 3046 [69%]
2024-01-02 16:09:09,252	44k	INFO	Losses: [1.9268747568130493, 2.901198625564575, 9.877967834472656, 14.57436752319336, 0.6104272603988647], step: 106600, lr: 6.834178699515862e-05, reference_loss: 29.890836715698242
2024-01-02 16:09:17,301	44k	INFO	====> Epoch: 3046, cost 26.79 s
2024-01-02 16:09:43,691	44k	INFO	====> Epoch: 3047, cost 26.39 s
2024-01-02 16:10:10,106	44k	INFO	====> Epoch: 3048, cost 26.42 s
2024-01-02 16:10:36,547	44k	INFO	====> Epoch: 3049, cost 26.44 s
2024-01-02 16:11:02,905	44k	INFO	====> Epoch: 3050, cost 26.36 s
2024-01-02 16:11:29,295	44k	INFO	====> Epoch: 3051, cost 26.39 s
2024-01-02 16:11:40,523	44k	INFO	Train Epoch: 3052 [40%]
2024-01-02 16:11:40,523	44k	INFO	Losses: [2.0424556732177734, 3.0666964054107666, 10.92827320098877, 16.922101974487305, 0.43537530303001404], step: 106800, lr: 6.829054666984923e-05, reference_loss: 33.394901275634766
2024-01-02 16:11:56,582	44k	INFO	====> Epoch: 3052, cost 27.29 s
2024-01-02 16:12:23,004	44k	INFO	====> Epoch: 3053, cost 26.42 s
2024-01-02 16:12:49,477	44k	INFO	====> Epoch: 3054, cost 26.47 s
2024-01-02 16:13:16,092	44k	INFO	====> Epoch: 3055, cost 26.62 s
2024-01-02 16:13:42,714	44k	INFO	====> Epoch: 3056, cost 26.62 s
2024-01-02 16:14:09,400	44k	INFO	====> Epoch: 3057, cost 26.69 s
2024-01-02 16:14:13,197	44k	INFO	Train Epoch: 3058 [11%]
2024-01-02 16:14:13,198	44k	INFO	Losses: [1.714998722076416, 3.207050085067749, 10.591306686401367, 16.07626724243164, 0.33017075061798096], step: 107000, lr: 6.823934476277636e-05, reference_loss: 31.9197940826416
2024-01-02 16:14:36,822	44k	INFO	====> Epoch: 3058, cost 27.42 s
2024-01-02 16:15:03,404	44k	INFO	====> Epoch: 3059, cost 26.58 s
2024-01-02 16:15:29,960	44k	INFO	====> Epoch: 3060, cost 26.56 s
2024-01-02 16:15:56,369	44k	INFO	====> Epoch: 3061, cost 26.41 s
2024-01-02 16:16:22,922	44k	INFO	====> Epoch: 3062, cost 26.55 s
2024-01-02 16:16:45,700	44k	INFO	Train Epoch: 3063 [83%]
2024-01-02 16:16:45,701	44k	INFO	Losses: [2.066347122192383, 2.70823335647583, 10.152609825134277, 14.906549453735352, 0.6035336256027222], step: 107200, lr: 6.819670583336453e-05, reference_loss: 30.437273025512695
2024-01-02 16:16:53,786	44k	INFO	Saving model and optimizer state at iteration 3063 to ./logs/44k/G_107200.pth
2024-01-02 16:16:54,708	44k	INFO	Saving model and optimizer state at iteration 3063 to ./logs/44k/D_107200.pth
2024-01-02 16:16:55,502	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_104800.pth
2024-01-02 16:16:55,559	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_104800.pth
2024-01-02 16:16:59,344	44k	INFO	====> Epoch: 3063, cost 36.42 s
2024-01-02 16:17:26,151	44k	INFO	====> Epoch: 3064, cost 26.81 s
2024-01-02 16:17:52,393	44k	INFO	====> Epoch: 3065, cost 26.24 s
2024-01-02 16:18:18,711	44k	INFO	====> Epoch: 3066, cost 26.32 s
2024-01-02 16:18:45,060	44k	INFO	====> Epoch: 3067, cost 26.35 s
2024-01-02 16:19:11,457	44k	INFO	====> Epoch: 3068, cost 26.40 s
2024-01-02 16:19:26,465	44k	INFO	Train Epoch: 3069 [54%]
2024-01-02 16:19:26,466	44k	INFO	Losses: [2.502497673034668, 2.3532605171203613, 8.87716293334961, 14.858636856079102, 0.24713139235973358], step: 107400, lr: 6.814557428492874e-05, reference_loss: 28.83868980407715
2024-01-02 16:19:38,553	44k	INFO	====> Epoch: 3069, cost 27.10 s
2024-01-02 16:20:04,835	44k	INFO	====> Epoch: 3070, cost 26.28 s
2024-01-02 16:20:31,258	44k	INFO	====> Epoch: 3071, cost 26.42 s
2024-01-02 16:20:57,678	44k	INFO	====> Epoch: 3072, cost 26.42 s
2024-01-02 16:21:24,325	44k	INFO	====> Epoch: 3073, cost 26.65 s
2024-01-02 16:21:50,779	44k	INFO	====> Epoch: 3074, cost 26.45 s
2024-01-02 16:21:58,299	44k	INFO	Train Epoch: 3075 [26%]
2024-01-02 16:21:58,299	44k	INFO	Losses: [1.8883899450302124, 3.104837417602539, 10.928168296813965, 17.810949325561523, 0.7353768348693848], step: 107600, lr: 6.809448107317232e-05, reference_loss: 34.46772384643555
2024-01-02 16:22:17,763	44k	INFO	====> Epoch: 3075, cost 26.98 s
2024-01-02 16:22:44,230	44k	INFO	====> Epoch: 3076, cost 26.47 s
2024-01-02 16:23:10,692	44k	INFO	====> Epoch: 3077, cost 26.46 s
2024-01-02 16:23:37,127	44k	INFO	====> Epoch: 3078, cost 26.44 s
2024-01-02 16:24:03,457	44k	INFO	====> Epoch: 3079, cost 26.33 s
2024-01-02 16:24:30,117	44k	INFO	Train Epoch: 3080 [97%]
2024-01-02 16:24:30,117	44k	INFO	Losses: [2.1881580352783203, 2.7876060009002686, 9.912476539611816, 17.570068359375, 0.5788926482200623], step: 107800, lr: 6.805193266093435e-05, reference_loss: 33.037200927734375
2024-01-02 16:24:30,604	44k	INFO	====> Epoch: 3080, cost 27.15 s
2024-01-02 16:24:57,033	44k	INFO	====> Epoch: 3081, cost 26.43 s
2024-01-02 16:25:23,480	44k	INFO	====> Epoch: 3082, cost 26.45 s
2024-01-02 16:25:49,840	44k	INFO	====> Epoch: 3083, cost 26.36 s
2024-01-02 16:26:16,295	44k	INFO	====> Epoch: 3084, cost 26.45 s
2024-01-02 16:26:42,688	44k	INFO	====> Epoch: 3085, cost 26.39 s
2024-01-02 16:27:01,539	44k	INFO	Train Epoch: 3086 [69%]
2024-01-02 16:27:01,540	44k	INFO	Losses: [2.3950273990631104, 2.5502614974975586, 8.407809257507324, 13.544977188110352, 0.5789041519165039], step: 108000, lr: 6.800090965845232e-05, reference_loss: 27.476978302001953
2024-01-02 16:27:09,521	44k	INFO	Saving model and optimizer state at iteration 3086 to ./logs/44k/G_108000.pth
2024-01-02 16:27:10,426	44k	INFO	Saving model and optimizer state at iteration 3086 to ./logs/44k/D_108000.pth
2024-01-02 16:27:11,206	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_105600.pth
2024-01-02 16:27:11,266	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_105600.pth
2024-01-02 16:27:18,770	44k	INFO	====> Epoch: 3086, cost 36.08 s
2024-01-02 16:27:45,203	44k	INFO	====> Epoch: 3087, cost 26.43 s
2024-01-02 16:28:11,714	44k	INFO	====> Epoch: 3088, cost 26.51 s
2024-01-02 16:28:38,188	44k	INFO	====> Epoch: 3089, cost 26.47 s
2024-01-02 16:29:04,761	44k	INFO	====> Epoch: 3090, cost 26.57 s
2024-01-02 16:29:31,270	44k	INFO	====> Epoch: 3091, cost 26.51 s
2024-01-02 16:29:42,551	44k	INFO	Train Epoch: 3092 [40%]
2024-01-02 16:29:42,551	44k	INFO	Losses: [2.3749358654022217, 2.476769208908081, 10.187909126281738, 17.012969970703125, 0.3535993993282318], step: 108200, lr: 6.794992491126563e-05, reference_loss: 32.40618133544922
2024-01-02 16:29:58,591	44k	INFO	====> Epoch: 3092, cost 27.32 s
2024-01-02 16:30:25,013	44k	INFO	====> Epoch: 3093, cost 26.42 s
2024-01-02 16:30:51,405	44k	INFO	====> Epoch: 3094, cost 26.39 s
2024-01-02 16:31:17,777	44k	INFO	====> Epoch: 3095, cost 26.37 s
2024-01-02 16:31:44,217	44k	INFO	====> Epoch: 3096, cost 26.44 s
2024-01-02 16:32:10,663	44k	INFO	====> Epoch: 3097, cost 26.45 s
2024-01-02 16:32:14,425	44k	INFO	Train Epoch: 3098 [11%]
2024-01-02 16:32:14,426	44k	INFO	Losses: [2.1545581817626953, 2.7535905838012695, 10.104557037353516, 17.80261993408203, 0.4221186637878418], step: 108400, lr: 6.789897839069178e-05, reference_loss: 33.23744583129883
2024-01-02 16:32:37,540	44k	INFO	====> Epoch: 3098, cost 26.88 s
2024-01-02 16:33:04,101	44k	INFO	====> Epoch: 3099, cost 26.56 s
2024-01-02 16:33:30,445	44k	INFO	====> Epoch: 3100, cost 26.34 s
2024-01-02 16:33:56,831	44k	INFO	====> Epoch: 3101, cost 26.39 s
2024-01-02 16:34:23,153	44k	INFO	====> Epoch: 3102, cost 26.32 s
2024-01-02 16:34:45,801	44k	INFO	Train Epoch: 3103 [83%]
2024-01-02 16:34:45,802	44k	INFO	Losses: [2.260453224182129, 2.529006242752075, 9.142370223999023, 15.264849662780762, 0.5429117679595947], step: 108600, lr: 6.785655213708687e-05, reference_loss: 29.73958969116211
2024-01-02 16:34:50,204	44k	INFO	====> Epoch: 3103, cost 27.05 s
2024-01-02 16:35:16,488	44k	INFO	====> Epoch: 3104, cost 26.28 s
2024-01-02 16:35:42,791	44k	INFO	====> Epoch: 3105, cost 26.30 s
2024-01-02 16:36:09,473	44k	INFO	====> Epoch: 3106, cost 26.68 s
2024-01-02 16:36:35,808	44k	INFO	====> Epoch: 3107, cost 26.34 s
2024-01-02 16:37:02,121	44k	INFO	====> Epoch: 3108, cost 26.31 s
2024-01-02 16:37:17,115	44k	INFO	Train Epoch: 3109 [54%]
2024-01-02 16:37:17,115	44k	INFO	Losses: [2.087310552597046, 2.842024087905884, 11.475922584533691, 16.125534057617188, 0.5377338528633118], step: 108800, lr: 6.780567562421305e-05, reference_loss: 33.06852722167969
2024-01-02 16:37:24,543	44k	INFO	Saving model and optimizer state at iteration 3109 to ./logs/44k/G_108800.pth
2024-01-02 16:37:25,445	44k	INFO	Saving model and optimizer state at iteration 3109 to ./logs/44k/D_108800.pth
2024-01-02 16:37:26,218	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_106400.pth
2024-01-02 16:37:26,276	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_106400.pth
2024-01-02 16:37:37,665	44k	INFO	====> Epoch: 3109, cost 35.54 s
2024-01-02 16:38:04,203	44k	INFO	====> Epoch: 3110, cost 26.54 s
2024-01-02 16:38:30,977	44k	INFO	====> Epoch: 3111, cost 26.77 s
2024-01-02 16:38:57,265	44k	INFO	====> Epoch: 3112, cost 26.29 s
2024-01-02 16:39:23,667	44k	INFO	====> Epoch: 3113, cost 26.40 s
2024-01-02 16:39:50,104	44k	INFO	====> Epoch: 3114, cost 26.44 s
2024-01-02 16:39:57,554	44k	INFO	Train Epoch: 3115 [26%]
2024-01-02 16:39:57,555	44k	INFO	Losses: [2.031141757965088, 3.138770818710327, 10.256071090698242, 15.847957611083984, 0.5648936033248901], step: 109000, lr: 6.775483725680169e-05, reference_loss: 31.838834762573242
2024-01-02 16:40:16,722	44k	INFO	====> Epoch: 3115, cost 26.62 s
2024-01-02 16:40:42,980	44k	INFO	====> Epoch: 3116, cost 26.26 s
2024-01-02 16:41:09,395	44k	INFO	====> Epoch: 3117, cost 26.42 s
2024-01-02 16:41:35,730	44k	INFO	====> Epoch: 3118, cost 26.33 s
2024-01-02 16:42:02,079	44k	INFO	====> Epoch: 3119, cost 26.35 s
2024-01-02 16:42:28,666	44k	INFO	Train Epoch: 3120 [97%]
2024-01-02 16:42:28,666	44k	INFO	Losses: [2.488248348236084, 2.422391176223755, 7.821775436401367, 14.881535530090332, 0.3704822361469269], step: 109200, lr: 6.771250106888624e-05, reference_loss: 27.984432220458984
2024-01-02 16:42:29,298	44k	INFO	====> Epoch: 3120, cost 27.22 s
2024-01-02 16:42:55,679	44k	INFO	====> Epoch: 3121, cost 26.38 s
2024-01-02 16:43:22,071	44k	INFO	====> Epoch: 3122, cost 26.39 s
2024-01-02 16:43:48,434	44k	INFO	====> Epoch: 3123, cost 26.36 s
2024-01-02 16:44:14,760	44k	INFO	====> Epoch: 3124, cost 26.33 s
2024-01-02 16:44:41,213	44k	INFO	====> Epoch: 3125, cost 26.45 s
2024-01-02 16:45:00,000	44k	INFO	Train Epoch: 3126 [69%]
2024-01-02 16:45:00,000	44k	INFO	Losses: [2.4077513217926025, 2.628779172897339, 8.667880058288574, 15.428425788879395, 0.5635715126991272], step: 109400, lr: 6.766173256055722e-05, reference_loss: 29.696407318115234
2024-01-02 16:45:08,412	44k	INFO	====> Epoch: 3126, cost 27.20 s
2024-01-02 16:45:34,800	44k	INFO	====> Epoch: 3127, cost 26.39 s
2024-01-02 16:46:01,176	44k	INFO	====> Epoch: 3128, cost 26.38 s
2024-01-02 16:46:27,637	44k	INFO	====> Epoch: 3129, cost 26.46 s
2024-01-02 16:46:54,045	44k	INFO	====> Epoch: 3130, cost 26.41 s
2024-01-02 16:47:20,331	44k	INFO	====> Epoch: 3131, cost 26.29 s
2024-01-02 16:47:31,530	44k	INFO	Train Epoch: 3132 [40%]
2024-01-02 16:47:31,531	44k	INFO	Losses: [2.24611759185791, 2.7186551094055176, 10.499482154846191, 17.710147857666016, 0.5036588907241821], step: 109600, lr: 6.761100211671257e-05, reference_loss: 33.67805862426758
2024-01-02 16:47:39,025	44k	INFO	Saving model and optimizer state at iteration 3132 to ./logs/44k/G_109600.pth
2024-01-02 16:47:40,251	44k	INFO	Saving model and optimizer state at iteration 3132 to ./logs/44k/D_109600.pth
2024-01-02 16:47:41,012	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_107200.pth
2024-01-02 16:47:41,069	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_107200.pth
2024-01-02 16:47:56,240	44k	INFO	====> Epoch: 3132, cost 35.91 s
2024-01-02 16:48:22,702	44k	INFO	====> Epoch: 3133, cost 26.46 s
2024-01-02 16:48:49,132	44k	INFO	====> Epoch: 3134, cost 26.43 s
2024-01-02 16:49:15,440	44k	INFO	====> Epoch: 3135, cost 26.31 s
2024-01-02 16:49:41,812	44k	INFO	====> Epoch: 3136, cost 26.37 s
2024-01-02 16:50:08,152	44k	INFO	====> Epoch: 3137, cost 26.34 s
2024-01-02 16:50:11,921	44k	INFO	Train Epoch: 3138 [11%]
2024-01-02 16:50:11,921	44k	INFO	Losses: [2.6014044284820557, 1.985008716583252, 7.607399940490723, 14.593157768249512, 0.4416920840740204], step: 109800, lr: 6.756030970881285e-05, reference_loss: 27.22866439819336
2024-01-02 16:50:35,066	44k	INFO	====> Epoch: 3138, cost 26.91 s
2024-01-02 16:51:01,747	44k	INFO	====> Epoch: 3139, cost 26.68 s
2024-01-02 16:51:28,080	44k	INFO	====> Epoch: 3140, cost 26.33 s
2024-01-02 16:51:54,359	44k	INFO	====> Epoch: 3141, cost 26.28 s
2024-01-02 16:52:20,537	44k	INFO	====> Epoch: 3142, cost 26.18 s
2024-01-02 16:52:43,145	44k	INFO	Train Epoch: 3143 [83%]
2024-01-02 16:52:43,146	44k	INFO	Losses: [2.384000778198242, 2.441849708557129, 8.39729118347168, 16.781564712524414, 0.5251732468605042], step: 110000, lr: 6.751809507022376e-05, reference_loss: 30.52988052368164
2024-01-02 16:52:47,438	44k	INFO	====> Epoch: 3143, cost 26.90 s
2024-01-02 16:53:13,854	44k	INFO	====> Epoch: 3144, cost 26.42 s
2024-01-02 16:53:40,272	44k	INFO	====> Epoch: 3145, cost 26.42 s
2024-01-02 16:54:06,970	44k	INFO	====> Epoch: 3146, cost 26.70 s
2024-01-02 16:54:33,401	44k	INFO	====> Epoch: 3147, cost 26.43 s
2024-01-02 16:54:59,765	44k	INFO	====> Epoch: 3148, cost 26.36 s
2024-01-02 16:55:14,766	44k	INFO	Train Epoch: 3149 [54%]
2024-01-02 16:55:14,766	44k	INFO	Losses: [1.999179720878601, 2.89023494720459, 11.289813041687012, 17.10116958618164, 0.4655557870864868], step: 110200, lr: 6.746747232083744e-05, reference_loss: 33.74595260620117
2024-01-02 16:55:26,787	44k	INFO	====> Epoch: 3149, cost 27.02 s
2024-01-02 16:55:53,148	44k	INFO	====> Epoch: 3150, cost 26.36 s
2024-01-02 16:56:19,560	44k	INFO	====> Epoch: 3151, cost 26.41 s
2024-01-02 16:56:45,924	44k	INFO	====> Epoch: 3152, cost 26.36 s
2024-01-02 16:57:12,704	44k	INFO	====> Epoch: 3153, cost 26.78 s
2024-01-02 16:57:39,113	44k	INFO	====> Epoch: 3154, cost 26.41 s
2024-01-02 16:57:46,632	44k	INFO	Train Epoch: 3155 [26%]
2024-01-02 16:57:46,633	44k	INFO	Losses: [2.2598955631256104, 3.122932195663452, 9.553947448730469, 16.765243530273438, 0.4420531988143921], step: 110400, lr: 6.741688752665043e-05, reference_loss: 32.144073486328125
2024-01-02 16:57:54,155	44k	INFO	Saving model and optimizer state at iteration 3155 to ./logs/44k/G_110400.pth
2024-01-02 16:57:55,034	44k	INFO	Saving model and optimizer state at iteration 3155 to ./logs/44k/D_110400.pth
2024-01-02 16:57:55,801	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_108000.pth
2024-01-02 16:57:55,858	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_108000.pth
2024-01-02 16:58:14,757	44k	INFO	====> Epoch: 3155, cost 35.64 s
2024-01-02 16:58:41,240	44k	INFO	====> Epoch: 3156, cost 26.48 s
2024-01-02 16:59:07,676	44k	INFO	====> Epoch: 3157, cost 26.44 s
2024-01-02 16:59:34,081	44k	INFO	====> Epoch: 3158, cost 26.40 s
2024-01-02 17:00:00,734	44k	INFO	====> Epoch: 3159, cost 26.65 s
2024-01-02 17:00:27,086	44k	INFO	Train Epoch: 3160 [97%]
2024-01-02 17:00:27,087	44k	INFO	Losses: [2.4109697341918945, 2.4313602447509766, 10.082887649536133, 16.825695037841797, 0.4036698043346405], step: 110600, lr: 6.737476250451829e-05, reference_loss: 32.15458297729492
2024-01-02 17:00:27,576	44k	INFO	====> Epoch: 3160, cost 26.84 s
2024-01-02 17:00:53,896	44k	INFO	====> Epoch: 3161, cost 26.32 s
2024-01-02 17:01:20,328	44k	INFO	====> Epoch: 3162, cost 26.43 s
2024-01-02 17:01:46,788	44k	INFO	====> Epoch: 3163, cost 26.46 s
2024-01-02 17:02:13,309	44k	INFO	====> Epoch: 3164, cost 26.52 s
2024-01-02 17:02:39,750	44k	INFO	====> Epoch: 3165, cost 26.44 s
2024-01-02 17:02:58,536	44k	INFO	Train Epoch: 3166 [69%]
2024-01-02 17:02:58,537	44k	INFO	Losses: [2.172954559326172, 2.7515506744384766, 10.987994194030762, 15.618410110473633, 0.6247755289077759], step: 110800, lr: 6.732424722096827e-05, reference_loss: 32.15568542480469
2024-01-02 17:03:07,031	44k	INFO	====> Epoch: 3166, cost 27.28 s
2024-01-02 17:03:33,427	44k	INFO	====> Epoch: 3167, cost 26.40 s
2024-01-02 17:03:59,797	44k	INFO	====> Epoch: 3168, cost 26.37 s
2024-01-02 17:04:26,268	44k	INFO	====> Epoch: 3169, cost 26.47 s
2024-01-02 17:04:52,565	44k	INFO	====> Epoch: 3170, cost 26.30 s
2024-01-02 17:05:18,836	44k	INFO	====> Epoch: 3171, cost 26.27 s
2024-01-02 17:05:30,088	44k	INFO	Train Epoch: 3172 [40%]
2024-01-02 17:05:30,089	44k	INFO	Losses: [2.2819390296936035, 2.574226140975952, 8.465405464172363, 15.48839282989502, 0.6135536432266235], step: 111000, lr: 6.727376981204337e-05, reference_loss: 29.42351722717285
2024-01-02 17:05:45,729	44k	INFO	====> Epoch: 3172, cost 26.89 s
2024-01-02 17:06:12,422	44k	INFO	====> Epoch: 3173, cost 26.69 s
2024-01-02 17:06:38,763	44k	INFO	====> Epoch: 3174, cost 26.34 s
2024-01-02 17:07:05,123	44k	INFO	====> Epoch: 3175, cost 26.36 s
2024-01-02 17:07:31,441	44k	INFO	====> Epoch: 3176, cost 26.32 s
2024-01-02 17:07:57,923	44k	INFO	====> Epoch: 3177, cost 26.48 s
2024-01-02 17:08:01,700	44k	INFO	Train Epoch: 3178 [11%]
2024-01-02 17:08:01,701	44k	INFO	Losses: [2.1186351776123047, 2.6150786876678467, 8.882339477539062, 14.733796119689941, 0.7288957238197327], step: 111200, lr: 6.722333024934648e-05, reference_loss: 29.078744888305664
2024-01-02 17:08:09,189	44k	INFO	Saving model and optimizer state at iteration 3178 to ./logs/44k/G_111200.pth
2024-01-02 17:08:10,081	44k	INFO	Saving model and optimizer state at iteration 3178 to ./logs/44k/D_111200.pth
2024-01-02 17:08:10,853	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_108800.pth
2024-01-02 17:08:10,911	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_108800.pth
2024-01-02 17:08:33,938	44k	INFO	====> Epoch: 3178, cost 36.01 s
2024-01-02 17:09:00,391	44k	INFO	====> Epoch: 3179, cost 26.45 s
2024-01-02 17:09:26,609	44k	INFO	====> Epoch: 3180, cost 26.22 s
2024-01-02 17:09:52,861	44k	INFO	====> Epoch: 3181, cost 26.25 s
2024-01-02 17:10:19,171	44k	INFO	====> Epoch: 3182, cost 26.31 s
2024-01-02 17:10:41,765	44k	INFO	Train Epoch: 3183 [83%]
2024-01-02 17:10:41,766	44k	INFO	Losses: [2.2708706855773926, 2.5614185333251953, 8.399867057800293, 14.954710006713867, 0.3885462284088135], step: 111400, lr: 6.71813261702731e-05, reference_loss: 28.57541275024414
2024-01-02 17:10:46,006	44k	INFO	====> Epoch: 3183, cost 26.83 s
2024-01-02 17:11:12,337	44k	INFO	====> Epoch: 3184, cost 26.33 s
2024-01-02 17:11:38,695	44k	INFO	====> Epoch: 3185, cost 26.36 s
2024-01-02 17:12:05,040	44k	INFO	====> Epoch: 3186, cost 26.35 s
2024-01-02 17:12:31,693	44k	INFO	====> Epoch: 3187, cost 26.65 s
2024-01-02 17:12:58,093	44k	INFO	====> Epoch: 3188, cost 26.40 s
2024-01-02 17:13:13,036	44k	INFO	Train Epoch: 3189 [54%]
2024-01-02 17:13:13,036	44k	INFO	Losses: [2.6765761375427246, 2.0977232456207275, 8.14758014678955, 15.643038749694824, 0.5930363535881042], step: 111600, lr: 6.713095591864469e-05, reference_loss: 29.157955169677734
2024-01-02 17:13:24,870	44k	INFO	====> Epoch: 3189, cost 26.78 s
2024-01-02 17:13:51,147	44k	INFO	====> Epoch: 3190, cost 26.28 s
2024-01-02 17:14:17,659	44k	INFO	====> Epoch: 3191, cost 26.51 s
2024-01-02 17:14:44,211	44k	INFO	====> Epoch: 3192, cost 26.55 s
2024-01-02 17:15:10,543	44k	INFO	====> Epoch: 3193, cost 26.33 s
2024-01-02 17:15:37,144	44k	INFO	====> Epoch: 3194, cost 26.60 s
2024-01-02 17:15:44,619	44k	INFO	Train Epoch: 3195 [26%]
2024-01-02 17:15:44,620	44k	INFO	Losses: [2.0259013175964355, 3.1979243755340576, 9.429885864257812, 14.74950122833252, 0.5362147688865662], step: 111800, lr: 6.708062343290141e-05, reference_loss: 29.939428329467773
2024-01-02 17:16:03,987	44k	INFO	====> Epoch: 3195, cost 26.84 s
2024-01-02 17:16:30,273	44k	INFO	====> Epoch: 3196, cost 26.29 s
2024-01-02 17:16:56,528	44k	INFO	====> Epoch: 3197, cost 26.26 s
2024-01-02 17:17:22,958	44k	INFO	====> Epoch: 3198, cost 26.43 s
2024-01-02 17:17:49,410	44k	INFO	====> Epoch: 3199, cost 26.45 s
2024-01-02 17:18:15,797	44k	INFO	Train Epoch: 3200 [97%]
2024-01-02 17:18:15,798	44k	INFO	Losses: [1.9724022150039673, 3.2584285736083984, 8.636688232421875, 14.466948509216309, 0.5094975233078003], step: 112000, lr: 6.703870852329315e-05, reference_loss: 28.843965530395508
2024-01-02 17:18:23,614	44k	INFO	Saving model and optimizer state at iteration 3200 to ./logs/44k/G_112000.pth
2024-01-02 17:18:24,508	44k	INFO	Saving model and optimizer state at iteration 3200 to ./logs/44k/D_112000.pth
2024-01-02 17:18:25,285	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_109600.pth
2024-01-02 17:18:25,342	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_109600.pth
2024-01-02 17:18:25,342	44k	INFO	====> Epoch: 3200, cost 35.93 s
2024-01-02 17:18:51,686	44k	INFO	====> Epoch: 3201, cost 26.34 s
2024-01-02 17:19:18,037	44k	INFO	====> Epoch: 3202, cost 26.35 s
2024-01-02 17:19:44,287	44k	INFO	====> Epoch: 3203, cost 26.25 s
2024-01-02 17:20:10,627	44k	INFO	====> Epoch: 3204, cost 26.34 s
2024-01-02 17:20:36,985	44k	INFO	====> Epoch: 3205, cost 26.36 s
2024-01-02 17:20:55,838	44k	INFO	Train Epoch: 3206 [69%]
2024-01-02 17:20:55,839	44k	INFO	Losses: [2.6116771697998047, 2.1516079902648926, 8.530672073364258, 13.575423240661621, 0.5633254051208496], step: 112200, lr: 6.698844520147953e-05, reference_loss: 27.432706832885742
2024-01-02 17:21:04,252	44k	INFO	====> Epoch: 3206, cost 27.27 s
2024-01-02 17:21:30,587	44k	INFO	====> Epoch: 3207, cost 26.33 s
2024-01-02 17:21:56,997	44k	INFO	====> Epoch: 3208, cost 26.41 s
2024-01-02 17:22:23,256	44k	INFO	====> Epoch: 3209, cost 26.26 s
2024-01-02 17:22:49,676	44k	INFO	====> Epoch: 3210, cost 26.42 s
2024-01-02 17:23:16,034	44k	INFO	====> Epoch: 3211, cost 26.36 s
2024-01-02 17:23:27,217	44k	INFO	Train Epoch: 3212 [40%]
2024-01-02 17:23:27,218	44k	INFO	Losses: [1.9326261281967163, 3.314155101776123, 11.264717102050781, 16.977807998657227, 0.49993664026260376], step: 112400, lr: 6.693821956537875e-05, reference_loss: 33.98923873901367
2024-01-02 17:23:42,817	44k	INFO	====> Epoch: 3212, cost 26.78 s
2024-01-02 17:24:09,414	44k	INFO	====> Epoch: 3213, cost 26.60 s
2024-01-02 17:24:35,676	44k	INFO	====> Epoch: 3214, cost 26.26 s
2024-01-02 17:25:02,125	44k	INFO	====> Epoch: 3215, cost 26.45 s
2024-01-02 17:25:28,618	44k	INFO	====> Epoch: 3216, cost 26.49 s
2024-01-02 17:25:55,020	44k	INFO	====> Epoch: 3217, cost 26.40 s
2024-01-02 17:25:58,762	44k	INFO	Train Epoch: 3218 [11%]
2024-01-02 17:25:58,763	44k	INFO	Losses: [2.0628466606140137, 2.855003595352173, 9.142440795898438, 15.427319526672363, 0.35907405614852905], step: 112600, lr: 6.688803158673538e-05, reference_loss: 29.846683502197266
2024-01-02 17:26:21,874	44k	INFO	====> Epoch: 3218, cost 26.85 s
2024-01-02 17:26:48,276	44k	INFO	====> Epoch: 3219, cost 26.40 s
2024-01-02 17:27:14,841	44k	INFO	====> Epoch: 3220, cost 26.57 s
2024-01-02 17:27:41,079	44k	INFO	====> Epoch: 3221, cost 26.24 s
2024-01-02 17:28:07,441	44k	INFO	====> Epoch: 3222, cost 26.36 s
2024-01-02 17:28:30,027	44k	INFO	Train Epoch: 3223 [83%]
2024-01-02 17:28:30,028	44k	INFO	Losses: [2.1723849773406982, 2.7316575050354004, 9.902615547180176, 14.520406723022461, 0.5160539746284485], step: 112800, lr: 6.684623701694226e-05, reference_loss: 29.84311866760254
2024-01-02 17:28:37,405	44k	INFO	Saving model and optimizer state at iteration 3223 to ./logs/44k/G_112800.pth
2024-01-02 17:28:38,304	44k	INFO	Saving model and optimizer state at iteration 3223 to ./logs/44k/D_112800.pth
2024-01-02 17:28:39,068	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_110400.pth
2024-01-02 17:28:39,125	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_110400.pth
2024-01-02 17:28:42,882	44k	INFO	====> Epoch: 3223, cost 35.44 s
2024-01-02 17:29:09,315	44k	INFO	====> Epoch: 3224, cost 26.43 s
2024-01-02 17:29:35,750	44k	INFO	====> Epoch: 3225, cost 26.43 s
2024-01-02 17:30:02,363	44k	INFO	====> Epoch: 3226, cost 26.61 s
2024-01-02 17:30:28,750	44k	INFO	====> Epoch: 3227, cost 26.39 s
2024-01-02 17:30:55,093	44k	INFO	====> Epoch: 3228, cost 26.34 s
2024-01-02 17:31:10,078	44k	INFO	Train Epoch: 3229 [54%]
2024-01-02 17:31:10,079	44k	INFO	Losses: [2.0575060844421387, 2.6377997398376465, 8.899534225463867, 14.744306564331055, 0.2565699517726898], step: 113000, lr: 6.679611800365542e-05, reference_loss: 28.59571647644043
2024-01-02 17:31:21,985	44k	INFO	====> Epoch: 3229, cost 26.89 s
2024-01-02 17:31:48,414	44k	INFO	====> Epoch: 3230, cost 26.43 s
2024-01-02 17:32:14,736	44k	INFO	====> Epoch: 3231, cost 26.32 s
2024-01-02 17:32:41,080	44k	INFO	====> Epoch: 3232, cost 26.34 s
2024-01-02 17:33:07,423	44k	INFO	====> Epoch: 3233, cost 26.34 s
2024-01-02 17:33:34,024	44k	INFO	====> Epoch: 3234, cost 26.60 s
2024-01-02 17:33:41,487	44k	INFO	Train Epoch: 3235 [26%]
2024-01-02 17:33:41,487	44k	INFO	Losses: [1.9718053340911865, 2.7737655639648438, 10.992440223693848, 17.70183563232422, 0.7610452771186829], step: 113200, lr: 6.674603656788383e-05, reference_loss: 34.200889587402344
2024-01-02 17:34:00,767	44k	INFO	====> Epoch: 3235, cost 26.74 s
2024-01-02 17:34:27,031	44k	INFO	====> Epoch: 3236, cost 26.26 s
2024-01-02 17:34:53,365	44k	INFO	====> Epoch: 3237, cost 26.33 s
2024-01-02 17:35:19,840	44k	INFO	====> Epoch: 3238, cost 26.48 s
2024-01-02 17:35:46,077	44k	INFO	====> Epoch: 3239, cost 26.24 s
2024-01-02 17:36:12,401	44k	INFO	Train Epoch: 3240 [97%]
2024-01-02 17:36:12,402	44k	INFO	Losses: [1.8843424320220947, 3.210480213165283, 10.501195907592773, 16.42763328552246, 0.664044976234436], step: 113400, lr: 6.670433072279354e-05, reference_loss: 32.68769454956055
2024-01-02 17:36:13,209	44k	INFO	====> Epoch: 3240, cost 27.13 s
2024-01-02 17:36:39,659	44k	INFO	====> Epoch: 3241, cost 26.45 s
2024-01-02 17:37:05,948	44k	INFO	====> Epoch: 3242, cost 26.29 s
2024-01-02 17:37:32,138	44k	INFO	====> Epoch: 3243, cost 26.19 s
2024-01-02 17:37:58,496	44k	INFO	====> Epoch: 3244, cost 26.36 s
2024-01-02 17:38:24,870	44k	INFO	====> Epoch: 3245, cost 26.37 s
2024-01-02 17:38:43,620	44k	INFO	Train Epoch: 3246 [69%]
2024-01-02 17:38:43,621	44k	INFO	Losses: [1.640724778175354, 3.913512945175171, 11.432740211486816, 14.35152816772461, 0.5126432776451111], step: 113600, lr: 6.665431810597356e-05, reference_loss: 31.851150512695312
2024-01-02 17:38:50,944	44k	INFO	Saving model and optimizer state at iteration 3246 to ./logs/44k/G_113600.pth
2024-01-02 17:38:52,184	44k	INFO	Saving model and optimizer state at iteration 3246 to ./logs/44k/D_113600.pth
2024-01-02 17:38:52,963	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_111200.pth
2024-01-02 17:38:53,020	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_111200.pth
2024-01-02 17:39:00,591	44k	INFO	====> Epoch: 3246, cost 35.72 s
2024-01-02 17:39:27,044	44k	INFO	====> Epoch: 3247, cost 26.45 s
2024-01-02 17:39:53,460	44k	INFO	====> Epoch: 3248, cost 26.42 s
2024-01-02 17:40:19,752	44k	INFO	====> Epoch: 3249, cost 26.29 s
2024-01-02 17:40:46,076	44k	INFO	====> Epoch: 3250, cost 26.32 s
2024-01-02 17:41:12,442	44k	INFO	====> Epoch: 3251, cost 26.37 s
2024-01-02 17:41:23,691	44k	INFO	Train Epoch: 3252 [40%]
2024-01-02 17:41:23,692	44k	INFO	Losses: [2.3900983333587646, 2.182154893875122, 9.565811157226562, 17.10409927368164, 0.3836164176464081], step: 113800, lr: 6.660434298689643e-05, reference_loss: 31.62578010559082
2024-01-02 17:41:39,279	44k	INFO	====> Epoch: 3252, cost 26.84 s
2024-01-02 17:42:05,941	44k	INFO	====> Epoch: 3253, cost 26.66 s
2024-01-02 17:42:32,371	44k	INFO	====> Epoch: 3254, cost 26.43 s
2024-01-02 17:42:58,621	44k	INFO	====> Epoch: 3255, cost 26.25 s
2024-01-02 17:43:24,945	44k	INFO	====> Epoch: 3256, cost 26.32 s
2024-01-02 17:43:51,333	44k	INFO	====> Epoch: 3257, cost 26.39 s
2024-01-02 17:43:55,099	44k	INFO	Train Epoch: 3258 [11%]
2024-01-02 17:43:55,100	44k	INFO	Losses: [2.196324110031128, 2.7789628505706787, 9.378366470336914, 17.27276039123535, 0.4242049753665924], step: 114000, lr: 6.655440533744762e-05, reference_loss: 32.05061721801758
2024-01-02 17:44:18,189	44k	INFO	====> Epoch: 3258, cost 26.86 s
2024-01-02 17:44:44,447	44k	INFO	====> Epoch: 3259, cost 26.26 s
2024-01-02 17:45:10,944	44k	INFO	====> Epoch: 3260, cost 26.50 s
2024-01-02 17:45:37,272	44k	INFO	====> Epoch: 3261, cost 26.33 s
2024-01-02 17:46:03,550	44k	INFO	====> Epoch: 3262, cost 26.28 s
2024-01-02 17:46:26,164	44k	INFO	Train Epoch: 3263 [83%]
2024-01-02 17:46:26,165	44k	INFO	Losses: [1.977728009223938, 3.3438148498535156, 9.874366760253906, 15.63929557800293, 0.5931985974311829], step: 114200, lr: 6.651281923193773e-05, reference_loss: 31.428403854370117
2024-01-02 17:46:30,538	44k	INFO	====> Epoch: 3263, cost 26.99 s
2024-01-02 17:46:56,853	44k	INFO	====> Epoch: 3264, cost 26.31 s
2024-01-02 17:47:23,209	44k	INFO	====> Epoch: 3265, cost 26.36 s
2024-01-02 17:47:49,444	44k	INFO	====> Epoch: 3266, cost 26.24 s
2024-01-02 17:48:16,059	44k	INFO	====> Epoch: 3267, cost 26.61 s
2024-01-02 17:48:42,423	44k	INFO	====> Epoch: 3268, cost 26.36 s
2024-01-02 17:48:57,433	44k	INFO	Train Epoch: 3269 [54%]
2024-01-02 17:48:57,433	44k	INFO	Losses: [2.2314999103546143, 2.6390981674194336, 11.374540328979492, 16.01532745361328, 0.5679048895835876], step: 114400, lr: 6.646295020385786e-05, reference_loss: 32.828372955322266
2024-01-02 17:49:05,040	44k	INFO	Saving model and optimizer state at iteration 3269 to ./logs/44k/G_114400.pth
2024-01-02 17:49:05,935	44k	INFO	Saving model and optimizer state at iteration 3269 to ./logs/44k/D_114400.pth
2024-01-02 17:49:06,700	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_112000.pth
2024-01-02 17:49:06,758	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_112000.pth
2024-01-02 17:49:18,154	44k	INFO	====> Epoch: 3269, cost 35.73 s
2024-01-02 17:49:44,556	44k	INFO	====> Epoch: 3270, cost 26.40 s
2024-01-02 17:50:10,887	44k	INFO	====> Epoch: 3271, cost 26.33 s
2024-01-02 17:50:37,309	44k	INFO	====> Epoch: 3272, cost 26.42 s
2024-01-02 17:51:03,987	44k	INFO	====> Epoch: 3273, cost 26.68 s
2024-01-02 17:51:30,397	44k	INFO	====> Epoch: 3274, cost 26.41 s
2024-01-02 17:51:37,911	44k	INFO	Train Epoch: 3275 [26%]
2024-01-02 17:51:37,911	44k	INFO	Losses: [2.140126943588257, 2.7614023685455322, 9.6514253616333, 16.044626235961914, 0.568656325340271], step: 114600, lr: 6.641311856586294e-05, reference_loss: 31.166236877441406
2024-01-02 17:51:57,166	44k	INFO	====> Epoch: 3275, cost 26.77 s
2024-01-02 17:52:23,531	44k	INFO	====> Epoch: 3276, cost 26.37 s
2024-01-02 17:52:49,871	44k	INFO	====> Epoch: 3277, cost 26.34 s
2024-01-02 17:53:16,224	44k	INFO	====> Epoch: 3278, cost 26.35 s
2024-01-02 17:53:42,400	44k	INFO	====> Epoch: 3279, cost 26.18 s
2024-01-02 17:54:08,630	44k	INFO	Train Epoch: 3280 [97%]
2024-01-02 17:54:08,630	44k	INFO	Losses: [2.062695026397705, 3.0403785705566406, 8.9357271194458, 16.131181716918945, 0.35111698508262634], step: 114800, lr: 6.637162074251199e-05, reference_loss: 30.521099090576172
2024-01-02 17:54:09,434	44k	INFO	====> Epoch: 3280, cost 27.03 s
2024-01-02 17:54:35,761	44k	INFO	====> Epoch: 3281, cost 26.33 s
2024-01-02 17:55:02,081	44k	INFO	====> Epoch: 3282, cost 26.32 s
2024-01-02 17:55:28,381	44k	INFO	====> Epoch: 3283, cost 26.30 s
2024-01-02 17:55:54,588	44k	INFO	====> Epoch: 3284, cost 26.21 s
2024-01-02 17:56:20,948	44k	INFO	====> Epoch: 3285, cost 26.36 s
2024-01-02 17:56:39,769	44k	INFO	Train Epoch: 3286 [69%]
2024-01-02 17:56:39,770	44k	INFO	Losses: [2.029874563217163, 2.792923927307129, 9.390885353088379, 15.108624458312988, 0.5079842209815979], step: 115000, lr: 6.63218575802113e-05, reference_loss: 29.830291748046875
2024-01-02 17:56:47,867	44k	INFO	====> Epoch: 3286, cost 26.92 s
2024-01-02 17:57:14,625	44k	INFO	====> Epoch: 3287, cost 26.76 s
2024-01-02 17:57:41,014	44k	INFO	====> Epoch: 3288, cost 26.39 s
2024-01-02 17:58:07,443	44k	INFO	====> Epoch: 3289, cost 26.43 s
2024-01-02 17:58:33,746	44k	INFO	====> Epoch: 3290, cost 26.30 s
2024-01-02 17:58:59,958	44k	INFO	====> Epoch: 3291, cost 26.21 s
2024-01-02 17:59:11,134	44k	INFO	Train Epoch: 3292 [40%]
2024-01-02 17:59:11,135	44k	INFO	Losses: [2.293280601501465, 2.64388108253479, 10.861650466918945, 17.372915267944336, 0.43996474146842957], step: 115200, lr: 6.627213172862103e-05, reference_loss: 33.611690521240234
2024-01-02 17:59:18,634	44k	INFO	Saving model and optimizer state at iteration 3292 to ./logs/44k/G_115200.pth
2024-01-02 17:59:19,617	44k	INFO	Saving model and optimizer state at iteration 3292 to ./logs/44k/D_115200.pth
2024-01-02 17:59:20,389	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_112800.pth
2024-01-02 17:59:20,446	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_112800.pth
2024-01-02 17:59:35,893	44k	INFO	====> Epoch: 3292, cost 35.94 s
2024-01-02 18:00:02,265	44k	INFO	====> Epoch: 3293, cost 26.37 s
2024-01-02 18:00:28,547	44k	INFO	====> Epoch: 3294, cost 26.28 s
2024-01-02 18:00:54,879	44k	INFO	====> Epoch: 3295, cost 26.33 s
2024-01-02 18:01:21,144	44k	INFO	====> Epoch: 3296, cost 26.26 s
2024-01-02 18:01:47,373	44k	INFO	====> Epoch: 3297, cost 26.23 s
2024-01-02 18:01:51,099	44k	INFO	Train Epoch: 3298 [11%]
2024-01-02 18:01:51,099	44k	INFO	Losses: [2.207554340362549, 2.8003153800964355, 8.745923042297363, 14.773300170898438, 0.4935695230960846], step: 115400, lr: 6.622244315976689e-05, reference_loss: 29.020662307739258
2024-01-02 18:02:14,070	44k	INFO	====> Epoch: 3298, cost 26.70 s
2024-01-02 18:02:40,450	44k	INFO	====> Epoch: 3299, cost 26.38 s
2024-01-02 18:03:06,702	44k	INFO	====> Epoch: 3300, cost 26.25 s
2024-01-02 18:03:33,172	44k	INFO	====> Epoch: 3301, cost 26.47 s
2024-01-02 18:03:59,378	44k	INFO	====> Epoch: 3302, cost 26.21 s
2024-01-02 18:04:21,860	44k	INFO	Train Epoch: 3303 [83%]
2024-01-02 18:04:21,861	44k	INFO	Losses: [1.9866478443145752, 2.93328595161438, 9.47353744506836, 16.190637588500977, 0.5031507015228271], step: 115600, lr: 6.618106447875545e-05, reference_loss: 31.08725929260254
2024-01-02 18:04:26,249	44k	INFO	====> Epoch: 3303, cost 26.87 s
2024-01-02 18:04:52,544	44k	INFO	====> Epoch: 3304, cost 26.30 s
2024-01-02 18:05:18,859	44k	INFO	====> Epoch: 3305, cost 26.32 s
2024-01-02 18:05:45,082	44k	INFO	====> Epoch: 3306, cost 26.22 s
2024-01-02 18:06:11,362	44k	INFO	====> Epoch: 3307, cost 26.28 s
2024-01-02 18:06:37,758	44k	INFO	====> Epoch: 3308, cost 26.40 s
2024-01-02 18:06:52,962	44k	INFO	Train Epoch: 3309 [54%]
2024-01-02 18:06:52,963	44k	INFO	Losses: [2.180966377258301, 3.8002278804779053, 11.366240501403809, 17.321056365966797, 0.4560551345348358], step: 115800, lr: 6.613144418899839e-05, reference_loss: 35.12454605102539
2024-01-02 18:07:04,844	44k	INFO	====> Epoch: 3309, cost 27.09 s
2024-01-02 18:07:31,214	44k	INFO	====> Epoch: 3310, cost 26.37 s
2024-01-02 18:07:57,476	44k	INFO	====> Epoch: 3311, cost 26.26 s
2024-01-02 18:08:23,771	44k	INFO	====> Epoch: 3312, cost 26.29 s
2024-01-02 18:08:49,937	44k	INFO	====> Epoch: 3313, cost 26.17 s
2024-01-02 18:09:15,947	44k	INFO	====> Epoch: 3314, cost 26.01 s
2024-01-02 18:09:23,404	44k	INFO	Train Epoch: 3315 [26%]
2024-01-02 18:09:23,405	44k	INFO	Losses: [2.206331253051758, 2.6265265941619873, 9.243210792541504, 15.452950477600098, 0.4655739963054657], step: 116000, lr: 6.608186110283082e-05, reference_loss: 29.994592666625977
2024-01-02 18:09:31,246	44k	INFO	Saving model and optimizer state at iteration 3315 to ./logs/44k/G_116000.pth
2024-01-02 18:09:32,136	44k	INFO	Saving model and optimizer state at iteration 3315 to ./logs/44k/D_116000.pth
2024-01-02 18:09:32,918	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_113600.pth
2024-01-02 18:09:32,975	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_113600.pth
2024-01-02 18:09:51,722	44k	INFO	====> Epoch: 3315, cost 35.77 s
2024-01-02 18:10:17,993	44k	INFO	====> Epoch: 3316, cost 26.27 s
2024-01-02 18:10:44,213	44k	INFO	====> Epoch: 3317, cost 26.22 s
2024-01-02 18:11:10,400	44k	INFO	====> Epoch: 3318, cost 26.19 s
2024-01-02 18:11:36,675	44k	INFO	====> Epoch: 3319, cost 26.28 s
2024-01-02 18:12:02,913	44k	INFO	Train Epoch: 3320 [97%]
2024-01-02 18:12:02,914	44k	INFO	Losses: [1.8609302043914795, 3.442350149154663, 11.730874061584473, 16.80852508544922, 0.42078834772109985], step: 116200, lr: 6.604057026364177e-05, reference_loss: 34.26346969604492
2024-01-02 18:12:03,705	44k	INFO	====> Epoch: 3320, cost 27.03 s
2024-01-02 18:12:29,996	44k	INFO	====> Epoch: 3321, cost 26.29 s
2024-01-02 18:12:56,123	44k	INFO	====> Epoch: 3322, cost 26.13 s
2024-01-02 18:13:22,474	44k	INFO	====> Epoch: 3323, cost 26.35 s
2024-01-02 18:13:48,595	44k	INFO	====> Epoch: 3324, cost 26.12 s
2024-01-02 18:14:14,787	44k	INFO	====> Epoch: 3325, cost 26.19 s
2024-01-02 18:14:33,568	44k	INFO	Train Epoch: 3326 [69%]
2024-01-02 18:14:33,568	44k	INFO	Losses: [2.288475275039673, 2.7334842681884766, 9.864104270935059, 14.875762939453125, 0.6566415429115295], step: 116400, lr: 6.599105531162321e-05, reference_loss: 30.418466567993164
2024-01-02 18:14:41,628	44k	INFO	====> Epoch: 3326, cost 26.84 s
2024-01-02 18:15:08,285	44k	INFO	====> Epoch: 3327, cost 26.66 s
2024-01-02 18:15:34,553	44k	INFO	====> Epoch: 3328, cost 26.27 s
2024-01-02 18:16:00,798	44k	INFO	====> Epoch: 3329, cost 26.24 s
2024-01-02 18:16:27,185	44k	INFO	====> Epoch: 3330, cost 26.39 s
2024-01-02 18:16:53,611	44k	INFO	====> Epoch: 3331, cost 26.43 s
2024-01-02 18:17:04,857	44k	INFO	Train Epoch: 3332 [40%]
2024-01-02 18:17:04,858	44k	INFO	Losses: [2.3195347785949707, 2.504887342453003, 8.76483154296875, 15.4036283493042, 0.6518406271934509], step: 116600, lr: 6.594157748421554e-05, reference_loss: 29.64472198486328
2024-01-02 18:17:20,658	44k	INFO	====> Epoch: 3332, cost 27.05 s
2024-01-02 18:17:47,015	44k	INFO	====> Epoch: 3333, cost 26.36 s
2024-01-02 18:18:13,277	44k	INFO	====> Epoch: 3334, cost 26.26 s
2024-01-02 18:18:39,853	44k	INFO	====> Epoch: 3335, cost 26.58 s
2024-01-02 18:19:06,145	44k	INFO	====> Epoch: 3336, cost 26.29 s
2024-01-02 18:19:32,532	44k	INFO	====> Epoch: 3337, cost 26.39 s
2024-01-02 18:19:36,276	44k	INFO	Train Epoch: 3338 [11%]
2024-01-02 18:19:36,277	44k	INFO	Losses: [2.168405294418335, 2.551189422607422, 9.028038024902344, 15.360746383666992, 0.6840943098068237], step: 116800, lr: 6.589213675358399e-05, reference_loss: 29.79247283935547
2024-01-02 18:19:43,661	44k	INFO	Saving model and optimizer state at iteration 3338 to ./logs/44k/G_116800.pth
2024-01-02 18:19:44,560	44k	INFO	Saving model and optimizer state at iteration 3338 to ./logs/44k/D_116800.pth
2024-01-02 18:19:45,331	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_114400.pth
2024-01-02 18:19:45,388	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_114400.pth
2024-01-02 18:20:07,900	44k	INFO	====> Epoch: 3338, cost 35.37 s
2024-01-02 18:20:34,298	44k	INFO	====> Epoch: 3339, cost 26.40 s
2024-01-02 18:21:00,983	44k	INFO	====> Epoch: 3340, cost 26.68 s
2024-01-02 18:21:27,343	44k	INFO	====> Epoch: 3341, cost 26.36 s
2024-01-02 18:21:53,653	44k	INFO	====> Epoch: 3342, cost 26.31 s
2024-01-02 18:22:16,073	44k	INFO	Train Epoch: 3343 [83%]
2024-01-02 18:22:16,073	44k	INFO	Losses: [1.8571993112564087, 2.838409900665283, 9.692436218261719, 15.336970329284668, 0.36790090799331665], step: 117000, lr: 6.585096446247248e-05, reference_loss: 30.09291648864746
2024-01-02 18:22:20,318	44k	INFO	====> Epoch: 3343, cost 26.67 s
2024-01-02 18:22:46,556	44k	INFO	====> Epoch: 3344, cost 26.24 s
2024-01-02 18:23:12,926	44k	INFO	====> Epoch: 3345, cost 26.37 s
2024-01-02 18:23:39,248	44k	INFO	====> Epoch: 3346, cost 26.32 s
2024-01-02 18:24:05,670	44k	INFO	====> Epoch: 3347, cost 26.42 s
2024-01-02 18:24:32,256	44k	INFO	====> Epoch: 3348, cost 26.59 s
2024-01-02 18:24:47,272	44k	INFO	Train Epoch: 3349 [54%]
2024-01-02 18:24:47,273	44k	INFO	Losses: [2.483572483062744, 2.7644801139831543, 8.60291576385498, 15.889205932617188, 0.6070899367332458], step: 117200, lr: 6.580159167037336e-05, reference_loss: 30.34726333618164
2024-01-02 18:24:59,278	44k	INFO	====> Epoch: 3349, cost 27.02 s
2024-01-02 18:25:25,581	44k	INFO	====> Epoch: 3350, cost 26.30 s
2024-01-02 18:25:51,962	44k	INFO	====> Epoch: 3351, cost 26.38 s
2024-01-02 18:26:18,385	44k	INFO	====> Epoch: 3352, cost 26.42 s
2024-01-02 18:26:44,747	44k	INFO	====> Epoch: 3353, cost 26.36 s
2024-01-02 18:27:11,188	44k	INFO	====> Epoch: 3354, cost 26.44 s
2024-01-02 18:27:18,702	44k	INFO	Train Epoch: 3355 [26%]
2024-01-02 18:27:18,703	44k	INFO	Losses: [2.0964102745056152, 2.9131782054901123, 9.738944053649902, 15.100512504577637, 0.507681667804718], step: 117400, lr: 6.575225589629848e-05, reference_loss: 30.356725692749023
2024-01-02 18:27:38,483	44k	INFO	====> Epoch: 3355, cost 27.29 s
2024-01-02 18:28:04,842	44k	INFO	====> Epoch: 3356, cost 26.36 s
2024-01-02 18:28:31,250	44k	INFO	====> Epoch: 3357, cost 26.41 s
2024-01-02 18:28:57,547	44k	INFO	====> Epoch: 3358, cost 26.30 s
2024-01-02 18:29:23,955	44k	INFO	====> Epoch: 3359, cost 26.41 s
2024-01-02 18:29:50,319	44k	INFO	Train Epoch: 3360 [97%]
2024-01-02 18:29:50,320	44k	INFO	Losses: [2.3824424743652344, 2.443981409072876, 8.354337692260742, 14.709436416625977, 0.49171504378318787], step: 117600, lr: 6.571117100886913e-05, reference_loss: 28.381912231445312
2024-01-02 18:29:57,674	44k	INFO	Saving model and optimizer state at iteration 3360 to ./logs/44k/G_117600.pth
2024-01-02 18:29:58,910	44k	INFO	Saving model and optimizer state at iteration 3360 to ./logs/44k/D_117600.pth
2024-01-02 18:29:59,688	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_115200.pth
2024-01-02 18:29:59,744	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_115200.pth
2024-01-02 18:29:59,745	44k	INFO	====> Epoch: 3360, cost 35.79 s
2024-01-02 18:30:26,104	44k	INFO	====> Epoch: 3361, cost 26.36 s
2024-01-02 18:30:52,396	44k	INFO	====> Epoch: 3362, cost 26.29 s
2024-01-02 18:31:18,599	44k	INFO	====> Epoch: 3363, cost 26.20 s
2024-01-02 18:31:44,712	44k	INFO	====> Epoch: 3364, cost 26.11 s
2024-01-02 18:32:11,000	44k	INFO	====> Epoch: 3365, cost 26.29 s
2024-01-02 18:32:29,809	44k	INFO	Train Epoch: 3366 [69%]
2024-01-02 18:32:29,810	44k	INFO	Losses: [1.994330883026123, 3.0430448055267334, 10.48531436920166, 15.976868629455566, 0.6172329783439636], step: 117800, lr: 6.566190302910156e-05, reference_loss: 32.116790771484375
2024-01-02 18:32:37,872	44k	INFO	====> Epoch: 3366, cost 26.87 s
2024-01-02 18:33:04,577	44k	INFO	====> Epoch: 3367, cost 26.71 s
2024-01-02 18:33:30,937	44k	INFO	====> Epoch: 3368, cost 26.36 s
2024-01-02 18:33:57,292	44k	INFO	====> Epoch: 3369, cost 26.36 s
2024-01-02 18:34:23,686	44k	INFO	====> Epoch: 3370, cost 26.39 s
2024-01-02 18:34:50,044	44k	INFO	====> Epoch: 3371, cost 26.36 s
2024-01-02 18:35:01,309	44k	INFO	Train Epoch: 3372 [40%]
2024-01-02 18:35:01,309	44k	INFO	Losses: [2.529670000076294, 2.492682933807373, 9.891032218933105, 16.74936294555664, 0.44495904445648193], step: 118000, lr: 6.561267198877358e-05, reference_loss: 32.10770797729492
2024-01-02 18:35:17,024	44k	INFO	====> Epoch: 3372, cost 26.98 s
2024-01-02 18:35:43,285	44k	INFO	====> Epoch: 3373, cost 26.26 s
2024-01-02 18:36:09,597	44k	INFO	====> Epoch: 3374, cost 26.31 s
2024-01-02 18:36:36,095	44k	INFO	====> Epoch: 3375, cost 26.50 s
2024-01-02 18:37:02,347	44k	INFO	====> Epoch: 3376, cost 26.25 s
2024-01-02 18:37:28,523	44k	INFO	====> Epoch: 3377, cost 26.18 s
2024-01-02 18:37:32,267	44k	INFO	Train Epoch: 3378 [11%]
2024-01-02 18:37:32,267	44k	INFO	Losses: [1.9476184844970703, 2.8288960456848145, 9.568052291870117, 15.146951675415039, 0.3999909460544586], step: 118200, lr: 6.556347786018923e-05, reference_loss: 29.891508102416992
2024-01-02 18:37:55,259	44k	INFO	====> Epoch: 3378, cost 26.74 s
2024-01-02 18:38:21,592	44k	INFO	====> Epoch: 3379, cost 26.33 s
2024-01-02 18:38:47,949	44k	INFO	====> Epoch: 3380, cost 26.36 s
2024-01-02 18:39:14,322	44k	INFO	====> Epoch: 3381, cost 26.37 s
2024-01-02 18:39:41,012	44k	INFO	====> Epoch: 3382, cost 26.69 s
2024-01-02 18:40:03,557	44k	INFO	Train Epoch: 3383 [83%]
2024-01-02 18:40:03,557	44k	INFO	Losses: [1.7214847803115845, 3.45611834526062, 11.438138008117676, 14.359821319580078, 0.5566863417625427], step: 118400, lr: 6.552251092953956e-05, reference_loss: 31.532249450683594
2024-01-02 18:40:11,055	44k	INFO	Saving model and optimizer state at iteration 3383 to ./logs/44k/G_118400.pth
2024-01-02 18:40:11,960	44k	INFO	Saving model and optimizer state at iteration 3383 to ./logs/44k/D_118400.pth
2024-01-02 18:40:12,728	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_116000.pth
2024-01-02 18:40:12,785	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_116000.pth
2024-01-02 18:40:16,537	44k	INFO	====> Epoch: 3383, cost 35.52 s
2024-01-02 18:40:42,751	44k	INFO	====> Epoch: 3384, cost 26.21 s
2024-01-02 18:41:08,998	44k	INFO	====> Epoch: 3385, cost 26.25 s
2024-01-02 18:41:35,270	44k	INFO	====> Epoch: 3386, cost 26.27 s
2024-01-02 18:42:02,005	44k	INFO	====> Epoch: 3387, cost 26.73 s
2024-01-02 18:42:28,417	44k	INFO	====> Epoch: 3388, cost 26.41 s
2024-01-02 18:42:43,333	44k	INFO	Train Epoch: 3389 [54%]
2024-01-02 18:42:43,333	44k	INFO	Losses: [2.1385107040405273, 2.5975770950317383, 9.207401275634766, 14.677608489990234, 0.28664901852607727], step: 118600, lr: 6.547338440062166e-05, reference_loss: 28.907747268676758
2024-01-02 18:42:55,137	44k	INFO	====> Epoch: 3389, cost 26.72 s
2024-01-02 18:43:21,377	44k	INFO	====> Epoch: 3390, cost 26.24 s
2024-01-02 18:43:47,602	44k	INFO	====> Epoch: 3391, cost 26.22 s
2024-01-02 18:44:13,800	44k	INFO	====> Epoch: 3392, cost 26.20 s
2024-01-02 18:44:40,061	44k	INFO	====> Epoch: 3393, cost 26.26 s
2024-01-02 18:45:06,297	44k	INFO	====> Epoch: 3394, cost 26.24 s
2024-01-02 18:45:13,772	44k	INFO	Train Epoch: 3395 [26%]
2024-01-02 18:45:13,773	44k	INFO	Losses: [1.8900078535079956, 3.1080470085144043, 11.815043449401855, 17.38920021057129, 0.7038049697875977], step: 118800, lr: 6.542429470508834e-05, reference_loss: 34.906105041503906
2024-01-02 18:45:33,450	44k	INFO	====> Epoch: 3395, cost 27.15 s
2024-01-02 18:45:59,805	44k	INFO	====> Epoch: 3396, cost 26.36 s
2024-01-02 18:46:26,226	44k	INFO	====> Epoch: 3397, cost 26.42 s
2024-01-02 18:46:52,489	44k	INFO	====> Epoch: 3398, cost 26.26 s
2024-01-02 18:47:18,876	44k	INFO	====> Epoch: 3399, cost 26.39 s
2024-01-02 18:47:45,238	44k	INFO	Train Epoch: 3400 [97%]
2024-01-02 18:47:45,238	44k	INFO	Losses: [1.9698832035064697, 2.8720879554748535, 11.29696273803711, 17.614681243896484, 0.5875117778778076], step: 119000, lr: 6.538341474216595e-05, reference_loss: 34.341129302978516
2024-01-02 18:47:45,724	44k	INFO	====> Epoch: 3400, cost 26.85 s
2024-01-02 18:48:12,282	44k	INFO	====> Epoch: 3401, cost 26.56 s
2024-01-02 18:48:38,513	44k	INFO	====> Epoch: 3402, cost 26.23 s
2024-01-02 18:49:04,811	44k	INFO	====> Epoch: 3403, cost 26.30 s
2024-01-02 18:49:31,065	44k	INFO	====> Epoch: 3404, cost 26.25 s
2024-01-02 18:49:57,432	44k	INFO	====> Epoch: 3405, cost 26.37 s
2024-01-02 18:50:16,256	44k	INFO	Train Epoch: 3406 [69%]
2024-01-02 18:50:16,256	44k	INFO	Losses: [1.6720302104949951, 3.780428886413574, 11.707154273986816, 14.300042152404785, 0.5932468175888062], step: 119200, lr: 6.533439250279335e-05, reference_loss: 32.05290222167969
2024-01-02 18:50:23,873	44k	INFO	Saving model and optimizer state at iteration 3406 to ./logs/44k/G_119200.pth
2024-01-02 18:50:24,759	44k	INFO	Saving model and optimizer state at iteration 3406 to ./logs/44k/D_119200.pth
2024-01-02 18:50:25,546	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_116800.pth
2024-01-02 18:50:25,604	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_116800.pth
2024-01-02 18:50:33,135	44k	INFO	====> Epoch: 3406, cost 35.70 s
2024-01-02 18:50:59,824	44k	INFO	====> Epoch: 3407, cost 26.69 s
2024-01-02 18:51:26,096	44k	INFO	====> Epoch: 3408, cost 26.27 s
2024-01-02 18:51:52,421	44k	INFO	====> Epoch: 3409, cost 26.32 s
2024-01-02 18:52:18,714	44k	INFO	====> Epoch: 3410, cost 26.29 s
2024-01-02 18:52:45,089	44k	INFO	====> Epoch: 3411, cost 26.38 s
2024-01-02 18:52:56,324	44k	INFO	Train Epoch: 3412 [40%]
2024-01-02 18:52:56,324	44k	INFO	Losses: [2.2169973850250244, 2.60280704498291, 10.14295482635498, 16.816022872924805, 0.33302968740463257], step: 119400, lr: 6.52854070186126e-05, reference_loss: 32.111812591552734
2024-01-02 18:53:12,125	44k	INFO	====> Epoch: 3412, cost 27.04 s
2024-01-02 18:53:38,531	44k	INFO	====> Epoch: 3413, cost 26.41 s
2024-01-02 18:54:04,845	44k	INFO	====> Epoch: 3414, cost 26.31 s
2024-01-02 18:54:31,228	44k	INFO	====> Epoch: 3415, cost 26.38 s
2024-01-02 18:54:57,916	44k	INFO	====> Epoch: 3416, cost 26.69 s
2024-01-02 18:55:24,185	44k	INFO	====> Epoch: 3417, cost 26.27 s
2024-01-02 18:55:27,936	44k	INFO	Train Epoch: 3418 [11%]
2024-01-02 18:55:27,936	44k	INFO	Losses: [2.089376449584961, 2.9669580459594727, 10.033662796020508, 17.163127899169922, 0.3950079679489136], step: 119600, lr: 6.523645826206592e-05, reference_loss: 32.64813232421875
2024-01-02 18:55:50,935	44k	INFO	====> Epoch: 3418, cost 26.75 s
2024-01-02 18:56:17,286	44k	INFO	====> Epoch: 3419, cost 26.35 s
2024-01-02 18:56:43,657	44k	INFO	====> Epoch: 3420, cost 26.37 s
2024-01-02 18:57:10,075	44k	INFO	====> Epoch: 3421, cost 26.42 s
2024-01-02 18:57:36,357	44k	INFO	====> Epoch: 3422, cost 26.28 s
2024-01-02 18:57:59,309	44k	INFO	Train Epoch: 3423 [83%]
2024-01-02 18:57:59,309	44k	INFO	Losses: [2.06119966506958, 3.0402824878692627, 10.606098175048828, 15.818391799926758, 0.5556872487068176], step: 119800, lr: 6.519569566757465e-05, reference_loss: 32.081661224365234
2024-01-02 18:58:03,567	44k	INFO	====> Epoch: 3423, cost 27.21 s
2024-01-02 18:58:30,020	44k	INFO	====> Epoch: 3424, cost 26.45 s
2024-01-02 18:58:56,360	44k	INFO	====> Epoch: 3425, cost 26.34 s
2024-01-02 18:59:22,674	44k	INFO	====> Epoch: 3426, cost 26.31 s
2024-01-02 18:59:48,879	44k	INFO	====> Epoch: 3427, cost 26.21 s
2024-01-02 19:00:15,180	44k	INFO	====> Epoch: 3428, cost 26.30 s
2024-01-02 19:00:30,139	44k	INFO	Train Epoch: 3429 [54%]
2024-01-02 19:00:30,140	44k	INFO	Losses: [2.4301586151123047, 2.268622398376465, 10.769739151000977, 15.667481422424316, 0.5534225702285767], step: 120000, lr: 6.514681417351867e-05, reference_loss: 31.689424514770508
2024-01-02 19:00:37,865	44k	INFO	Saving model and optimizer state at iteration 3429 to ./logs/44k/G_120000.pth
2024-01-02 19:00:38,766	44k	INFO	Saving model and optimizer state at iteration 3429 to ./logs/44k/D_120000.pth
2024-01-02 19:00:39,544	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_117600.pth
2024-01-02 19:00:39,600	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_117600.pth
2024-01-02 19:00:50,962	44k	INFO	====> Epoch: 3429, cost 35.78 s
2024-01-02 19:01:17,308	44k	INFO	====> Epoch: 3430, cost 26.35 s
2024-01-02 19:01:43,726	44k	INFO	====> Epoch: 3431, cost 26.42 s
2024-01-02 19:02:09,991	44k	INFO	====> Epoch: 3432, cost 26.27 s
2024-01-02 19:02:36,234	44k	INFO	====> Epoch: 3433, cost 26.24 s
2024-01-02 19:03:02,539	44k	INFO	====> Epoch: 3434, cost 26.30 s
2024-01-02 19:03:10,084	44k	INFO	Train Epoch: 3435 [26%]
2024-01-02 19:03:10,084	44k	INFO	Losses: [2.044109582901001, 3.1991024017333984, 8.856220245361328, 14.812986373901367, 0.6741273403167725], step: 120200, lr: 6.509796932912854e-05, reference_loss: 29.586545944213867
2024-01-02 19:03:29,802	44k	INFO	====> Epoch: 3435, cost 27.26 s
2024-01-02 19:03:56,184	44k	INFO	====> Epoch: 3436, cost 26.38 s
2024-01-02 19:04:22,480	44k	INFO	====> Epoch: 3437, cost 26.30 s
2024-01-02 19:04:48,812	44k	INFO	====> Epoch: 3438, cost 26.33 s
2024-01-02 19:05:15,193	44k	INFO	====> Epoch: 3439, cost 26.38 s
2024-01-02 19:05:41,583	44k	INFO	Train Epoch: 3440 [97%]
2024-01-02 19:05:41,584	44k	INFO	Losses: [2.182055711746216, 2.775139570236206, 9.274242401123047, 15.671747207641602, 0.3705216944217682], step: 120400, lr: 6.505729326858415e-05, reference_loss: 30.273706436157227
2024-01-02 19:05:42,068	44k	INFO	====> Epoch: 3440, cost 26.87 s
2024-01-02 19:06:08,395	44k	INFO	====> Epoch: 3441, cost 26.33 s
2024-01-02 19:06:35,023	44k	INFO	====> Epoch: 3442, cost 26.63 s
2024-01-02 19:07:01,395	44k	INFO	====> Epoch: 3443, cost 26.37 s
2024-01-02 19:07:27,906	44k	INFO	====> Epoch: 3444, cost 26.51 s
2024-01-02 19:07:54,407	44k	INFO	====> Epoch: 3445, cost 26.50 s
2024-01-02 19:08:13,217	44k	INFO	Train Epoch: 3446 [69%]
2024-01-02 19:08:13,218	44k	INFO	Losses: [2.1699635982513428, 2.8440592288970947, 8.945050239562988, 14.759414672851562, 0.540393054485321], step: 120600, lr: 6.500851554389474e-05, reference_loss: 29.258880615234375
2024-01-02 19:08:21,321	44k	INFO	====> Epoch: 3446, cost 26.91 s
2024-01-02 19:08:47,804	44k	INFO	====> Epoch: 3447, cost 26.48 s
2024-01-02 19:09:14,287	44k	INFO	====> Epoch: 3448, cost 26.48 s
2024-01-02 19:09:40,981	44k	INFO	====> Epoch: 3449, cost 26.69 s
2024-01-02 19:10:07,408	44k	INFO	====> Epoch: 3450, cost 26.43 s
2024-01-02 19:10:33,772	44k	INFO	====> Epoch: 3451, cost 26.36 s
2024-01-02 19:10:45,005	44k	INFO	Train Epoch: 3452 [40%]
2024-01-02 19:10:45,006	44k	INFO	Losses: [2.25651216506958, 2.9622559547424316, 11.294022560119629, 17.386566162109375, 0.43539944291114807], step: 120800, lr: 6.495977439106845e-05, reference_loss: 34.334754943847656
2024-01-02 19:10:52,588	44k	INFO	Saving model and optimizer state at iteration 3452 to ./logs/44k/G_120800.pth
2024-01-02 19:10:53,490	44k	INFO	Saving model and optimizer state at iteration 3452 to ./logs/44k/D_120800.pth
2024-01-02 19:10:54,266	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_118400.pth
2024-01-02 19:10:54,325	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_118400.pth
2024-01-02 19:11:09,524	44k	INFO	====> Epoch: 3452, cost 35.75 s
2024-01-02 19:11:36,014	44k	INFO	====> Epoch: 3453, cost 26.49 s
2024-01-02 19:12:02,820	44k	INFO	====> Epoch: 3454, cost 26.81 s
2024-01-02 19:12:29,342	44k	INFO	====> Epoch: 3455, cost 26.52 s
2024-01-02 19:12:55,665	44k	INFO	====> Epoch: 3456, cost 26.32 s
2024-01-02 19:13:21,991	44k	INFO	====> Epoch: 3457, cost 26.33 s
2024-01-02 19:13:25,771	44k	INFO	Train Epoch: 3458 [11%]
2024-01-02 19:13:25,772	44k	INFO	Losses: [2.1666340827941895, 2.9141786098480225, 9.04783821105957, 14.601537704467773, 0.48275819420814514], step: 121000, lr: 6.491106978268502e-05, reference_loss: 29.21294593811035
2024-01-02 19:13:48,950	44k	INFO	====> Epoch: 3458, cost 26.96 s
2024-01-02 19:14:15,232	44k	INFO	====> Epoch: 3459, cost 26.28 s
2024-01-02 19:14:41,516	44k	INFO	====> Epoch: 3460, cost 26.28 s
2024-01-02 19:15:07,956	44k	INFO	====> Epoch: 3461, cost 26.44 s
2024-01-02 19:15:34,413	44k	INFO	====> Epoch: 3462, cost 26.46 s
2024-01-02 19:15:57,432	44k	INFO	Train Epoch: 3463 [83%]
2024-01-02 19:15:57,432	44k	INFO	Losses: [2.377981662750244, 2.4409430027008057, 8.682950973510742, 16.22247314453125, 0.5118404030799866], step: 121200, lr: 6.487051050515777e-05, reference_loss: 30.236190795898438
2024-01-02 19:16:01,751	44k	INFO	====> Epoch: 3463, cost 27.34 s
2024-01-02 19:16:28,163	44k	INFO	====> Epoch: 3464, cost 26.41 s
2024-01-02 19:16:54,516	44k	INFO	====> Epoch: 3465, cost 26.35 s
2024-01-02 19:17:20,956	44k	INFO	====> Epoch: 3466, cost 26.44 s
2024-01-02 19:17:47,424	44k	INFO	====> Epoch: 3467, cost 26.47 s
2024-01-02 19:18:13,920	44k	INFO	====> Epoch: 3468, cost 26.50 s
2024-01-02 19:18:28,923	44k	INFO	Train Epoch: 3469 [54%]
2024-01-02 19:18:28,924	44k	INFO	Losses: [1.797480583190918, 3.1136832237243652, 11.885071754455566, 16.904150009155273, 0.45076268911361694], step: 121400, lr: 6.4821872823771e-05, reference_loss: 34.15114974975586
2024-01-02 19:18:41,082	44k	INFO	====> Epoch: 3469, cost 27.16 s
2024-01-02 19:19:07,468	44k	INFO	====> Epoch: 3470, cost 26.39 s
2024-01-02 19:19:33,905	44k	INFO	====> Epoch: 3471, cost 26.44 s
2024-01-02 19:20:00,221	44k	INFO	====> Epoch: 3472, cost 26.32 s
2024-01-02 19:20:26,618	44k	INFO	====> Epoch: 3473, cost 26.40 s
2024-01-02 19:20:52,786	44k	INFO	====> Epoch: 3474, cost 26.17 s
2024-01-02 19:21:00,320	44k	INFO	Train Epoch: 3475 [26%]
2024-01-02 19:21:00,321	44k	INFO	Losses: [2.1217665672302246, 2.8295061588287354, 9.432876586914062, 14.9705171585083, 0.4462249279022217], step: 121600, lr: 6.477327160924775e-05, reference_loss: 29.800891876220703
2024-01-02 19:21:08,249	44k	INFO	Saving model and optimizer state at iteration 3475 to ./logs/44k/G_121600.pth
2024-01-02 19:21:09,504	44k	INFO	Saving model and optimizer state at iteration 3475 to ./logs/44k/D_121600.pth
2024-01-02 19:21:10,280	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_119200.pth
2024-01-02 19:21:10,338	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_119200.pth
2024-01-02 19:21:29,185	44k	INFO	====> Epoch: 3475, cost 36.40 s
2024-01-02 19:21:55,740	44k	INFO	====> Epoch: 3476, cost 26.55 s
2024-01-02 19:22:22,127	44k	INFO	====> Epoch: 3477, cost 26.39 s
2024-01-02 19:22:48,435	44k	INFO	====> Epoch: 3478, cost 26.31 s
2024-01-02 19:23:14,708	44k	INFO	====> Epoch: 3479, cost 26.27 s
2024-01-02 19:23:41,144	44k	INFO	Train Epoch: 3480 [97%]
2024-01-02 19:23:41,145	44k	INFO	Losses: [2.0550432205200195, 3.1102793216705322, 11.940009117126465, 17.248579025268555, 0.38052526116371155], step: 121800, lr: 6.47327984340506e-05, reference_loss: 34.73443603515625
2024-01-02 19:23:41,653	44k	INFO	====> Epoch: 3480, cost 26.94 s
2024-01-02 19:24:08,043	44k	INFO	====> Epoch: 3481, cost 26.39 s
2024-01-02 19:24:34,761	44k	INFO	====> Epoch: 3482, cost 26.72 s
2024-01-02 19:25:01,192	44k	INFO	====> Epoch: 3483, cost 26.43 s
2024-01-02 19:25:27,553	44k	INFO	====> Epoch: 3484, cost 26.36 s
2024-01-02 19:25:53,809	44k	INFO	====> Epoch: 3485, cost 26.26 s
2024-01-02 19:26:12,534	44k	INFO	Train Epoch: 3486 [69%]
2024-01-02 19:26:12,534	44k	INFO	Losses: [2.2102036476135254, 2.8132569789886475, 10.943931579589844, 15.902066230773926, 0.6359676122665405], step: 122000, lr: 6.46842640044463e-05, reference_loss: 32.50542449951172
2024-01-02 19:26:20,607	44k	INFO	====> Epoch: 3486, cost 26.80 s
2024-01-02 19:26:46,923	44k	INFO	====> Epoch: 3487, cost 26.32 s
2024-01-02 19:27:13,158	44k	INFO	====> Epoch: 3488, cost 26.23 s
2024-01-02 19:27:39,799	44k	INFO	====> Epoch: 3489, cost 26.64 s
2024-01-02 19:28:06,190	44k	INFO	====> Epoch: 3490, cost 26.39 s
2024-01-02 19:28:32,572	44k	INFO	====> Epoch: 3491, cost 26.38 s
2024-01-02 19:28:43,776	44k	INFO	Train Epoch: 3492 [40%]
2024-01-02 19:28:43,777	44k	INFO	Losses: [2.299031972885132, 2.5434324741363525, 8.7339506149292, 15.291680335998535, 0.6807700991630554], step: 122200, lr: 6.463576596429083e-05, reference_loss: 29.548866271972656
2024-01-02 19:28:59,452	44k	INFO	====> Epoch: 3492, cost 26.88 s
2024-01-02 19:29:25,826	44k	INFO	====> Epoch: 3493, cost 26.37 s
2024-01-02 19:29:52,065	44k	INFO	====> Epoch: 3494, cost 26.24 s
2024-01-02 19:30:18,400	44k	INFO	====> Epoch: 3495, cost 26.33 s
2024-01-02 19:30:45,047	44k	INFO	====> Epoch: 3496, cost 26.65 s
2024-01-02 19:31:11,435	44k	INFO	====> Epoch: 3497, cost 26.39 s
2024-01-02 19:31:15,211	44k	INFO	Train Epoch: 3498 [11%]
2024-01-02 19:31:15,212	44k	INFO	Losses: [1.9443050622940063, 3.2560300827026367, 9.768741607666016, 14.984837532043457, 0.6909154653549194], step: 122400, lr: 6.458730428630065e-05, reference_loss: 30.64483070373535
2024-01-02 19:31:22,753	44k	INFO	Saving model and optimizer state at iteration 3498 to ./logs/44k/G_122400.pth
2024-01-02 19:31:23,652	44k	INFO	Saving model and optimizer state at iteration 3498 to ./logs/44k/D_122400.pth
2024-01-02 19:31:24,427	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_120000.pth
2024-01-02 19:31:24,485	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_120000.pth
2024-01-02 19:31:47,052	44k	INFO	====> Epoch: 3498, cost 35.62 s
2024-01-02 19:32:13,386	44k	INFO	====> Epoch: 3499, cost 26.33 s
2024-01-02 19:32:39,771	44k	INFO	====> Epoch: 3500, cost 26.39 s
2024-01-02 19:33:06,484	44k	INFO	====> Epoch: 3501, cost 26.71 s
2024-01-02 19:33:32,826	44k	INFO	====> Epoch: 3502, cost 26.34 s
2024-01-02 19:33:55,321	44k	INFO	Train Epoch: 3503 [83%]
2024-01-02 19:33:55,322	44k	INFO	Losses: [2.249561071395874, 2.7456250190734863, 8.528884887695312, 13.76414680480957, 0.3956802487373352], step: 122600, lr: 6.45469473116266e-05, reference_loss: 27.683897018432617
2024-01-02 19:33:59,560	44k	INFO	====> Epoch: 3503, cost 26.73 s
2024-01-02 19:34:25,833	44k	INFO	====> Epoch: 3504, cost 26.27 s
2024-01-02 19:34:52,231	44k	INFO	====> Epoch: 3505, cost 26.40 s
2024-01-02 19:35:18,491	44k	INFO	====> Epoch: 3506, cost 26.26 s
2024-01-02 19:35:44,799	44k	INFO	====> Epoch: 3507, cost 26.31 s
2024-01-02 19:36:11,209	44k	INFO	====> Epoch: 3508, cost 26.41 s
2024-01-02 19:36:26,199	44k	INFO	Train Epoch: 3509 [54%]
2024-01-02 19:36:26,199	44k	INFO	Losses: [2.1052157878875732, 2.752293825149536, 9.474847793579102, 15.88138484954834, 0.5856034159660339], step: 122800, lr: 6.44985522268125e-05, reference_loss: 30.799345016479492
2024-01-02 19:36:38,379	44k	INFO	====> Epoch: 3509, cost 27.17 s
2024-01-02 19:37:04,780	44k	INFO	====> Epoch: 3510, cost 26.40 s
2024-01-02 19:37:31,088	44k	INFO	====> Epoch: 3511, cost 26.31 s
2024-01-02 19:37:57,437	44k	INFO	====> Epoch: 3512, cost 26.35 s
2024-01-02 19:38:23,729	44k	INFO	====> Epoch: 3513, cost 26.29 s
2024-01-02 19:38:50,095	44k	INFO	====> Epoch: 3514, cost 26.37 s
2024-01-02 19:38:57,594	44k	INFO	Train Epoch: 3515 [26%]
2024-01-02 19:38:57,595	44k	INFO	Losses: [2.607445240020752, 2.3417022228240967, 8.782598495483398, 15.312932014465332, 0.5845264792442322], step: 123000, lr: 6.44501934269713e-05, reference_loss: 29.62920379638672
2024-01-02 19:39:17,287	44k	INFO	====> Epoch: 3515, cost 27.19 s
2024-01-02 19:39:43,553	44k	INFO	====> Epoch: 3516, cost 26.27 s
2024-01-02 19:40:09,925	44k	INFO	====> Epoch: 3517, cost 26.37 s
2024-01-02 19:40:36,281	44k	INFO	====> Epoch: 3518, cost 26.36 s
2024-01-02 19:41:02,722	44k	INFO	====> Epoch: 3519, cost 26.44 s
2024-01-02 19:41:28,937	44k	INFO	Train Epoch: 3520 [97%]
2024-01-02 19:41:28,937	44k	INFO	Losses: [1.7521089315414429, 3.4063425064086914, 9.322301864624023, 13.830757141113281, 0.4785023629665375], step: 123200, lr: 6.440992212516346e-05, reference_loss: 28.79001235961914
2024-01-02 19:41:36,514	44k	INFO	Saving model and optimizer state at iteration 3520 to ./logs/44k/G_123200.pth
2024-01-02 19:41:37,417	44k	INFO	Saving model and optimizer state at iteration 3520 to ./logs/44k/D_123200.pth
2024-01-02 19:41:38,212	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_120800.pth
2024-01-02 19:41:38,269	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_120800.pth
2024-01-02 19:41:38,269	44k	INFO	====> Epoch: 3520, cost 35.55 s
2024-01-02 19:42:04,800	44k	INFO	====> Epoch: 3521, cost 26.53 s
2024-01-02 19:42:31,103	44k	INFO	====> Epoch: 3522, cost 26.30 s
2024-01-02 19:42:57,431	44k	INFO	====> Epoch: 3523, cost 26.33 s
2024-01-02 19:43:23,677	44k	INFO	====> Epoch: 3524, cost 26.25 s
2024-01-02 19:43:50,124	44k	INFO	====> Epoch: 3525, cost 26.45 s
2024-01-02 19:44:08,974	44k	INFO	Train Epoch: 3526 [69%]
2024-01-02 19:44:08,974	44k	INFO	Losses: [2.0336413383483887, 3.0473194122314453, 10.429403305053711, 15.02422046661377, 0.5633232593536377], step: 123400, lr: 6.43616297771293e-05, reference_loss: 31.09790802001953
2024-01-02 19:44:17,037	44k	INFO	====> Epoch: 3526, cost 26.91 s
2024-01-02 19:44:43,437	44k	INFO	====> Epoch: 3527, cost 26.40 s
2024-01-02 19:45:09,866	44k	INFO	====> Epoch: 3528, cost 26.43 s
2024-01-02 19:45:36,209	44k	INFO	====> Epoch: 3529, cost 26.34 s
2024-01-02 19:46:02,688	44k	INFO	====> Epoch: 3530, cost 26.48 s
2024-01-02 19:46:28,885	44k	INFO	====> Epoch: 3531, cost 26.20 s
2024-01-02 19:46:40,040	44k	INFO	Train Epoch: 3532 [40%]
2024-01-02 19:46:40,040	44k	INFO	Losses: [2.1174941062927246, 2.7176554203033447, 10.1708402633667, 16.659839630126953, 0.41065502166748047], step: 123600, lr: 6.431337363703953e-05, reference_loss: 32.07648468017578
2024-01-02 19:46:55,667	44k	INFO	====> Epoch: 3532, cost 26.78 s
2024-01-02 19:47:22,004	44k	INFO	====> Epoch: 3533, cost 26.34 s
2024-01-02 19:47:48,395	44k	INFO	====> Epoch: 3534, cost 26.39 s
2024-01-02 19:48:14,724	44k	INFO	====> Epoch: 3535, cost 26.33 s
2024-01-02 19:48:40,914	44k	INFO	====> Epoch: 3536, cost 26.19 s
2024-01-02 19:49:07,515	44k	INFO	====> Epoch: 3537, cost 26.60 s
2024-01-02 19:49:11,226	44k	INFO	Train Epoch: 3538 [11%]
2024-01-02 19:49:11,227	44k	INFO	Losses: [2.008937120437622, 2.882035255432129, 10.270234107971191, 15.462090492248535, 0.3134160041809082], step: 123800, lr: 6.426515367774668e-05, reference_loss: 30.93671226501465
2024-01-02 19:49:34,260	44k	INFO	====> Epoch: 3538, cost 26.75 s
2024-01-02 19:50:00,597	44k	INFO	====> Epoch: 3539, cost 26.34 s
2024-01-02 19:50:26,833	44k	INFO	====> Epoch: 3540, cost 26.24 s
2024-01-02 19:50:53,033	44k	INFO	====> Epoch: 3541, cost 26.20 s
2024-01-02 19:51:19,298	44k	INFO	====> Epoch: 3542, cost 26.27 s
2024-01-02 19:51:41,922	44k	INFO	Train Epoch: 3543 [83%]
2024-01-02 19:51:41,923	44k	INFO	Losses: [2.12965989112854, 2.68660044670105, 10.404257774353027, 14.537060737609863, 0.5688254237174988], step: 124000, lr: 6.422499799687324e-05, reference_loss: 30.326404571533203
2024-01-02 19:51:49,523	44k	INFO	Saving model and optimizer state at iteration 3543 to ./logs/44k/G_124000.pth
2024-01-02 19:51:50,431	44k	INFO	Saving model and optimizer state at iteration 3543 to ./logs/44k/D_124000.pth
2024-01-02 19:51:51,196	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_121600.pth
2024-01-02 19:51:51,257	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_121600.pth
2024-01-02 19:51:54,978	44k	INFO	====> Epoch: 3543, cost 35.68 s
2024-01-02 19:52:21,205	44k	INFO	====> Epoch: 3544, cost 26.23 s
2024-01-02 19:52:47,411	44k	INFO	====> Epoch: 3545, cost 26.21 s
2024-01-02 19:53:13,613	44k	INFO	====> Epoch: 3546, cost 26.20 s
2024-01-02 19:53:39,805	44k	INFO	====> Epoch: 3547, cost 26.19 s
2024-01-02 19:54:06,076	44k	INFO	====> Epoch: 3548, cost 26.27 s
2024-01-02 19:54:20,978	44k	INFO	Train Epoch: 3549 [54%]
2024-01-02 19:54:20,979	44k	INFO	Losses: [2.6224567890167236, 2.0924549102783203, 8.255851745605469, 14.870770454406738, 0.2791432738304138], step: 124200, lr: 6.417684429860093e-05, reference_loss: 28.120676040649414
2024-01-02 19:54:33,208	44k	INFO	====> Epoch: 3549, cost 27.13 s
2024-01-02 19:54:59,377	44k	INFO	====> Epoch: 3550, cost 26.17 s
2024-01-02 19:55:25,695	44k	INFO	====> Epoch: 3551, cost 26.32 s
2024-01-02 19:55:51,986	44k	INFO	====> Epoch: 3552, cost 26.29 s
2024-01-02 19:56:18,305	44k	INFO	====> Epoch: 3553, cost 26.32 s
2024-01-02 19:56:44,682	44k	INFO	====> Epoch: 3554, cost 26.38 s
2024-01-02 19:56:52,139	44k	INFO	Train Epoch: 3555 [26%]
2024-01-02 19:56:52,140	44k	INFO	Losses: [2.208800792694092, 2.5649173259735107, 10.596097946166992, 17.39842987060547, 0.7079682350158691], step: 124400, lr: 6.412872670431817e-05, reference_loss: 33.47621536254883
2024-01-02 19:57:11,524	44k	INFO	====> Epoch: 3555, cost 26.84 s
2024-01-02 19:57:38,222	44k	INFO	====> Epoch: 3556, cost 26.70 s
2024-01-02 19:58:04,460	44k	INFO	====> Epoch: 3557, cost 26.24 s
2024-01-02 19:58:30,708	44k	INFO	====> Epoch: 3558, cost 26.25 s
2024-01-02 19:58:57,006	44k	INFO	====> Epoch: 3559, cost 26.30 s
2024-01-02 19:59:23,453	44k	INFO	Train Epoch: 3560 [97%]
2024-01-02 19:59:23,454	44k	INFO	Losses: [1.9837092161178589, 2.9026904106140137, 10.780438423156738, 17.18992805480957, 0.5585443377494812], step: 124600, lr: 6.408865626898906e-05, reference_loss: 33.41530990600586
2024-01-02 19:59:23,931	44k	INFO	====> Epoch: 3560, cost 26.92 s
2024-01-02 19:59:50,318	44k	INFO	====> Epoch: 3561, cost 26.39 s
2024-01-02 20:00:16,547	44k	INFO	====> Epoch: 3562, cost 26.23 s
2024-01-02 20:00:43,039	44k	INFO	====> Epoch: 3563, cost 26.49 s
2024-01-02 20:01:09,224	44k	INFO	====> Epoch: 3564, cost 26.19 s
2024-01-02 20:01:35,409	44k	INFO	====> Epoch: 3565, cost 26.18 s
2024-01-02 20:01:54,114	44k	INFO	Train Epoch: 3566 [69%]
2024-01-02 20:01:54,115	44k	INFO	Losses: [2.024623155593872, 3.4012653827667236, 10.1693754196167, 13.011956214904785, 0.551506757736206], step: 124800, lr: 6.404060479506291e-05, reference_loss: 29.15872573852539
2024-01-02 20:02:01,485	44k	INFO	Saving model and optimizer state at iteration 3566 to ./logs/44k/G_124800.pth
2024-01-02 20:02:02,400	44k	INFO	Saving model and optimizer state at iteration 3566 to ./logs/44k/D_124800.pth
2024-01-02 20:02:03,175	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_122400.pth
2024-01-02 20:02:03,232	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_122400.pth
2024-01-02 20:02:10,811	44k	INFO	====> Epoch: 3566, cost 35.40 s
2024-01-02 20:02:37,182	44k	INFO	====> Epoch: 3567, cost 26.37 s
2024-01-02 20:03:03,855	44k	INFO	====> Epoch: 3568, cost 26.67 s
2024-01-02 20:03:30,233	44k	INFO	====> Epoch: 3569, cost 26.38 s
2024-01-02 20:03:56,606	44k	INFO	====> Epoch: 3570, cost 26.37 s
2024-01-02 20:04:22,914	44k	INFO	====> Epoch: 3571, cost 26.31 s
2024-01-02 20:04:34,138	44k	INFO	Train Epoch: 3572 [40%]
2024-01-02 20:04:34,139	44k	INFO	Losses: [2.0561037063598633, 2.7607364654541016, 10.776572227478027, 16.774063110351562, 0.33355212211608887], step: 125000, lr: 6.3992589348482e-05, reference_loss: 32.70103073120117
2024-01-02 20:04:49,779	44k	INFO	====> Epoch: 3572, cost 26.87 s
2024-01-02 20:05:16,048	44k	INFO	====> Epoch: 3573, cost 26.27 s
2024-01-02 20:05:42,380	44k	INFO	====> Epoch: 3574, cost 26.33 s
2024-01-02 20:06:08,598	44k	INFO	====> Epoch: 3575, cost 26.22 s
2024-01-02 20:06:34,901	44k	INFO	====> Epoch: 3576, cost 26.30 s
2024-01-02 20:07:01,562	44k	INFO	====> Epoch: 3577, cost 26.66 s
2024-01-02 20:07:05,320	44k	INFO	Train Epoch: 3578 [11%]
2024-01-02 20:07:05,321	44k	INFO	Losses: [2.2689552307128906, 2.8895263671875, 10.532143592834473, 17.282262802124023, 0.44061240553855896], step: 125200, lr: 6.394460990223428e-05, reference_loss: 33.41350173950195
2024-01-02 20:07:28,471	44k	INFO	====> Epoch: 3578, cost 26.91 s
2024-01-02 20:07:54,872	44k	INFO	====> Epoch: 3579, cost 26.40 s
2024-01-02 20:08:21,397	44k	INFO	====> Epoch: 3580, cost 26.52 s
2024-01-02 20:08:47,642	44k	INFO	====> Epoch: 3581, cost 26.25 s
2024-01-02 20:09:13,941	44k	INFO	====> Epoch: 3582, cost 26.30 s
2024-01-02 20:09:36,570	44k	INFO	Train Epoch: 3583 [83%]
2024-01-02 20:09:36,571	44k	INFO	Losses: [2.1906394958496094, 2.5330257415771484, 9.77061939239502, 14.60718822479248, 0.5440423488616943], step: 125400, lr: 6.390465451114183e-05, reference_loss: 29.64551544189453
2024-01-02 20:09:41,122	44k	INFO	====> Epoch: 3583, cost 27.18 s
2024-01-02 20:10:07,251	44k	INFO	====> Epoch: 3584, cost 26.13 s
2024-01-02 20:10:33,596	44k	INFO	====> Epoch: 3585, cost 26.35 s
2024-01-02 20:10:59,972	44k	INFO	====> Epoch: 3586, cost 26.38 s
2024-01-02 20:11:26,352	44k	INFO	====> Epoch: 3587, cost 26.38 s
2024-01-02 20:11:52,494	44k	INFO	====> Epoch: 3588, cost 26.14 s
2024-01-02 20:12:07,490	44k	INFO	Train Epoch: 3589 [54%]
2024-01-02 20:12:07,490	44k	INFO	Losses: [2.25443434715271, 2.747499942779541, 11.790831565856934, 15.815618515014648, 0.5549072623252869], step: 125600, lr: 6.38567409954158e-05, reference_loss: 33.163291931152344
2024-01-02 20:12:14,869	44k	INFO	Saving model and optimizer state at iteration 3589 to ./logs/44k/G_125600.pth
2024-01-02 20:12:16,101	44k	INFO	Saving model and optimizer state at iteration 3589 to ./logs/44k/D_125600.pth
2024-01-02 20:12:16,885	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_123200.pth
2024-01-02 20:12:16,942	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_123200.pth
2024-01-02 20:12:28,261	44k	INFO	====> Epoch: 3589, cost 35.77 s
2024-01-02 20:12:54,571	44k	INFO	====> Epoch: 3590, cost 26.31 s
2024-01-02 20:13:20,909	44k	INFO	====> Epoch: 3591, cost 26.34 s
2024-01-02 20:13:47,193	44k	INFO	====> Epoch: 3592, cost 26.28 s
2024-01-02 20:14:13,382	44k	INFO	====> Epoch: 3593, cost 26.19 s
2024-01-02 20:14:39,591	44k	INFO	====> Epoch: 3594, cost 26.21 s
2024-01-02 20:14:47,050	44k	INFO	Train Epoch: 3595 [26%]
2024-01-02 20:14:47,051	44k	INFO	Losses: [2.2274222373962402, 2.680402994155884, 8.522425651550293, 14.377511024475098, 0.6133748292922974], step: 125800, lr: 6.380886340359873e-05, reference_loss: 28.4211368560791
2024-01-02 20:15:06,702	44k	INFO	====> Epoch: 3595, cost 27.11 s
2024-01-02 20:15:33,069	44k	INFO	====> Epoch: 3596, cost 26.37 s
2024-01-02 20:15:59,413	44k	INFO	====> Epoch: 3597, cost 26.34 s
2024-01-02 20:16:25,815	44k	INFO	====> Epoch: 3598, cost 26.40 s
2024-01-02 20:16:52,145	44k	INFO	====> Epoch: 3599, cost 26.33 s
2024-01-02 20:17:18,490	44k	INFO	Train Epoch: 3600 [97%]
2024-01-02 20:17:18,491	44k	INFO	Losses: [1.9462449550628662, 3.235517740249634, 11.28709602355957, 16.644285202026367, 0.3425891101360321], step: 126000, lr: 6.376899283286019e-05, reference_loss: 33.45573425292969
2024-01-02 20:17:18,987	44k	INFO	====> Epoch: 3600, cost 26.84 s
2024-01-02 20:17:45,479	44k	INFO	====> Epoch: 3601, cost 26.49 s
2024-01-02 20:18:11,921	44k	INFO	====> Epoch: 3602, cost 26.44 s
2024-01-02 20:18:38,528	44k	INFO	====> Epoch: 3603, cost 26.61 s
2024-01-02 20:19:04,980	44k	INFO	====> Epoch: 3604, cost 26.45 s
2024-01-02 20:19:31,440	44k	INFO	====> Epoch: 3605, cost 26.46 s
2024-01-02 20:19:50,273	44k	INFO	Train Epoch: 3606 [69%]
2024-01-02 20:19:50,274	44k	INFO	Losses: [1.741544246673584, 3.396671772003174, 9.848488807678223, 14.045113563537598, 0.5387793183326721], step: 126200, lr: 6.372118103160248e-05, reference_loss: 29.570598602294922
2024-01-02 20:19:58,373	44k	INFO	====> Epoch: 3606, cost 26.93 s
2024-01-02 20:20:24,783	44k	INFO	====> Epoch: 3607, cost 26.41 s
2024-01-02 20:20:51,137	44k	INFO	====> Epoch: 3608, cost 26.35 s
2024-01-02 20:21:17,627	44k	INFO	====> Epoch: 3609, cost 26.49 s
2024-01-02 20:21:44,230	44k	INFO	====> Epoch: 3610, cost 26.60 s
2024-01-02 20:22:10,648	44k	INFO	====> Epoch: 3611, cost 26.42 s
2024-01-02 20:22:21,904	44k	INFO	Train Epoch: 3612 [40%]
2024-01-02 20:22:21,905	44k	INFO	Losses: [2.256615400314331, 2.741591691970825, 11.562167167663574, 17.262271881103516, 0.5145984292030334], step: 126400, lr: 6.36734050779917e-05, reference_loss: 34.33724594116211
2024-01-02 20:22:29,456	44k	INFO	Saving model and optimizer state at iteration 3612 to ./logs/44k/G_126400.pth
2024-01-02 20:22:30,354	44k	INFO	Saving model and optimizer state at iteration 3612 to ./logs/44k/D_126400.pth
2024-01-02 20:22:31,133	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_124000.pth
2024-01-02 20:22:31,191	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_124000.pth
2024-01-02 20:22:46,335	44k	INFO	====> Epoch: 3612, cost 35.69 s
2024-01-02 20:23:12,742	44k	INFO	====> Epoch: 3613, cost 26.41 s
2024-01-02 20:23:39,162	44k	INFO	====> Epoch: 3614, cost 26.42 s
2024-01-02 20:24:05,897	44k	INFO	====> Epoch: 3615, cost 26.74 s
2024-01-02 20:24:32,361	44k	INFO	====> Epoch: 3616, cost 26.46 s
2024-01-02 20:24:58,642	44k	INFO	====> Epoch: 3617, cost 26.28 s
2024-01-02 20:25:02,407	44k	INFO	Train Epoch: 3618 [11%]
2024-01-02 20:25:02,408	44k	INFO	Losses: [1.8643162250518799, 3.495241641998291, 11.354588508605957, 15.367146492004395, 0.5467912554740906], step: 126600, lr: 6.362566494515048e-05, reference_loss: 32.628082275390625
2024-01-02 20:25:25,521	44k	INFO	====> Epoch: 3618, cost 26.88 s
2024-01-02 20:25:51,996	44k	INFO	====> Epoch: 3619, cost 26.47 s
2024-01-02 20:26:18,474	44k	INFO	====> Epoch: 3620, cost 26.48 s
2024-01-02 20:26:44,850	44k	INFO	====> Epoch: 3621, cost 26.38 s
2024-01-02 20:27:10,976	44k	INFO	====> Epoch: 3622, cost 26.13 s
2024-01-02 20:27:33,819	44k	INFO	Train Epoch: 3623 [83%]
2024-01-02 20:27:33,820	44k	INFO	Losses: [2.44980525970459, 2.382540225982666, 8.07467269897461, 15.42082405090332, 0.5452983975410461], step: 126800, lr: 6.358590884482729e-05, reference_loss: 28.873140335083008
2024-01-02 20:27:38,080	44k	INFO	====> Epoch: 3623, cost 27.10 s
2024-01-02 20:28:04,484	44k	INFO	====> Epoch: 3624, cost 26.40 s
2024-01-02 20:28:30,715	44k	INFO	====> Epoch: 3625, cost 26.23 s
2024-01-02 20:28:57,036	44k	INFO	====> Epoch: 3626, cost 26.32 s
2024-01-02 20:29:23,303	44k	INFO	====> Epoch: 3627, cost 26.27 s
2024-01-02 20:29:49,534	44k	INFO	====> Epoch: 3628, cost 26.23 s
2024-01-02 20:30:04,511	44k	INFO	Train Epoch: 3629 [54%]
2024-01-02 20:30:04,511	44k	INFO	Losses: [2.021273612976074, 3.126518487930298, 11.102985382080078, 16.9315128326416, 0.49386364221572876], step: 127000, lr: 6.353823431365744e-05, reference_loss: 33.676151275634766
2024-01-02 20:30:16,666	44k	INFO	====> Epoch: 3629, cost 27.13 s
2024-01-02 20:30:42,955	44k	INFO	====> Epoch: 3630, cost 26.29 s
2024-01-02 20:31:09,144	44k	INFO	====> Epoch: 3631, cost 26.19 s
2024-01-02 20:31:35,403	44k	INFO	====> Epoch: 3632, cost 26.26 s
2024-01-02 20:32:01,735	44k	INFO	====> Epoch: 3633, cost 26.33 s
2024-01-02 20:32:27,956	44k	INFO	====> Epoch: 3634, cost 26.22 s
2024-01-02 20:32:35,397	44k	INFO	Train Epoch: 3635 [26%]
2024-01-02 20:32:35,398	44k	INFO	Losses: [2.441080331802368, 2.381808042526245, 8.351922035217285, 14.415958404541016, 0.4107685089111328], step: 127200, lr: 6.349059552721413e-05, reference_loss: 28.001537322998047
2024-01-02 20:32:42,728	44k	INFO	Saving model and optimizer state at iteration 3635 to ./logs/44k/G_127200.pth
2024-01-02 20:32:43,951	44k	INFO	Saving model and optimizer state at iteration 3635 to ./logs/44k/D_127200.pth
2024-01-02 20:32:44,722	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_124800.pth
2024-01-02 20:32:44,781	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_124800.pth
2024-01-02 20:33:03,549	44k	INFO	====> Epoch: 3635, cost 35.59 s
2024-01-02 20:33:29,899	44k	INFO	====> Epoch: 3636, cost 26.35 s
2024-01-02 20:33:56,277	44k	INFO	====> Epoch: 3637, cost 26.38 s
2024-01-02 20:34:22,568	44k	INFO	====> Epoch: 3638, cost 26.29 s
2024-01-02 20:34:48,934	44k	INFO	====> Epoch: 3639, cost 26.37 s
2024-01-02 20:35:15,240	44k	INFO	Train Epoch: 3640 [97%]
2024-01-02 20:35:15,240	44k	INFO	Losses: [2.141258955001831, 3.003328323364258, 11.43535327911377, 16.904998779296875, 0.3724554479122162], step: 127400, lr: 6.34509238241752e-05, reference_loss: 33.85739517211914
2024-01-02 20:35:15,735	44k	INFO	====> Epoch: 3640, cost 26.80 s
2024-01-02 20:35:42,076	44k	INFO	====> Epoch: 3641, cost 26.34 s
2024-01-02 20:36:08,725	44k	INFO	====> Epoch: 3642, cost 26.65 s
2024-01-02 20:36:35,078	44k	INFO	====> Epoch: 3643, cost 26.35 s
2024-01-02 20:37:01,384	44k	INFO	====> Epoch: 3644, cost 26.31 s
2024-01-02 20:37:27,756	44k	INFO	====> Epoch: 3645, cost 26.37 s
2024-01-02 20:37:46,552	44k	INFO	Train Epoch: 3646 [69%]
2024-01-02 20:37:46,553	44k	INFO	Losses: [2.352947235107422, 2.702718734741211, 10.277002334594727, 14.255590438842773, 0.6455121040344238], step: 127600, lr: 6.340335050013899e-05, reference_loss: 30.2337703704834
2024-01-02 20:37:54,596	44k	INFO	====> Epoch: 3646, cost 26.84 s
2024-01-02 20:38:21,012	44k	INFO	====> Epoch: 3647, cost 26.42 s
2024-01-02 20:38:47,437	44k	INFO	====> Epoch: 3648, cost 26.42 s
2024-01-02 20:39:13,987	44k	INFO	====> Epoch: 3649, cost 26.55 s
2024-01-02 20:39:40,228	44k	INFO	====> Epoch: 3650, cost 26.24 s
2024-01-02 20:40:06,513	44k	INFO	====> Epoch: 3651, cost 26.28 s
2024-01-02 20:40:17,685	44k	INFO	Train Epoch: 3652 [40%]
2024-01-02 20:40:17,686	44k	INFO	Losses: [2.2668848037719727, 2.62408709526062, 9.160379409790039, 15.28612232208252, 0.6322352886199951], step: 127800, lr: 6.335581284494769e-05, reference_loss: 29.969709396362305
2024-01-02 20:40:33,301	44k	INFO	====> Epoch: 3652, cost 26.79 s
2024-01-02 20:40:59,547	44k	INFO	====> Epoch: 3653, cost 26.25 s
2024-01-02 20:41:26,007	44k	INFO	====> Epoch: 3654, cost 26.46 s
2024-01-02 20:41:52,362	44k	INFO	====> Epoch: 3655, cost 26.36 s
2024-01-02 20:42:18,763	44k	INFO	====> Epoch: 3656, cost 26.40 s
2024-01-02 20:42:45,446	44k	INFO	====> Epoch: 3657, cost 26.68 s
2024-01-02 20:42:49,197	44k	INFO	Train Epoch: 3658 [11%]
2024-01-02 20:42:49,198	44k	INFO	Losses: [2.5738792419433594, 2.276212215423584, 8.259632110595703, 14.89597225189209, 0.6718470454216003], step: 128000, lr: 6.3308310831858e-05, reference_loss: 28.677541732788086
2024-01-02 20:42:56,888	44k	INFO	Saving model and optimizer state at iteration 3658 to ./logs/44k/G_128000.pth
2024-01-02 20:42:57,795	44k	INFO	Saving model and optimizer state at iteration 3658 to ./logs/44k/D_128000.pth
2024-01-02 20:42:58,580	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_125600.pth
2024-01-02 20:42:58,637	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_125600.pth
2024-01-02 20:43:21,363	44k	INFO	====> Epoch: 3658, cost 35.92 s
2024-01-02 20:43:47,904	44k	INFO	====> Epoch: 3659, cost 26.54 s
2024-01-02 20:44:14,303	44k	INFO	====> Epoch: 3660, cost 26.40 s
2024-01-02 20:44:40,600	44k	INFO	====> Epoch: 3661, cost 26.30 s
2024-01-02 20:45:07,290	44k	INFO	====> Epoch: 3662, cost 26.69 s
2024-01-02 20:45:29,901	44k	INFO	Train Epoch: 3663 [83%]
2024-01-02 20:45:29,902	44k	INFO	Losses: [1.6295435428619385, 3.585989475250244, 11.136911392211914, 13.94722843170166, 0.35198506712913513], step: 128200, lr: 6.326875302827524e-05, reference_loss: 30.651657104492188
2024-01-02 20:45:34,175	44k	INFO	====> Epoch: 3663, cost 26.89 s
2024-01-02 20:46:00,489	44k	INFO	====> Epoch: 3664, cost 26.31 s
2024-01-02 20:46:26,903	44k	INFO	====> Epoch: 3665, cost 26.41 s
2024-01-02 20:46:53,233	44k	INFO	====> Epoch: 3666, cost 26.33 s
2024-01-02 20:47:19,627	44k	INFO	====> Epoch: 3667, cost 26.39 s
2024-01-02 20:47:45,960	44k	INFO	====> Epoch: 3668, cost 26.33 s
2024-01-02 20:48:00,947	44k	INFO	Train Epoch: 3669 [54%]
2024-01-02 20:48:00,947	44k	INFO	Losses: [1.9444527626037598, 3.050452947616577, 10.631614685058594, 15.662323951721191, 0.6027891039848328], step: 128400, lr: 6.32213162896468e-05, reference_loss: 31.891633987426758
2024-01-02 20:48:13,130	44k	INFO	====> Epoch: 3669, cost 27.17 s
2024-01-02 20:48:39,488	44k	INFO	====> Epoch: 3670, cost 26.36 s
2024-01-02 20:49:05,878	44k	INFO	====> Epoch: 3671, cost 26.39 s
2024-01-02 20:49:32,286	44k	INFO	====> Epoch: 3672, cost 26.41 s
2024-01-02 20:49:58,676	44k	INFO	====> Epoch: 3673, cost 26.39 s
2024-01-02 20:50:25,122	44k	INFO	====> Epoch: 3674, cost 26.45 s
2024-01-02 20:50:32,641	44k	INFO	Train Epoch: 3675 [26%]
2024-01-02 20:50:32,642	44k	INFO	Losses: [1.745648741722107, 3.5439939498901367, 10.413893699645996, 14.672640800476074, 0.5081523656845093], step: 128600, lr: 6.317391511745622e-05, reference_loss: 30.88433074951172
2024-01-02 20:50:52,142	44k	INFO	====> Epoch: 3675, cost 27.02 s
2024-01-02 20:51:18,748	44k	INFO	====> Epoch: 3676, cost 26.61 s
2024-01-02 20:51:45,052	44k	INFO	====> Epoch: 3677, cost 26.30 s
2024-01-02 20:52:11,425	44k	INFO	====> Epoch: 3678, cost 26.37 s
2024-01-02 20:52:37,733	44k	INFO	====> Epoch: 3679, cost 26.31 s
2024-01-02 20:53:04,106	44k	INFO	Train Epoch: 3680 [97%]
2024-01-02 20:53:04,106	44k	INFO	Losses: [1.9532203674316406, 3.2461118698120117, 9.37275505065918, 15.029426574707031, 0.4571562707424164], step: 128800, lr: 6.313444129019825e-05, reference_loss: 30.058670043945312
2024-01-02 20:53:11,660	44k	INFO	Saving model and optimizer state at iteration 3680 to ./logs/44k/G_128800.pth
2024-01-02 20:53:12,553	44k	INFO	Saving model and optimizer state at iteration 3680 to ./logs/44k/D_128800.pth
2024-01-02 20:53:13,335	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_126400.pth
2024-01-02 20:53:13,391	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_126400.pth
2024-01-02 20:53:13,392	44k	INFO	====> Epoch: 3680, cost 35.66 s
2024-01-02 20:53:40,078	44k	INFO	====> Epoch: 3681, cost 26.69 s
2024-01-02 20:54:06,482	44k	INFO	====> Epoch: 3682, cost 26.40 s
2024-01-02 20:54:32,874	44k	INFO	====> Epoch: 3683, cost 26.39 s
2024-01-02 20:54:59,161	44k	INFO	====> Epoch: 3684, cost 26.29 s
2024-01-02 20:55:25,432	44k	INFO	====> Epoch: 3685, cost 26.27 s
2024-01-02 20:55:44,243	44k	INFO	Train Epoch: 3686 [69%]
2024-01-02 20:55:44,243	44k	INFO	Losses: [1.8676633834838867, 3.0982558727264404, 11.191322326660156, 14.928831100463867, 0.6087178587913513], step: 129000, lr: 6.30871052538993e-05, reference_loss: 31.69478988647461
2024-01-02 20:55:52,292	44k	INFO	====> Epoch: 3686, cost 26.86 s
2024-01-02 20:56:18,561	44k	INFO	====> Epoch: 3687, cost 26.27 s
2024-01-02 20:56:44,818	44k	INFO	====> Epoch: 3688, cost 26.26 s
2024-01-02 20:57:11,081	44k	INFO	====> Epoch: 3689, cost 26.26 s
2024-01-02 20:57:37,617	44k	INFO	====> Epoch: 3690, cost 26.54 s
2024-01-02 20:58:03,932	44k	INFO	====> Epoch: 3691, cost 26.32 s
2024-01-02 20:58:15,210	44k	INFO	Train Epoch: 3692 [40%]
2024-01-02 20:58:15,210	44k	INFO	Losses: [1.8901150226593018, 3.447394371032715, 11.911489486694336, 16.704336166381836, 0.41002392768859863], step: 129200, lr: 6.303980470853507e-05, reference_loss: 34.36335754394531
2024-01-02 20:58:30,847	44k	INFO	====> Epoch: 3692, cost 26.91 s
2024-01-02 20:58:57,116	44k	INFO	====> Epoch: 3693, cost 26.27 s
2024-01-02 20:59:23,476	44k	INFO	====> Epoch: 3694, cost 26.36 s
2024-01-02 20:59:49,781	44k	INFO	====> Epoch: 3695, cost 26.30 s
2024-01-02 21:00:16,236	44k	INFO	====> Epoch: 3696, cost 26.46 s
2024-01-02 21:00:42,841	44k	INFO	====> Epoch: 3697, cost 26.60 s
2024-01-02 21:00:46,603	44k	INFO	Train Epoch: 3698 [11%]
2024-01-02 21:00:46,604	44k	INFO	Losses: [2.0351438522338867, 2.9258527755737305, 10.141729354858398, 15.371404647827148, 0.3040323853492737], step: 129400, lr: 6.299253962749561e-05, reference_loss: 30.77816390991211
2024-01-02 21:01:09,686	44k	INFO	====> Epoch: 3698, cost 26.85 s
2024-01-02 21:01:36,127	44k	INFO	====> Epoch: 3699, cost 26.44 s
2024-01-02 21:02:02,630	44k	INFO	====> Epoch: 3700, cost 26.50 s
2024-01-02 21:02:29,015	44k	INFO	====> Epoch: 3701, cost 26.39 s
2024-01-02 21:02:55,374	44k	INFO	====> Epoch: 3702, cost 26.36 s
2024-01-02 21:03:17,974	44k	INFO	Train Epoch: 3703 [83%]
2024-01-02 21:03:17,975	44k	INFO	Losses: [2.3614907264709473, 2.45169997215271, 10.150728225708008, 14.693180084228516, 0.5791857838630676], step: 129600, lr: 6.295317913158248e-05, reference_loss: 30.236284255981445
2024-01-02 21:03:25,904	44k	INFO	Saving model and optimizer state at iteration 3703 to ./logs/44k/G_129600.pth
2024-01-02 21:03:26,827	44k	INFO	Saving model and optimizer state at iteration 3703 to ./logs/44k/D_129600.pth
2024-01-02 21:03:27,594	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_127200.pth
2024-01-02 21:03:27,652	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_127200.pth
2024-01-02 21:03:31,423	44k	INFO	====> Epoch: 3703, cost 36.05 s
2024-01-02 21:03:57,865	44k	INFO	====> Epoch: 3704, cost 26.44 s
2024-01-02 21:04:24,189	44k	INFO	====> Epoch: 3705, cost 26.32 s
2024-01-02 21:04:50,523	44k	INFO	====> Epoch: 3706, cost 26.33 s
2024-01-02 21:05:16,933	44k	INFO	====> Epoch: 3707, cost 26.41 s
2024-01-02 21:05:43,224	44k	INFO	====> Epoch: 3708, cost 26.29 s
2024-01-02 21:05:58,161	44k	INFO	Train Epoch: 3709 [54%]
2024-01-02 21:05:58,161	44k	INFO	Losses: [2.2132155895233154, 2.7214999198913574, 9.331473350524902, 14.685464859008789, 0.24606573581695557], step: 129800, lr: 6.290597899942625e-05, reference_loss: 29.197717666625977
2024-01-02 21:06:10,373	44k	INFO	====> Epoch: 3709, cost 27.15 s
2024-01-02 21:06:36,767	44k	INFO	====> Epoch: 3710, cost 26.39 s
2024-01-02 21:07:03,006	44k	INFO	====> Epoch: 3711, cost 26.24 s
2024-01-02 21:07:29,380	44k	INFO	====> Epoch: 3712, cost 26.37 s
2024-01-02 21:07:55,610	44k	INFO	====> Epoch: 3713, cost 26.23 s
2024-01-02 21:08:21,836	44k	INFO	====> Epoch: 3714, cost 26.23 s
2024-01-02 21:08:29,365	44k	INFO	Train Epoch: 3715 [26%]
2024-01-02 21:08:29,366	44k	INFO	Losses: [2.1919312477111816, 2.700798749923706, 10.725483894348145, 16.776098251342773, 0.7396693825721741], step: 130000, lr: 6.285881425630847e-05, reference_loss: 33.13397979736328
2024-01-02 21:08:48,885	44k	INFO	====> Epoch: 3715, cost 27.05 s
2024-01-02 21:09:15,427	44k	INFO	====> Epoch: 3716, cost 26.54 s
2024-01-02 21:09:41,799	44k	INFO	====> Epoch: 3717, cost 26.37 s
2024-01-02 21:10:08,119	44k	INFO	====> Epoch: 3718, cost 26.32 s
2024-01-02 21:10:34,510	44k	INFO	====> Epoch: 3719, cost 26.39 s
2024-01-02 21:11:00,973	44k	INFO	Train Epoch: 3720 [97%]
2024-01-02 21:11:00,973	44k	INFO	Losses: [2.3172991275787354, 2.568020820617676, 10.725679397583008, 17.035274505615234, 0.6693782806396484], step: 130200, lr: 6.281953731786035e-05, reference_loss: 33.315650939941406
2024-01-02 21:11:01,462	44k	INFO	====> Epoch: 3720, cost 26.95 s
2024-01-02 21:11:27,900	44k	INFO	====> Epoch: 3721, cost 26.44 s
2024-01-02 21:11:54,370	44k	INFO	====> Epoch: 3722, cost 26.47 s
2024-01-02 21:12:21,082	44k	INFO	====> Epoch: 3723, cost 26.71 s
2024-01-02 21:12:47,501	44k	INFO	====> Epoch: 3724, cost 26.42 s
2024-01-02 21:13:13,905	44k	INFO	====> Epoch: 3725, cost 26.40 s
2024-01-02 21:13:32,816	44k	INFO	Train Epoch: 3726 [69%]
2024-01-02 21:13:32,816	44k	INFO	Losses: [1.8329408168792725, 3.257633686065674, 9.758780479431152, 13.55797290802002, 0.5301787257194519], step: 130400, lr: 6.277243738574735e-05, reference_loss: 28.9375057220459
2024-01-02 21:13:40,453	44k	INFO	Saving model and optimizer state at iteration 3726 to ./logs/44k/G_130400.pth
2024-01-02 21:13:41,367	44k	INFO	Saving model and optimizer state at iteration 3726 to ./logs/44k/D_130400.pth
2024-01-02 21:13:42,155	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_128000.pth
2024-01-02 21:13:42,212	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_128000.pth
2024-01-02 21:13:49,765	44k	INFO	====> Epoch: 3726, cost 35.86 s
2024-01-02 21:14:16,245	44k	INFO	====> Epoch: 3727, cost 26.48 s
2024-01-02 21:14:42,655	44k	INFO	====> Epoch: 3728, cost 26.41 s
2024-01-02 21:15:09,470	44k	INFO	====> Epoch: 3729, cost 26.81 s
2024-01-02 21:15:35,934	44k	INFO	====> Epoch: 3730, cost 26.46 s
2024-01-02 21:16:02,244	44k	INFO	====> Epoch: 3731, cost 26.31 s
2024-01-02 21:16:13,417	44k	INFO	Train Epoch: 3732 [40%]
2024-01-02 21:16:13,417	44k	INFO	Losses: [2.3077762126922607, 2.358078718185425, 10.396387100219727, 16.622865676879883, 0.3454691767692566], step: 130600, lr: 6.272537276754621e-05, reference_loss: 32.03057861328125
2024-01-02 21:16:29,059	44k	INFO	====> Epoch: 3732, cost 26.82 s
2024-01-02 21:16:55,546	44k	INFO	====> Epoch: 3733, cost 26.49 s
2024-01-02 21:17:21,975	44k	INFO	====> Epoch: 3734, cost 26.43 s
2024-01-02 21:17:48,368	44k	INFO	====> Epoch: 3735, cost 26.39 s
2024-01-02 21:18:14,780	44k	INFO	====> Epoch: 3736, cost 26.41 s
2024-01-02 21:18:41,450	44k	INFO	====> Epoch: 3737, cost 26.67 s
2024-01-02 21:18:45,206	44k	INFO	Train Epoch: 3738 [11%]
2024-01-02 21:18:45,206	44k	INFO	Losses: [2.0486679077148438, 2.854849338531494, 10.184369087219238, 16.634111404418945, 0.3363615572452545], step: 130800, lr: 6.267834343677979e-05, reference_loss: 32.0583610534668
2024-01-02 21:19:08,397	44k	INFO	====> Epoch: 3738, cost 26.95 s
2024-01-02 21:19:34,875	44k	INFO	====> Epoch: 3739, cost 26.48 s
2024-01-02 21:20:01,267	44k	INFO	====> Epoch: 3740, cost 26.39 s
2024-01-02 21:20:27,723	44k	INFO	====> Epoch: 3741, cost 26.46 s
2024-01-02 21:20:54,179	44k	INFO	====> Epoch: 3742, cost 26.46 s
2024-01-02 21:21:16,825	44k	INFO	Train Epoch: 3743 [83%]
2024-01-02 21:21:16,826	44k	INFO	Losses: [1.9643596410751343, 3.0450501441955566, 10.065202713012695, 13.963211059570312, 0.5571068525314331], step: 131000, lr: 6.263917926439885e-05, reference_loss: 29.594928741455078
2024-01-02 21:21:21,431	44k	INFO	====> Epoch: 3743, cost 27.25 s
2024-01-02 21:21:47,845	44k	INFO	====> Epoch: 3744, cost 26.41 s
2024-01-02 21:22:14,201	44k	INFO	====> Epoch: 3745, cost 26.36 s
2024-01-02 21:22:40,667	44k	INFO	====> Epoch: 3746, cost 26.47 s
2024-01-02 21:23:07,114	44k	INFO	====> Epoch: 3747, cost 26.45 s
2024-01-02 21:23:33,338	44k	INFO	====> Epoch: 3748, cost 26.22 s
2024-01-02 21:23:48,312	44k	INFO	Train Epoch: 3749 [54%]
2024-01-02 21:23:48,313	44k	INFO	Losses: [1.989195466041565, 2.880671977996826, 13.304490089416504, 15.985005378723145, 0.6076636910438538], step: 131200, lr: 6.259221455856156e-05, reference_loss: 34.767024993896484
2024-01-02 21:23:55,953	44k	INFO	Saving model and optimizer state at iteration 3749 to ./logs/44k/G_131200.pth
2024-01-02 21:23:57,176	44k	INFO	Saving model and optimizer state at iteration 3749 to ./logs/44k/D_131200.pth
2024-01-02 21:23:57,944	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_128800.pth
2024-01-02 21:23:58,001	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_128800.pth
2024-01-02 21:24:09,431	44k	INFO	====> Epoch: 3749, cost 36.09 s
2024-01-02 21:24:35,880	44k	INFO	====> Epoch: 3750, cost 26.45 s
2024-01-02 21:25:02,367	44k	INFO	====> Epoch: 3751, cost 26.49 s
2024-01-02 21:25:28,657	44k	INFO	====> Epoch: 3752, cost 26.29 s
2024-01-02 21:25:54,987	44k	INFO	====> Epoch: 3753, cost 26.33 s
2024-01-02 21:26:21,370	44k	INFO	====> Epoch: 3754, cost 26.38 s
2024-01-02 21:26:28,933	44k	INFO	Train Epoch: 3755 [26%]
2024-01-02 21:26:28,934	44k	INFO	Losses: [2.2464206218719482, 2.752303123474121, 9.716578483581543, 15.327651977539062, 0.6145153045654297], step: 131400, lr: 6.254528506524815e-05, reference_loss: 30.657468795776367
2024-01-02 21:26:48,417	44k	INFO	====> Epoch: 3755, cost 27.05 s
2024-01-02 21:27:15,030	44k	INFO	====> Epoch: 3756, cost 26.61 s
2024-01-02 21:27:41,451	44k	INFO	====> Epoch: 3757, cost 26.42 s
2024-01-02 21:28:07,926	44k	INFO	====> Epoch: 3758, cost 26.48 s
2024-01-02 21:28:34,432	44k	INFO	====> Epoch: 3759, cost 26.51 s
2024-01-02 21:29:00,939	44k	INFO	Train Epoch: 3760 [97%]
2024-01-02 21:29:00,939	44k	INFO	Losses: [2.4193062782287598, 2.7610981464385986, 8.827096939086914, 15.69335651397705, 0.32296016812324524], step: 131600, lr: 6.250620403356163e-05, reference_loss: 30.023818969726562
2024-01-02 21:29:01,438	44k	INFO	====> Epoch: 3760, cost 27.01 s
2024-01-02 21:29:27,808	44k	INFO	====> Epoch: 3761, cost 26.37 s
2024-01-02 21:29:54,113	44k	INFO	====> Epoch: 3762, cost 26.30 s
2024-01-02 21:30:20,692	44k	INFO	====> Epoch: 3763, cost 26.58 s
2024-01-02 21:30:46,887	44k	INFO	====> Epoch: 3764, cost 26.20 s
2024-01-02 21:31:13,097	44k	INFO	====> Epoch: 3765, cost 26.21 s
2024-01-02 21:31:31,820	44k	INFO	Train Epoch: 3766 [69%]
2024-01-02 21:31:31,820	44k	INFO	Losses: [1.7466731071472168, 3.744131088256836, 10.324705123901367, 14.776505470275879, 0.5500275492668152], step: 131800, lr: 6.24593390279866e-05, reference_loss: 31.14204216003418
2024-01-02 21:31:40,069	44k	INFO	====> Epoch: 3766, cost 26.97 s
2024-01-02 21:32:06,540	44k	INFO	====> Epoch: 3767, cost 26.47 s
2024-01-02 21:32:32,851	44k	INFO	====> Epoch: 3768, cost 26.31 s
2024-01-02 21:32:59,283	44k	INFO	====> Epoch: 3769, cost 26.43 s
2024-01-02 21:33:26,020	44k	INFO	====> Epoch: 3770, cost 26.74 s
2024-01-02 21:33:52,482	44k	INFO	====> Epoch: 3771, cost 26.46 s
2024-01-02 21:34:03,773	44k	INFO	Train Epoch: 3772 [40%]
2024-01-02 21:34:03,774	44k	INFO	Losses: [2.2320618629455566, 2.752354383468628, 11.754895210266113, 17.073963165283203, 0.4571681022644043], step: 132000, lr: 6.24125091601836e-05, reference_loss: 34.270442962646484
2024-01-02 21:34:11,457	44k	INFO	Saving model and optimizer state at iteration 3772 to ./logs/44k/G_132000.pth
2024-01-02 21:34:12,354	44k	INFO	Saving model and optimizer state at iteration 3772 to ./logs/44k/D_132000.pth
2024-01-02 21:34:13,155	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_129600.pth
2024-01-02 21:34:13,213	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_129600.pth
2024-01-02 21:34:28,277	44k	INFO	====> Epoch: 3772, cost 35.79 s
2024-01-02 21:34:54,656	44k	INFO	====> Epoch: 3773, cost 26.38 s
2024-01-02 21:35:20,934	44k	INFO	====> Epoch: 3774, cost 26.28 s
2024-01-02 21:35:47,282	44k	INFO	====> Epoch: 3775, cost 26.35 s
2024-01-02 21:36:13,897	44k	INFO	====> Epoch: 3776, cost 26.62 s
2024-01-02 21:36:40,257	44k	INFO	====> Epoch: 3777, cost 26.36 s
2024-01-02 21:36:44,031	44k	INFO	Train Epoch: 3778 [11%]
2024-01-02 21:36:44,032	44k	INFO	Losses: [2.395610809326172, 2.9267520904541016, 9.447914123535156, 15.09249496459961, 0.462117463350296], step: 132200, lr: 6.236571440380753e-05, reference_loss: 30.32489013671875
2024-01-02 21:37:07,118	44k	INFO	====> Epoch: 3778, cost 26.86 s
2024-01-02 21:37:33,586	44k	INFO	====> Epoch: 3779, cost 26.47 s
2024-01-02 21:38:00,020	44k	INFO	====> Epoch: 3780, cost 26.43 s
2024-01-02 21:38:26,369	44k	INFO	====> Epoch: 3781, cost 26.35 s
2024-01-02 21:38:52,873	44k	INFO	====> Epoch: 3782, cost 26.50 s
2024-01-02 21:39:15,503	44k	INFO	Train Epoch: 3783 [83%]
2024-01-02 21:39:15,503	44k	INFO	Losses: [1.8910183906555176, 2.9205329418182373, 9.767570495605469, 16.07154655456543, 0.5398034453392029], step: 132400, lr: 6.232674557573002e-05, reference_loss: 31.190471649169922
2024-01-02 21:39:20,249	44k	INFO	====> Epoch: 3783, cost 27.38 s
2024-01-02 21:39:46,692	44k	INFO	====> Epoch: 3784, cost 26.44 s
2024-01-02 21:40:13,104	44k	INFO	====> Epoch: 3785, cost 26.41 s
2024-01-02 21:40:39,476	44k	INFO	====> Epoch: 3786, cost 26.37 s
2024-01-02 21:41:05,858	44k	INFO	====> Epoch: 3787, cost 26.38 s
2024-01-02 21:41:32,256	44k	INFO	====> Epoch: 3788, cost 26.40 s
2024-01-02 21:41:47,278	44k	INFO	Train Epoch: 3789 [54%]
2024-01-02 21:41:47,279	44k	INFO	Losses: [2.4386420249938965, 2.640962839126587, 10.661614418029785, 16.32286834716797, 0.4345957040786743], step: 132600, lr: 6.22800151219448e-05, reference_loss: 32.49868392944336
2024-01-02 21:41:59,187	44k	INFO	====> Epoch: 3789, cost 26.93 s
2024-01-02 21:42:25,934	44k	INFO	====> Epoch: 3790, cost 26.75 s
2024-01-02 21:42:52,181	44k	INFO	====> Epoch: 3791, cost 26.25 s
2024-01-02 21:43:18,322	44k	INFO	====> Epoch: 3792, cost 26.14 s
2024-01-02 21:43:44,506	44k	INFO	====> Epoch: 3793, cost 26.18 s
2024-01-02 21:44:10,882	44k	INFO	====> Epoch: 3794, cost 26.38 s
2024-01-02 21:44:18,354	44k	INFO	Train Epoch: 3795 [26%]
2024-01-02 21:44:18,354	44k	INFO	Losses: [1.8475489616394043, 3.4815773963928223, 11.07535171508789, 15.281538963317871, 0.4282587766647339], step: 132800, lr: 6.223331970504928e-05, reference_loss: 32.11427307128906
2024-01-02 21:44:25,938	44k	INFO	Saving model and optimizer state at iteration 3795 to ./logs/44k/G_132800.pth
2024-01-02 21:44:26,840	44k	INFO	Saving model and optimizer state at iteration 3795 to ./logs/44k/D_132800.pth
2024-01-02 21:44:27,638	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_130400.pth
2024-01-02 21:44:27,695	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_130400.pth
2024-01-02 21:44:46,937	44k	INFO	====> Epoch: 3795, cost 36.05 s
2024-01-02 21:45:13,371	44k	INFO	====> Epoch: 3796, cost 26.43 s
2024-01-02 21:45:39,805	44k	INFO	====> Epoch: 3797, cost 26.43 s
2024-01-02 21:46:06,189	44k	INFO	====> Epoch: 3798, cost 26.38 s
2024-01-02 21:46:32,674	44k	INFO	====> Epoch: 3799, cost 26.49 s
2024-01-02 21:46:59,072	44k	INFO	Train Epoch: 3800 [97%]
2024-01-02 21:46:59,072	44k	INFO	Losses: [2.2484323978424072, 2.8367812633514404, 12.253986358642578, 17.836883544921875, 0.4436095058917999], step: 133000, lr: 6.21944336029744e-05, reference_loss: 35.619693756103516
2024-01-02 21:46:59,592	44k	INFO	====> Epoch: 3800, cost 26.92 s
2024-01-02 21:47:26,053	44k	INFO	====> Epoch: 3801, cost 26.46 s
2024-01-02 21:47:52,476	44k	INFO	====> Epoch: 3802, cost 26.42 s
2024-01-02 21:48:18,942	44k	INFO	====> Epoch: 3803, cost 26.47 s
2024-01-02 21:48:45,661	44k	INFO	====> Epoch: 3804, cost 26.72 s
2024-01-02 21:49:11,951	44k	INFO	====> Epoch: 3805, cost 26.29 s
2024-01-02 21:49:30,812	44k	INFO	Train Epoch: 3806 [69%]
2024-01-02 21:49:30,813	44k	INFO	Losses: [1.9839954376220703, 3.0432276725769043, 11.168824195861816, 15.021172523498535, 0.6343249082565308], step: 133200, lr: 6.214780235216329e-05, reference_loss: 31.851545333862305
2024-01-02 21:49:38,923	44k	INFO	====> Epoch: 3806, cost 26.97 s
2024-01-02 21:50:05,366	44k	INFO	====> Epoch: 3807, cost 26.44 s
2024-01-02 21:50:31,773	44k	INFO	====> Epoch: 3808, cost 26.41 s
2024-01-02 21:50:58,134	44k	INFO	====> Epoch: 3809, cost 26.36 s
2024-01-02 21:51:24,408	44k	INFO	====> Epoch: 3810, cost 26.27 s
2024-01-02 21:51:51,102	44k	INFO	====> Epoch: 3811, cost 26.69 s
2024-01-02 21:52:02,374	44k	INFO	Train Epoch: 3812 [40%]
2024-01-02 21:52:02,375	44k	INFO	Losses: [2.143334150314331, 2.768897771835327, 9.590874671936035, 15.158595085144043, 0.6825190782546997], step: 133400, lr: 6.210120606386292e-05, reference_loss: 30.344221115112305
2024-01-02 21:52:18,193	44k	INFO	====> Epoch: 3812, cost 27.09 s
2024-01-02 21:52:44,542	44k	INFO	====> Epoch: 3813, cost 26.35 s
2024-01-02 21:53:10,983	44k	INFO	====> Epoch: 3814, cost 26.44 s
2024-01-02 21:53:37,346	44k	INFO	====> Epoch: 3815, cost 26.36 s
2024-01-02 21:54:03,821	44k	INFO	====> Epoch: 3816, cost 26.47 s
2024-01-02 21:54:30,295	44k	INFO	====> Epoch: 3817, cost 26.47 s
2024-01-02 21:54:34,058	44k	INFO	Train Epoch: 3818 [11%]
2024-01-02 21:54:34,059	44k	INFO	Losses: [2.0163795948028564, 3.0160019397735596, 9.630207061767578, 15.033802032470703, 0.6872968673706055], step: 133600, lr: 6.205464471185957e-05, reference_loss: 30.383686065673828
2024-01-02 21:54:41,974	44k	INFO	Saving model and optimizer state at iteration 3818 to ./logs/44k/G_133600.pth
2024-01-02 21:54:42,873	44k	INFO	Saving model and optimizer state at iteration 3818 to ./logs/44k/D_133600.pth
2024-01-02 21:54:43,657	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_131200.pth
2024-01-02 21:54:43,714	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_131200.pth
2024-01-02 21:55:06,290	44k	INFO	====> Epoch: 3818, cost 35.99 s
2024-01-02 21:55:32,575	44k	INFO	====> Epoch: 3819, cost 26.29 s
2024-01-02 21:55:58,971	44k	INFO	====> Epoch: 3820, cost 26.40 s
2024-01-02 21:56:25,342	44k	INFO	====> Epoch: 3821, cost 26.37 s
2024-01-02 21:56:51,744	44k	INFO	====> Epoch: 3822, cost 26.40 s
2024-01-02 21:57:14,254	44k	INFO	Train Epoch: 3823 [83%]
2024-01-02 21:57:14,254	44k	INFO	Losses: [2.0399723052978516, 3.0520646572113037, 9.811716079711914, 14.446191787719727, 0.3565596640110016], step: 133800, lr: 6.201587025374095e-05, reference_loss: 29.706504821777344
2024-01-02 21:57:18,951	44k	INFO	====> Epoch: 3823, cost 27.21 s
2024-01-02 21:57:45,401	44k	INFO	====> Epoch: 3824, cost 26.45 s
2024-01-02 21:58:11,776	44k	INFO	====> Epoch: 3825, cost 26.37 s
2024-01-02 21:58:38,089	44k	INFO	====> Epoch: 3826, cost 26.31 s
2024-01-02 21:59:04,311	44k	INFO	====> Epoch: 3827, cost 26.22 s
2024-01-02 21:59:30,781	44k	INFO	====> Epoch: 3828, cost 26.47 s
2024-01-02 21:59:45,820	44k	INFO	Train Epoch: 3829 [54%]
2024-01-02 21:59:45,821	44k	INFO	Losses: [2.3143763542175293, 2.6123046875, 9.097892761230469, 15.553778648376465, 0.5384678840637207], step: 134000, lr: 6.196937288359794e-05, reference_loss: 30.1168212890625
2024-01-02 21:59:57,712	44k	INFO	====> Epoch: 3829, cost 26.93 s
2024-01-02 22:00:24,531	44k	INFO	====> Epoch: 3830, cost 26.82 s
2024-01-02 22:00:51,026	44k	INFO	====> Epoch: 3831, cost 26.49 s
2024-01-02 22:01:17,511	44k	INFO	====> Epoch: 3832, cost 26.49 s
2024-01-02 22:01:43,959	44k	INFO	====> Epoch: 3833, cost 26.45 s
2024-01-02 22:02:10,266	44k	INFO	====> Epoch: 3834, cost 26.31 s
2024-01-02 22:02:17,802	44k	INFO	Train Epoch: 3835 [26%]
2024-01-02 22:02:17,802	44k	INFO	Losses: [1.7133463621139526, 3.5861687660217285, 9.731857299804688, 12.948882102966309, 0.5290387272834778], step: 134200, lr: 6.192291037558654e-05, reference_loss: 28.509294509887695
2024-01-02 22:02:37,086	44k	INFO	====> Epoch: 3835, cost 26.82 s
2024-01-02 22:03:03,438	44k	INFO	====> Epoch: 3836, cost 26.35 s
2024-01-02 22:03:29,993	44k	INFO	====> Epoch: 3837, cost 26.56 s
2024-01-02 22:03:56,355	44k	INFO	====> Epoch: 3838, cost 26.36 s
2024-01-02 22:04:22,747	44k	INFO	====> Epoch: 3839, cost 26.39 s
2024-01-02 22:04:49,150	44k	INFO	Train Epoch: 3840 [97%]
2024-01-02 22:04:49,150	44k	INFO	Losses: [1.9599337577819824, 2.768564462661743, 8.52741813659668, 13.466411590576172, 0.4745389521121979], step: 134400, lr: 6.188421823084718e-05, reference_loss: 27.196866989135742
2024-01-02 22:04:56,909	44k	INFO	Saving model and optimizer state at iteration 3840 to ./logs/44k/G_134400.pth
2024-01-02 22:04:57,806	44k	INFO	Saving model and optimizer state at iteration 3840 to ./logs/44k/D_134400.pth
2024-01-02 22:04:58,583	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_132000.pth
2024-01-02 22:04:58,640	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_132000.pth
2024-01-02 22:04:58,641	44k	INFO	====> Epoch: 3840, cost 35.89 s
2024-01-02 22:05:25,123	44k	INFO	====> Epoch: 3841, cost 26.48 s
2024-01-02 22:05:51,434	44k	INFO	====> Epoch: 3842, cost 26.31 s
2024-01-02 22:06:18,087	44k	INFO	====> Epoch: 3843, cost 26.65 s
2024-01-02 22:06:44,316	44k	INFO	====> Epoch: 3844, cost 26.23 s
2024-01-02 22:07:10,674	44k	INFO	====> Epoch: 3845, cost 26.36 s
2024-01-02 22:07:29,486	44k	INFO	Train Epoch: 3846 [69%]
2024-01-02 22:07:29,487	44k	INFO	Losses: [2.0573318004608154, 2.8935344219207764, 12.03378963470459, 15.335338592529297, 0.6057314276695251], step: 134600, lr: 6.183781956887054e-05, reference_loss: 32.925724029541016
2024-01-02 22:07:37,561	44k	INFO	====> Epoch: 3846, cost 26.89 s
2024-01-02 22:08:03,957	44k	INFO	====> Epoch: 3847, cost 26.40 s
2024-01-02 22:08:30,168	44k	INFO	====> Epoch: 3848, cost 26.21 s
2024-01-02 22:08:56,544	44k	INFO	====> Epoch: 3849, cost 26.38 s
2024-01-02 22:09:23,049	44k	INFO	====> Epoch: 3850, cost 26.50 s
2024-01-02 22:09:49,590	44k	INFO	====> Epoch: 3851, cost 26.54 s
2024-01-02 22:10:00,840	44k	INFO	Train Epoch: 3852 [40%]
2024-01-02 22:10:00,840	44k	INFO	Losses: [2.229997158050537, 2.7728307247161865, 10.670451164245605, 16.371089935302734, 0.39602988958358765], step: 134800, lr: 6.179145569501752e-05, reference_loss: 32.440399169921875
2024-01-02 22:10:16,512	44k	INFO	====> Epoch: 3852, cost 26.92 s
2024-01-02 22:10:42,923	44k	INFO	====> Epoch: 3853, cost 26.41 s
2024-01-02 22:11:09,272	44k	INFO	====> Epoch: 3854, cost 26.35 s
2024-01-02 22:11:35,600	44k	INFO	====> Epoch: 3855, cost 26.33 s
2024-01-02 22:12:01,965	44k	INFO	====> Epoch: 3856, cost 26.36 s
2024-01-02 22:12:28,297	44k	INFO	====> Epoch: 3857, cost 26.33 s
2024-01-02 22:12:32,055	44k	INFO	Train Epoch: 3858 [11%]
2024-01-02 22:12:32,056	44k	INFO	Losses: [1.8400115966796875, 3.07206392288208, 10.881940841674805, 15.539266586303711, 0.35239067673683167], step: 135000, lr: 6.174512658320517e-05, reference_loss: 31.685672760009766
2024-01-02 22:12:55,458	44k	INFO	====> Epoch: 3858, cost 27.16 s
2024-01-02 22:13:21,714	44k	INFO	====> Epoch: 3859, cost 26.26 s
2024-01-02 22:13:47,898	44k	INFO	====> Epoch: 3860, cost 26.18 s
2024-01-02 22:14:14,256	44k	INFO	====> Epoch: 3861, cost 26.36 s
2024-01-02 22:14:40,547	44k	INFO	====> Epoch: 3862, cost 26.29 s
2024-01-02 22:15:03,144	44k	INFO	Train Epoch: 3863 [83%]
2024-01-02 22:15:03,145	44k	INFO	Losses: [2.4257311820983887, 2.3322229385375977, 9.504343032836914, 14.39103889465332, 0.5502371191978455], step: 135200, lr: 6.170654552556078e-05, reference_loss: 29.20357322692871
2024-01-02 22:15:10,539	44k	INFO	Saving model and optimizer state at iteration 3863 to ./logs/44k/G_135200.pth
2024-01-02 22:15:11,775	44k	INFO	Saving model and optimizer state at iteration 3863 to ./logs/44k/D_135200.pth
2024-01-02 22:15:12,553	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_132800.pth
2024-01-02 22:15:12,610	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_132800.pth
2024-01-02 22:15:16,376	44k	INFO	====> Epoch: 3863, cost 35.83 s
2024-01-02 22:15:42,703	44k	INFO	====> Epoch: 3864, cost 26.33 s
2024-01-02 22:16:09,054	44k	INFO	====> Epoch: 3865, cost 26.35 s
2024-01-02 22:16:35,341	44k	INFO	====> Epoch: 3866, cost 26.29 s
2024-01-02 22:17:01,644	44k	INFO	====> Epoch: 3867, cost 26.30 s
2024-01-02 22:17:27,886	44k	INFO	====> Epoch: 3868, cost 26.24 s
2024-01-02 22:17:42,769	44k	INFO	Train Epoch: 3869 [54%]
2024-01-02 22:17:42,769	44k	INFO	Losses: [1.5413408279418945, 3.716714859008789, 12.125815391540527, 14.72744369506836, 0.2378806173801422], step: 135400, lr: 6.166028007647802e-05, reference_loss: 32.34919357299805
2024-01-02 22:17:54,599	44k	INFO	====> Epoch: 3869, cost 26.71 s
2024-01-02 22:18:21,334	44k	INFO	====> Epoch: 3870, cost 26.73 s
2024-01-02 22:18:47,645	44k	INFO	====> Epoch: 3871, cost 26.31 s
2024-01-02 22:19:14,087	44k	INFO	====> Epoch: 3872, cost 26.44 s
2024-01-02 22:19:40,578	44k	INFO	====> Epoch: 3873, cost 26.49 s
2024-01-02 22:20:07,068	44k	INFO	====> Epoch: 3874, cost 26.49 s
2024-01-02 22:20:14,574	44k	INFO	Train Epoch: 3875 [26%]
2024-01-02 22:20:14,575	44k	INFO	Losses: [2.222339630126953, 2.612058162689209, 10.415719985961914, 17.28229522705078, 0.6828590035438538], step: 135600, lr: 6.161404931564041e-05, reference_loss: 33.21527099609375
2024-01-02 22:20:33,815	44k	INFO	====> Epoch: 3875, cost 26.75 s
2024-01-02 22:21:00,184	44k	INFO	====> Epoch: 3876, cost 26.37 s
2024-01-02 22:21:26,842	44k	INFO	====> Epoch: 3877, cost 26.66 s
2024-01-02 22:21:53,416	44k	INFO	====> Epoch: 3878, cost 26.57 s
2024-01-02 22:22:19,909	44k	INFO	====> Epoch: 3879, cost 26.49 s
2024-01-02 22:22:46,282	44k	INFO	Train Epoch: 3880 [97%]
2024-01-02 22:22:46,283	44k	INFO	Losses: [2.0896034240722656, 2.5641627311706543, 9.821390151977539, 16.04501724243164, 0.586266040802002], step: 135800, lr: 6.157555016081001e-05, reference_loss: 31.1064395904541
2024-01-02 22:22:46,784	44k	INFO	====> Epoch: 3880, cost 26.88 s
2024-01-02 22:23:13,219	44k	INFO	====> Epoch: 3881, cost 26.43 s
2024-01-02 22:23:39,584	44k	INFO	====> Epoch: 3882, cost 26.37 s
2024-01-02 22:24:05,933	44k	INFO	====> Epoch: 3883, cost 26.35 s
2024-01-02 22:24:32,617	44k	INFO	====> Epoch: 3884, cost 26.68 s
2024-01-02 22:24:59,103	44k	INFO	====> Epoch: 3885, cost 26.49 s
2024-01-02 22:25:17,890	44k	INFO	Train Epoch: 3886 [69%]
2024-01-02 22:25:17,891	44k	INFO	Losses: [1.6422648429870605, 4.361417293548584, 12.415613174438477, 13.997314453125, 0.5436182618141174], step: 136000, lr: 6.152938292755391e-05, reference_loss: 32.960227966308594
2024-01-02 22:25:25,416	44k	INFO	Saving model and optimizer state at iteration 3886 to ./logs/44k/G_136000.pth
2024-01-02 22:25:26,313	44k	INFO	Saving model and optimizer state at iteration 3886 to ./logs/44k/D_136000.pth
2024-01-02 22:25:27,093	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_133600.pth
2024-01-02 22:25:27,150	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_133600.pth
2024-01-02 22:25:34,757	44k	INFO	====> Epoch: 3886, cost 35.65 s
2024-01-02 22:26:01,208	44k	INFO	====> Epoch: 3887, cost 26.45 s
2024-01-02 22:26:27,710	44k	INFO	====> Epoch: 3888, cost 26.50 s
2024-01-02 22:26:54,136	44k	INFO	====> Epoch: 3889, cost 26.43 s
2024-01-02 22:27:20,926	44k	INFO	====> Epoch: 3890, cost 26.79 s
2024-01-02 22:27:47,373	44k	INFO	====> Epoch: 3891, cost 26.45 s
2024-01-02 22:27:58,597	44k	INFO	Train Epoch: 3892 [40%]
2024-01-02 22:27:58,598	44k	INFO	Losses: [2.3065452575683594, 2.416614532470703, 9.998554229736328, 16.407873153686523, 0.3534483015537262], step: 136200, lr: 6.148325030890408e-05, reference_loss: 31.483036041259766
2024-01-02 22:28:14,337	44k	INFO	====> Epoch: 3892, cost 26.96 s
2024-01-02 22:28:40,728	44k	INFO	====> Epoch: 3893, cost 26.39 s
2024-01-02 22:29:07,089	44k	INFO	====> Epoch: 3894, cost 26.36 s
2024-01-02 22:29:33,547	44k	INFO	====> Epoch: 3895, cost 26.46 s
2024-01-02 22:29:59,998	44k	INFO	====> Epoch: 3896, cost 26.45 s
2024-01-02 22:30:26,434	44k	INFO	====> Epoch: 3897, cost 26.44 s
2024-01-02 22:30:30,199	44k	INFO	Train Epoch: 3898 [11%]
2024-01-02 22:30:30,200	44k	INFO	Losses: [1.7905199527740479, 3.0553197860717773, 11.969850540161133, 17.32838249206543, 0.36483073234558105], step: 136400, lr: 6.14371522789077e-05, reference_loss: 34.50890350341797
2024-01-02 22:30:53,640	44k	INFO	====> Epoch: 3898, cost 27.21 s
2024-01-02 22:31:19,967	44k	INFO	====> Epoch: 3899, cost 26.33 s
2024-01-02 22:31:46,346	44k	INFO	====> Epoch: 3900, cost 26.38 s
2024-01-02 22:32:12,610	44k	INFO	====> Epoch: 3901, cost 26.26 s
2024-01-02 22:32:39,037	44k	INFO	====> Epoch: 3902, cost 26.43 s
2024-01-02 22:33:01,647	44k	INFO	Train Epoch: 3903 [83%]
2024-01-02 22:33:01,648	44k	INFO	Losses: [2.044144630432129, 2.7811474800109863, 10.571304321289062, 15.619664192199707, 0.5487105846405029], step: 136600, lr: 6.139876365708857e-05, reference_loss: 31.564971923828125
2024-01-02 22:33:05,929	44k	INFO	====> Epoch: 3903, cost 26.89 s
2024-01-02 22:33:32,748	44k	INFO	====> Epoch: 3904, cost 26.82 s
2024-01-02 22:33:59,090	44k	INFO	====> Epoch: 3905, cost 26.34 s
2024-01-02 22:34:25,230	44k	INFO	====> Epoch: 3906, cost 26.14 s
2024-01-02 22:34:51,642	44k	INFO	====> Epoch: 3907, cost 26.41 s
2024-01-02 22:35:18,153	44k	INFO	====> Epoch: 3908, cost 26.51 s
2024-01-02 22:35:33,202	44k	INFO	Train Epoch: 3909 [54%]
2024-01-02 22:35:33,202	44k	INFO	Losses: [2.3205795288085938, 2.5155436992645264, 11.530917167663574, 15.854681968688965, 0.6186342239379883], step: 136800, lr: 6.135272897228282e-05, reference_loss: 32.840354919433594
2024-01-02 22:35:40,914	44k	INFO	Saving model and optimizer state at iteration 3909 to ./logs/44k/G_136800.pth
2024-01-02 22:35:41,805	44k	INFO	Saving model and optimizer state at iteration 3909 to ./logs/44k/D_136800.pth
2024-01-02 22:35:42,589	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_134400.pth
2024-01-02 22:35:42,647	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_134400.pth
2024-01-02 22:35:54,384	44k	INFO	====> Epoch: 3909, cost 36.23 s
2024-01-02 22:36:20,901	44k	INFO	====> Epoch: 3910, cost 26.52 s
2024-01-02 22:36:47,383	44k	INFO	====> Epoch: 3911, cost 26.48 s
2024-01-02 22:37:13,852	44k	INFO	====> Epoch: 3912, cost 26.47 s
2024-01-02 22:37:40,319	44k	INFO	====> Epoch: 3913, cost 26.47 s
2024-01-02 22:38:06,797	44k	INFO	====> Epoch: 3914, cost 26.48 s
2024-01-02 22:38:14,259	44k	INFO	Train Epoch: 3915 [26%]
2024-01-02 22:38:14,260	44k	INFO	Losses: [2.313894748687744, 2.949436902999878, 9.606062889099121, 15.721346855163574, 0.6054638624191284], step: 137000, lr: 6.130672880270308e-05, reference_loss: 31.196203231811523
2024-01-02 22:38:33,439	44k	INFO	====> Epoch: 3915, cost 26.64 s
2024-01-02 22:38:59,716	44k	INFO	====> Epoch: 3916, cost 26.28 s
2024-01-02 22:39:25,856	44k	INFO	====> Epoch: 3917, cost 26.14 s
2024-01-02 22:39:52,604	44k	INFO	====> Epoch: 3918, cost 26.75 s
2024-01-02 22:40:19,060	44k	INFO	====> Epoch: 3919, cost 26.46 s
2024-01-02 22:40:45,305	44k	INFO	Train Epoch: 3920 [97%]
2024-01-02 22:40:45,306	44k	INFO	Losses: [2.1169261932373047, 3.274073362350464, 9.583681106567383, 15.746110916137695, 0.3737621307373047], step: 137200, lr: 6.126842167518043e-05, reference_loss: 31.094552993774414
2024-01-02 22:40:45,796	44k	INFO	====> Epoch: 3920, cost 26.74 s
2024-01-02 22:41:12,125	44k	INFO	====> Epoch: 3921, cost 26.33 s
2024-01-02 22:41:38,501	44k	INFO	====> Epoch: 3922, cost 26.38 s
2024-01-02 22:42:04,785	44k	INFO	====> Epoch: 3923, cost 26.28 s
2024-01-02 22:42:31,220	44k	INFO	====> Epoch: 3924, cost 26.44 s
2024-01-02 22:42:57,685	44k	INFO	====> Epoch: 3925, cost 26.46 s
2024-01-02 22:43:16,841	44k	INFO	Train Epoch: 3926 [69%]
2024-01-02 22:43:16,841	44k	INFO	Losses: [2.0568673610687256, 3.0393710136413574, 10.043126106262207, 14.127285957336426, 0.5301086902618408], step: 137400, lr: 6.122248471631729e-05, reference_loss: 29.79676055908203
2024-01-02 22:43:24,957	44k	INFO	====> Epoch: 3926, cost 27.27 s
2024-01-02 22:43:51,354	44k	INFO	====> Epoch: 3927, cost 26.40 s
2024-01-02 22:44:17,761	44k	INFO	====> Epoch: 3928, cost 26.41 s
2024-01-02 22:44:44,253	44k	INFO	====> Epoch: 3929, cost 26.49 s
2024-01-02 22:45:10,663	44k	INFO	====> Epoch: 3930, cost 26.41 s
2024-01-02 22:45:37,156	44k	INFO	====> Epoch: 3931, cost 26.49 s
2024-01-02 22:45:48,428	44k	INFO	Train Epoch: 3932 [40%]
2024-01-02 22:45:48,428	44k	INFO	Losses: [2.1597237586975098, 2.98215389251709, 12.245729446411133, 17.075056076049805, 0.500970721244812], step: 137600, lr: 6.117658219940862e-05, reference_loss: 34.96363067626953
2024-01-02 22:45:56,556	44k	INFO	Saving model and optimizer state at iteration 3932 to ./logs/44k/G_137600.pth
2024-01-02 22:45:57,468	44k	INFO	Saving model and optimizer state at iteration 3932 to ./logs/44k/D_137600.pth
2024-01-02 22:45:58,260	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_135200.pth
2024-01-02 22:45:58,318	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_135200.pth
2024-01-02 22:46:13,529	44k	INFO	====> Epoch: 3932, cost 36.37 s
2024-01-02 22:46:40,023	44k	INFO	====> Epoch: 3933, cost 26.49 s
2024-01-02 22:47:06,506	44k	INFO	====> Epoch: 3934, cost 26.48 s
2024-01-02 22:47:32,794	44k	INFO	====> Epoch: 3935, cost 26.29 s
2024-01-02 22:47:59,164	44k	INFO	====> Epoch: 3936, cost 26.37 s
2024-01-02 22:48:25,604	44k	INFO	====> Epoch: 3937, cost 26.44 s
2024-01-02 22:48:29,385	44k	INFO	Train Epoch: 3938 [11%]
2024-01-02 22:48:29,386	44k	INFO	Losses: [2.075195550918579, 2.9810097217559814, 10.539202690124512, 15.035276412963867, 0.49391835927963257], step: 137800, lr: 6.113071409863102e-05, reference_loss: 31.124601364135742
2024-01-02 22:48:52,813	44k	INFO	====> Epoch: 3938, cost 27.21 s
2024-01-02 22:49:19,227	44k	INFO	====> Epoch: 3939, cost 26.41 s
2024-01-02 22:49:45,696	44k	INFO	====> Epoch: 3940, cost 26.47 s
2024-01-02 22:50:12,173	44k	INFO	====> Epoch: 3941, cost 26.48 s
2024-01-02 22:50:38,669	44k	INFO	====> Epoch: 3942, cost 26.50 s
2024-01-02 22:51:01,312	44k	INFO	Train Epoch: 3943 [83%]
2024-01-02 22:51:01,312	44k	INFO	Losses: [2.105426788330078, 2.787018060684204, 9.045248985290527, 15.737241744995117, 0.5210814476013184], step: 138000, lr: 6.109251695279955e-05, reference_loss: 30.196016311645508
2024-01-02 22:51:05,584	44k	INFO	====> Epoch: 3943, cost 26.91 s
2024-01-02 22:51:32,391	44k	INFO	====> Epoch: 3944, cost 26.81 s
2024-01-02 22:51:58,781	44k	INFO	====> Epoch: 3945, cost 26.39 s
2024-01-02 22:52:25,214	44k	INFO	====> Epoch: 3946, cost 26.43 s
2024-01-02 22:52:51,596	44k	INFO	====> Epoch: 3947, cost 26.38 s
2024-01-02 22:53:18,013	44k	INFO	====> Epoch: 3948, cost 26.42 s
2024-01-02 22:53:32,963	44k	INFO	Train Epoch: 3949 [54%]
2024-01-02 22:53:32,963	44k	INFO	Losses: [1.793562412261963, 3.3784027099609375, 12.127249717712402, 16.137495040893555, 0.4488399624824524], step: 138200, lr: 6.10467118812574e-05, reference_loss: 33.88555145263672
2024-01-02 22:53:44,817	44k	INFO	====> Epoch: 3949, cost 26.80 s
2024-01-02 22:54:11,251	44k	INFO	====> Epoch: 3950, cost 26.43 s
2024-01-02 22:54:38,059	44k	INFO	====> Epoch: 3951, cost 26.81 s
2024-01-02 22:55:04,536	44k	INFO	====> Epoch: 3952, cost 26.48 s
2024-01-02 22:55:31,007	44k	INFO	====> Epoch: 3953, cost 26.47 s
2024-01-02 22:55:57,467	44k	INFO	====> Epoch: 3954, cost 26.46 s
2024-01-02 22:56:04,953	44k	INFO	Train Epoch: 3955 [26%]
2024-01-02 22:56:04,954	44k	INFO	Losses: [2.0977044105529785, 3.3317511081695557, 10.681585311889648, 15.950746536254883, 0.4654574692249298], step: 138400, lr: 6.100094115278513e-05, reference_loss: 32.52724838256836
2024-01-02 22:56:12,631	44k	INFO	Saving model and optimizer state at iteration 3955 to ./logs/44k/G_138400.pth
2024-01-02 22:56:13,536	44k	INFO	Saving model and optimizer state at iteration 3955 to ./logs/44k/D_138400.pth
2024-01-02 22:56:14,321	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_136000.pth
2024-01-02 22:56:14,378	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_136000.pth
2024-01-02 22:56:33,184	44k	INFO	====> Epoch: 3955, cost 35.72 s
2024-01-02 22:56:59,466	44k	INFO	====> Epoch: 3956, cost 26.28 s
2024-01-02 22:57:26,173	44k	INFO	====> Epoch: 3957, cost 26.71 s
2024-01-02 22:57:52,579	44k	INFO	====> Epoch: 3958, cost 26.41 s
2024-01-02 22:58:19,014	44k	INFO	====> Epoch: 3959, cost 26.44 s
2024-01-02 22:58:45,452	44k	INFO	Train Epoch: 3960 [97%]
2024-01-02 22:58:45,453	44k	INFO	Losses: [2.138211250305176, 3.0586166381835938, 11.571348190307617, 17.268808364868164, 0.4131917953491211], step: 138600, lr: 6.096282509477033e-05, reference_loss: 34.45018005371094
2024-01-02 22:58:45,944	44k	INFO	====> Epoch: 3960, cost 26.93 s
2024-01-02 22:59:12,447	44k	INFO	====> Epoch: 3961, cost 26.50 s
2024-01-02 22:59:38,883	44k	INFO	====> Epoch: 3962, cost 26.44 s
2024-01-02 23:00:05,185	44k	INFO	====> Epoch: 3963, cost 26.30 s
2024-01-02 23:00:31,556	44k	INFO	====> Epoch: 3964, cost 26.37 s
2024-01-02 23:00:58,305	44k	INFO	====> Epoch: 3965, cost 26.75 s
2024-01-02 23:01:17,179	44k	INFO	Train Epoch: 3966 [69%]
2024-01-02 23:01:17,180	44k	INFO	Losses: [2.041588306427002, 3.5652365684509277, 12.306048393249512, 15.016996383666992, 0.6907098293304443], step: 138800, lr: 6.0917117261730226e-05, reference_loss: 33.62057876586914
2024-01-02 23:01:25,290	44k	INFO	====> Epoch: 3966, cost 26.98 s
2024-01-02 23:01:51,732	44k	INFO	====> Epoch: 3967, cost 26.44 s
2024-01-02 23:02:18,233	44k	INFO	====> Epoch: 3968, cost 26.50 s
2024-01-02 23:02:44,617	44k	INFO	====> Epoch: 3969, cost 26.38 s
2024-01-02 23:03:10,998	44k	INFO	====> Epoch: 3970, cost 26.38 s
2024-01-02 23:03:37,349	44k	INFO	====> Epoch: 3971, cost 26.35 s
2024-01-02 23:03:48,550	44k	INFO	Train Epoch: 3972 [40%]
2024-01-02 23:03:48,550	44k	INFO	Losses: [1.996382236480713, 3.2193334102630615, 10.03654956817627, 15.03670883178711, 0.6486929059028625], step: 139000, lr: 6.087144369885392e-05, reference_loss: 30.937667846679688
2024-01-02 23:04:04,520	44k	INFO	====> Epoch: 3972, cost 27.17 s
2024-01-02 23:04:30,854	44k	INFO	====> Epoch: 3973, cost 26.33 s
2024-01-02 23:04:57,257	44k	INFO	====> Epoch: 3974, cost 26.40 s
2024-01-02 23:05:23,642	44k	INFO	====> Epoch: 3975, cost 26.38 s
2024-01-02 23:05:50,080	44k	INFO	====> Epoch: 3976, cost 26.44 s
2024-01-02 23:06:16,534	44k	INFO	====> Epoch: 3977, cost 26.45 s
2024-01-02 23:06:20,303	44k	INFO	Train Epoch: 3978 [11%]
2024-01-02 23:06:20,303	44k	INFO	Losses: [2.581073760986328, 2.078550100326538, 8.013506889343262, 14.568340301513672, 0.6717715263366699], step: 139200, lr: 6.0825804380446814e-05, reference_loss: 27.91324234008789
2024-01-02 23:06:27,853	44k	INFO	Saving model and optimizer state at iteration 3978 to ./logs/44k/G_139200.pth
2024-01-02 23:06:29,087	44k	INFO	Saving model and optimizer state at iteration 3978 to ./logs/44k/D_139200.pth
2024-01-02 23:06:29,855	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_136800.pth
2024-01-02 23:06:29,912	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_136800.pth
2024-01-02 23:06:52,554	44k	INFO	====> Epoch: 3978, cost 36.02 s
2024-01-02 23:07:18,954	44k	INFO	====> Epoch: 3979, cost 26.40 s
2024-01-02 23:07:45,471	44k	INFO	====> Epoch: 3980, cost 26.52 s
2024-01-02 23:08:11,871	44k	INFO	====> Epoch: 3981, cost 26.40 s
2024-01-02 23:08:38,179	44k	INFO	====> Epoch: 3982, cost 26.31 s
2024-01-02 23:09:00,840	44k	INFO	Train Epoch: 3983 [83%]
2024-01-02 23:09:00,841	44k	INFO	Losses: [1.608788251876831, 3.770772695541382, 11.61923885345459, 14.488985061645508, 0.36161673069000244], step: 139400, lr: 6.078779775555303e-05, reference_loss: 31.849401473999023
2024-01-02 23:09:05,082	44k	INFO	====> Epoch: 3983, cost 26.90 s
2024-01-02 23:09:31,638	44k	INFO	====> Epoch: 3984, cost 26.56 s
2024-01-02 23:09:58,031	44k	INFO	====> Epoch: 3985, cost 26.39 s
2024-01-02 23:10:24,370	44k	INFO	====> Epoch: 3986, cost 26.34 s
2024-01-02 23:10:50,605	44k	INFO	====> Epoch: 3987, cost 26.23 s
2024-01-02 23:11:16,908	44k	INFO	====> Epoch: 3988, cost 26.30 s
2024-01-02 23:11:31,933	44k	INFO	Train Epoch: 3989 [54%]
2024-01-02 23:11:31,934	44k	INFO	Losses: [1.9425475597381592, 3.0867810249328613, 10.507317543029785, 15.549487113952637, 0.5835869312286377], step: 139600, lr: 6.0742221152002156e-05, reference_loss: 31.669719696044922
2024-01-02 23:11:43,812	44k	INFO	====> Epoch: 3989, cost 26.90 s
2024-01-02 23:12:10,110	44k	INFO	====> Epoch: 3990, cost 26.30 s
2024-01-02 23:12:36,693	44k	INFO	====> Epoch: 3991, cost 26.58 s
2024-01-02 23:13:03,102	44k	INFO	====> Epoch: 3992, cost 26.41 s
2024-01-02 23:13:29,516	44k	INFO	====> Epoch: 3993, cost 26.41 s
2024-01-02 23:13:56,015	44k	INFO	====> Epoch: 3994, cost 26.50 s
2024-01-02 23:14:03,561	44k	INFO	Train Epoch: 3995 [26%]
2024-01-02 23:14:03,562	44k	INFO	Losses: [2.1448168754577637, 2.896157741546631, 9.999903678894043, 14.692256927490234, 0.5266127586364746], step: 139800, lr: 6.0696678720223696e-05, reference_loss: 30.259748458862305
2024-01-02 23:14:23,146	44k	INFO	====> Epoch: 3995, cost 27.13 s
2024-01-02 23:14:49,593	44k	INFO	====> Epoch: 3996, cost 26.45 s
2024-01-02 23:15:16,040	44k	INFO	====> Epoch: 3997, cost 26.45 s
2024-01-02 23:15:42,498	44k	INFO	====> Epoch: 3998, cost 26.46 s
2024-01-02 23:16:09,257	44k	INFO	====> Epoch: 3999, cost 26.76 s
2024-01-02 23:16:35,648	44k	INFO	Train Epoch: 4000 [97%]
2024-01-02 23:16:35,648	44k	INFO	Losses: [2.166201114654541, 2.9790725708007812, 8.675684928894043, 14.82434368133545, 0.49704256653785706], step: 140000, lr: 6.0658752778694185e-05, reference_loss: 29.142343521118164
2024-01-02 23:16:43,198	44k	INFO	Saving model and optimizer state at iteration 4000 to ./logs/44k/G_140000.pth
2024-01-02 23:16:44,103	44k	INFO	Saving model and optimizer state at iteration 4000 to ./logs/44k/D_140000.pth
2024-01-02 23:16:44,885	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_137600.pth
2024-01-02 23:16:44,943	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_137600.pth
2024-01-02 23:16:44,944	44k	INFO	====> Epoch: 4000, cost 35.69 s
2024-01-02 23:17:11,153	44k	INFO	====> Epoch: 4001, cost 26.21 s
2024-01-02 23:17:37,451	44k	INFO	====> Epoch: 4002, cost 26.30 s
2024-01-02 23:18:03,710	44k	INFO	====> Epoch: 4003, cost 26.26 s
2024-01-02 23:18:30,462	44k	INFO	====> Epoch: 4004, cost 26.75 s
2024-01-02 23:18:56,902	44k	INFO	====> Epoch: 4005, cost 26.44 s
2024-01-02 23:19:15,632	44k	INFO	Train Epoch: 4006 [69%]
2024-01-02 23:19:15,633	44k	INFO	Losses: [2.1050658226013184, 2.978053092956543, 11.319101333618164, 15.15449333190918, 0.6468942761421204], step: 140200, lr: 6.0613272928636076e-05, reference_loss: 32.20360565185547
2024-01-02 23:19:23,660	44k	INFO	====> Epoch: 4006, cost 26.76 s
2024-01-02 23:19:50,097	44k	INFO	====> Epoch: 4007, cost 26.44 s
2024-01-02 23:20:16,530	44k	INFO	====> Epoch: 4008, cost 26.43 s
2024-01-02 23:20:42,993	44k	INFO	====> Epoch: 4009, cost 26.46 s
2024-01-02 23:21:09,424	44k	INFO	====> Epoch: 4010, cost 26.43 s
2024-01-02 23:21:35,870	44k	INFO	====> Epoch: 4011, cost 26.45 s
2024-01-02 23:21:47,163	44k	INFO	Train Epoch: 4012 [40%]
2024-01-02 23:21:47,164	44k	INFO	Losses: [2.2017266750335693, 2.6044905185699463, 10.580219268798828, 16.46198081970215, 0.4214136004447937], step: 140400, lr: 6.0567827177807944e-05, reference_loss: 32.269832611083984
2024-01-02 23:22:03,202	44k	INFO	====> Epoch: 4012, cost 27.33 s
2024-01-02 23:22:29,659	44k	INFO	====> Epoch: 4013, cost 26.46 s
2024-01-02 23:22:55,892	44k	INFO	====> Epoch: 4014, cost 26.23 s
2024-01-02 23:23:22,297	44k	INFO	====> Epoch: 4015, cost 26.40 s
2024-01-02 23:23:48,653	44k	INFO	====> Epoch: 4016, cost 26.36 s
2024-01-02 23:24:14,972	44k	INFO	====> Epoch: 4017, cost 26.32 s
2024-01-02 23:24:18,709	44k	INFO	Train Epoch: 4018 [11%]
2024-01-02 23:24:18,709	44k	INFO	Losses: [1.8305033445358276, 3.1694812774658203, 11.193559646606445, 15.491448402404785, 0.3249953091144562], step: 140600, lr: 6.052241550064335e-05, reference_loss: 32.00999069213867
2024-01-02 23:24:42,013	44k	INFO	====> Epoch: 4018, cost 27.04 s
2024-01-02 23:25:08,356	44k	INFO	====> Epoch: 4019, cost 26.34 s
2024-01-02 23:25:34,767	44k	INFO	====> Epoch: 4020, cost 26.41 s
2024-01-02 23:26:01,207	44k	INFO	====> Epoch: 4021, cost 26.44 s
2024-01-02 23:26:27,407	44k	INFO	====> Epoch: 4022, cost 26.20 s
2024-01-02 23:26:49,963	44k	INFO	Train Epoch: 4023 [83%]
2024-01-02 23:26:49,963	44k	INFO	Losses: [1.986612319946289, 2.905097723007202, 10.697381973266602, 14.124258041381836, 0.5557271242141724], step: 140800, lr: 6.0484598446400866e-05, reference_loss: 30.26907730102539
2024-01-02 23:26:57,559	44k	INFO	Saving model and optimizer state at iteration 4023 to ./logs/44k/G_140800.pth
2024-01-02 23:26:58,785	44k	INFO	Saving model and optimizer state at iteration 4023 to ./logs/44k/D_140800.pth
2024-01-02 23:26:59,554	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_138400.pth
2024-01-02 23:26:59,610	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_138400.pth
2024-01-02 23:27:03,393	44k	INFO	====> Epoch: 4023, cost 35.99 s
2024-01-02 23:27:29,774	44k	INFO	====> Epoch: 4024, cost 26.38 s
2024-01-02 23:27:56,144	44k	INFO	====> Epoch: 4025, cost 26.37 s
2024-01-02 23:28:22,402	44k	INFO	====> Epoch: 4026, cost 26.26 s
2024-01-02 23:28:48,739	44k	INFO	====> Epoch: 4027, cost 26.34 s
2024-01-02 23:29:15,168	44k	INFO	====> Epoch: 4028, cost 26.43 s
2024-01-02 23:29:30,149	44k	INFO	Train Epoch: 4029 [54%]
2024-01-02 23:29:30,150	44k	INFO	Losses: [2.107858180999756, 2.5923383235931396, 9.351106643676758, 14.579566955566406, 0.2483803778886795], step: 141000, lr: 6.043924917128135e-05, reference_loss: 28.87925148010254
2024-01-02 23:29:42,153	44k	INFO	====> Epoch: 4029, cost 26.98 s
2024-01-02 23:30:08,530	44k	INFO	====> Epoch: 4030, cost 26.38 s
2024-01-02 23:30:35,228	44k	INFO	====> Epoch: 4031, cost 26.70 s
2024-01-02 23:31:01,505	44k	INFO	====> Epoch: 4032, cost 26.28 s
2024-01-02 23:31:27,900	44k	INFO	====> Epoch: 4033, cost 26.39 s
2024-01-02 23:31:54,196	44k	INFO	====> Epoch: 4034, cost 26.30 s
2024-01-02 23:32:01,665	44k	INFO	Train Epoch: 4035 [26%]
2024-01-02 23:32:01,666	44k	INFO	Losses: [2.3858325481414795, 2.5166397094726562, 9.022305488586426, 15.608307838439941, 0.7366803884506226], step: 141200, lr: 6.039393389749121e-05, reference_loss: 30.269765853881836
2024-01-02 23:32:20,910	44k	INFO	====> Epoch: 4035, cost 26.71 s
2024-01-02 23:32:47,254	44k	INFO	====> Epoch: 4036, cost 26.34 s
2024-01-02 23:33:13,611	44k	INFO	====> Epoch: 4037, cost 26.36 s
2024-01-02 23:33:40,251	44k	INFO	====> Epoch: 4038, cost 26.64 s
2024-01-02 23:34:06,497	44k	INFO	====> Epoch: 4039, cost 26.25 s
2024-01-02 23:34:32,710	44k	INFO	Train Epoch: 4040 [97%]
2024-01-02 23:34:32,710	44k	INFO	Losses: [1.8724725246429443, 3.0700454711914062, 12.017126083374023, 17.7471866607666, 0.533628523349762], step: 141400, lr: 6.035619712417794e-05, reference_loss: 35.24046325683594
2024-01-02 23:34:33,342	44k	INFO	====> Epoch: 4040, cost 26.85 s
2024-01-02 23:34:59,666	44k	INFO	====> Epoch: 4041, cost 26.32 s
2024-01-02 23:35:26,077	44k	INFO	====> Epoch: 4042, cost 26.41 s
2024-01-02 23:35:52,520	44k	INFO	====> Epoch: 4043, cost 26.44 s
2024-01-02 23:36:18,947	44k	INFO	====> Epoch: 4044, cost 26.43 s
2024-01-02 23:36:45,750	44k	INFO	====> Epoch: 4045, cost 26.80 s
2024-01-02 23:37:04,602	44k	INFO	Train Epoch: 4046 [69%]
2024-01-02 23:37:04,603	44k	INFO	Losses: [2.4276351928710938, 3.0810511112213135, 9.497024536132812, 12.636552810668945, 0.5352474451065063], step: 141600, lr: 6.031094411996105e-05, reference_loss: 28.17751121520996
2024-01-02 23:37:12,361	44k	INFO	Saving model and optimizer state at iteration 4046 to ./logs/44k/G_141600.pth
2024-01-02 23:37:13,263	44k	INFO	Saving model and optimizer state at iteration 4046 to ./logs/44k/D_141600.pth
2024-01-02 23:37:14,030	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_139200.pth
2024-01-02 23:37:14,087	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_139200.pth
2024-01-02 23:37:21,715	44k	INFO	====> Epoch: 4046, cost 35.97 s
2024-01-02 23:37:48,159	44k	INFO	====> Epoch: 4047, cost 26.44 s
2024-01-02 23:38:14,565	44k	INFO	====> Epoch: 4048, cost 26.41 s
2024-01-02 23:38:40,934	44k	INFO	====> Epoch: 4049, cost 26.37 s
2024-01-02 23:39:07,274	44k	INFO	====> Epoch: 4050, cost 26.34 s
2024-01-02 23:39:34,008	44k	INFO	====> Epoch: 4051, cost 26.73 s
2024-01-02 23:39:45,264	44k	INFO	Train Epoch: 4052 [40%]
2024-01-02 23:39:45,264	44k	INFO	Losses: [2.0981171131134033, 2.660874128341675, 10.682881355285645, 16.54942512512207, 0.32000672817230225], step: 141800, lr: 6.026572504489291e-05, reference_loss: 32.31130599975586
2024-01-02 23:40:01,051	44k	INFO	====> Epoch: 4052, cost 27.04 s
2024-01-02 23:40:27,373	44k	INFO	====> Epoch: 4053, cost 26.32 s
2024-01-02 23:40:53,679	44k	INFO	====> Epoch: 4054, cost 26.31 s
2024-01-02 23:41:20,062	44k	INFO	====> Epoch: 4055, cost 26.38 s
2024-01-02 23:41:46,556	44k	INFO	====> Epoch: 4056, cost 26.49 s
2024-01-02 23:42:12,909	44k	INFO	====> Epoch: 4057, cost 26.35 s
2024-01-02 23:42:16,654	44k	INFO	Train Epoch: 4058 [11%]
2024-01-02 23:42:16,655	44k	INFO	Losses: [2.274019956588745, 2.495302200317383, 9.9346923828125, 16.73689079284668, 0.3872206509113312], step: 142000, lr: 6.022053987353462e-05, reference_loss: 31.828126907348633
2024-01-02 23:42:40,072	44k	INFO	====> Epoch: 4058, cost 27.16 s
2024-01-02 23:43:06,419	44k	INFO	====> Epoch: 4059, cost 26.35 s
2024-01-02 23:43:32,847	44k	INFO	====> Epoch: 4060, cost 26.43 s
2024-01-02 23:43:59,257	44k	INFO	====> Epoch: 4061, cost 26.41 s
2024-01-02 23:44:25,570	44k	INFO	====> Epoch: 4062, cost 26.31 s
2024-01-02 23:44:48,179	44k	INFO	Train Epoch: 4063 [83%]
2024-01-02 23:44:48,179	44k	INFO	Losses: [1.9534542560577393, 2.7344374656677246, 10.944931030273438, 15.703912734985352, 0.5090346336364746], step: 142200, lr: 6.01829114443969e-05, reference_loss: 31.84576988220215
2024-01-02 23:44:52,432	44k	INFO	====> Epoch: 4063, cost 26.86 s
2024-01-02 23:45:19,081	44k	INFO	====> Epoch: 4064, cost 26.65 s
2024-01-02 23:45:45,354	44k	INFO	====> Epoch: 4065, cost 26.27 s
2024-01-02 23:46:11,708	44k	INFO	====> Epoch: 4066, cost 26.35 s
2024-01-02 23:46:37,935	44k	INFO	====> Epoch: 4067, cost 26.23 s
2024-01-02 23:47:04,345	44k	INFO	====> Epoch: 4068, cost 26.41 s
2024-01-02 23:47:19,334	44k	INFO	Train Epoch: 4069 [54%]
2024-01-02 23:47:19,334	44k	INFO	Losses: [2.0139174461364746, 2.978208065032959, 12.861734390258789, 16.01771354675293, 0.617935836315155], step: 142400, lr: 6.013778836383279e-05, reference_loss: 34.48950958251953
2024-01-02 23:47:26,874	44k	INFO	Saving model and optimizer state at iteration 4069 to ./logs/44k/G_142400.pth
2024-01-02 23:47:27,785	44k	INFO	Saving model and optimizer state at iteration 4069 to ./logs/44k/D_142400.pth
2024-01-02 23:47:28,579	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_140000.pth
2024-01-02 23:47:28,636	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_140000.pth
2024-01-02 23:47:39,982	44k	INFO	====> Epoch: 4069, cost 35.64 s
2024-01-02 23:48:06,581	44k	INFO	====> Epoch: 4070, cost 26.60 s
2024-01-02 23:48:32,925	44k	INFO	====> Epoch: 4071, cost 26.34 s
2024-01-02 23:48:59,298	44k	INFO	====> Epoch: 4072, cost 26.37 s
2024-01-02 23:49:25,674	44k	INFO	====> Epoch: 4073, cost 26.38 s
2024-01-02 23:49:51,955	44k	INFO	====> Epoch: 4074, cost 26.28 s
2024-01-02 23:49:59,468	44k	INFO	Train Epoch: 4075 [26%]
2024-01-02 23:49:59,469	44k	INFO	Losses: [2.1031100749969482, 2.9327950477600098, 10.131892204284668, 16.49799346923828, 0.5879704356193542], step: 142600, lr: 6.009269911500513e-05, reference_loss: 32.253761291503906
2024-01-02 23:50:18,872	44k	INFO	====> Epoch: 4075, cost 26.92 s
2024-01-02 23:50:45,368	44k	INFO	====> Epoch: 4076, cost 26.50 s
2024-01-02 23:51:11,873	44k	INFO	====> Epoch: 4077, cost 26.50 s
2024-01-02 23:51:38,292	44k	INFO	====> Epoch: 4078, cost 26.42 s
2024-01-02 23:52:04,979	44k	INFO	====> Epoch: 4079, cost 26.69 s
2024-01-02 23:52:31,342	44k	INFO	Train Epoch: 4080 [97%]
2024-01-02 23:52:31,342	44k	INFO	Losses: [2.0624747276306152, 2.987555742263794, 10.487836837768555, 16.20783042907715, 0.35415223240852356], step: 142800, lr: 6.005515056636887e-05, reference_loss: 32.099849700927734
2024-01-02 23:52:31,835	44k	INFO	====> Epoch: 4080, cost 26.86 s
2024-01-02 23:52:58,133	44k	INFO	====> Epoch: 4081, cost 26.30 s
2024-01-02 23:53:24,570	44k	INFO	====> Epoch: 4082, cost 26.44 s
2024-01-02 23:53:50,967	44k	INFO	====> Epoch: 4083, cost 26.40 s
2024-01-02 23:54:17,430	44k	INFO	====> Epoch: 4084, cost 26.46 s
2024-01-02 23:54:43,884	44k	INFO	====> Epoch: 4085, cost 26.45 s
2024-01-02 23:55:03,042	44k	INFO	Train Epoch: 4086 [69%]
2024-01-02 23:55:03,042	44k	INFO	Losses: [2.077218770980835, 3.119575023651123, 9.649201393127441, 13.812931060791016, 0.5276198983192444], step: 143000, lr: 6.001012327652431e-05, reference_loss: 29.186546325683594
2024-01-02 23:55:11,160	44k	INFO	====> Epoch: 4086, cost 27.28 s
2024-01-02 23:55:37,624	44k	INFO	====> Epoch: 4087, cost 26.46 s
2024-01-02 23:56:03,982	44k	INFO	====> Epoch: 4088, cost 26.36 s
2024-01-02 23:56:30,362	44k	INFO	====> Epoch: 4089, cost 26.38 s
2024-01-02 23:56:56,661	44k	INFO	====> Epoch: 4090, cost 26.30 s
2024-01-02 23:57:22,929	44k	INFO	====> Epoch: 4091, cost 26.27 s
2024-01-02 23:57:34,134	44k	INFO	Train Epoch: 4092 [40%]
2024-01-02 23:57:34,135	44k	INFO	Losses: [2.1350936889648438, 2.875891923904419, 12.173991203308105, 17.207202911376953, 0.46906620264053345], step: 143200, lr: 5.9965129746595615e-05, reference_loss: 34.86124801635742
2024-01-02 23:57:41,987	44k	INFO	Saving model and optimizer state at iteration 4092 to ./logs/44k/G_143200.pth
2024-01-02 23:57:42,899	44k	INFO	Saving model and optimizer state at iteration 4092 to ./logs/44k/D_143200.pth
2024-01-02 23:57:43,674	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_140800.pth
2024-01-02 23:57:43,731	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_140800.pth
2024-01-02 23:57:58,904	44k	INFO	====> Epoch: 4092, cost 35.97 s
2024-01-02 23:58:25,300	44k	INFO	====> Epoch: 4093, cost 26.40 s
2024-01-02 23:58:51,654	44k	INFO	====> Epoch: 4094, cost 26.35 s
2024-01-02 23:59:17,907	44k	INFO	====> Epoch: 4095, cost 26.25 s
2024-01-02 23:59:44,220	44k	INFO	====> Epoch: 4096, cost 26.31 s
2024-01-03 00:00:10,675	44k	INFO	====> Epoch: 4097, cost 26.45 s
2024-01-03 00:00:14,467	44k	INFO	Train Epoch: 4098 [11%]
2024-01-03 00:00:14,468	44k	INFO	Losses: [1.9309971332550049, 3.4937095642089844, 10.89773178100586, 14.89876937866211, 0.5026628971099854], step: 143400, lr: 5.9920169951270764e-05, reference_loss: 31.72386932373047
2024-01-03 00:00:37,886	44k	INFO	====> Epoch: 4098, cost 27.21 s
2024-01-03 00:01:04,318	44k	INFO	====> Epoch: 4099, cost 26.43 s
2024-01-03 00:01:30,711	44k	INFO	====> Epoch: 4100, cost 26.39 s
2024-01-03 00:01:57,037	44k	INFO	====> Epoch: 4101, cost 26.33 s
2024-01-03 00:02:23,338	44k	INFO	====> Epoch: 4102, cost 26.30 s
2024-01-03 00:02:45,857	44k	INFO	Train Epoch: 4103 [83%]
2024-01-03 00:02:45,857	44k	INFO	Losses: [2.3711154460906982, 2.783731460571289, 8.827332496643066, 16.2296199798584, 0.5930193662643433], step: 143600, lr: 5.988272920640752e-05, reference_loss: 30.804819107055664
2024-01-03 00:02:50,131	44k	INFO	====> Epoch: 4103, cost 26.79 s
2024-01-03 00:03:16,455	44k	INFO	====> Epoch: 4104, cost 26.32 s
2024-01-03 00:03:43,041	44k	INFO	====> Epoch: 4105, cost 26.59 s
2024-01-03 00:04:09,433	44k	INFO	====> Epoch: 4106, cost 26.39 s
2024-01-03 00:04:35,847	44k	INFO	====> Epoch: 4107, cost 26.41 s
2024-01-03 00:05:02,301	44k	INFO	====> Epoch: 4108, cost 26.45 s
2024-01-03 00:05:17,344	44k	INFO	Train Epoch: 4109 [54%]
2024-01-03 00:05:17,345	44k	INFO	Losses: [2.274033784866333, 2.477304458618164, 10.46179485321045, 16.368162155151367, 0.4758618175983429], step: 143800, lr: 5.98378311921784e-05, reference_loss: 32.05715560913086
2024-01-03 00:05:29,415	44k	INFO	====> Epoch: 4109, cost 27.11 s
2024-01-03 00:05:55,864	44k	INFO	====> Epoch: 4110, cost 26.45 s
2024-01-03 00:06:22,137	44k	INFO	====> Epoch: 4111, cost 26.27 s
2024-01-03 00:06:48,706	44k	INFO	====> Epoch: 4112, cost 26.57 s
2024-01-03 00:07:15,093	44k	INFO	====> Epoch: 4113, cost 26.39 s
2024-01-03 00:07:41,381	44k	INFO	====> Epoch: 4114, cost 26.29 s
2024-01-03 00:07:48,853	44k	INFO	Train Epoch: 4115 [26%]
2024-01-03 00:07:48,853	44k	INFO	Losses: [2.1883394718170166, 3.0080747604370117, 10.533327102661133, 15.977396965026855, 0.42892664670944214], step: 144000, lr: 5.9792966840938744e-05, reference_loss: 32.13606643676758
2024-01-03 00:07:56,499	44k	INFO	Saving model and optimizer state at iteration 4115 to ./logs/44k/G_144000.pth
2024-01-03 00:07:57,390	44k	INFO	Saving model and optimizer state at iteration 4115 to ./logs/44k/D_144000.pth
2024-01-03 00:07:58,161	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_141600.pth
2024-01-03 00:07:58,219	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_141600.pth
2024-01-03 00:08:17,081	44k	INFO	====> Epoch: 4115, cost 35.70 s
2024-01-03 00:08:43,482	44k	INFO	====> Epoch: 4116, cost 26.40 s
2024-01-03 00:09:10,271	44k	INFO	====> Epoch: 4117, cost 26.79 s
2024-01-03 00:09:36,742	44k	INFO	====> Epoch: 4118, cost 26.47 s
2024-01-03 00:10:03,191	44k	INFO	====> Epoch: 4119, cost 26.45 s
2024-01-03 00:10:29,417	44k	INFO	Train Epoch: 4120 [97%]
2024-01-03 00:10:29,417	44k	INFO	Losses: [1.8814321756362915, 3.6478774547576904, 13.068379402160645, 16.387327194213867, 0.380630224943161], step: 144200, lr: 5.975560557814646e-05, reference_loss: 35.36564636230469
2024-01-03 00:10:29,926	44k	INFO	====> Epoch: 4120, cost 26.74 s
2024-01-03 00:10:56,181	44k	INFO	====> Epoch: 4121, cost 26.25 s
2024-01-03 00:11:22,514	44k	INFO	====> Epoch: 4122, cost 26.33 s
2024-01-03 00:11:48,829	44k	INFO	====> Epoch: 4123, cost 26.31 s
2024-01-03 00:12:15,299	44k	INFO	====> Epoch: 4124, cost 26.47 s
2024-01-03 00:12:41,636	44k	INFO	====> Epoch: 4125, cost 26.34 s
2024-01-03 00:13:00,591	44k	INFO	Train Epoch: 4126 [69%]
2024-01-03 00:13:00,592	44k	INFO	Losses: [2.142561435699463, 2.7973849773406982, 10.735940933227539, 13.36700439453125, 0.6725229620933533], step: 144400, lr: 5.97108028768489e-05, reference_loss: 29.715415954589844
2024-01-03 00:13:08,646	44k	INFO	====> Epoch: 4126, cost 27.01 s
2024-01-03 00:13:35,006	44k	INFO	====> Epoch: 4127, cost 26.36 s
2024-01-03 00:14:01,345	44k	INFO	====> Epoch: 4128, cost 26.34 s
2024-01-03 00:14:27,664	44k	INFO	====> Epoch: 4129, cost 26.32 s
2024-01-03 00:14:54,072	44k	INFO	====> Epoch: 4130, cost 26.41 s
2024-01-03 00:15:20,520	44k	INFO	====> Epoch: 4131, cost 26.45 s
2024-01-03 00:15:31,792	44k	INFO	Train Epoch: 4132 [40%]
2024-01-03 00:15:31,793	44k	INFO	Losses: [2.0312087535858154, 3.048630714416504, 10.222548484802246, 14.764453887939453, 0.663121223449707], step: 144600, lr: 5.966603376707844e-05, reference_loss: 30.729961395263672
2024-01-03 00:15:47,778	44k	INFO	====> Epoch: 4132, cost 27.26 s
2024-01-03 00:16:14,158	44k	INFO	====> Epoch: 4133, cost 26.38 s
2024-01-03 00:16:40,472	44k	INFO	====> Epoch: 4134, cost 26.31 s
2024-01-03 00:17:06,879	44k	INFO	====> Epoch: 4135, cost 26.41 s
2024-01-03 00:17:33,373	44k	INFO	====> Epoch: 4136, cost 26.49 s
2024-01-03 00:17:59,883	44k	INFO	====> Epoch: 4137, cost 26.51 s
2024-01-03 00:18:03,686	44k	INFO	Train Epoch: 4138 [11%]
2024-01-03 00:18:03,686	44k	INFO	Losses: [2.467085361480713, 2.1178159713745117, 7.99810791015625, 14.096356391906738, 0.7101354598999023], step: 144800, lr: 5.96212982236493e-05, reference_loss: 27.389503479003906
2024-01-03 00:18:11,235	44k	INFO	Saving model and optimizer state at iteration 4138 to ./logs/44k/G_144800.pth
2024-01-03 00:18:12,489	44k	INFO	Saving model and optimizer state at iteration 4138 to ./logs/44k/D_144800.pth
2024-01-03 00:18:13,252	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_142400.pth
2024-01-03 00:18:13,309	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_142400.pth
2024-01-03 00:18:36,004	44k	INFO	====> Epoch: 4138, cost 36.12 s
2024-01-03 00:19:02,481	44k	INFO	====> Epoch: 4139, cost 26.48 s
2024-01-03 00:19:28,976	44k	INFO	====> Epoch: 4140, cost 26.50 s
2024-01-03 00:19:55,445	44k	INFO	====> Epoch: 4141, cost 26.47 s
2024-01-03 00:20:21,925	44k	INFO	====> Epoch: 4142, cost 26.48 s
2024-01-03 00:20:44,598	44k	INFO	Train Epoch: 4143 [83%]
2024-01-03 00:20:44,599	44k	INFO	Losses: [2.168503999710083, 2.5516951084136963, 8.298328399658203, 12.924542427062988, 0.3901764452457428], step: 145000, lr: 5.958404422692294e-05, reference_loss: 26.3332462310791
2024-01-03 00:20:49,019	44k	INFO	====> Epoch: 4143, cost 27.09 s
2024-01-03 00:21:15,505	44k	INFO	====> Epoch: 4144, cost 26.49 s
2024-01-03 00:21:42,192	44k	INFO	====> Epoch: 4145, cost 26.69 s
2024-01-03 00:22:08,385	44k	INFO	====> Epoch: 4146, cost 26.19 s
2024-01-03 00:22:34,804	44k	INFO	====> Epoch: 4147, cost 26.42 s
2024-01-03 00:23:01,155	44k	INFO	====> Epoch: 4148, cost 26.35 s
2024-01-03 00:23:16,112	44k	INFO	Train Epoch: 4149 [54%]
2024-01-03 00:23:16,112	44k	INFO	Losses: [1.983654499053955, 2.784637928009033, 10.064225196838379, 15.2093505859375, 0.5671926140785217], step: 145200, lr: 5.953937015643582e-05, reference_loss: 30.609060287475586
2024-01-03 00:23:27,967	44k	INFO	====> Epoch: 4149, cost 26.81 s
2024-01-03 00:23:54,287	44k	INFO	====> Epoch: 4150, cost 26.32 s
2024-01-03 00:24:20,641	44k	INFO	====> Epoch: 4151, cost 26.35 s
2024-01-03 00:24:47,397	44k	INFO	====> Epoch: 4152, cost 26.76 s
2024-01-03 00:25:13,828	44k	INFO	====> Epoch: 4153, cost 26.43 s
2024-01-03 00:25:40,222	44k	INFO	====> Epoch: 4154, cost 26.39 s
2024-01-03 00:25:47,741	44k	INFO	Train Epoch: 4155 [26%]
2024-01-03 00:25:47,742	44k	INFO	Losses: [2.2745234966278076, 2.5559797286987305, 10.101644515991211, 15.192381858825684, 0.49432602524757385], step: 145400, lr: 5.949472958103281e-05, reference_loss: 30.61885643005371
2024-01-03 00:26:07,010	44k	INFO	====> Epoch: 4155, cost 26.79 s
2024-01-03 00:26:33,411	44k	INFO	====> Epoch: 4156, cost 26.40 s
2024-01-03 00:26:59,773	44k	INFO	====> Epoch: 4157, cost 26.36 s
2024-01-03 00:27:26,180	44k	INFO	====> Epoch: 4158, cost 26.41 s
2024-01-03 00:27:52,747	44k	INFO	====> Epoch: 4159, cost 26.57 s
2024-01-03 00:28:19,265	44k	INFO	Train Epoch: 4160 [97%]
2024-01-03 00:28:19,266	44k	INFO	Losses: [1.9484347105026245, 3.111572027206421, 9.316129684448242, 14.489919662475586, 0.5265907049179077], step: 145600, lr: 5.945755466993421e-05, reference_loss: 29.39264678955078
2024-01-03 00:28:27,128	44k	INFO	Saving model and optimizer state at iteration 4160 to ./logs/44k/G_145600.pth
2024-01-03 00:28:28,042	44k	INFO	Saving model and optimizer state at iteration 4160 to ./logs/44k/D_145600.pth
2024-01-03 00:28:28,827	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_143200.pth
2024-01-03 00:28:28,884	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_143200.pth
2024-01-03 00:28:28,884	44k	INFO	====> Epoch: 4160, cost 36.14 s
2024-01-03 00:28:55,176	44k	INFO	====> Epoch: 4161, cost 26.29 s
2024-01-03 00:29:21,498	44k	INFO	====> Epoch: 4162, cost 26.32 s
2024-01-03 00:29:47,917	44k	INFO	====> Epoch: 4163, cost 26.42 s
2024-01-03 00:30:14,582	44k	INFO	====> Epoch: 4164, cost 26.66 s
2024-01-03 00:30:40,922	44k	INFO	====> Epoch: 4165, cost 26.34 s
2024-01-03 00:30:59,657	44k	INFO	Train Epoch: 4166 [69%]
2024-01-03 00:30:59,657	44k	INFO	Losses: [2.318754196166992, 2.5057802200317383, 9.419343948364258, 14.0267915725708, 0.6175619959831238], step: 145800, lr: 5.941297543697379e-05, reference_loss: 28.88823127746582
2024-01-03 00:31:07,743	44k	INFO	====> Epoch: 4166, cost 26.82 s
2024-01-03 00:31:33,999	44k	INFO	====> Epoch: 4167, cost 26.26 s
2024-01-03 00:32:00,455	44k	INFO	====> Epoch: 4168, cost 26.46 s
2024-01-03 00:32:26,880	44k	INFO	====> Epoch: 4169, cost 26.43 s
2024-01-03 00:32:53,078	44k	INFO	====> Epoch: 4170, cost 26.20 s
2024-01-03 00:33:19,417	44k	INFO	====> Epoch: 4171, cost 26.34 s
2024-01-03 00:33:30,567	44k	INFO	Train Epoch: 4172 [40%]
2024-01-03 00:33:30,568	44k	INFO	Losses: [2.3461501598358154, 2.605646848678589, 10.480096817016602, 16.294967651367188, 0.44704464077949524], step: 146000, lr: 5.936842962799156e-05, reference_loss: 32.17390823364258
2024-01-03 00:33:46,480	44k	INFO	====> Epoch: 4172, cost 27.06 s
2024-01-03 00:34:12,908	44k	INFO	====> Epoch: 4173, cost 26.43 s
2024-01-03 00:34:39,342	44k	INFO	====> Epoch: 4174, cost 26.43 s
2024-01-03 00:35:05,704	44k	INFO	====> Epoch: 4175, cost 26.36 s
2024-01-03 00:35:32,223	44k	INFO	====> Epoch: 4176, cost 26.52 s
2024-01-03 00:35:58,706	44k	INFO	====> Epoch: 4177, cost 26.48 s
2024-01-03 00:36:02,479	44k	INFO	Train Epoch: 4178 [11%]
2024-01-03 00:36:02,480	44k	INFO	Losses: [2.1760950088500977, 2.9031338691711426, 10.462395668029785, 15.172086715698242, 0.28422388434410095], step: 146200, lr: 5.9323917217927384e-05, reference_loss: 30.997934341430664
2024-01-03 00:36:25,958	44k	INFO	====> Epoch: 4178, cost 27.25 s
2024-01-03 00:36:52,416	44k	INFO	====> Epoch: 4179, cost 26.46 s
2024-01-03 00:37:18,855	44k	INFO	====> Epoch: 4180, cost 26.44 s
2024-01-03 00:37:45,205	44k	INFO	====> Epoch: 4181, cost 26.35 s
2024-01-03 00:38:11,688	44k	INFO	====> Epoch: 4182, cost 26.48 s
2024-01-03 00:38:34,239	44k	INFO	Train Epoch: 4183 [83%]
2024-01-03 00:38:34,239	44k	INFO	Losses: [2.0417630672454834, 2.9191856384277344, 11.148340225219727, 14.72751235961914, 0.5493089556694031], step: 146400, lr: 5.9286849037869634e-05, reference_loss: 31.386110305786133
2024-01-03 00:38:42,090	44k	INFO	Saving model and optimizer state at iteration 4183 to ./logs/44k/G_146400.pth
2024-01-03 00:38:42,997	44k	INFO	Saving model and optimizer state at iteration 4183 to ./logs/44k/D_146400.pth
2024-01-03 00:38:43,786	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_144000.pth
2024-01-03 00:38:43,844	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_144000.pth
2024-01-03 00:38:47,624	44k	INFO	====> Epoch: 4183, cost 35.94 s
2024-01-03 00:39:14,376	44k	INFO	====> Epoch: 4184, cost 26.75 s
2024-01-03 00:39:40,711	44k	INFO	====> Epoch: 4185, cost 26.34 s
2024-01-03 00:40:07,165	44k	INFO	====> Epoch: 4186, cost 26.45 s
2024-01-03 00:40:33,568	44k	INFO	====> Epoch: 4187, cost 26.40 s
2024-01-03 00:40:59,942	44k	INFO	====> Epoch: 4188, cost 26.37 s
2024-01-03 00:41:14,884	44k	INFO	Train Epoch: 4189 [54%]
2024-01-03 00:41:14,884	44k	INFO	Losses: [1.6091296672821045, 3.477027416229248, 10.855469703674316, 14.3627290725708, 0.285265177488327], step: 146600, lr: 5.9242397794130785e-05, reference_loss: 30.58962059020996
2024-01-03 00:41:26,824	44k	INFO	====> Epoch: 4189, cost 26.88 s
2024-01-03 00:41:53,115	44k	INFO	====> Epoch: 4190, cost 26.29 s
2024-01-03 00:42:19,530	44k	INFO	====> Epoch: 4191, cost 26.41 s
2024-01-03 00:42:45,912	44k	INFO	====> Epoch: 4192, cost 26.38 s
2024-01-03 00:43:12,618	44k	INFO	====> Epoch: 4193, cost 26.71 s
2024-01-03 00:43:38,866	44k	INFO	====> Epoch: 4194, cost 26.25 s
2024-01-03 00:43:46,386	44k	INFO	Train Epoch: 4195 [26%]
2024-01-03 00:43:46,386	44k	INFO	Losses: [2.155285120010376, 2.75228214263916, 11.642047882080078, 17.405914306640625, 0.7235165238380432], step: 146800, lr: 5.9197979878408214e-05, reference_loss: 34.679046630859375
2024-01-03 00:44:05,843	44k	INFO	====> Epoch: 4195, cost 26.98 s
2024-01-03 00:44:32,219	44k	INFO	====> Epoch: 4196, cost 26.38 s
2024-01-03 00:44:58,568	44k	INFO	====> Epoch: 4197, cost 26.35 s
2024-01-03 00:45:25,015	44k	INFO	====> Epoch: 4198, cost 26.45 s
2024-01-03 00:45:51,292	44k	INFO	====> Epoch: 4199, cost 26.28 s
2024-01-03 00:46:17,900	44k	INFO	Train Epoch: 4200 [97%]
2024-01-03 00:46:17,901	44k	INFO	Losses: [1.8898284435272217, 3.185849666595459, 12.71252155303955, 17.66340446472168, 0.6329168081283569], step: 147000, lr: 5.916099038951241e-05, reference_loss: 36.08452224731445
2024-01-03 00:46:18,406	44k	INFO	====> Epoch: 4200, cost 27.11 s
2024-01-03 00:46:44,628	44k	INFO	====> Epoch: 4201, cost 26.22 s
2024-01-03 00:47:10,941	44k	INFO	====> Epoch: 4202, cost 26.31 s
2024-01-03 00:47:37,195	44k	INFO	====> Epoch: 4203, cost 26.25 s
2024-01-03 00:48:03,514	44k	INFO	====> Epoch: 4204, cost 26.32 s
2024-01-03 00:48:29,988	44k	INFO	====> Epoch: 4205, cost 26.47 s
2024-01-03 00:48:48,871	44k	INFO	Train Epoch: 4206 [69%]
2024-01-03 00:48:48,872	44k	INFO	Losses: [1.8429659605026245, 3.5365424156188965, 10.301033973693848, 12.913643836975098, 0.5726947784423828], step: 147200, lr: 5.911663351026662e-05, reference_loss: 29.166879653930664
2024-01-03 00:48:56,839	44k	INFO	Saving model and optimizer state at iteration 4206 to ./logs/44k/G_147200.pth
2024-01-03 00:48:57,740	44k	INFO	Saving model and optimizer state at iteration 4206 to ./logs/44k/D_147200.pth
2024-01-03 00:48:58,528	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_144800.pth
2024-01-03 00:48:58,585	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_144800.pth
2024-01-03 00:49:06,121	44k	INFO	====> Epoch: 4206, cost 36.13 s
