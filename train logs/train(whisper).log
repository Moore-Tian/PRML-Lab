2024-01-01 18:40:41,827	44k	INFO	{'train': {'log_interval': 200, 'eval_interval': 800, 'seed': 1234, 'epochs': 10000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 19, 'fp16_run': False, 'half_type': 'fp16', 'lr_decay': 0.999875, 'segment_size': 10240, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0, 'use_sr': True, 'max_speclen': 512, 'port': '8001', 'keep_ckpts': 3, 'all_in_mem': True, 'vol_aug': False}, 'data': {'training_files': 'filelists/train.txt', 'validation_files': 'filelists/val.txt', 'max_wav_value': 32768.0, 'sampling_rate': 44100, 'filter_length': 2048, 'hop_length': 512, 'win_length': 2048, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': 22050, 'unit_interpolate_mode': 'nearest'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 1024, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4, 4], 'n_layers_q': 3, 'n_layers_trans_flow': 3, 'n_flow_layer': 4, 'use_spectral_norm': False, 'gin_channels': 1024, 'ssl_dim': 1024, 'n_speakers': 1, 'vocoder_name': 'nsf-hifigan', 'speech_encoder': 'whisper-ppg', 'speaker_embedding': False, 'vol_embedding': False, 'use_depthwise_conv': False, 'flow_share_parameter': False, 'use_automatic_f0_prediction': True, 'use_transformer_flow': False}, 'spk': {'Ganyu': 0}, 'model_dir': './logs/44k'}
2024-01-01 18:40:41,827	44k	WARNING	/mnt/workspace/so-vits-svc-4.1-Stable is not a git repository, therefore hash value comparison will be ignored.
2024-01-01 18:40:56,081	44k	INFO	Train Epoch: 1 [0%]
2024-01-01 18:40:56,084	44k	INFO	Losses: [5.951442718505859, 5.020297050476074, 2.5823006629943848, 117.99833679199219, 361.46771240234375], step: 0, lr: 0.0001, reference_loss: 493.02008056640625
2024-01-01 18:41:04,128	44k	INFO	Saving model and optimizer state at iteration 1 to ./logs/44k/G_0.pth
2024-01-01 18:41:06,903	44k	INFO	Saving model and optimizer state at iteration 1 to ./logs/44k/D_0.pth
2024-01-01 18:41:37,695	44k	INFO	====> Epoch: 1, cost 55.87 s
2024-01-01 18:42:00,388	44k	INFO	====> Epoch: 2, cost 22.69 s
2024-01-01 18:42:23,137	44k	INFO	====> Epoch: 3, cost 22.75 s
2024-01-01 18:42:46,032	44k	INFO	====> Epoch: 4, cost 22.90 s
2024-01-01 18:43:08,858	44k	INFO	====> Epoch: 5, cost 22.83 s
2024-01-01 18:43:31,702	44k	INFO	====> Epoch: 6, cost 22.84 s
2024-01-01 18:43:54,621	44k	INFO	====> Epoch: 7, cost 22.92 s
2024-01-01 18:44:11,549	44k	INFO	Train Epoch: 8 [69%]
2024-01-01 18:44:11,551	44k	INFO	Losses: [1.9820955991744995, 2.3903658390045166, 5.372044563293457, 53.19414138793945, 3.4488022327423096], step: 200, lr: 9.991253280566489e-05, reference_loss: 66.387451171875
2024-01-01 18:44:17,993	44k	INFO	====> Epoch: 8, cost 23.37 s
2024-01-01 18:44:41,153	44k	INFO	====> Epoch: 9, cost 23.16 s
2024-01-01 18:45:04,373	44k	INFO	====> Epoch: 10, cost 23.22 s
2024-01-01 18:45:27,425	44k	INFO	====> Epoch: 11, cost 23.05 s
2024-01-01 18:45:50,469	44k	INFO	====> Epoch: 12, cost 23.04 s
2024-01-01 18:46:13,389	44k	INFO	====> Epoch: 13, cost 22.92 s
2024-01-01 18:46:36,398	44k	INFO	====> Epoch: 14, cost 23.01 s
2024-01-01 18:46:59,524	44k	INFO	====> Epoch: 15, cost 23.13 s
2024-01-01 18:47:09,471	44k	INFO	Train Epoch: 16 [38%]
2024-01-01 18:47:09,473	44k	INFO	Losses: [1.2807831764221191, 3.9312503337860107, 8.066895484924316, 35.91986846923828, 2.0528295040130615], step: 400, lr: 9.981266397366609e-05, reference_loss: 51.25162887573242
2024-01-01 18:47:23,052	44k	INFO	====> Epoch: 16, cost 23.53 s
2024-01-01 18:47:46,099	44k	INFO	====> Epoch: 17, cost 23.05 s
2024-01-01 18:48:09,133	44k	INFO	====> Epoch: 18, cost 23.03 s
2024-01-01 18:48:32,113	44k	INFO	====> Epoch: 19, cost 22.98 s
2024-01-01 18:48:55,214	44k	INFO	====> Epoch: 20, cost 23.10 s
2024-01-01 18:49:18,139	44k	INFO	====> Epoch: 21, cost 22.93 s
2024-01-01 18:49:41,052	44k	INFO	====> Epoch: 22, cost 22.91 s
2024-01-01 18:50:03,878	44k	INFO	====> Epoch: 23, cost 22.83 s
2024-01-01 18:50:06,564	44k	INFO	Train Epoch: 24 [8%]
2024-01-01 18:50:06,567	44k	INFO	Losses: [1.6239262819290161, 3.267080307006836, 7.082605838775635, 38.04954528808594, 1.6829769611358643], step: 600, lr: 9.971289496681757e-05, reference_loss: 51.70613098144531
2024-01-01 18:50:27,293	44k	INFO	====> Epoch: 24, cost 23.42 s
2024-01-01 18:50:50,336	44k	INFO	====> Epoch: 25, cost 23.04 s
2024-01-01 18:51:13,377	44k	INFO	====> Epoch: 26, cost 23.04 s
2024-01-01 18:51:36,365	44k	INFO	====> Epoch: 27, cost 22.99 s
2024-01-01 18:51:59,375	44k	INFO	====> Epoch: 28, cost 23.01 s
2024-01-01 18:52:22,476	44k	INFO	====> Epoch: 29, cost 23.10 s
2024-01-01 18:52:45,651	44k	INFO	====> Epoch: 30, cost 23.17 s
2024-01-01 18:53:04,375	44k	INFO	Train Epoch: 31 [77%]
2024-01-01 18:53:04,377	44k	INFO	Losses: [1.3782827854156494, 3.7728209495544434, 8.726844787597656, 32.27392578125, 1.3707131147384644], step: 800, lr: 9.962567889519979e-05, reference_loss: 47.522586822509766
2024-01-01 18:53:10,506	44k	INFO	Saving model and optimizer state at iteration 31 to ./logs/44k/G_800.pth
2024-01-01 18:53:11,414	44k	INFO	Saving model and optimizer state at iteration 31 to ./logs/44k/D_800.pth
2024-01-01 18:53:16,138	44k	INFO	====> Epoch: 31, cost 30.49 s
2024-01-01 18:53:39,196	44k	INFO	====> Epoch: 32, cost 23.06 s
2024-01-01 18:54:02,234	44k	INFO	====> Epoch: 33, cost 23.04 s
2024-01-01 18:54:25,308	44k	INFO	====> Epoch: 34, cost 23.07 s
2024-01-01 18:54:48,232	44k	INFO	====> Epoch: 35, cost 22.92 s
2024-01-01 18:55:11,224	44k	INFO	====> Epoch: 36, cost 22.99 s
2024-01-01 18:55:34,339	44k	INFO	====> Epoch: 37, cost 23.11 s
2024-01-01 18:55:57,475	44k	INFO	====> Epoch: 38, cost 23.14 s
2024-01-01 18:56:09,081	44k	INFO	Train Epoch: 39 [46%]
2024-01-01 18:56:09,083	44k	INFO	Losses: [1.0846606492996216, 3.529782295227051, 9.51768970489502, 33.24101257324219, 0.9431332945823669], step: 1000, lr: 9.952609679164422e-05, reference_loss: 48.316280364990234
2024-01-01 18:56:20,949	44k	INFO	====> Epoch: 39, cost 23.47 s
2024-01-01 18:56:43,937	44k	INFO	====> Epoch: 40, cost 22.99 s
2024-01-01 18:57:07,045	44k	INFO	====> Epoch: 41, cost 23.11 s
2024-01-01 18:57:29,968	44k	INFO	====> Epoch: 42, cost 22.92 s
2024-01-01 18:57:52,928	44k	INFO	====> Epoch: 43, cost 22.96 s
2024-01-01 18:58:15,869	44k	INFO	====> Epoch: 44, cost 22.94 s
2024-01-01 18:58:38,849	44k	INFO	====> Epoch: 45, cost 22.98 s
2024-01-01 18:59:01,880	44k	INFO	====> Epoch: 46, cost 23.03 s
2024-01-01 18:59:06,402	44k	INFO	Train Epoch: 47 [15%]
2024-01-01 18:59:06,405	44k	INFO	Losses: [2.0676369667053223, 2.939206123352051, 6.169763565063477, 35.11162185668945, 0.7978337407112122], step: 1200, lr: 9.942661422663591e-05, reference_loss: 47.086063385009766
2024-01-01 18:59:25,492	44k	INFO	====> Epoch: 47, cost 23.61 s
2024-01-01 18:59:48,424	44k	INFO	====> Epoch: 48, cost 22.93 s
2024-01-01 19:00:11,362	44k	INFO	====> Epoch: 49, cost 22.94 s
2024-01-01 19:00:34,553	44k	INFO	====> Epoch: 50, cost 23.19 s
2024-01-01 19:00:57,518	44k	INFO	====> Epoch: 51, cost 22.96 s
2024-01-01 19:01:20,601	44k	INFO	====> Epoch: 52, cost 23.08 s
2024-01-01 19:01:43,767	44k	INFO	====> Epoch: 53, cost 23.17 s
2024-01-01 19:02:04,290	44k	INFO	Train Epoch: 54 [85%]
2024-01-01 19:02:04,292	44k	INFO	Losses: [2.316401243209839, 2.768512725830078, 4.548633575439453, 32.02968978881836, 0.9543330073356628], step: 1400, lr: 9.933964855674948e-05, reference_loss: 42.61757278442383
2024-01-01 19:02:07,236	44k	INFO	====> Epoch: 54, cost 23.47 s
2024-01-01 19:02:30,322	44k	INFO	====> Epoch: 55, cost 23.09 s
2024-01-01 19:02:53,624	44k	INFO	====> Epoch: 56, cost 23.30 s
2024-01-01 19:03:16,724	44k	INFO	====> Epoch: 57, cost 23.10 s
2024-01-01 19:03:39,823	44k	INFO	====> Epoch: 58, cost 23.10 s
2024-01-01 19:04:02,814	44k	INFO	====> Epoch: 59, cost 22.99 s
2024-01-01 19:04:25,908	44k	INFO	====> Epoch: 60, cost 23.09 s
2024-01-01 19:04:48,929	44k	INFO	====> Epoch: 61, cost 23.02 s
2024-01-01 19:05:02,393	44k	INFO	Train Epoch: 62 [54%]
2024-01-01 19:05:02,395	44k	INFO	Losses: [2.272905111312866, 2.3300371170043945, 4.407779216766357, 32.00288009643555, 0.649130642414093], step: 1600, lr: 9.924035235842533e-05, reference_loss: 41.66273498535156
2024-01-01 19:05:08,744	44k	INFO	Saving model and optimizer state at iteration 62 to ./logs/44k/G_1600.pth
2024-01-01 19:05:09,647	44k	INFO	Saving model and optimizer state at iteration 62 to ./logs/44k/D_1600.pth
2024-01-01 19:05:19,720	44k	INFO	====> Epoch: 62, cost 30.79 s
2024-01-01 19:05:43,058	44k	INFO	====> Epoch: 63, cost 23.34 s
2024-01-01 19:06:06,220	44k	INFO	====> Epoch: 64, cost 23.16 s
2024-01-01 19:06:29,191	44k	INFO	====> Epoch: 65, cost 22.97 s
2024-01-01 19:06:52,254	44k	INFO	====> Epoch: 66, cost 23.06 s
2024-01-01 19:07:15,368	44k	INFO	====> Epoch: 67, cost 23.11 s
2024-01-01 19:07:38,486	44k	INFO	====> Epoch: 68, cost 23.12 s
2024-01-01 19:08:01,598	44k	INFO	====> Epoch: 69, cost 23.11 s
2024-01-01 19:08:07,924	44k	INFO	Train Epoch: 70 [23%]
2024-01-01 19:08:07,926	44k	INFO	Losses: [2.4882240295410156, 2.3217785358428955, 3.1709420680999756, 29.4036865234375, 0.7628337740898132], step: 1800, lr: 9.914115541286833e-05, reference_loss: 38.147464752197266
2024-01-01 19:08:25,103	44k	INFO	====> Epoch: 70, cost 23.50 s
2024-01-01 19:08:48,201	44k	INFO	====> Epoch: 71, cost 23.10 s
2024-01-01 19:09:11,177	44k	INFO	====> Epoch: 72, cost 22.98 s
2024-01-01 19:09:34,123	44k	INFO	====> Epoch: 73, cost 22.95 s
2024-01-01 19:09:57,252	44k	INFO	====> Epoch: 74, cost 23.13 s
2024-01-01 19:10:20,523	44k	INFO	====> Epoch: 75, cost 23.27 s
2024-01-01 19:10:43,538	44k	INFO	====> Epoch: 76, cost 23.02 s
2024-01-01 19:11:05,926	44k	INFO	Train Epoch: 77 [92%]
2024-01-01 19:11:05,928	44k	INFO	Losses: [2.073070764541626, 2.6491317749023438, 5.665109634399414, 32.94279098510742, 0.9408771395683289], step: 2000, lr: 9.905443942579728e-05, reference_loss: 44.27097702026367
2024-01-01 19:11:07,046	44k	INFO	====> Epoch: 77, cost 23.51 s
2024-01-01 19:11:30,076	44k	INFO	====> Epoch: 78, cost 23.03 s
2024-01-01 19:11:53,121	44k	INFO	====> Epoch: 79, cost 23.04 s
2024-01-01 19:12:16,171	44k	INFO	====> Epoch: 80, cost 23.05 s
2024-01-01 19:12:39,237	44k	INFO	====> Epoch: 81, cost 23.07 s
2024-01-01 19:13:02,251	44k	INFO	====> Epoch: 82, cost 23.01 s
2024-01-01 19:13:25,304	44k	INFO	====> Epoch: 83, cost 23.05 s
2024-01-01 19:13:48,311	44k	INFO	====> Epoch: 84, cost 23.01 s
2024-01-01 19:14:03,765	44k	INFO	Train Epoch: 85 [62%]
2024-01-01 19:14:03,767	44k	INFO	Losses: [2.2064642906188965, 2.6290416717529297, 5.0810465812683105, 28.938034057617188, 0.702492356300354], step: 2200, lr: 9.895542831185631e-05, reference_loss: 39.55707931518555
2024-01-01 19:14:12,016	44k	INFO	====> Epoch: 85, cost 23.70 s
2024-01-01 19:14:35,158	44k	INFO	====> Epoch: 86, cost 23.14 s
2024-01-01 19:14:58,253	44k	INFO	====> Epoch: 87, cost 23.09 s
2024-01-01 19:15:21,312	44k	INFO	====> Epoch: 88, cost 23.06 s
2024-01-01 19:15:44,488	44k	INFO	====> Epoch: 89, cost 23.18 s
2024-01-01 19:16:07,612	44k	INFO	====> Epoch: 90, cost 23.12 s
2024-01-01 19:16:30,506	44k	INFO	====> Epoch: 91, cost 22.89 s
2024-01-01 19:16:53,520	44k	INFO	====> Epoch: 92, cost 23.01 s
2024-01-01 19:17:01,637	44k	INFO	Train Epoch: 93 [31%]
2024-01-01 19:17:01,639	44k	INFO	Losses: [2.473710060119629, 2.5566678047180176, 3.6167211532592773, 27.129728317260742, 0.9315124154090881], step: 2400, lr: 9.885651616572276e-05, reference_loss: 36.708335876464844
2024-01-01 19:17:08,050	44k	INFO	Saving model and optimizer state at iteration 93 to ./logs/44k/G_2400.pth
2024-01-01 19:17:08,950	44k	INFO	Saving model and optimizer state at iteration 93 to ./logs/44k/D_2400.pth
2024-01-01 19:17:24,311	44k	INFO	====> Epoch: 93, cost 30.79 s
2024-01-01 19:17:47,389	44k	INFO	====> Epoch: 94, cost 23.08 s
2024-01-01 19:18:10,467	44k	INFO	====> Epoch: 95, cost 23.08 s
2024-01-01 19:18:33,580	44k	INFO	====> Epoch: 96, cost 23.11 s
2024-01-01 19:18:56,600	44k	INFO	====> Epoch: 97, cost 23.02 s
2024-01-01 19:19:19,590	44k	INFO	====> Epoch: 98, cost 22.99 s
2024-01-01 19:19:42,636	44k	INFO	====> Epoch: 99, cost 23.05 s
2024-01-01 19:20:05,680	44k	INFO	====> Epoch: 100, cost 23.04 s
2024-01-01 19:20:06,579	44k	INFO	Train Epoch: 101 [0%]
2024-01-01 19:20:06,581	44k	INFO	Losses: [2.1147286891937256, 2.952759027481079, 5.488287448883057, 31.250267028808594, 0.5221655964851379], step: 2600, lr: 9.875770288847208e-05, reference_loss: 42.328208923339844
2024-01-01 19:20:29,340	44k	INFO	====> Epoch: 101, cost 23.66 s
2024-01-01 19:20:52,265	44k	INFO	====> Epoch: 102, cost 22.93 s
2024-01-01 19:21:15,285	44k	INFO	====> Epoch: 103, cost 23.02 s
2024-01-01 19:21:38,417	44k	INFO	====> Epoch: 104, cost 23.13 s
2024-01-01 19:22:01,633	44k	INFO	====> Epoch: 105, cost 23.22 s
2024-01-01 19:22:24,587	44k	INFO	====> Epoch: 106, cost 22.95 s
2024-01-01 19:22:47,680	44k	INFO	====> Epoch: 107, cost 23.09 s
2024-01-01 19:23:04,781	44k	INFO	Train Epoch: 108 [69%]
2024-01-01 19:23:04,783	44k	INFO	Losses: [2.3275058269500732, 2.4962515830993652, 5.203211784362793, 30.20310401916504, 0.9384515285491943], step: 2800, lr: 9.867132229656573e-05, reference_loss: 41.168521881103516
2024-01-01 19:23:11,214	44k	INFO	====> Epoch: 108, cost 23.53 s
2024-01-01 19:23:34,368	44k	INFO	====> Epoch: 109, cost 23.15 s
2024-01-01 19:23:57,593	44k	INFO	====> Epoch: 110, cost 23.22 s
2024-01-01 19:24:20,631	44k	INFO	====> Epoch: 111, cost 23.04 s
2024-01-01 19:24:43,610	44k	INFO	====> Epoch: 112, cost 22.98 s
2024-01-01 19:25:06,702	44k	INFO	====> Epoch: 113, cost 23.09 s
2024-01-01 19:25:29,811	44k	INFO	====> Epoch: 114, cost 23.11 s
2024-01-01 19:25:52,748	44k	INFO	====> Epoch: 115, cost 22.94 s
2024-01-01 19:26:02,609	44k	INFO	Train Epoch: 116 [38%]
2024-01-01 19:26:02,612	44k	INFO	Losses: [2.0901005268096924, 2.4789319038391113, 5.730666160583496, 28.928874969482422, 0.9171666502952576], step: 3000, lr: 9.857269413218213e-05, reference_loss: 40.1457405090332
2024-01-01 19:26:16,205	44k	INFO	====> Epoch: 116, cost 23.46 s
2024-01-01 19:26:39,152	44k	INFO	====> Epoch: 117, cost 22.95 s
2024-01-01 19:27:02,143	44k	INFO	====> Epoch: 118, cost 22.99 s
2024-01-01 19:27:25,127	44k	INFO	====> Epoch: 119, cost 22.98 s
2024-01-01 19:27:48,375	44k	INFO	====> Epoch: 120, cost 23.25 s
2024-01-01 19:28:11,370	44k	INFO	====> Epoch: 121, cost 22.99 s
2024-01-01 19:28:34,420	44k	INFO	====> Epoch: 122, cost 23.05 s
2024-01-01 19:28:57,387	44k	INFO	====> Epoch: 123, cost 22.97 s
2024-01-01 19:29:00,075	44k	INFO	Train Epoch: 124 [8%]
2024-01-01 19:29:00,077	44k	INFO	Losses: [2.0948143005371094, 2.572516679763794, 5.847188949584961, 31.673084259033203, 0.8128568530082703], step: 3200, lr: 9.847416455282387e-05, reference_loss: 43.00046157836914
2024-01-01 19:29:06,403	44k	INFO	Saving model and optimizer state at iteration 124 to ./logs/44k/G_3200.pth
2024-01-01 19:29:07,320	44k	INFO	Saving model and optimizer state at iteration 124 to ./logs/44k/D_3200.pth
2024-01-01 19:29:07,862	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_800.pth
2024-01-01 19:29:07,902	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_800.pth
2024-01-01 19:29:28,207	44k	INFO	====> Epoch: 124, cost 30.82 s
2024-01-01 19:29:51,378	44k	INFO	====> Epoch: 125, cost 23.17 s
2024-01-01 19:30:14,512	44k	INFO	====> Epoch: 126, cost 23.13 s
2024-01-01 19:30:37,878	44k	INFO	====> Epoch: 127, cost 23.37 s
2024-01-01 19:31:00,927	44k	INFO	====> Epoch: 128, cost 23.05 s
2024-01-01 19:31:23,836	44k	INFO	====> Epoch: 129, cost 22.91 s
2024-01-01 19:31:46,913	44k	INFO	====> Epoch: 130, cost 23.08 s
2024-01-01 19:32:05,669	44k	INFO	Train Epoch: 131 [77%]
2024-01-01 19:32:05,672	44k	INFO	Losses: [2.0724871158599854, 3.0260252952575684, 6.271958827972412, 26.901220321655273, 0.9422178864479065], step: 3400, lr: 9.838803196394459e-05, reference_loss: 39.21390914916992
2024-01-01 19:32:10,305	44k	INFO	====> Epoch: 131, cost 23.39 s
2024-01-01 19:32:33,362	44k	INFO	====> Epoch: 132, cost 23.06 s
2024-01-01 19:32:56,330	44k	INFO	====> Epoch: 133, cost 22.97 s
2024-01-01 19:33:19,356	44k	INFO	====> Epoch: 134, cost 23.03 s
2024-01-01 19:33:42,496	44k	INFO	====> Epoch: 135, cost 23.14 s
2024-01-01 19:34:05,438	44k	INFO	====> Epoch: 136, cost 22.94 s
2024-01-01 19:34:28,345	44k	INFO	====> Epoch: 137, cost 22.91 s
2024-01-01 19:34:51,577	44k	INFO	====> Epoch: 138, cost 23.23 s
2024-01-01 19:35:03,232	44k	INFO	Train Epoch: 139 [46%]
2024-01-01 19:35:03,235	44k	INFO	Losses: [2.6142303943634033, 1.8043899536132812, 3.4958481788635254, 25.148677825927734, 0.7535061240196228], step: 3600, lr: 9.828968696598508e-05, reference_loss: 33.816650390625
2024-01-01 19:35:15,130	44k	INFO	====> Epoch: 139, cost 23.55 s
2024-01-01 19:35:38,065	44k	INFO	====> Epoch: 140, cost 22.93 s
2024-01-01 19:36:01,093	44k	INFO	====> Epoch: 141, cost 23.03 s
2024-01-01 19:36:24,095	44k	INFO	====> Epoch: 142, cost 23.00 s
2024-01-01 19:36:47,055	44k	INFO	====> Epoch: 143, cost 22.96 s
2024-01-01 19:37:09,967	44k	INFO	====> Epoch: 144, cost 22.91 s
2024-01-01 19:37:33,024	44k	INFO	====> Epoch: 145, cost 23.06 s
2024-01-01 19:37:56,019	44k	INFO	====> Epoch: 146, cost 23.00 s
2024-01-01 19:38:00,521	44k	INFO	Train Epoch: 147 [15%]
2024-01-01 19:38:00,522	44k	INFO	Losses: [2.4670050144195557, 2.3075246810913086, 3.935760498046875, 24.55418586730957, 0.936080276966095], step: 3800, lr: 9.819144027000834e-05, reference_loss: 34.200557708740234
2024-01-01 19:38:19,751	44k	INFO	====> Epoch: 147, cost 23.73 s
2024-01-01 19:38:42,773	44k	INFO	====> Epoch: 148, cost 23.02 s
2024-01-01 19:39:05,748	44k	INFO	====> Epoch: 149, cost 22.98 s
2024-01-01 19:39:28,673	44k	INFO	====> Epoch: 150, cost 22.92 s
2024-01-01 19:39:51,768	44k	INFO	====> Epoch: 151, cost 23.10 s
2024-01-01 19:40:14,815	44k	INFO	====> Epoch: 152, cost 23.05 s
2024-01-01 19:40:37,810	44k	INFO	====> Epoch: 153, cost 22.99 s
2024-01-01 19:40:58,402	44k	INFO	Train Epoch: 154 [85%]
2024-01-01 19:40:58,404	44k	INFO	Losses: [2.2068674564361572, 2.6568026542663574, 5.079724311828613, 26.038612365722656, 0.8504822254180908], step: 4000, lr: 9.810555497212693e-05, reference_loss: 36.832489013671875
2024-01-01 19:41:04,477	44k	INFO	Saving model and optimizer state at iteration 154 to ./logs/44k/G_4000.pth
2024-01-01 19:41:05,605	44k	INFO	Saving model and optimizer state at iteration 154 to ./logs/44k/D_4000.pth
2024-01-01 19:41:06,138	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_1600.pth
2024-01-01 19:41:06,179	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_1600.pth
2024-01-01 19:41:08,682	44k	INFO	====> Epoch: 154, cost 30.87 s
2024-01-01 19:41:31,635	44k	INFO	====> Epoch: 155, cost 22.95 s
2024-01-01 19:41:54,654	44k	INFO	====> Epoch: 156, cost 23.02 s
2024-01-01 19:42:17,695	44k	INFO	====> Epoch: 157, cost 23.04 s
2024-01-01 19:42:40,663	44k	INFO	====> Epoch: 158, cost 22.97 s
2024-01-01 19:43:03,774	44k	INFO	====> Epoch: 159, cost 23.11 s
2024-01-01 19:43:26,884	44k	INFO	====> Epoch: 160, cost 23.11 s
2024-01-01 19:43:49,978	44k	INFO	====> Epoch: 161, cost 23.09 s
2024-01-01 19:44:03,441	44k	INFO	Train Epoch: 162 [54%]
2024-01-01 19:44:03,444	44k	INFO	Losses: [2.525759220123291, 2.3306145668029785, 4.543220043182373, 25.727933883666992, 1.1028227806091309], step: 4200, lr: 9.800749232760646e-05, reference_loss: 36.2303466796875
2024-01-01 19:44:13,609	44k	INFO	====> Epoch: 162, cost 23.63 s
2024-01-01 19:44:36,677	44k	INFO	====> Epoch: 163, cost 23.07 s
2024-01-01 19:44:59,954	44k	INFO	====> Epoch: 164, cost 23.28 s
2024-01-01 19:45:23,115	44k	INFO	====> Epoch: 165, cost 23.16 s
2024-01-01 19:45:46,094	44k	INFO	====> Epoch: 166, cost 22.98 s
2024-01-01 19:46:08,986	44k	INFO	====> Epoch: 167, cost 22.89 s
2024-01-01 19:46:32,083	44k	INFO	====> Epoch: 168, cost 23.10 s
2024-01-01 19:46:55,004	44k	INFO	====> Epoch: 169, cost 22.92 s
2024-01-01 19:47:01,270	44k	INFO	Train Epoch: 170 [23%]
2024-01-01 19:47:01,272	44k	INFO	Losses: [2.2796669006347656, 2.3742213249206543, 4.282741546630859, 21.47555923461914, 0.8261767029762268], step: 4400, lr: 9.790952770283884e-05, reference_loss: 31.238367080688477
2024-01-01 19:47:18,549	44k	INFO	====> Epoch: 170, cost 23.55 s
2024-01-01 19:47:41,467	44k	INFO	====> Epoch: 171, cost 22.92 s
2024-01-01 19:48:04,594	44k	INFO	====> Epoch: 172, cost 23.13 s
2024-01-01 19:48:27,741	44k	INFO	====> Epoch: 173, cost 23.15 s
2024-01-01 19:48:50,793	44k	INFO	====> Epoch: 174, cost 23.05 s
2024-01-01 19:49:13,820	44k	INFO	====> Epoch: 175, cost 23.03 s
2024-01-01 19:49:36,782	44k	INFO	====> Epoch: 176, cost 22.96 s
2024-01-01 19:49:59,019	44k	INFO	Train Epoch: 177 [92%]
2024-01-01 19:49:59,021	44k	INFO	Losses: [2.3393325805664062, 2.4797675609588623, 4.522575855255127, 25.988170623779297, 0.8067408800125122], step: 4600, lr: 9.782388898597041e-05, reference_loss: 36.13658905029297
2024-01-01 19:50:00,151	44k	INFO	====> Epoch: 177, cost 23.37 s
2024-01-01 19:50:23,317	44k	INFO	====> Epoch: 178, cost 23.17 s
2024-01-01 19:50:46,314	44k	INFO	====> Epoch: 179, cost 23.00 s
2024-01-01 19:51:09,301	44k	INFO	====> Epoch: 180, cost 22.99 s
2024-01-01 19:51:32,399	44k	INFO	====> Epoch: 181, cost 23.10 s
2024-01-01 19:51:55,413	44k	INFO	====> Epoch: 182, cost 23.01 s
2024-01-01 19:52:18,668	44k	INFO	====> Epoch: 183, cost 23.25 s
2024-01-01 19:52:41,801	44k	INFO	====> Epoch: 184, cost 23.13 s
2024-01-01 19:52:57,004	44k	INFO	Train Epoch: 185 [62%]
2024-01-01 19:52:57,007	44k	INFO	Losses: [2.3661227226257324, 2.335625410079956, 4.382413387298584, 22.52182960510254, 0.8004220128059387], step: 4800, lr: 9.772610788423802e-05, reference_loss: 32.40641403198242
2024-01-01 19:53:03,122	44k	INFO	Saving model and optimizer state at iteration 185 to ./logs/44k/G_4800.pth
2024-01-01 19:53:04,036	44k	INFO	Saving model and optimizer state at iteration 185 to ./logs/44k/D_4800.pth
2024-01-01 19:53:04,571	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_2400.pth
2024-01-01 19:53:04,611	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_2400.pth
2024-01-01 19:53:12,370	44k	INFO	====> Epoch: 185, cost 30.57 s
2024-01-01 19:53:35,354	44k	INFO	====> Epoch: 186, cost 22.98 s
2024-01-01 19:53:58,495	44k	INFO	====> Epoch: 187, cost 23.14 s
2024-01-01 19:54:21,499	44k	INFO	====> Epoch: 188, cost 23.00 s
2024-01-01 19:54:44,549	44k	INFO	====> Epoch: 189, cost 23.05 s
2024-01-01 19:55:07,860	44k	INFO	====> Epoch: 190, cost 23.31 s
2024-01-01 19:55:30,890	44k	INFO	====> Epoch: 191, cost 23.03 s
2024-01-01 19:55:53,751	44k	INFO	====> Epoch: 192, cost 22.86 s
2024-01-01 19:56:01,767	44k	INFO	Train Epoch: 193 [31%]
2024-01-01 19:56:01,768	44k	INFO	Losses: [2.382896900177002, 2.5913517475128174, 4.961630821228027, 28.146318435668945, 0.8276077508926392], step: 5000, lr: 9.762842452083883e-05, reference_loss: 38.90980529785156
2024-01-01 19:56:17,090	44k	INFO	====> Epoch: 193, cost 23.34 s
2024-01-01 19:56:40,134	44k	INFO	====> Epoch: 194, cost 23.04 s
2024-01-01 19:57:03,217	44k	INFO	====> Epoch: 195, cost 23.08 s
2024-01-01 19:57:26,221	44k	INFO	====> Epoch: 196, cost 23.00 s
2024-01-01 19:57:49,387	44k	INFO	====> Epoch: 197, cost 23.17 s
2024-01-01 19:58:12,485	44k	INFO	====> Epoch: 198, cost 23.10 s
2024-01-01 19:58:35,618	44k	INFO	====> Epoch: 199, cost 23.13 s
2024-01-01 19:58:58,680	44k	INFO	====> Epoch: 200, cost 23.06 s
2024-01-01 19:58:59,578	44k	INFO	Train Epoch: 201 [0%]
2024-01-01 19:58:59,580	44k	INFO	Losses: [2.2695345878601074, 2.627490520477295, 4.862268924713135, 25.03565216064453, 0.826793372631073], step: 5200, lr: 9.753083879807726e-05, reference_loss: 35.62173843383789
2024-01-01 19:59:22,238	44k	INFO	====> Epoch: 201, cost 23.56 s
2024-01-01 19:59:45,345	44k	INFO	====> Epoch: 202, cost 23.11 s
2024-01-01 20:00:08,476	44k	INFO	====> Epoch: 203, cost 23.13 s
2024-01-01 20:00:31,510	44k	INFO	====> Epoch: 204, cost 23.03 s
2024-01-01 20:00:54,497	44k	INFO	====> Epoch: 205, cost 22.99 s
2024-01-01 20:01:17,441	44k	INFO	====> Epoch: 206, cost 22.94 s
2024-01-01 20:01:40,509	44k	INFO	====> Epoch: 207, cost 23.07 s
2024-01-01 20:01:57,492	44k	INFO	Train Epoch: 208 [69%]
2024-01-01 20:01:57,494	44k	INFO	Losses: [2.142925977706909, 2.533975124359131, 5.8060197830200195, 27.210466384887695, 0.7600438594818115], step: 5400, lr: 9.744553130976908e-05, reference_loss: 38.45343017578125
2024-01-01 20:02:03,956	44k	INFO	====> Epoch: 208, cost 23.45 s
2024-01-01 20:02:27,257	44k	INFO	====> Epoch: 209, cost 23.30 s
2024-01-01 20:02:50,410	44k	INFO	====> Epoch: 210, cost 23.15 s
2024-01-01 20:03:13,553	44k	INFO	====> Epoch: 211, cost 23.14 s
2024-01-01 20:03:36,592	44k	INFO	====> Epoch: 212, cost 23.04 s
2024-01-01 20:03:59,545	44k	INFO	====> Epoch: 213, cost 22.95 s
2024-01-01 20:04:22,476	44k	INFO	====> Epoch: 214, cost 22.93 s
2024-01-01 20:04:45,403	44k	INFO	====> Epoch: 215, cost 22.93 s
2024-01-01 20:04:55,243	44k	INFO	Train Epoch: 216 [38%]
2024-01-01 20:04:55,246	44k	INFO	Losses: [2.4433977603912354, 2.523365020751953, 4.087379455566406, 23.631214141845703, 0.8674048781394958], step: 5600, lr: 9.734812840022278e-05, reference_loss: 33.55276107788086
2024-01-01 20:05:01,293	44k	INFO	Saving model and optimizer state at iteration 216 to ./logs/44k/G_5600.pth
2024-01-01 20:05:02,202	44k	INFO	Saving model and optimizer state at iteration 216 to ./logs/44k/D_5600.pth
2024-01-01 20:05:02,736	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_3200.pth
2024-01-01 20:05:02,776	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_3200.pth
2024-01-01 20:05:16,058	44k	INFO	====> Epoch: 216, cost 30.66 s
2024-01-01 20:05:39,025	44k	INFO	====> Epoch: 217, cost 22.97 s
2024-01-01 20:06:02,027	44k	INFO	====> Epoch: 218, cost 23.00 s
2024-01-01 20:06:25,083	44k	INFO	====> Epoch: 219, cost 23.06 s
2024-01-01 20:06:48,068	44k	INFO	====> Epoch: 220, cost 22.98 s
2024-01-01 20:07:11,037	44k	INFO	====> Epoch: 221, cost 22.97 s
2024-01-01 20:07:34,281	44k	INFO	====> Epoch: 222, cost 23.24 s
2024-01-01 20:07:57,307	44k	INFO	====> Epoch: 223, cost 23.03 s
2024-01-01 20:07:59,976	44k	INFO	Train Epoch: 224 [8%]
2024-01-01 20:07:59,979	44k	INFO	Losses: [2.1798031330108643, 2.2239997386932373, 4.466533184051514, 22.835220336914062, 0.6091225743293762], step: 5800, lr: 9.725082285098293e-05, reference_loss: 32.31467819213867
2024-01-01 20:08:20,726	44k	INFO	====> Epoch: 224, cost 23.42 s
2024-01-01 20:08:43,663	44k	INFO	====> Epoch: 225, cost 22.94 s
2024-01-01 20:09:06,668	44k	INFO	====> Epoch: 226, cost 23.00 s
2024-01-01 20:09:29,801	44k	INFO	====> Epoch: 227, cost 23.13 s
2024-01-01 20:09:52,890	44k	INFO	====> Epoch: 228, cost 23.09 s
2024-01-01 20:10:16,159	44k	INFO	====> Epoch: 229, cost 23.27 s
2024-01-01 20:10:39,290	44k	INFO	====> Epoch: 230, cost 23.13 s
2024-01-01 20:10:58,102	44k	INFO	Train Epoch: 231 [77%]
2024-01-01 20:10:58,104	44k	INFO	Losses: [2.3647537231445312, 2.152108669281006, 5.961562633514404, 26.439741134643555, 0.7556853294372559], step: 6000, lr: 9.716576028476738e-05, reference_loss: 37.673851013183594
2024-01-01 20:11:02,743	44k	INFO	====> Epoch: 231, cost 23.45 s
2024-01-01 20:11:25,803	44k	INFO	====> Epoch: 232, cost 23.06 s
2024-01-01 20:11:48,859	44k	INFO	====> Epoch: 233, cost 23.06 s
2024-01-01 20:12:11,989	44k	INFO	====> Epoch: 234, cost 23.13 s
2024-01-01 20:12:35,049	44k	INFO	====> Epoch: 235, cost 23.06 s
2024-01-01 20:12:58,108	44k	INFO	====> Epoch: 236, cost 23.06 s
2024-01-01 20:13:21,063	44k	INFO	====> Epoch: 237, cost 22.95 s
2024-01-01 20:13:44,322	44k	INFO	====> Epoch: 238, cost 23.26 s
2024-01-01 20:13:55,898	44k	INFO	Train Epoch: 239 [46%]
2024-01-01 20:13:55,901	44k	INFO	Losses: [2.2574141025543213, 2.5719099044799805, 5.006875991821289, 24.579444885253906, 0.7766217589378357], step: 6200, lr: 9.706863702387684e-05, reference_loss: 35.19226837158203
2024-01-01 20:14:07,750	44k	INFO	====> Epoch: 239, cost 23.43 s
2024-01-01 20:14:30,815	44k	INFO	====> Epoch: 240, cost 23.07 s
2024-01-01 20:14:53,923	44k	INFO	====> Epoch: 241, cost 23.11 s
2024-01-01 20:15:17,053	44k	INFO	====> Epoch: 242, cost 23.13 s
2024-01-01 20:15:40,217	44k	INFO	====> Epoch: 243, cost 23.16 s
2024-01-01 20:16:03,326	44k	INFO	====> Epoch: 244, cost 23.11 s
2024-01-01 20:16:26,294	44k	INFO	====> Epoch: 245, cost 22.97 s
2024-01-01 20:16:49,375	44k	INFO	====> Epoch: 246, cost 23.08 s
2024-01-01 20:16:53,884	44k	INFO	Train Epoch: 247 [15%]
2024-01-01 20:16:53,886	44k	INFO	Losses: [2.4198851585388184, 2.1579043865203857, 4.826954364776611, 24.354473114013672, 0.6539345383644104], step: 6400, lr: 9.69716108437664e-05, reference_loss: 34.413150787353516
2024-01-01 20:17:00,173	44k	INFO	Saving model and optimizer state at iteration 247 to ./logs/44k/G_6400.pth
2024-01-01 20:17:01,075	44k	INFO	Saving model and optimizer state at iteration 247 to ./logs/44k/D_6400.pth
2024-01-01 20:17:01,614	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_4000.pth
2024-01-01 20:17:01,653	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_4000.pth
2024-01-01 20:17:20,143	44k	INFO	====> Epoch: 247, cost 30.77 s
2024-01-01 20:17:43,252	44k	INFO	====> Epoch: 248, cost 23.11 s
2024-01-01 20:18:06,172	44k	INFO	====> Epoch: 249, cost 22.92 s
2024-01-01 20:18:29,212	44k	INFO	====> Epoch: 250, cost 23.04 s
2024-01-01 20:18:52,171	44k	INFO	====> Epoch: 251, cost 22.96 s
2024-01-01 20:19:15,212	44k	INFO	====> Epoch: 252, cost 23.04 s
2024-01-01 20:19:38,268	44k	INFO	====> Epoch: 253, cost 23.06 s
2024-01-01 20:19:58,758	44k	INFO	Train Epoch: 254 [85%]
2024-01-01 20:19:58,760	44k	INFO	Losses: [2.6037325859069824, 2.032358169555664, 3.2840323448181152, 22.829303741455078, 0.7974573373794556], step: 6600, lr: 9.68867924964598e-05, reference_loss: 31.546884536743164
2024-01-01 20:20:01,991	44k	INFO	====> Epoch: 254, cost 23.72 s
2024-01-01 20:20:25,189	44k	INFO	====> Epoch: 255, cost 23.20 s
2024-01-01 20:20:48,291	44k	INFO	====> Epoch: 256, cost 23.10 s
2024-01-01 20:21:11,223	44k	INFO	====> Epoch: 257, cost 22.93 s
2024-01-01 20:21:34,276	44k	INFO	====> Epoch: 258, cost 23.05 s
2024-01-01 20:21:57,246	44k	INFO	====> Epoch: 259, cost 22.97 s
2024-01-01 20:22:20,321	44k	INFO	====> Epoch: 260, cost 23.08 s
2024-01-01 20:22:43,378	44k	INFO	====> Epoch: 261, cost 23.06 s
2024-01-01 20:22:56,768	44k	INFO	Train Epoch: 262 [54%]
2024-01-01 20:22:56,771	44k	INFO	Losses: [2.190380096435547, 2.6136510372161865, 5.657233238220215, 25.91773796081543, 0.9410629272460938], step: 6800, lr: 9.678994808133967e-05, reference_loss: 37.320064544677734
2024-01-01 20:23:06,777	44k	INFO	====> Epoch: 262, cost 23.40 s
2024-01-01 20:23:29,992	44k	INFO	====> Epoch: 263, cost 23.22 s
2024-01-01 20:23:53,082	44k	INFO	====> Epoch: 264, cost 23.09 s
2024-01-01 20:24:16,104	44k	INFO	====> Epoch: 265, cost 23.02 s
2024-01-01 20:24:39,211	44k	INFO	====> Epoch: 266, cost 23.11 s
2024-01-01 20:25:02,301	44k	INFO	====> Epoch: 267, cost 23.09 s
2024-01-01 20:25:25,402	44k	INFO	====> Epoch: 268, cost 23.10 s
2024-01-01 20:25:48,444	44k	INFO	====> Epoch: 269, cost 23.04 s
2024-01-01 20:25:54,698	44k	INFO	Train Epoch: 270 [23%]
2024-01-01 20:25:54,700	44k	INFO	Losses: [2.2486817836761475, 2.927250862121582, 5.052109718322754, 22.711660385131836, 0.6993517279624939], step: 7000, lr: 9.669320046827584e-05, reference_loss: 33.63905715942383
2024-01-01 20:26:11,804	44k	INFO	====> Epoch: 270, cost 23.36 s
2024-01-01 20:26:34,731	44k	INFO	====> Epoch: 271, cost 22.93 s
2024-01-01 20:26:57,663	44k	INFO	====> Epoch: 272, cost 22.93 s
2024-01-01 20:27:20,921	44k	INFO	====> Epoch: 273, cost 23.26 s
2024-01-01 20:27:44,007	44k	INFO	====> Epoch: 274, cost 23.09 s
2024-01-01 20:28:07,151	44k	INFO	====> Epoch: 275, cost 23.14 s
2024-01-01 20:28:30,254	44k	INFO	====> Epoch: 276, cost 23.10 s
2024-01-01 20:28:52,538	44k	INFO	Train Epoch: 277 [92%]
2024-01-01 20:28:52,541	44k	INFO	Losses: [2.399059772491455, 2.3889758586883545, 4.733154296875, 22.658964157104492, 0.8418223261833191], step: 7200, lr: 9.660862563871342e-05, reference_loss: 33.021976470947266
2024-01-01 20:28:58,680	44k	INFO	Saving model and optimizer state at iteration 277 to ./logs/44k/G_7200.pth
2024-01-01 20:28:59,595	44k	INFO	Saving model and optimizer state at iteration 277 to ./logs/44k/D_7200.pth
2024-01-01 20:29:00,131	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_4800.pth
2024-01-01 20:29:00,170	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_4800.pth
2024-01-01 20:29:00,870	44k	INFO	====> Epoch: 277, cost 30.62 s
2024-01-01 20:29:23,918	44k	INFO	====> Epoch: 278, cost 23.05 s
2024-01-01 20:29:47,035	44k	INFO	====> Epoch: 279, cost 23.12 s
2024-01-01 20:30:10,237	44k	INFO	====> Epoch: 280, cost 23.20 s
2024-01-01 20:30:33,285	44k	INFO	====> Epoch: 281, cost 23.05 s
2024-01-01 20:30:56,337	44k	INFO	====> Epoch: 282, cost 23.05 s
2024-01-01 20:31:19,421	44k	INFO	====> Epoch: 283, cost 23.08 s
2024-01-01 20:31:42,429	44k	INFO	====> Epoch: 284, cost 23.01 s
2024-01-01 20:31:57,669	44k	INFO	Train Epoch: 285 [62%]
2024-01-01 20:31:57,671	44k	INFO	Losses: [2.58992600440979, 2.2532505989074707, 3.7693402767181396, 20.920658111572266, 0.9282987117767334], step: 7400, lr: 9.651205926878348e-05, reference_loss: 30.461475372314453
2024-01-01 20:32:05,929	44k	INFO	====> Epoch: 285, cost 23.50 s
2024-01-01 20:32:29,069	44k	INFO	====> Epoch: 286, cost 23.14 s
2024-01-01 20:32:52,109	44k	INFO	====> Epoch: 287, cost 23.04 s
2024-01-01 20:33:15,182	44k	INFO	====> Epoch: 288, cost 23.07 s
2024-01-01 20:33:38,220	44k	INFO	====> Epoch: 289, cost 23.04 s
2024-01-01 20:34:01,222	44k	INFO	====> Epoch: 290, cost 23.00 s
2024-01-01 20:34:24,218	44k	INFO	====> Epoch: 291, cost 23.00 s
2024-01-01 20:34:47,368	44k	INFO	====> Epoch: 292, cost 23.15 s
2024-01-01 20:34:55,489	44k	INFO	Train Epoch: 293 [31%]
2024-01-01 20:34:55,491	44k	INFO	Losses: [2.5523641109466553, 2.370884656906128, 4.208256721496582, 22.226537704467773, 0.8426896929740906], step: 7600, lr: 9.641558942298625e-05, reference_loss: 32.20073318481445
2024-01-01 20:35:11,119	44k	INFO	====> Epoch: 293, cost 23.75 s
2024-01-01 20:35:34,208	44k	INFO	====> Epoch: 294, cost 23.09 s
2024-01-01 20:35:57,325	44k	INFO	====> Epoch: 295, cost 23.12 s
2024-01-01 20:36:20,358	44k	INFO	====> Epoch: 296, cost 23.03 s
2024-01-01 20:36:43,338	44k	INFO	====> Epoch: 297, cost 22.98 s
2024-01-01 20:37:06,381	44k	INFO	====> Epoch: 298, cost 23.04 s
2024-01-01 20:37:29,436	44k	INFO	====> Epoch: 299, cost 23.05 s
2024-01-01 20:37:52,523	44k	INFO	====> Epoch: 300, cost 23.09 s
2024-01-01 20:37:53,426	44k	INFO	Train Epoch: 301 [0%]
2024-01-01 20:37:53,428	44k	INFO	Losses: [2.3344902992248535, 2.7399768829345703, 4.689729690551758, 22.055973052978516, 0.8036239743232727], step: 7800, lr: 9.631921600483981e-05, reference_loss: 32.62379455566406
2024-01-01 20:38:16,142	44k	INFO	====> Epoch: 301, cost 23.62 s
2024-01-01 20:38:39,235	44k	INFO	====> Epoch: 302, cost 23.09 s
2024-01-01 20:39:02,363	44k	INFO	====> Epoch: 303, cost 23.13 s
2024-01-01 20:39:25,387	44k	INFO	====> Epoch: 304, cost 23.02 s
2024-01-01 20:39:48,278	44k	INFO	====> Epoch: 305, cost 22.89 s
2024-01-01 20:40:11,256	44k	INFO	====> Epoch: 306, cost 22.98 s
2024-01-01 20:40:34,394	44k	INFO	====> Epoch: 307, cost 23.14 s
2024-01-01 20:40:51,448	44k	INFO	Train Epoch: 308 [69%]
2024-01-01 20:40:51,450	44k	INFO	Losses: [2.206223726272583, 2.538025140762329, 5.1113505363464355, 20.988271713256836, 0.7488334774971008], step: 8000, lr: 9.62349682889948e-05, reference_loss: 31.59270477294922
2024-01-01 20:40:57,535	44k	INFO	Saving model and optimizer state at iteration 308 to ./logs/44k/G_8000.pth
2024-01-01 20:40:58,612	44k	INFO	Saving model and optimizer state at iteration 308 to ./logs/44k/D_8000.pth
2024-01-01 20:40:59,154	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_5600.pth
2024-01-01 20:40:59,193	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_5600.pth
2024-01-01 20:41:05,244	44k	INFO	====> Epoch: 308, cost 30.85 s
2024-01-01 20:41:28,410	44k	INFO	====> Epoch: 309, cost 23.17 s
2024-01-01 20:41:51,593	44k	INFO	====> Epoch: 310, cost 23.18 s
2024-01-01 20:42:14,735	44k	INFO	====> Epoch: 311, cost 23.14 s
2024-01-01 20:42:37,818	44k	INFO	====> Epoch: 312, cost 23.08 s
2024-01-01 20:43:00,896	44k	INFO	====> Epoch: 313, cost 23.08 s
2024-01-01 20:43:23,830	44k	INFO	====> Epoch: 314, cost 22.93 s
2024-01-01 20:43:46,865	44k	INFO	====> Epoch: 315, cost 23.04 s
2024-01-01 20:43:56,742	44k	INFO	Train Epoch: 316 [38%]
2024-01-01 20:43:56,745	44k	INFO	Losses: [2.42183256149292, 2.4668402671813965, 5.510920524597168, 23.601076126098633, 0.8518521189689636], step: 8200, lr: 9.613877541298036e-05, reference_loss: 34.85252380371094
2024-01-01 20:44:10,413	44k	INFO	====> Epoch: 316, cost 23.55 s
2024-01-01 20:44:33,625	44k	INFO	====> Epoch: 317, cost 23.21 s
2024-01-01 20:44:56,554	44k	INFO	====> Epoch: 318, cost 22.93 s
2024-01-01 20:45:19,636	44k	INFO	====> Epoch: 319, cost 23.08 s
2024-01-01 20:45:42,734	44k	INFO	====> Epoch: 320, cost 23.10 s
2024-01-01 20:46:05,740	44k	INFO	====> Epoch: 321, cost 23.01 s
2024-01-01 20:46:28,850	44k	INFO	====> Epoch: 322, cost 23.11 s
2024-01-01 20:46:52,004	44k	INFO	====> Epoch: 323, cost 23.15 s
2024-01-01 20:46:54,710	44k	INFO	Train Epoch: 324 [8%]
2024-01-01 20:46:54,713	44k	INFO	Losses: [2.2417449951171875, 2.5159668922424316, 4.865494251251221, 23.16343879699707, 0.6532372236251831], step: 8400, lr: 9.604267868776807e-05, reference_loss: 33.43988037109375
2024-01-01 20:47:15,594	44k	INFO	====> Epoch: 324, cost 23.59 s
2024-01-01 20:47:38,595	44k	INFO	====> Epoch: 325, cost 23.00 s
2024-01-01 20:48:01,701	44k	INFO	====> Epoch: 326, cost 23.11 s
2024-01-01 20:48:24,740	44k	INFO	====> Epoch: 327, cost 23.04 s
2024-01-01 20:48:47,787	44k	INFO	====> Epoch: 328, cost 23.05 s
2024-01-01 20:49:10,807	44k	INFO	====> Epoch: 329, cost 23.02 s
2024-01-01 20:49:33,764	44k	INFO	====> Epoch: 330, cost 22.96 s
2024-01-01 20:49:52,525	44k	INFO	Train Epoch: 331 [77%]
2024-01-01 20:49:52,527	44k	INFO	Losses: [2.5472798347473145, 2.61906099319458, 5.330436706542969, 26.341833114624023, 0.7220350503921509], step: 8600, lr: 9.595867285135558e-05, reference_loss: 37.560646057128906
2024-01-01 20:49:57,260	44k	INFO	====> Epoch: 331, cost 23.50 s
2024-01-01 20:50:20,162	44k	INFO	====> Epoch: 332, cost 22.90 s
2024-01-01 20:50:43,245	44k	INFO	====> Epoch: 333, cost 23.08 s
2024-01-01 20:51:06,360	44k	INFO	====> Epoch: 334, cost 23.11 s
2024-01-01 20:51:29,413	44k	INFO	====> Epoch: 335, cost 23.05 s
2024-01-01 20:51:52,731	44k	INFO	====> Epoch: 336, cost 23.32 s
2024-01-01 20:52:15,856	44k	INFO	====> Epoch: 337, cost 23.13 s
2024-01-01 20:52:38,974	44k	INFO	====> Epoch: 338, cost 23.12 s
2024-01-01 20:52:50,647	44k	INFO	Train Epoch: 339 [46%]
2024-01-01 20:52:50,650	44k	INFO	Losses: [2.3209283351898193, 2.7230992317199707, 4.931713104248047, 20.645263671875, 0.5534765124320984], step: 8800, lr: 9.586275614992974e-05, reference_loss: 31.174480438232422
2024-01-01 20:52:56,703	44k	INFO	Saving model and optimizer state at iteration 339 to ./logs/44k/G_8800.pth
2024-01-01 20:52:57,600	44k	INFO	Saving model and optimizer state at iteration 339 to ./logs/44k/D_8800.pth
2024-01-01 20:52:58,147	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_6400.pth
2024-01-01 20:52:58,186	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_6400.pth
2024-01-01 20:53:09,604	44k	INFO	====> Epoch: 339, cost 30.63 s
2024-01-01 20:53:32,631	44k	INFO	====> Epoch: 340, cost 23.03 s
2024-01-01 20:53:55,632	44k	INFO	====> Epoch: 341, cost 23.00 s
2024-01-01 20:54:18,566	44k	INFO	====> Epoch: 342, cost 22.93 s
2024-01-01 20:54:41,819	44k	INFO	====> Epoch: 343, cost 23.25 s
2024-01-01 20:55:04,920	44k	INFO	====> Epoch: 344, cost 23.10 s
2024-01-01 20:55:27,965	44k	INFO	====> Epoch: 345, cost 23.05 s
2024-01-01 20:55:50,830	44k	INFO	====> Epoch: 346, cost 22.86 s
2024-01-01 20:55:55,337	44k	INFO	Train Epoch: 347 [15%]
2024-01-01 20:55:55,339	44k	INFO	Losses: [2.488452672958374, 2.1887991428375244, 4.457027912139893, 21.013103485107422, 0.6785579323768616], step: 9000, lr: 9.576693532325224e-05, reference_loss: 30.82594108581543
2024-01-01 20:56:14,360	44k	INFO	====> Epoch: 347, cost 23.53 s
2024-01-01 20:56:37,503	44k	INFO	====> Epoch: 348, cost 23.14 s
2024-01-01 20:57:00,602	44k	INFO	====> Epoch: 349, cost 23.10 s
2024-01-01 20:57:23,732	44k	INFO	====> Epoch: 350, cost 23.13 s
2024-01-01 20:57:46,763	44k	INFO	====> Epoch: 351, cost 23.03 s
2024-01-01 20:58:09,734	44k	INFO	====> Epoch: 352, cost 22.97 s
2024-01-01 20:58:32,713	44k	INFO	====> Epoch: 353, cost 22.98 s
2024-01-01 20:58:53,366	44k	INFO	Train Epoch: 354 [85%]
2024-01-01 20:58:53,369	44k	INFO	Losses: [2.3957903385162354, 2.287938356399536, 4.597548961639404, 22.620962142944336, 0.8793910145759583], step: 9200, lr: 9.568317067182427e-05, reference_loss: 32.78163146972656
2024-01-01 20:58:56,278	44k	INFO	====> Epoch: 354, cost 23.57 s
2024-01-01 20:59:19,359	44k	INFO	====> Epoch: 355, cost 23.08 s
2024-01-01 20:59:42,490	44k	INFO	====> Epoch: 356, cost 23.13 s
2024-01-01 21:00:05,548	44k	INFO	====> Epoch: 357, cost 23.06 s
2024-01-01 21:00:28,620	44k	INFO	====> Epoch: 358, cost 23.07 s
2024-01-01 21:00:51,743	44k	INFO	====> Epoch: 359, cost 23.12 s
2024-01-01 21:01:14,852	44k	INFO	====> Epoch: 360, cost 23.11 s
2024-01-01 21:01:37,823	44k	INFO	====> Epoch: 361, cost 22.97 s
2024-01-01 21:01:51,177	44k	INFO	Train Epoch: 362 [54%]
2024-01-01 21:01:51,179	44k	INFO	Losses: [2.672441005706787, 2.108567237854004, 3.7336416244506836, 20.348392486572266, 0.6550267338752747], step: 9400, lr: 9.558752935207586e-05, reference_loss: 29.518070220947266
2024-01-01 21:02:01,484	44k	INFO	====> Epoch: 362, cost 23.66 s
2024-01-01 21:02:24,550	44k	INFO	====> Epoch: 363, cost 23.07 s
2024-01-01 21:02:47,424	44k	INFO	====> Epoch: 364, cost 22.87 s
2024-01-01 21:03:10,326	44k	INFO	====> Epoch: 365, cost 22.90 s
2024-01-01 21:03:33,393	44k	INFO	====> Epoch: 366, cost 23.07 s
2024-01-01 21:03:56,471	44k	INFO	====> Epoch: 367, cost 23.08 s
2024-01-01 21:04:19,395	44k	INFO	====> Epoch: 368, cost 22.92 s
2024-01-01 21:04:42,299	44k	INFO	====> Epoch: 369, cost 22.90 s
2024-01-01 21:04:48,553	44k	INFO	Train Epoch: 370 [23%]
2024-01-01 21:04:48,556	44k	INFO	Losses: [2.245574712753296, 2.4001405239105225, 4.758875370025635, 21.18682861328125, 0.9332628846168518], step: 9600, lr: 9.54919836318146e-05, reference_loss: 31.524682998657227
2024-01-01 21:04:54,707	44k	INFO	Saving model and optimizer state at iteration 370 to ./logs/44k/G_9600.pth
2024-01-01 21:04:55,814	44k	INFO	Saving model and optimizer state at iteration 370 to ./logs/44k/D_9600.pth
2024-01-01 21:04:56,343	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_7200.pth
2024-01-01 21:04:56,382	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_7200.pth
2024-01-01 21:05:13,173	44k	INFO	====> Epoch: 370, cost 30.87 s
2024-01-01 21:05:36,259	44k	INFO	====> Epoch: 371, cost 23.09 s
2024-01-01 21:05:59,472	44k	INFO	====> Epoch: 372, cost 23.21 s
2024-01-01 21:06:22,587	44k	INFO	====> Epoch: 373, cost 23.12 s
2024-01-01 21:06:45,671	44k	INFO	====> Epoch: 374, cost 23.08 s
2024-01-01 21:07:08,715	44k	INFO	====> Epoch: 375, cost 23.04 s
2024-01-01 21:07:31,849	44k	INFO	====> Epoch: 376, cost 23.13 s
2024-01-01 21:07:54,234	44k	INFO	Train Epoch: 377 [92%]
2024-01-01 21:07:54,235	44k	INFO	Losses: [2.320845127105713, 2.4012584686279297, 5.1618218421936035, 22.713415145874023, 0.845842182636261], step: 9800, lr: 9.540845947291691e-05, reference_loss: 33.443180084228516
2024-01-01 21:07:55,362	44k	INFO	====> Epoch: 377, cost 23.51 s
2024-01-01 21:08:18,329	44k	INFO	====> Epoch: 378, cost 22.97 s
2024-01-01 21:08:41,388	44k	INFO	====> Epoch: 379, cost 23.06 s
2024-01-01 21:09:04,366	44k	INFO	====> Epoch: 380, cost 22.98 s
2024-01-01 21:09:27,314	44k	INFO	====> Epoch: 381, cost 22.95 s
2024-01-01 21:09:50,398	44k	INFO	====> Epoch: 382, cost 23.08 s
2024-01-01 21:10:13,559	44k	INFO	====> Epoch: 383, cost 23.16 s
2024-01-01 21:10:36,703	44k	INFO	====> Epoch: 384, cost 23.14 s
2024-01-01 21:10:51,934	44k	INFO	Train Epoch: 385 [62%]
2024-01-01 21:10:51,936	44k	INFO	Losses: [2.3675363063812256, 2.447587728500366, 5.272059440612793, 20.997089385986328, 0.6879863142967224], step: 10000, lr: 9.53130927442113e-05, reference_loss: 31.772258758544922
2024-01-01 21:11:00,212	44k	INFO	====> Epoch: 385, cost 23.51 s
2024-01-01 21:11:23,344	44k	INFO	====> Epoch: 386, cost 23.13 s
2024-01-01 21:11:46,442	44k	INFO	====> Epoch: 387, cost 23.10 s
2024-01-01 21:12:09,479	44k	INFO	====> Epoch: 388, cost 23.04 s
2024-01-01 21:12:32,616	44k	INFO	====> Epoch: 389, cost 23.14 s
2024-01-01 21:12:55,673	44k	INFO	====> Epoch: 390, cost 23.06 s
2024-01-01 21:13:18,649	44k	INFO	====> Epoch: 391, cost 22.98 s
2024-01-01 21:13:41,572	44k	INFO	====> Epoch: 392, cost 22.92 s
2024-01-01 21:13:49,627	44k	INFO	Train Epoch: 393 [31%]
2024-01-01 21:13:49,629	44k	INFO	Losses: [2.3767361640930176, 2.6095728874206543, 4.516658306121826, 18.354379653930664, 0.6408237218856812], step: 10200, lr: 9.52178213405219e-05, reference_loss: 28.498170852661133
2024-01-01 21:14:04,942	44k	INFO	====> Epoch: 393, cost 23.37 s
2024-01-01 21:14:27,888	44k	INFO	====> Epoch: 394, cost 22.95 s
2024-01-01 21:14:50,892	44k	INFO	====> Epoch: 395, cost 23.00 s
2024-01-01 21:15:13,894	44k	INFO	====> Epoch: 396, cost 23.00 s
2024-01-01 21:15:37,012	44k	INFO	====> Epoch: 397, cost 23.12 s
2024-01-01 21:16:00,093	44k	INFO	====> Epoch: 398, cost 23.08 s
2024-01-01 21:16:23,365	44k	INFO	====> Epoch: 399, cost 23.27 s
2024-01-01 21:16:46,468	44k	INFO	====> Epoch: 400, cost 23.10 s
2024-01-01 21:16:47,373	44k	INFO	Train Epoch: 401 [0%]
2024-01-01 21:16:47,375	44k	INFO	Losses: [2.4843509197235107, 2.4809083938598633, 4.640381336212158, 20.509990692138672, 0.4831177890300751], step: 10400, lr: 9.512264516656537e-05, reference_loss: 30.5987491607666
2024-01-01 21:16:53,509	44k	INFO	Saving model and optimizer state at iteration 401 to ./logs/44k/G_10400.pth
2024-01-01 21:16:54,374	44k	INFO	Saving model and optimizer state at iteration 401 to ./logs/44k/D_10400.pth
2024-01-01 21:16:54,912	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_8000.pth
2024-01-01 21:16:54,952	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_8000.pth
2024-01-01 21:17:16,990	44k	INFO	====> Epoch: 401, cost 30.52 s
2024-01-01 21:17:40,091	44k	INFO	====> Epoch: 402, cost 23.10 s
2024-01-01 21:18:03,224	44k	INFO	====> Epoch: 403, cost 23.13 s
2024-01-01 21:18:26,266	44k	INFO	====> Epoch: 404, cost 23.04 s
2024-01-01 21:18:49,174	44k	INFO	====> Epoch: 405, cost 22.91 s
2024-01-01 21:19:12,219	44k	INFO	====> Epoch: 406, cost 23.05 s
2024-01-01 21:19:35,291	44k	INFO	====> Epoch: 407, cost 23.07 s
2024-01-01 21:19:52,314	44k	INFO	Train Epoch: 408 [69%]
2024-01-01 21:19:52,317	44k	INFO	Losses: [2.0085699558258057, 2.794280529022217, 6.006420612335205, 23.495899200439453, 0.8280477523803711], step: 10600, lr: 9.503944405766085e-05, reference_loss: 35.133216857910156
2024-01-01 21:19:58,886	44k	INFO	====> Epoch: 408, cost 23.59 s
2024-01-01 21:20:21,915	44k	INFO	====> Epoch: 409, cost 23.03 s
2024-01-01 21:20:44,993	44k	INFO	====> Epoch: 410, cost 23.08 s
2024-01-01 21:21:08,018	44k	INFO	====> Epoch: 411, cost 23.02 s
2024-01-01 21:21:31,034	44k	INFO	====> Epoch: 412, cost 23.02 s
2024-01-01 21:21:54,124	44k	INFO	====> Epoch: 413, cost 23.09 s
2024-01-01 21:22:17,215	44k	INFO	====> Epoch: 414, cost 23.09 s
2024-01-01 21:22:40,369	44k	INFO	====> Epoch: 415, cost 23.15 s
2024-01-01 21:22:50,288	44k	INFO	Train Epoch: 416 [38%]
2024-01-01 21:22:50,289	44k	INFO	Losses: [2.334691047668457, 2.491123676300049, 5.742227077484131, 23.214506149291992, 0.5087090730667114], step: 10800, lr: 9.494444618296661e-05, reference_loss: 34.291255950927734
2024-01-01 21:23:03,982	44k	INFO	====> Epoch: 416, cost 23.61 s
2024-01-01 21:23:27,128	44k	INFO	====> Epoch: 417, cost 23.15 s
2024-01-01 21:23:50,219	44k	INFO	====> Epoch: 418, cost 23.09 s
2024-01-01 21:24:13,324	44k	INFO	====> Epoch: 419, cost 23.10 s
2024-01-01 21:24:36,410	44k	INFO	====> Epoch: 420, cost 23.09 s
2024-01-01 21:24:59,430	44k	INFO	====> Epoch: 421, cost 23.02 s
2024-01-01 21:25:22,413	44k	INFO	====> Epoch: 422, cost 22.98 s
2024-01-01 21:25:45,471	44k	INFO	====> Epoch: 423, cost 23.06 s
2024-01-01 21:25:48,179	44k	INFO	Train Epoch: 424 [8%]
2024-01-01 21:25:48,181	44k	INFO	Losses: [2.2507340908050537, 2.5732290744781494, 5.6912455558776855, 23.589197158813477, 0.711295485496521], step: 11000, lr: 9.484954326459589e-05, reference_loss: 34.815704345703125
2024-01-01 21:26:08,941	44k	INFO	====> Epoch: 424, cost 23.47 s
2024-01-01 21:26:32,030	44k	INFO	====> Epoch: 425, cost 23.09 s
2024-01-01 21:26:55,114	44k	INFO	====> Epoch: 426, cost 23.08 s
2024-01-01 21:27:18,154	44k	INFO	====> Epoch: 427, cost 23.04 s
2024-01-01 21:27:41,231	44k	INFO	====> Epoch: 428, cost 23.08 s
2024-01-01 21:28:04,303	44k	INFO	====> Epoch: 429, cost 23.07 s
2024-01-01 21:28:27,383	44k	INFO	====> Epoch: 430, cost 23.08 s
2024-01-01 21:28:46,270	44k	INFO	Train Epoch: 431 [77%]
2024-01-01 21:28:46,272	44k	INFO	Losses: [1.8836848735809326, 2.7203335762023926, 7.11826753616333, 24.12327003479004, 0.9143009185791016], step: 11200, lr: 9.47665810302627e-05, reference_loss: 36.759857177734375
2024-01-01 21:28:52,333	44k	INFO	Saving model and optimizer state at iteration 431 to ./logs/44k/G_11200.pth
2024-01-01 21:28:53,260	44k	INFO	Saving model and optimizer state at iteration 431 to ./logs/44k/D_11200.pth
2024-01-01 21:28:53,817	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_8800.pth
2024-01-01 21:28:53,856	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_8800.pth
2024-01-01 21:28:58,105	44k	INFO	====> Epoch: 431, cost 30.72 s
2024-01-01 21:29:21,531	44k	INFO	====> Epoch: 432, cost 23.43 s
2024-01-01 21:29:44,673	44k	INFO	====> Epoch: 433, cost 23.14 s
2024-01-01 21:30:07,835	44k	INFO	====> Epoch: 434, cost 23.16 s
2024-01-01 21:30:30,895	44k	INFO	====> Epoch: 435, cost 23.06 s
2024-01-01 21:30:53,841	44k	INFO	====> Epoch: 436, cost 22.95 s
2024-01-01 21:31:16,964	44k	INFO	====> Epoch: 437, cost 23.12 s
2024-01-01 21:31:39,994	44k	INFO	====> Epoch: 438, cost 23.03 s
2024-01-01 21:31:51,561	44k	INFO	Train Epoch: 439 [46%]
2024-01-01 21:31:51,564	44k	INFO	Losses: [2.2690765857696533, 2.3408334255218506, 5.873562812805176, 23.404787063598633, 0.5619617104530334], step: 11400, lr: 9.467185589924815e-05, reference_loss: 34.45022201538086
2024-01-01 21:32:03,356	44k	INFO	====> Epoch: 439, cost 23.36 s
2024-01-01 21:32:26,298	44k	INFO	====> Epoch: 440, cost 22.94 s
2024-01-01 21:32:49,237	44k	INFO	====> Epoch: 441, cost 22.94 s
2024-01-01 21:33:12,414	44k	INFO	====> Epoch: 442, cost 23.18 s
2024-01-01 21:33:35,549	44k	INFO	====> Epoch: 443, cost 23.14 s
2024-01-01 21:33:58,737	44k	INFO	====> Epoch: 444, cost 23.19 s
2024-01-01 21:34:21,829	44k	INFO	====> Epoch: 445, cost 23.09 s
2024-01-01 21:34:44,918	44k	INFO	====> Epoch: 446, cost 23.09 s
2024-01-01 21:34:49,441	44k	INFO	Train Epoch: 447 [15%]
2024-01-01 21:34:49,443	44k	INFO	Losses: [2.2552669048309326, 2.3941006660461426, 5.750175476074219, 22.972122192382812, 0.7370301485061646], step: 11600, lr: 9.457722545193272e-05, reference_loss: 34.10869598388672
2024-01-01 21:35:08,545	44k	INFO	====> Epoch: 447, cost 23.63 s
2024-01-01 21:35:31,712	44k	INFO	====> Epoch: 448, cost 23.17 s
2024-01-01 21:35:54,862	44k	INFO	====> Epoch: 449, cost 23.15 s
2024-01-01 21:36:17,945	44k	INFO	====> Epoch: 450, cost 23.08 s
2024-01-01 21:36:40,942	44k	INFO	====> Epoch: 451, cost 23.00 s
2024-01-01 21:37:03,903	44k	INFO	====> Epoch: 452, cost 22.96 s
2024-01-01 21:37:26,904	44k	INFO	====> Epoch: 453, cost 23.00 s
2024-01-01 21:37:47,708	44k	INFO	Train Epoch: 454 [85%]
2024-01-01 21:37:47,710	44k	INFO	Losses: [2.096078872680664, 2.768465280532837, 5.920535564422607, 21.124542236328125, 0.8771429657936096], step: 11800, lr: 9.44945014063499e-05, reference_loss: 32.786766052246094
2024-01-01 21:37:50,726	44k	INFO	====> Epoch: 454, cost 23.82 s
2024-01-01 21:38:13,907	44k	INFO	====> Epoch: 455, cost 23.18 s
2024-01-01 21:38:37,106	44k	INFO	====> Epoch: 456, cost 23.20 s
2024-01-01 21:39:00,291	44k	INFO	====> Epoch: 457, cost 23.18 s
2024-01-01 21:39:23,420	44k	INFO	====> Epoch: 458, cost 23.13 s
2024-01-01 21:39:46,509	44k	INFO	====> Epoch: 459, cost 23.09 s
2024-01-01 21:40:09,672	44k	INFO	====> Epoch: 460, cost 23.16 s
2024-01-01 21:40:32,815	44k	INFO	====> Epoch: 461, cost 23.14 s
2024-01-01 21:40:46,264	44k	INFO	Train Epoch: 462 [54%]
2024-01-01 21:40:46,265	44k	INFO	Losses: [2.4791064262390137, 2.337890863418579, 5.121422290802002, 22.29395294189453, 0.4994334578514099], step: 12000, lr: 9.440004823595418e-05, reference_loss: 32.73180389404297
2024-01-01 21:40:52,545	44k	INFO	Saving model and optimizer state at iteration 462 to ./logs/44k/G_12000.pth
2024-01-01 21:40:53,442	44k	INFO	Saving model and optimizer state at iteration 462 to ./logs/44k/D_12000.pth
2024-01-01 21:40:53,977	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_9600.pth
2024-01-01 21:40:54,016	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_9600.pth
2024-01-01 21:41:03,638	44k	INFO	====> Epoch: 462, cost 30.82 s
2024-01-01 21:41:26,658	44k	INFO	====> Epoch: 463, cost 23.02 s
2024-01-01 21:41:49,806	44k	INFO	====> Epoch: 464, cost 23.15 s
2024-01-01 21:42:12,911	44k	INFO	====> Epoch: 465, cost 23.11 s
2024-01-01 21:42:35,988	44k	INFO	====> Epoch: 466, cost 23.08 s
2024-01-01 21:42:59,102	44k	INFO	====> Epoch: 467, cost 23.11 s
2024-01-01 21:43:22,140	44k	INFO	====> Epoch: 468, cost 23.04 s
2024-01-01 21:43:45,113	44k	INFO	====> Epoch: 469, cost 22.97 s
2024-01-01 21:43:51,408	44k	INFO	Train Epoch: 470 [23%]
2024-01-01 21:43:51,410	44k	INFO	Losses: [2.592710494995117, 2.120081663131714, 3.8497254848480225, 19.599218368530273, 0.7258126139640808], step: 12200, lr: 9.430568947741589e-05, reference_loss: 28.887548446655273
2024-01-01 21:44:08,735	44k	INFO	====> Epoch: 470, cost 23.62 s
2024-01-01 21:44:31,686	44k	INFO	====> Epoch: 471, cost 22.95 s
2024-01-01 21:44:54,788	44k	INFO	====> Epoch: 472, cost 23.10 s
2024-01-01 21:45:17,855	44k	INFO	====> Epoch: 473, cost 23.07 s
2024-01-01 21:45:40,951	44k	INFO	====> Epoch: 474, cost 23.10 s
2024-01-01 21:46:04,021	44k	INFO	====> Epoch: 475, cost 23.07 s
2024-01-01 21:46:27,114	44k	INFO	====> Epoch: 476, cost 23.09 s
2024-01-01 21:46:49,513	44k	INFO	Train Epoch: 477 [92%]
2024-01-01 21:46:49,516	44k	INFO	Losses: [2.3621301651000977, 2.234382152557373, 5.630462646484375, 25.340280532836914, 0.9152445197105408], step: 12400, lr: 9.422320293673162e-05, reference_loss: 36.48249816894531
2024-01-01 21:46:50,731	44k	INFO	====> Epoch: 477, cost 23.62 s
2024-01-01 21:47:13,815	44k	INFO	====> Epoch: 478, cost 23.08 s
2024-01-01 21:47:37,061	44k	INFO	====> Epoch: 479, cost 23.25 s
2024-01-01 21:48:00,112	44k	INFO	====> Epoch: 480, cost 23.05 s
2024-01-01 21:48:23,206	44k	INFO	====> Epoch: 481, cost 23.09 s
2024-01-01 21:48:46,187	44k	INFO	====> Epoch: 482, cost 22.98 s
2024-01-01 21:49:09,099	44k	INFO	====> Epoch: 483, cost 22.91 s
2024-01-01 21:49:32,079	44k	INFO	====> Epoch: 484, cost 22.98 s
2024-01-01 21:49:47,349	44k	INFO	Train Epoch: 485 [62%]
2024-01-01 21:49:47,352	44k	INFO	Losses: [2.4009127616882324, 2.8990511894226074, 5.964433193206787, 22.316293716430664, 0.5216314196586609], step: 12600, lr: 9.412902094614211e-05, reference_loss: 34.10232162475586
2024-01-01 21:49:55,682	44k	INFO	====> Epoch: 485, cost 23.60 s
2024-01-01 21:50:18,818	44k	INFO	====> Epoch: 486, cost 23.14 s
2024-01-01 21:50:41,794	44k	INFO	====> Epoch: 487, cost 22.98 s
2024-01-01 21:51:04,865	44k	INFO	====> Epoch: 488, cost 23.07 s
2024-01-01 21:51:28,044	44k	INFO	====> Epoch: 489, cost 23.18 s
2024-01-01 21:51:51,153	44k	INFO	====> Epoch: 490, cost 23.11 s
2024-01-01 21:52:14,174	44k	INFO	====> Epoch: 491, cost 23.02 s
2024-01-01 21:52:37,178	44k	INFO	====> Epoch: 492, cost 23.00 s
2024-01-01 21:52:45,300	44k	INFO	Train Epoch: 493 [31%]
2024-01-01 21:52:45,303	44k	INFO	Losses: [2.4415626525878906, 2.5759596824645996, 5.202731132507324, 20.971708297729492, 0.7277929186820984], step: 12800, lr: 9.403493309634886e-05, reference_loss: 31.919754028320312
2024-01-01 21:52:51,494	44k	INFO	Saving model and optimizer state at iteration 493 to ./logs/44k/G_12800.pth
2024-01-01 21:52:52,378	44k	INFO	Saving model and optimizer state at iteration 493 to ./logs/44k/D_12800.pth
2024-01-01 21:52:52,927	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_10400.pth
2024-01-01 21:52:52,966	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_10400.pth
2024-01-01 21:53:07,815	44k	INFO	====> Epoch: 493, cost 30.64 s
2024-01-01 21:53:30,838	44k	INFO	====> Epoch: 494, cost 23.02 s
2024-01-01 21:53:53,848	44k	INFO	====> Epoch: 495, cost 23.01 s
2024-01-01 21:54:17,102	44k	INFO	====> Epoch: 496, cost 23.25 s
2024-01-01 21:54:40,046	44k	INFO	====> Epoch: 497, cost 22.94 s
2024-01-01 21:55:03,002	44k	INFO	====> Epoch: 498, cost 22.96 s
2024-01-01 21:55:25,975	44k	INFO	====> Epoch: 499, cost 22.97 s
2024-01-01 21:55:48,966	44k	INFO	====> Epoch: 500, cost 22.99 s
2024-01-01 21:55:49,870	44k	INFO	Train Epoch: 501 [0%]
2024-01-01 21:55:49,872	44k	INFO	Losses: [2.2954442501068115, 2.5043435096740723, 5.504108428955078, 22.396024703979492, 0.5677474737167358], step: 13000, lr: 9.394093929325224e-05, reference_loss: 33.267669677734375
2024-01-01 21:56:12,398	44k	INFO	====> Epoch: 501, cost 23.43 s
2024-01-01 21:56:35,427	44k	INFO	====> Epoch: 502, cost 23.03 s
2024-01-01 21:56:58,373	44k	INFO	====> Epoch: 503, cost 22.95 s
2024-01-01 21:57:21,386	44k	INFO	====> Epoch: 504, cost 23.01 s
2024-01-01 21:57:44,478	44k	INFO	====> Epoch: 505, cost 23.09 s
2024-01-01 21:58:07,559	44k	INFO	====> Epoch: 506, cost 23.08 s
2024-01-01 21:58:30,799	44k	INFO	====> Epoch: 507, cost 23.24 s
2024-01-01 21:58:47,720	44k	INFO	Train Epoch: 508 [69%]
2024-01-01 21:58:47,722	44k	INFO	Losses: [2.2530148029327393, 2.3876218795776367, 5.627906799316406, 22.759790420532227, 0.6589245796203613], step: 13200, lr: 9.385877178932038e-05, reference_loss: 33.687259674072266
2024-01-01 21:58:54,146	44k	INFO	====> Epoch: 508, cost 23.35 s
2024-01-01 21:59:17,044	44k	INFO	====> Epoch: 509, cost 22.90 s
2024-01-01 21:59:40,098	44k	INFO	====> Epoch: 510, cost 23.05 s
2024-01-01 22:00:03,075	44k	INFO	====> Epoch: 511, cost 22.98 s
2024-01-01 22:00:25,989	44k	INFO	====> Epoch: 512, cost 22.91 s
2024-01-01 22:00:48,941	44k	INFO	====> Epoch: 513, cost 22.95 s
2024-01-01 22:01:11,893	44k	INFO	====> Epoch: 514, cost 22.95 s
2024-01-01 22:01:34,810	44k	INFO	====> Epoch: 515, cost 22.92 s
2024-01-01 22:01:44,670	44k	INFO	Train Epoch: 516 [38%]
2024-01-01 22:01:44,672	44k	INFO	Losses: [2.1327548027038574, 2.704533338546753, 6.8353190422058105, 22.019329071044922, 0.7057209014892578], step: 13400, lr: 9.376495407047951e-05, reference_loss: 34.39765930175781
2024-01-01 22:01:58,414	44k	INFO	====> Epoch: 516, cost 23.60 s
2024-01-01 22:02:21,462	44k	INFO	====> Epoch: 517, cost 23.05 s
2024-01-01 22:02:44,439	44k	INFO	====> Epoch: 518, cost 22.98 s
2024-01-01 22:03:07,521	44k	INFO	====> Epoch: 519, cost 23.08 s
2024-01-01 22:03:30,540	44k	INFO	====> Epoch: 520, cost 23.02 s
2024-01-01 22:03:53,672	44k	INFO	====> Epoch: 521, cost 23.13 s
2024-01-01 22:04:16,757	44k	INFO	====> Epoch: 522, cost 23.08 s
2024-01-01 22:04:39,858	44k	INFO	====> Epoch: 523, cost 23.10 s
2024-01-01 22:04:42,567	44k	INFO	Train Epoch: 524 [8%]
2024-01-01 22:04:42,568	44k	INFO	Losses: [2.3065552711486816, 2.6612558364868164, 6.071407794952393, 25.222436904907227, 0.4815855622291565], step: 13600, lr: 9.367123012832248e-05, reference_loss: 36.74324417114258
2024-01-01 22:04:48,659	44k	INFO	Saving model and optimizer state at iteration 524 to ./logs/44k/G_13600.pth
2024-01-01 22:04:49,755	44k	INFO	Saving model and optimizer state at iteration 524 to ./logs/44k/D_13600.pth
2024-01-01 22:04:50,285	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_11200.pth
2024-01-01 22:04:50,325	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_11200.pth
2024-01-01 22:05:10,648	44k	INFO	====> Epoch: 524, cost 30.79 s
2024-01-01 22:05:33,678	44k	INFO	====> Epoch: 525, cost 23.03 s
2024-01-01 22:05:56,493	44k	INFO	====> Epoch: 526, cost 22.82 s
2024-01-01 22:06:19,367	44k	INFO	====> Epoch: 527, cost 22.87 s
2024-01-01 22:06:42,286	44k	INFO	====> Epoch: 528, cost 22.92 s
2024-01-01 22:07:05,264	44k	INFO	====> Epoch: 529, cost 22.98 s
2024-01-01 22:07:28,242	44k	INFO	====> Epoch: 530, cost 22.98 s
2024-01-01 22:07:47,089	44k	INFO	Train Epoch: 531 [77%]
2024-01-01 22:07:47,092	44k	INFO	Losses: [2.322002649307251, 2.2641069889068604, 4.882208824157715, 22.103099822998047, 0.757440447807312], step: 13800, lr: 9.358929853143005e-05, reference_loss: 32.328857421875
2024-01-01 22:07:51,738	44k	INFO	====> Epoch: 531, cost 23.50 s
2024-01-01 22:08:14,680	44k	INFO	====> Epoch: 532, cost 22.94 s
2024-01-01 22:08:37,818	44k	INFO	====> Epoch: 533, cost 23.14 s
2024-01-01 22:09:00,830	44k	INFO	====> Epoch: 534, cost 23.01 s
2024-01-01 22:09:23,873	44k	INFO	====> Epoch: 535, cost 23.04 s
2024-01-01 22:09:47,024	44k	INFO	====> Epoch: 536, cost 23.15 s
2024-01-01 22:10:10,047	44k	INFO	====> Epoch: 537, cost 23.02 s
2024-01-01 22:10:33,140	44k	INFO	====> Epoch: 538, cost 23.09 s
2024-01-01 22:10:44,785	44k	INFO	Train Epoch: 539 [46%]
2024-01-01 22:10:44,788	44k	INFO	Losses: [2.2568821907043457, 2.5417938232421875, 5.067656517028809, 21.251256942749023, 0.5758480429649353], step: 14000, lr: 9.349575016798194e-05, reference_loss: 31.693437576293945
2024-01-01 22:10:56,648	44k	INFO	====> Epoch: 539, cost 23.51 s
2024-01-01 22:11:19,695	44k	INFO	====> Epoch: 540, cost 23.05 s
2024-01-01 22:11:42,784	44k	INFO	====> Epoch: 541, cost 23.09 s
2024-01-01 22:12:05,819	44k	INFO	====> Epoch: 542, cost 23.03 s
2024-01-01 22:12:29,102	44k	INFO	====> Epoch: 543, cost 23.28 s
2024-01-01 22:12:52,143	44k	INFO	====> Epoch: 544, cost 23.04 s
2024-01-01 22:13:15,254	44k	INFO	====> Epoch: 545, cost 23.11 s
2024-01-01 22:13:38,332	44k	INFO	====> Epoch: 546, cost 23.08 s
2024-01-01 22:13:42,843	44k	INFO	Train Epoch: 547 [15%]
2024-01-01 22:13:42,845	44k	INFO	Losses: [2.5170063972473145, 2.3336174488067627, 4.552136421203613, 19.836666107177734, 0.600998044013977], step: 14200, lr: 9.340229531198015e-05, reference_loss: 29.840423583984375
2024-01-01 22:14:01,846	44k	INFO	====> Epoch: 547, cost 23.51 s
2024-01-01 22:14:24,948	44k	INFO	====> Epoch: 548, cost 23.10 s
2024-01-01 22:14:48,087	44k	INFO	====> Epoch: 549, cost 23.14 s
2024-01-01 22:15:11,232	44k	INFO	====> Epoch: 550, cost 23.15 s
2024-01-01 22:15:34,341	44k	INFO	====> Epoch: 551, cost 23.11 s
2024-01-01 22:15:57,662	44k	INFO	====> Epoch: 552, cost 23.32 s
2024-01-01 22:16:20,746	44k	INFO	====> Epoch: 553, cost 23.08 s
2024-01-01 22:16:41,338	44k	INFO	Train Epoch: 554 [85%]
2024-01-01 22:16:41,341	44k	INFO	Losses: [2.1897435188293457, 2.9147419929504395, 5.614920139312744, 20.740848541259766, 0.7396829128265381], step: 14400, lr: 9.332059894482616e-05, reference_loss: 32.19993591308594
2024-01-01 22:16:47,488	44k	INFO	Saving model and optimizer state at iteration 554 to ./logs/44k/G_14400.pth
2024-01-01 22:16:48,376	44k	INFO	Saving model and optimizer state at iteration 554 to ./logs/44k/D_14400.pth
2024-01-01 22:16:48,909	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_12000.pth
2024-01-01 22:16:48,948	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_12000.pth
2024-01-01 22:16:51,454	44k	INFO	====> Epoch: 554, cost 30.71 s
2024-01-01 22:17:14,616	44k	INFO	====> Epoch: 555, cost 23.16 s
2024-01-01 22:17:37,777	44k	INFO	====> Epoch: 556, cost 23.16 s
2024-01-01 22:18:00,799	44k	INFO	====> Epoch: 557, cost 23.02 s
2024-01-01 22:18:23,745	44k	INFO	====> Epoch: 558, cost 22.95 s
2024-01-01 22:18:46,765	44k	INFO	====> Epoch: 559, cost 23.02 s
2024-01-01 22:19:10,081	44k	INFO	====> Epoch: 560, cost 23.32 s
2024-01-01 22:19:33,209	44k	INFO	====> Epoch: 561, cost 23.13 s
2024-01-01 22:19:46,627	44k	INFO	Train Epoch: 562 [54%]
2024-01-01 22:19:46,629	44k	INFO	Losses: [2.215738534927368, 2.6489386558532715, 6.370410442352295, 21.778564453125, 1.004758596420288], step: 14600, lr: 9.322731916343797e-05, reference_loss: 34.018409729003906
2024-01-01 22:19:56,657	44k	INFO	====> Epoch: 562, cost 23.45 s
2024-01-01 22:20:19,663	44k	INFO	====> Epoch: 563, cost 23.01 s
2024-01-01 22:20:42,795	44k	INFO	====> Epoch: 564, cost 23.13 s
2024-01-01 22:21:05,879	44k	INFO	====> Epoch: 565, cost 23.08 s
2024-01-01 22:21:28,976	44k	INFO	====> Epoch: 566, cost 23.10 s
2024-01-01 22:21:52,186	44k	INFO	====> Epoch: 567, cost 23.21 s
2024-01-01 22:22:15,323	44k	INFO	====> Epoch: 568, cost 23.14 s
2024-01-01 22:22:38,370	44k	INFO	====> Epoch: 569, cost 23.05 s
2024-01-01 22:22:44,666	44k	INFO	Train Epoch: 570 [23%]
2024-01-01 22:22:44,668	44k	INFO	Losses: [2.447361469268799, 2.4532456398010254, 5.214013576507568, 18.952062606811523, 0.5645827651023865], step: 14800, lr: 9.313413262103149e-05, reference_loss: 29.63126564025879
2024-01-01 22:23:01,913	44k	INFO	====> Epoch: 570, cost 23.54 s
2024-01-01 22:23:25,108	44k	INFO	====> Epoch: 571, cost 23.20 s
2024-01-01 22:23:48,298	44k	INFO	====> Epoch: 572, cost 23.19 s
2024-01-01 22:24:11,429	44k	INFO	====> Epoch: 573, cost 23.13 s
2024-01-01 22:24:34,379	44k	INFO	====> Epoch: 574, cost 22.95 s
2024-01-01 22:24:57,349	44k	INFO	====> Epoch: 575, cost 22.97 s
2024-01-01 22:25:20,475	44k	INFO	====> Epoch: 576, cost 23.13 s
2024-01-01 22:25:42,912	44k	INFO	Train Epoch: 577 [92%]
2024-01-01 22:25:42,915	44k	INFO	Losses: [2.3649864196777344, 2.441460132598877, 4.942169666290283, 20.440805435180664, 0.7243496179580688], step: 15000, lr: 9.305267080825953e-05, reference_loss: 30.913772583007812
2024-01-01 22:25:44,043	44k	INFO	====> Epoch: 577, cost 23.57 s
2024-01-01 22:26:07,255	44k	INFO	====> Epoch: 578, cost 23.21 s
2024-01-01 22:26:30,268	44k	INFO	====> Epoch: 579, cost 23.01 s
2024-01-01 22:26:53,181	44k	INFO	====> Epoch: 580, cost 22.91 s
2024-01-01 22:27:16,334	44k	INFO	====> Epoch: 581, cost 23.15 s
2024-01-01 22:27:39,512	44k	INFO	====> Epoch: 582, cost 23.18 s
2024-01-01 22:28:02,570	44k	INFO	====> Epoch: 583, cost 23.06 s
2024-01-01 22:28:25,675	44k	INFO	====> Epoch: 584, cost 23.11 s
2024-01-01 22:28:40,988	44k	INFO	Train Epoch: 585 [62%]
2024-01-01 22:28:40,990	44k	INFO	Losses: [2.58431077003479, 2.1167197227478027, 4.372685432434082, 18.295841217041016, 0.5957373976707458], step: 15200, lr: 9.295965883781867e-05, reference_loss: 27.965293884277344
2024-01-01 22:28:47,178	44k	INFO	Saving model and optimizer state at iteration 585 to ./logs/44k/G_15200.pth
2024-01-01 22:28:48,087	44k	INFO	Saving model and optimizer state at iteration 585 to ./logs/44k/D_15200.pth
2024-01-01 22:28:48,636	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_12800.pth
2024-01-01 22:28:48,676	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_12800.pth
2024-01-01 22:28:56,489	44k	INFO	====> Epoch: 585, cost 30.81 s
2024-01-01 22:29:19,668	44k	INFO	====> Epoch: 586, cost 23.18 s
2024-01-01 22:29:42,757	44k	INFO	====> Epoch: 587, cost 23.09 s
2024-01-01 22:30:05,870	44k	INFO	====> Epoch: 588, cost 23.11 s
2024-01-01 22:30:28,970	44k	INFO	====> Epoch: 589, cost 23.10 s
2024-01-01 22:30:51,985	44k	INFO	====> Epoch: 590, cost 23.02 s
2024-01-01 22:31:15,161	44k	INFO	====> Epoch: 591, cost 23.18 s
2024-01-01 22:31:38,292	44k	INFO	====> Epoch: 592, cost 23.13 s
2024-01-01 22:31:46,426	44k	INFO	Train Epoch: 593 [31%]
2024-01-01 22:31:46,429	44k	INFO	Losses: [2.1678578853607178, 2.384761333465576, 5.62996768951416, 20.717100143432617, 0.8048486113548279], step: 15400, lr: 9.286673983866569e-05, reference_loss: 31.70453453063965
2024-01-01 22:32:01,927	44k	INFO	====> Epoch: 593, cost 23.64 s
2024-01-01 22:32:25,143	44k	INFO	====> Epoch: 594, cost 23.22 s
2024-01-01 22:32:48,287	44k	INFO	====> Epoch: 595, cost 23.14 s
2024-01-01 22:33:11,466	44k	INFO	====> Epoch: 596, cost 23.18 s
2024-01-01 22:33:34,469	44k	INFO	====> Epoch: 597, cost 23.00 s
2024-01-01 22:33:57,792	44k	INFO	====> Epoch: 598, cost 23.32 s
2024-01-01 22:34:20,883	44k	INFO	====> Epoch: 599, cost 23.09 s
2024-01-01 22:34:43,986	44k	INFO	====> Epoch: 600, cost 23.10 s
2024-01-01 22:34:44,897	44k	INFO	Train Epoch: 601 [0%]
2024-01-01 22:34:44,898	44k	INFO	Losses: [2.3851985931396484, 2.6314690113067627, 6.105772495269775, 22.137136459350586, 0.44626888632774353], step: 15600, lr: 9.277391371786995e-05, reference_loss: 33.70584487915039
2024-01-01 22:35:07,569	44k	INFO	====> Epoch: 601, cost 23.58 s
2024-01-01 22:35:30,726	44k	INFO	====> Epoch: 602, cost 23.16 s
2024-01-01 22:35:53,819	44k	INFO	====> Epoch: 603, cost 23.09 s
2024-01-01 22:36:16,793	44k	INFO	====> Epoch: 604, cost 22.97 s
2024-01-01 22:36:39,730	44k	INFO	====> Epoch: 605, cost 22.94 s
2024-01-01 22:37:02,688	44k	INFO	====> Epoch: 606, cost 22.96 s
2024-01-01 22:37:25,839	44k	INFO	====> Epoch: 607, cost 23.15 s
2024-01-01 22:37:42,793	44k	INFO	Train Epoch: 608 [69%]
2024-01-01 22:37:42,795	44k	INFO	Losses: [2.0173797607421875, 2.50703763961792, 7.004368782043457, 23.792932510375977, 0.6104849576950073], step: 15800, lr: 9.269276697846605e-05, reference_loss: 35.93220138549805
2024-01-01 22:37:49,365	44k	INFO	====> Epoch: 608, cost 23.53 s
2024-01-01 22:38:12,487	44k	INFO	====> Epoch: 609, cost 23.12 s
2024-01-01 22:38:35,444	44k	INFO	====> Epoch: 610, cost 22.96 s
2024-01-01 22:38:58,550	44k	INFO	====> Epoch: 611, cost 23.11 s
2024-01-01 22:39:21,606	44k	INFO	====> Epoch: 612, cost 23.06 s
2024-01-01 22:39:44,676	44k	INFO	====> Epoch: 613, cost 23.07 s
2024-01-01 22:40:07,747	44k	INFO	====> Epoch: 614, cost 23.07 s
2024-01-01 22:40:30,826	44k	INFO	====> Epoch: 615, cost 23.08 s
2024-01-01 22:40:40,744	44k	INFO	Train Epoch: 616 [38%]
2024-01-01 22:40:40,746	44k	INFO	Losses: [2.4107038974761963, 2.160628318786621, 4.4754638671875, 19.22007179260254, 0.7368190288543701], step: 16000, lr: 9.260011475443641e-05, reference_loss: 29.003686904907227
2024-01-01 22:40:47,236	44k	INFO	Saving model and optimizer state at iteration 616 to ./logs/44k/G_16000.pth
2024-01-01 22:40:48,145	44k	INFO	Saving model and optimizer state at iteration 616 to ./logs/44k/D_16000.pth
2024-01-01 22:40:48,677	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_13600.pth
2024-01-01 22:40:48,717	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_13600.pth
2024-01-01 22:41:01,724	44k	INFO	====> Epoch: 616, cost 30.90 s
2024-01-01 22:41:24,711	44k	INFO	====> Epoch: 617, cost 22.99 s
2024-01-01 22:41:48,139	44k	INFO	====> Epoch: 618, cost 23.43 s
2024-01-01 22:42:11,253	44k	INFO	====> Epoch: 619, cost 23.11 s
2024-01-01 22:42:34,358	44k	INFO	====> Epoch: 620, cost 23.10 s
2024-01-01 22:42:57,511	44k	INFO	====> Epoch: 621, cost 23.15 s
2024-01-01 22:43:20,713	44k	INFO	====> Epoch: 622, cost 23.20 s
2024-01-01 22:43:43,900	44k	INFO	====> Epoch: 623, cost 23.19 s
2024-01-01 22:43:46,618	44k	INFO	Train Epoch: 624 [8%]
2024-01-01 22:43:46,621	44k	INFO	Losses: [2.5734729766845703, 2.3343088626861572, 4.775425910949707, 20.041988372802734, 0.5234963893890381], step: 16200, lr: 9.250755514210558e-05, reference_loss: 30.248693466186523
2024-01-01 22:44:07,700	44k	INFO	====> Epoch: 624, cost 23.80 s
2024-01-01 22:44:30,862	44k	INFO	====> Epoch: 625, cost 23.16 s
2024-01-01 22:44:54,040	44k	INFO	====> Epoch: 626, cost 23.18 s
2024-01-01 22:45:17,108	44k	INFO	====> Epoch: 627, cost 23.07 s
2024-01-01 22:45:40,085	44k	INFO	====> Epoch: 628, cost 22.98 s
2024-01-01 22:46:03,031	44k	INFO	====> Epoch: 629, cost 22.95 s
2024-01-01 22:46:26,037	44k	INFO	====> Epoch: 630, cost 23.01 s
2024-01-01 22:46:44,873	44k	INFO	Train Epoch: 631 [77%]
2024-01-01 22:46:44,875	44k	INFO	Losses: [2.015498161315918, 2.811401844024658, 7.514585494995117, 23.796958923339844, 0.678996741771698], step: 16400, lr: 9.242664137907478e-05, reference_loss: 36.817440032958984
2024-01-01 22:46:49,633	44k	INFO	====> Epoch: 631, cost 23.60 s
2024-01-01 22:47:12,748	44k	INFO	====> Epoch: 632, cost 23.12 s
2024-01-01 22:47:36,041	44k	INFO	====> Epoch: 633, cost 23.29 s
2024-01-01 22:47:59,104	44k	INFO	====> Epoch: 634, cost 23.06 s
2024-01-01 22:48:22,238	44k	INFO	====> Epoch: 635, cost 23.13 s
2024-01-01 22:48:45,376	44k	INFO	====> Epoch: 636, cost 23.14 s
2024-01-01 22:49:08,485	44k	INFO	====> Epoch: 637, cost 23.11 s
2024-01-01 22:49:31,529	44k	INFO	====> Epoch: 638, cost 23.04 s
2024-01-01 22:49:43,079	44k	INFO	Train Epoch: 639 [46%]
2024-01-01 22:49:43,082	44k	INFO	Losses: [2.3074352741241455, 2.527815818786621, 5.623569965362549, 21.529966354370117, 0.6988338232040405], step: 16600, lr: 9.233425516424368e-05, reference_loss: 32.6876220703125
2024-01-01 22:49:54,964	44k	INFO	====> Epoch: 639, cost 23.43 s
2024-01-01 22:50:17,917	44k	INFO	====> Epoch: 640, cost 22.95 s
2024-01-01 22:50:40,970	44k	INFO	====> Epoch: 641, cost 23.05 s
2024-01-01 22:51:04,211	44k	INFO	====> Epoch: 642, cost 23.24 s
2024-01-01 22:51:27,170	44k	INFO	====> Epoch: 643, cost 22.96 s
2024-01-01 22:51:50,145	44k	INFO	====> Epoch: 644, cost 22.98 s
2024-01-01 22:52:13,144	44k	INFO	====> Epoch: 645, cost 23.00 s
2024-01-01 22:52:36,272	44k	INFO	====> Epoch: 646, cost 23.13 s
2024-01-01 22:52:40,799	44k	INFO	Train Epoch: 647 [15%]
2024-01-01 22:52:40,801	44k	INFO	Losses: [2.295219659805298, 2.6448068618774414, 6.535399913787842, 22.483463287353516, 0.5339415073394775], step: 16800, lr: 9.224196129521857e-05, reference_loss: 34.49283218383789
2024-01-01 22:52:46,884	44k	INFO	Saving model and optimizer state at iteration 647 to ./logs/44k/G_16800.pth
2024-01-01 22:52:47,780	44k	INFO	Saving model and optimizer state at iteration 647 to ./logs/44k/D_16800.pth
2024-01-01 22:52:48,305	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_14400.pth
2024-01-01 22:52:48,344	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_14400.pth
2024-01-01 22:53:06,901	44k	INFO	====> Epoch: 647, cost 30.63 s
2024-01-01 22:53:29,897	44k	INFO	====> Epoch: 648, cost 23.00 s
2024-01-01 22:53:52,813	44k	INFO	====> Epoch: 649, cost 22.92 s
2024-01-01 22:54:16,126	44k	INFO	====> Epoch: 650, cost 23.31 s
2024-01-01 22:54:39,195	44k	INFO	====> Epoch: 651, cost 23.07 s
2024-01-01 22:55:02,268	44k	INFO	====> Epoch: 652, cost 23.07 s
2024-01-01 22:55:25,311	44k	INFO	====> Epoch: 653, cost 23.04 s
2024-01-01 22:55:45,853	44k	INFO	Train Epoch: 654 [85%]
2024-01-01 22:55:45,856	44k	INFO	Losses: [2.4177656173706055, 2.4278624057769775, 4.4676594734191895, 20.10731315612793, 0.7515913248062134], step: 17000, lr: 9.216127983967398e-05, reference_loss: 30.172191619873047
2024-01-01 22:55:48,762	44k	INFO	====> Epoch: 654, cost 23.45 s
2024-01-01 22:56:11,737	44k	INFO	====> Epoch: 655, cost 22.97 s
2024-01-01 22:56:34,665	44k	INFO	====> Epoch: 656, cost 22.93 s
2024-01-01 22:56:57,720	44k	INFO	====> Epoch: 657, cost 23.06 s
2024-01-01 22:57:20,837	44k	INFO	====> Epoch: 658, cost 23.12 s
2024-01-01 22:57:43,977	44k	INFO	====> Epoch: 659, cost 23.14 s
2024-01-01 22:58:07,124	44k	INFO	====> Epoch: 660, cost 23.15 s
2024-01-01 22:58:30,416	44k	INFO	====> Epoch: 661, cost 23.29 s
2024-01-01 22:58:43,899	44k	INFO	Train Epoch: 662 [54%]
2024-01-01 22:58:43,901	44k	INFO	Losses: [2.4386613368988037, 2.2696428298950195, 5.543859481811523, 21.679128646850586, 0.7627230286598206], step: 17200, lr: 9.206915887031564e-05, reference_loss: 32.69401550292969
2024-01-01 22:58:53,983	44k	INFO	====> Epoch: 662, cost 23.57 s
2024-01-01 22:59:16,938	44k	INFO	====> Epoch: 663, cost 22.96 s
2024-01-01 22:59:39,999	44k	INFO	====> Epoch: 664, cost 23.06 s
2024-01-01 23:00:02,958	44k	INFO	====> Epoch: 665, cost 22.96 s
2024-01-01 23:00:25,997	44k	INFO	====> Epoch: 666, cost 23.04 s
2024-01-01 23:00:49,108	44k	INFO	====> Epoch: 667, cost 23.11 s
2024-01-01 23:01:12,021	44k	INFO	====> Epoch: 668, cost 22.91 s
2024-01-01 23:01:35,032	44k	INFO	====> Epoch: 669, cost 23.01 s
2024-01-01 23:01:41,358	44k	INFO	Train Epoch: 670 [23%]
2024-01-01 23:01:41,360	44k	INFO	Losses: [2.299811840057373, 2.3689064979553223, 4.877317428588867, 19.51140594482422, 0.5953523516654968], step: 17400, lr: 9.19771299816338e-05, reference_loss: 29.652793884277344
2024-01-01 23:01:58,835	44k	INFO	====> Epoch: 670, cost 23.80 s
2024-01-01 23:02:21,902	44k	INFO	====> Epoch: 671, cost 23.07 s
2024-01-01 23:02:44,840	44k	INFO	====> Epoch: 672, cost 22.94 s
2024-01-01 23:03:07,822	44k	INFO	====> Epoch: 673, cost 22.98 s
2024-01-01 23:03:30,900	44k	INFO	====> Epoch: 674, cost 23.08 s
2024-01-01 23:03:53,977	44k	INFO	====> Epoch: 675, cost 23.08 s
2024-01-01 23:04:16,903	44k	INFO	====> Epoch: 676, cost 22.93 s
2024-01-01 23:04:39,248	44k	INFO	Train Epoch: 677 [92%]
2024-01-01 23:04:39,250	44k	INFO	Losses: [2.5968170166015625, 2.1715846061706543, 4.816648006439209, 19.273391723632812, 0.7646995782852173], step: 17600, lr: 9.189668016660891e-05, reference_loss: 29.623140335083008
2024-01-01 23:04:45,333	44k	INFO	Saving model and optimizer state at iteration 677 to ./logs/44k/G_17600.pth
2024-01-01 23:04:46,450	44k	INFO	Saving model and optimizer state at iteration 677 to ./logs/44k/D_17600.pth
2024-01-01 23:04:46,986	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_15200.pth
2024-01-01 23:04:47,025	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_15200.pth
2024-01-01 23:04:47,718	44k	INFO	====> Epoch: 677, cost 30.82 s
2024-01-01 23:05:10,758	44k	INFO	====> Epoch: 678, cost 23.04 s
2024-01-01 23:05:33,984	44k	INFO	====> Epoch: 679, cost 23.23 s
2024-01-01 23:05:56,988	44k	INFO	====> Epoch: 680, cost 23.00 s
2024-01-01 23:06:19,937	44k	INFO	====> Epoch: 681, cost 22.95 s
2024-01-01 23:06:43,034	44k	INFO	====> Epoch: 682, cost 23.10 s
2024-01-01 23:07:06,166	44k	INFO	====> Epoch: 683, cost 23.13 s
2024-01-01 23:07:29,307	44k	INFO	====> Epoch: 684, cost 23.14 s
2024-01-01 23:07:44,488	44k	INFO	Train Epoch: 685 [62%]
2024-01-01 23:07:44,490	44k	INFO	Losses: [2.5975325107574463, 2.224809408187866, 3.6926567554473877, 17.03870391845703, 0.9593232870101929], step: 17800, lr: 9.180482368119022e-05, reference_loss: 26.51302719116211
2024-01-01 23:07:52,856	44k	INFO	====> Epoch: 685, cost 23.55 s
2024-01-01 23:08:16,137	44k	INFO	====> Epoch: 686, cost 23.28 s
2024-01-01 23:08:39,161	44k	INFO	====> Epoch: 687, cost 23.02 s
2024-01-01 23:09:02,117	44k	INFO	====> Epoch: 688, cost 22.96 s
2024-01-01 23:09:25,101	44k	INFO	====> Epoch: 689, cost 22.98 s
2024-01-01 23:09:48,238	44k	INFO	====> Epoch: 690, cost 23.14 s
2024-01-01 23:10:11,409	44k	INFO	====> Epoch: 691, cost 23.17 s
2024-01-01 23:10:34,498	44k	INFO	====> Epoch: 692, cost 23.09 s
2024-01-01 23:10:42,649	44k	INFO	Train Epoch: 693 [31%]
2024-01-01 23:10:42,652	44k	INFO	Losses: [2.046330213546753, 2.851503849029541, 5.9765143394470215, 20.09596061706543, 0.7776803374290466], step: 18000, lr: 9.171305901207978e-05, reference_loss: 31.747987747192383
2024-01-01 23:10:58,107	44k	INFO	====> Epoch: 693, cost 23.61 s
2024-01-01 23:11:21,208	44k	INFO	====> Epoch: 694, cost 23.10 s
2024-01-01 23:11:44,303	44k	INFO	====> Epoch: 695, cost 23.09 s
2024-01-01 23:12:07,521	44k	INFO	====> Epoch: 696, cost 23.22 s
2024-01-01 23:12:30,634	44k	INFO	====> Epoch: 697, cost 23.11 s
2024-01-01 23:12:53,787	44k	INFO	====> Epoch: 698, cost 23.15 s
2024-01-01 23:13:16,935	44k	INFO	====> Epoch: 699, cost 23.15 s
2024-01-01 23:13:40,057	44k	INFO	====> Epoch: 700, cost 23.12 s
2024-01-01 23:13:40,962	44k	INFO	Train Epoch: 701 [0%]
2024-01-01 23:13:40,964	44k	INFO	Losses: [2.389906883239746, 2.282170295715332, 4.778898239135742, 18.323986053466797, 0.8457810878753662], step: 18200, lr: 9.162138606750142e-05, reference_loss: 28.620742797851562
2024-01-01 23:14:03,549	44k	INFO	====> Epoch: 701, cost 23.49 s
2024-01-01 23:14:26,345	44k	INFO	====> Epoch: 702, cost 22.80 s
2024-01-01 23:14:49,415	44k	INFO	====> Epoch: 703, cost 23.07 s
2024-01-01 23:15:12,359	44k	INFO	====> Epoch: 704, cost 22.94 s
2024-01-01 23:15:35,495	44k	INFO	====> Epoch: 705, cost 23.14 s
2024-01-01 23:15:58,452	44k	INFO	====> Epoch: 706, cost 22.96 s
2024-01-01 23:16:21,580	44k	INFO	====> Epoch: 707, cost 23.13 s
2024-01-01 23:16:38,667	44k	INFO	Train Epoch: 708 [69%]
2024-01-01 23:16:38,669	44k	INFO	Losses: [2.393606185913086, 2.6098382472991943, 4.8509039878845215, 17.54518699645996, 0.7372354865074158], step: 18400, lr: 9.154124741169722e-05, reference_loss: 28.13677215576172
2024-01-01 23:16:44,651	44k	INFO	Saving model and optimizer state at iteration 708 to ./logs/44k/G_18400.pth
2024-01-01 23:16:45,548	44k	INFO	Saving model and optimizer state at iteration 708 to ./logs/44k/D_18400.pth
2024-01-01 23:16:46,080	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_16000.pth
2024-01-01 23:16:46,119	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_16000.pth
2024-01-01 23:16:52,135	44k	INFO	====> Epoch: 708, cost 30.56 s
2024-01-01 23:17:15,294	44k	INFO	====> Epoch: 709, cost 23.16 s
2024-01-01 23:17:38,515	44k	INFO	====> Epoch: 710, cost 23.22 s
2024-01-01 23:18:01,654	44k	INFO	====> Epoch: 711, cost 23.14 s
2024-01-01 23:18:24,702	44k	INFO	====> Epoch: 712, cost 23.05 s
2024-01-01 23:18:47,921	44k	INFO	====> Epoch: 713, cost 23.22 s
2024-01-01 23:19:10,991	44k	INFO	====> Epoch: 714, cost 23.07 s
2024-01-01 23:19:33,960	44k	INFO	====> Epoch: 715, cost 22.97 s
2024-01-01 23:19:43,786	44k	INFO	Train Epoch: 716 [38%]
2024-01-01 23:19:43,789	44k	INFO	Losses: [2.3822174072265625, 2.3249013423919678, 5.491127014160156, 21.61737060546875, 1.0840263366699219], step: 18600, lr: 9.144974620357048e-05, reference_loss: 32.89964294433594
2024-01-01 23:19:57,255	44k	INFO	====> Epoch: 716, cost 23.30 s
2024-01-01 23:20:20,215	44k	INFO	====> Epoch: 717, cost 22.96 s
2024-01-01 23:20:43,200	44k	INFO	====> Epoch: 718, cost 22.98 s
2024-01-01 23:21:06,150	44k	INFO	====> Epoch: 719, cost 22.95 s
2024-01-01 23:21:29,051	44k	INFO	====> Epoch: 720, cost 22.90 s
2024-01-01 23:21:52,144	44k	INFO	====> Epoch: 721, cost 23.09 s
2024-01-01 23:22:15,256	44k	INFO	====> Epoch: 722, cost 23.11 s
2024-01-01 23:22:38,539	44k	INFO	====> Epoch: 723, cost 23.28 s
2024-01-01 23:22:41,245	44k	INFO	Train Epoch: 724 [8%]
2024-01-01 23:22:41,248	44k	INFO	Losses: [2.34916353225708, 2.665780544281006, 6.021373748779297, 22.276432037353516, 0.6198359131813049], step: 18800, lr: 9.13583364566301e-05, reference_loss: 33.932586669921875
2024-01-01 23:23:02,024	44k	INFO	====> Epoch: 724, cost 23.49 s
2024-01-01 23:23:25,157	44k	INFO	====> Epoch: 725, cost 23.13 s
2024-01-01 23:23:48,123	44k	INFO	====> Epoch: 726, cost 22.97 s
2024-01-01 23:24:11,062	44k	INFO	====> Epoch: 727, cost 22.94 s
2024-01-01 23:24:34,129	44k	INFO	====> Epoch: 728, cost 23.07 s
2024-01-01 23:24:57,119	44k	INFO	====> Epoch: 729, cost 22.99 s
2024-01-01 23:25:20,159	44k	INFO	====> Epoch: 730, cost 23.04 s
2024-01-01 23:25:38,894	44k	INFO	Train Epoch: 731 [77%]
2024-01-01 23:25:38,896	44k	INFO	Losses: [1.9702411890029907, 2.8212568759918213, 7.754114151000977, 23.57270050048828, 0.5795587301254272], step: 19000, lr: 9.127842788294025e-05, reference_loss: 36.697872161865234
2024-01-01 23:25:43,774	44k	INFO	====> Epoch: 731, cost 23.61 s
2024-01-01 23:26:06,806	44k	INFO	====> Epoch: 732, cost 23.03 s
2024-01-01 23:26:29,803	44k	INFO	====> Epoch: 733, cost 23.00 s
2024-01-01 23:26:52,763	44k	INFO	====> Epoch: 734, cost 22.96 s
2024-01-01 23:27:15,884	44k	INFO	====> Epoch: 735, cost 23.12 s
2024-01-01 23:27:38,988	44k	INFO	====> Epoch: 736, cost 23.10 s
2024-01-01 23:28:02,105	44k	INFO	====> Epoch: 737, cost 23.12 s
2024-01-01 23:28:25,195	44k	INFO	====> Epoch: 738, cost 23.09 s
2024-01-01 23:28:36,836	44k	INFO	Train Epoch: 739 [46%]
2024-01-01 23:28:36,838	44k	INFO	Losses: [2.4225974082946777, 2.0490336418151855, 4.2121734619140625, 17.2946834564209, 0.549799382686615], step: 19200, lr: 9.118718937938746e-05, reference_loss: 26.528287887573242
2024-01-01 23:28:42,869	44k	INFO	Saving model and optimizer state at iteration 739 to ./logs/44k/G_19200.pth
2024-01-01 23:28:43,953	44k	INFO	Saving model and optimizer state at iteration 739 to ./logs/44k/D_19200.pth
2024-01-01 23:28:44,472	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_16800.pth
2024-01-01 23:28:44,511	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_16800.pth
2024-01-01 23:28:55,969	44k	INFO	====> Epoch: 739, cost 30.77 s
2024-01-01 23:29:19,212	44k	INFO	====> Epoch: 740, cost 23.24 s
2024-01-01 23:29:42,499	44k	INFO	====> Epoch: 741, cost 23.29 s
2024-01-01 23:30:05,488	44k	INFO	====> Epoch: 742, cost 22.99 s
2024-01-01 23:30:28,455	44k	INFO	====> Epoch: 743, cost 22.97 s
2024-01-01 23:30:51,523	44k	INFO	====> Epoch: 744, cost 23.07 s
2024-01-01 23:31:14,463	44k	INFO	====> Epoch: 745, cost 22.94 s
2024-01-01 23:31:37,486	44k	INFO	====> Epoch: 746, cost 23.02 s
2024-01-01 23:31:41,966	44k	INFO	Train Epoch: 747 [15%]
2024-01-01 23:31:41,968	44k	INFO	Losses: [2.6253538131713867, 2.0200693607330322, 4.566616535186768, 18.518753051757812, 0.6703080534934998], step: 19400, lr: 9.109604207443135e-05, reference_loss: 28.401100158691406
2024-01-01 23:32:00,876	44k	INFO	====> Epoch: 747, cost 23.39 s
2024-01-01 23:32:23,868	44k	INFO	====> Epoch: 748, cost 22.99 s
2024-01-01 23:32:47,021	44k	INFO	====> Epoch: 749, cost 23.15 s
2024-01-01 23:33:09,965	44k	INFO	====> Epoch: 750, cost 22.94 s
2024-01-01 23:33:32,995	44k	INFO	====> Epoch: 751, cost 23.03 s
2024-01-01 23:33:56,086	44k	INFO	====> Epoch: 752, cost 23.09 s
2024-01-01 23:34:19,047	44k	INFO	====> Epoch: 753, cost 22.96 s
2024-01-01 23:34:39,525	44k	INFO	Train Epoch: 754 [85%]
2024-01-01 23:34:39,528	44k	INFO	Losses: [2.3514914512634277, 2.4927425384521484, 5.485005855560303, 19.9774227142334, 0.8093010187149048], step: 19600, lr: 9.101636292227852e-05, reference_loss: 31.115964889526367
2024-01-01 23:34:42,439	44k	INFO	====> Epoch: 754, cost 23.39 s
2024-01-01 23:35:05,493	44k	INFO	====> Epoch: 755, cost 23.05 s
2024-01-01 23:35:28,669	44k	INFO	====> Epoch: 756, cost 23.18 s
2024-01-01 23:35:51,810	44k	INFO	====> Epoch: 757, cost 23.14 s
2024-01-01 23:36:15,005	44k	INFO	====> Epoch: 758, cost 23.19 s
2024-01-01 23:36:38,035	44k	INFO	====> Epoch: 759, cost 23.03 s
2024-01-01 23:37:01,093	44k	INFO	====> Epoch: 760, cost 23.06 s
2024-01-01 23:37:24,077	44k	INFO	====> Epoch: 761, cost 22.98 s
2024-01-01 23:37:37,481	44k	INFO	Train Epoch: 762 [54%]
2024-01-01 23:37:37,484	44k	INFO	Losses: [2.215148687362671, 2.69608211517334, 6.143497467041016, 20.00738525390625, 0.7077696323394775], step: 19800, lr: 9.092538636906162e-05, reference_loss: 31.76988410949707
2024-01-01 23:37:47,534	44k	INFO	====> Epoch: 762, cost 23.46 s
2024-01-01 23:38:10,571	44k	INFO	====> Epoch: 763, cost 23.04 s
2024-01-01 23:38:33,678	44k	INFO	====> Epoch: 764, cost 23.11 s
2024-01-01 23:38:56,780	44k	INFO	====> Epoch: 765, cost 23.10 s
2024-01-01 23:39:19,948	44k	INFO	====> Epoch: 766, cost 23.17 s
2024-01-01 23:39:43,057	44k	INFO	====> Epoch: 767, cost 23.11 s
2024-01-01 23:40:06,405	44k	INFO	====> Epoch: 768, cost 23.35 s
2024-01-01 23:40:29,417	44k	INFO	====> Epoch: 769, cost 23.01 s
2024-01-01 23:40:35,685	44k	INFO	Train Epoch: 770 [23%]
2024-01-01 23:40:35,687	44k	INFO	Losses: [2.6974453926086426, 2.36995530128479, 5.173403263092041, 19.703529357910156, 0.7435740232467651], step: 20000, lr: 9.083450075260563e-05, reference_loss: 30.687908172607422
2024-01-01 23:40:41,843	44k	INFO	Saving model and optimizer state at iteration 770 to ./logs/44k/G_20000.pth
2024-01-01 23:40:42,752	44k	INFO	Saving model and optimizer state at iteration 770 to ./logs/44k/D_20000.pth
2024-01-01 23:40:43,291	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_17600.pth
2024-01-01 23:40:43,332	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_17600.pth
2024-01-01 23:40:59,897	44k	INFO	====> Epoch: 770, cost 30.48 s
2024-01-01 23:41:22,839	44k	INFO	====> Epoch: 771, cost 22.94 s
2024-01-01 23:41:45,916	44k	INFO	====> Epoch: 772, cost 23.08 s
2024-01-01 23:42:08,911	44k	INFO	====> Epoch: 773, cost 22.99 s
2024-01-01 23:42:31,926	44k	INFO	====> Epoch: 774, cost 23.02 s
2024-01-01 23:42:55,244	44k	INFO	====> Epoch: 775, cost 23.32 s
2024-01-01 23:43:18,348	44k	INFO	====> Epoch: 776, cost 23.10 s
2024-01-01 23:43:40,768	44k	INFO	Train Epoch: 777 [92%]
2024-01-01 23:43:40,771	44k	INFO	Losses: [2.358619451522827, 2.383039712905884, 5.112362384796143, 19.245149612426758, 0.9742250442504883], step: 20200, lr: 9.0755050363309e-05, reference_loss: 30.073394775390625
2024-01-01 23:43:41,900	44k	INFO	====> Epoch: 777, cost 23.55 s
2024-01-01 23:44:04,899	44k	INFO	====> Epoch: 778, cost 23.00 s
2024-01-01 23:44:27,912	44k	INFO	====> Epoch: 779, cost 23.01 s
2024-01-01 23:44:51,084	44k	INFO	====> Epoch: 780, cost 23.17 s
2024-01-01 23:45:14,226	44k	INFO	====> Epoch: 781, cost 23.14 s
2024-01-01 23:45:37,380	44k	INFO	====> Epoch: 782, cost 23.15 s
2024-01-01 23:46:00,512	44k	INFO	====> Epoch: 783, cost 23.13 s
2024-01-01 23:46:23,660	44k	INFO	====> Epoch: 784, cost 23.15 s
2024-01-01 23:46:38,932	44k	INFO	Train Epoch: 785 [62%]
2024-01-01 23:46:38,934	44k	INFO	Losses: [2.5871307849884033, 2.1767172813415527, 5.2528300285339355, 19.13174057006836, 0.8070648908615112], step: 20400, lr: 9.066433500835542e-05, reference_loss: 29.955482482910156
2024-01-01 23:46:47,413	44k	INFO	====> Epoch: 785, cost 23.75 s
2024-01-01 23:47:10,632	44k	INFO	====> Epoch: 786, cost 23.22 s
2024-01-01 23:47:33,810	44k	INFO	====> Epoch: 787, cost 23.18 s
2024-01-01 23:47:56,777	44k	INFO	====> Epoch: 788, cost 22.97 s
2024-01-01 23:48:19,997	44k	INFO	====> Epoch: 789, cost 23.22 s
2024-01-01 23:48:43,169	44k	INFO	====> Epoch: 790, cost 23.17 s
2024-01-01 23:49:06,316	44k	INFO	====> Epoch: 791, cost 23.15 s
2024-01-01 23:49:29,475	44k	INFO	====> Epoch: 792, cost 23.16 s
2024-01-01 23:49:37,573	44k	INFO	Train Epoch: 793 [31%]
2024-01-01 23:49:37,575	44k	INFO	Losses: [2.3612332344055176, 2.527033567428589, 5.420010089874268, 18.00152015686035, 0.7047948837280273], step: 20600, lr: 9.057371032907876e-05, reference_loss: 29.014591217041016
2024-01-01 23:49:52,993	44k	INFO	====> Epoch: 793, cost 23.52 s
2024-01-01 23:50:16,283	44k	INFO	====> Epoch: 794, cost 23.29 s
2024-01-01 23:50:39,401	44k	INFO	====> Epoch: 795, cost 23.12 s
2024-01-01 23:51:02,507	44k	INFO	====> Epoch: 796, cost 23.11 s
2024-01-01 23:51:25,648	44k	INFO	====> Epoch: 797, cost 23.14 s
2024-01-01 23:51:48,836	44k	INFO	====> Epoch: 798, cost 23.19 s
2024-01-01 23:52:11,986	44k	INFO	====> Epoch: 799, cost 23.15 s
2024-01-01 23:52:35,122	44k	INFO	====> Epoch: 800, cost 23.14 s
2024-01-01 23:52:36,031	44k	INFO	Train Epoch: 801 [0%]
2024-01-01 23:52:36,034	44k	INFO	Losses: [2.348930597305298, 2.474865436553955, 5.9073486328125, 20.194129943847656, 0.4620034694671631], step: 20800, lr: 9.048317623484297e-05, reference_loss: 31.387277603149414
2024-01-01 23:52:42,088	44k	INFO	Saving model and optimizer state at iteration 801 to ./logs/44k/G_20800.pth
2024-01-01 23:52:42,984	44k	INFO	Saving model and optimizer state at iteration 801 to ./logs/44k/D_20800.pth
2024-01-01 23:52:43,512	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_18400.pth
2024-01-01 23:52:43,553	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_18400.pth
2024-01-01 23:53:05,909	44k	INFO	====> Epoch: 801, cost 30.79 s
2024-01-01 23:53:29,115	44k	INFO	====> Epoch: 802, cost 23.21 s
2024-01-01 23:53:52,341	44k	INFO	====> Epoch: 803, cost 23.23 s
2024-01-01 23:54:15,367	44k	INFO	====> Epoch: 804, cost 23.03 s
2024-01-01 23:54:38,320	44k	INFO	====> Epoch: 805, cost 22.95 s
2024-01-01 23:55:01,339	44k	INFO	====> Epoch: 806, cost 23.02 s
2024-01-01 23:55:24,333	44k	INFO	====> Epoch: 807, cost 22.99 s
2024-01-01 23:55:41,273	44k	INFO	Train Epoch: 808 [69%]
2024-01-01 23:55:41,274	44k	INFO	Losses: [2.3265018463134766, 2.2996113300323486, 5.99825382232666, 20.278581619262695, 0.907270610332489], step: 21000, lr: 9.040403313924505e-05, reference_loss: 31.810218811035156
2024-01-01 23:55:47,708	44k	INFO	====> Epoch: 808, cost 23.38 s
2024-01-01 23:56:10,762	44k	INFO	====> Epoch: 809, cost 23.05 s
2024-01-01 23:56:33,772	44k	INFO	====> Epoch: 810, cost 23.01 s
2024-01-01 23:56:56,884	44k	INFO	====> Epoch: 811, cost 23.11 s
2024-01-01 23:57:19,858	44k	INFO	====> Epoch: 812, cost 22.97 s
2024-01-01 23:57:42,959	44k	INFO	====> Epoch: 813, cost 23.10 s
2024-01-01 23:58:06,088	44k	INFO	====> Epoch: 814, cost 23.13 s
2024-01-01 23:58:29,234	44k	INFO	====> Epoch: 815, cost 23.15 s
2024-01-01 23:58:39,189	44k	INFO	Train Epoch: 816 [38%]
2024-01-01 23:58:39,192	44k	INFO	Losses: [2.452425241470337, 2.3075149059295654, 5.782520294189453, 20.048755645751953, 0.5280033349990845], step: 21200, lr: 9.031366864798387e-05, reference_loss: 31.119220733642578
2024-01-01 23:58:52,798	44k	INFO	====> Epoch: 816, cost 23.56 s
2024-01-01 23:59:15,944	44k	INFO	====> Epoch: 817, cost 23.15 s
2024-01-01 23:59:38,980	44k	INFO	====> Epoch: 818, cost 23.04 s
2024-01-02 00:00:02,036	44k	INFO	====> Epoch: 819, cost 23.06 s
2024-01-02 00:00:24,970	44k	INFO	====> Epoch: 820, cost 22.93 s
2024-01-02 00:00:48,072	44k	INFO	====> Epoch: 821, cost 23.10 s
2024-01-02 00:01:11,060	44k	INFO	====> Epoch: 822, cost 22.99 s
2024-01-02 00:01:34,223	44k	INFO	====> Epoch: 823, cost 23.16 s
2024-01-02 00:01:36,912	44k	INFO	Train Epoch: 824 [8%]
2024-01-02 00:01:36,914	44k	INFO	Losses: [2.4219655990600586, 2.4145076274871826, 5.917908191680908, 21.029827117919922, 0.6826988458633423], step: 21400, lr: 9.022339448168936e-05, reference_loss: 32.4669075012207
2024-01-02 00:01:57,714	44k	INFO	====> Epoch: 824, cost 23.49 s
2024-01-02 00:02:20,841	44k	INFO	====> Epoch: 825, cost 23.13 s
2024-01-02 00:02:43,940	44k	INFO	====> Epoch: 826, cost 23.10 s
2024-01-02 00:03:07,106	44k	INFO	====> Epoch: 827, cost 23.17 s
2024-01-02 00:03:30,270	44k	INFO	====> Epoch: 828, cost 23.16 s
2024-01-02 00:03:53,425	44k	INFO	====> Epoch: 829, cost 23.15 s
2024-01-02 00:04:16,586	44k	INFO	====> Epoch: 830, cost 23.16 s
2024-01-02 00:04:35,373	44k	INFO	Train Epoch: 831 [77%]
2024-01-02 00:04:35,375	44k	INFO	Losses: [2.2791881561279297, 2.396188259124756, 6.049055099487305, 20.44346809387207, 0.9389811754226685], step: 21600, lr: 9.014447860990232e-05, reference_loss: 32.10688018798828
2024-01-02 00:04:41,583	44k	INFO	Saving model and optimizer state at iteration 831 to ./logs/44k/G_21600.pth
2024-01-02 00:04:42,486	44k	INFO	Saving model and optimizer state at iteration 831 to ./logs/44k/D_21600.pth
2024-01-02 00:04:43,023	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_19200.pth
2024-01-02 00:04:43,062	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_19200.pth
2024-01-02 00:04:47,283	44k	INFO	====> Epoch: 831, cost 30.70 s
2024-01-02 00:05:10,203	44k	INFO	====> Epoch: 832, cost 22.92 s
2024-01-02 00:05:33,212	44k	INFO	====> Epoch: 833, cost 23.01 s
2024-01-02 00:05:56,262	44k	INFO	====> Epoch: 834, cost 23.05 s
2024-01-02 00:06:19,356	44k	INFO	====> Epoch: 835, cost 23.09 s
2024-01-02 00:06:42,322	44k	INFO	====> Epoch: 836, cost 22.97 s
2024-01-02 00:07:05,301	44k	INFO	====> Epoch: 837, cost 22.98 s
2024-01-02 00:07:28,262	44k	INFO	====> Epoch: 838, cost 22.96 s
2024-01-02 00:07:39,855	44k	INFO	Train Epoch: 839 [46%]
2024-01-02 00:07:39,857	44k	INFO	Losses: [2.4247097969055176, 2.347564458847046, 7.005914211273193, 21.356687545776367, 0.6686326265335083], step: 21800, lr: 9.005437355964375e-05, reference_loss: 33.80350875854492
2024-01-02 00:07:51,865	44k	INFO	====> Epoch: 839, cost 23.60 s
2024-01-02 00:08:15,040	44k	INFO	====> Epoch: 840, cost 23.17 s
2024-01-02 00:08:38,068	44k	INFO	====> Epoch: 841, cost 23.03 s
2024-01-02 00:09:01,191	44k	INFO	====> Epoch: 842, cost 23.12 s
2024-01-02 00:09:24,313	44k	INFO	====> Epoch: 843, cost 23.12 s
2024-01-02 00:09:47,305	44k	INFO	====> Epoch: 844, cost 22.99 s
2024-01-02 00:10:10,372	44k	INFO	====> Epoch: 845, cost 23.07 s
2024-01-02 00:10:33,503	44k	INFO	====> Epoch: 846, cost 23.13 s
2024-01-02 00:10:38,018	44k	INFO	Train Epoch: 847 [15%]
2024-01-02 00:10:38,020	44k	INFO	Losses: [2.6528193950653076, 2.516533851623535, 6.003824710845947, 20.653358459472656, 0.5257204174995422], step: 22000, lr: 8.996435857502436e-05, reference_loss: 32.352256774902344
2024-01-02 00:10:57,051	44k	INFO	====> Epoch: 847, cost 23.55 s
2024-01-02 00:11:20,212	44k	INFO	====> Epoch: 848, cost 23.16 s
2024-01-02 00:11:43,514	44k	INFO	====> Epoch: 849, cost 23.30 s
2024-01-02 00:12:06,652	44k	INFO	====> Epoch: 850, cost 23.14 s
2024-01-02 00:12:29,804	44k	INFO	====> Epoch: 851, cost 23.15 s
2024-01-02 00:12:52,928	44k	INFO	====> Epoch: 852, cost 23.12 s
2024-01-02 00:13:15,921	44k	INFO	====> Epoch: 853, cost 22.99 s
2024-01-02 00:13:36,341	44k	INFO	Train Epoch: 854 [85%]
2024-01-02 00:13:36,343	44k	INFO	Losses: [2.3198957443237305, 2.967437982559204, 7.12819766998291, 19.745948791503906, 0.7948439121246338], step: 22200, lr: 8.98856692746772e-05, reference_loss: 32.95632553100586
2024-01-02 00:13:39,271	44k	INFO	====> Epoch: 854, cost 23.35 s
2024-01-02 00:14:02,370	44k	INFO	====> Epoch: 855, cost 23.10 s
2024-01-02 00:14:25,474	44k	INFO	====> Epoch: 856, cost 23.10 s
2024-01-02 00:14:48,645	44k	INFO	====> Epoch: 857, cost 23.17 s
2024-01-02 00:15:11,864	44k	INFO	====> Epoch: 858, cost 23.22 s
2024-01-02 00:15:34,926	44k	INFO	====> Epoch: 859, cost 23.06 s
2024-01-02 00:15:58,106	44k	INFO	====> Epoch: 860, cost 23.18 s
2024-01-02 00:16:21,162	44k	INFO	====> Epoch: 861, cost 23.06 s
2024-01-02 00:16:34,562	44k	INFO	Train Epoch: 862 [54%]
2024-01-02 00:16:34,565	44k	INFO	Losses: [2.229641914367676, 2.810248374938965, 7.402453899383545, 20.684106826782227, 0.4646117687225342], step: 22400, lr: 8.979582292055309e-05, reference_loss: 33.591060638427734
2024-01-02 00:16:40,665	44k	INFO	Saving model and optimizer state at iteration 862 to ./logs/44k/G_22400.pth
2024-01-02 00:16:41,567	44k	INFO	Saving model and optimizer state at iteration 862 to ./logs/44k/D_22400.pth
2024-01-02 00:16:42,095	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_20000.pth
2024-01-02 00:16:42,135	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_20000.pth
2024-01-02 00:16:51,675	44k	INFO	====> Epoch: 862, cost 30.51 s
2024-01-02 00:17:14,783	44k	INFO	====> Epoch: 863, cost 23.11 s
2024-01-02 00:17:38,017	44k	INFO	====> Epoch: 864, cost 23.23 s
2024-01-02 00:18:01,053	44k	INFO	====> Epoch: 865, cost 23.04 s
2024-01-02 00:18:24,354	44k	INFO	====> Epoch: 866, cost 23.30 s
2024-01-02 00:18:47,507	44k	INFO	====> Epoch: 867, cost 23.15 s
2024-01-02 00:19:10,645	44k	INFO	====> Epoch: 868, cost 23.14 s
2024-01-02 00:19:33,844	44k	INFO	====> Epoch: 869, cost 23.20 s
2024-01-02 00:19:40,186	44k	INFO	Train Epoch: 870 [23%]
2024-01-02 00:19:40,187	44k	INFO	Losses: [2.690763473510742, 2.138324499130249, 4.3086042404174805, 17.692344665527344, 0.7896150946617126], step: 22600, lr: 8.970606637348517e-05, reference_loss: 27.619651794433594
2024-01-02 00:19:57,405	44k	INFO	====> Epoch: 870, cost 23.56 s
2024-01-02 00:20:20,575	44k	INFO	====> Epoch: 871, cost 23.17 s
2024-01-02 00:20:43,605	44k	INFO	====> Epoch: 872, cost 23.03 s
2024-01-02 00:21:06,752	44k	INFO	====> Epoch: 873, cost 23.15 s
2024-01-02 00:21:29,929	44k	INFO	====> Epoch: 874, cost 23.18 s
2024-01-02 00:21:52,960	44k	INFO	====> Epoch: 875, cost 23.03 s
2024-01-02 00:22:16,051	44k	INFO	====> Epoch: 876, cost 23.09 s
2024-01-02 00:22:38,585	44k	INFO	Train Epoch: 877 [92%]
2024-01-02 00:22:38,587	44k	INFO	Losses: [2.481708526611328, 2.595538854598999, 6.133622646331787, 22.06905746459961, 0.9737484455108643], step: 22800, lr: 8.962760299407988e-05, reference_loss: 34.25367736816406
2024-01-02 00:22:39,713	44k	INFO	====> Epoch: 877, cost 23.66 s
2024-01-02 00:23:02,802	44k	INFO	====> Epoch: 878, cost 23.09 s
2024-01-02 00:23:25,987	44k	INFO	====> Epoch: 879, cost 23.19 s
2024-01-02 00:23:49,128	44k	INFO	====> Epoch: 880, cost 23.14 s
2024-01-02 00:24:12,115	44k	INFO	====> Epoch: 881, cost 22.99 s
2024-01-02 00:24:35,155	44k	INFO	====> Epoch: 882, cost 23.04 s
2024-01-02 00:24:58,395	44k	INFO	====> Epoch: 883, cost 23.24 s
2024-01-02 00:25:21,398	44k	INFO	====> Epoch: 884, cost 23.00 s
2024-01-02 00:25:36,711	44k	INFO	Train Epoch: 885 [62%]
2024-01-02 00:25:36,714	44k	INFO	Losses: [2.3210554122924805, 2.427035331726074, 5.495707035064697, 20.347570419311523, 0.521787166595459], step: 23000, lr: 8.95380145933606e-05, reference_loss: 31.113155364990234
2024-01-02 00:25:45,213	44k	INFO	====> Epoch: 885, cost 23.82 s
2024-01-02 00:26:08,397	44k	INFO	====> Epoch: 886, cost 23.18 s
2024-01-02 00:26:31,342	44k	INFO	====> Epoch: 887, cost 22.95 s
2024-01-02 00:26:54,368	44k	INFO	====> Epoch: 888, cost 23.03 s
2024-01-02 00:27:17,456	44k	INFO	====> Epoch: 889, cost 23.09 s
2024-01-02 00:27:40,435	44k	INFO	====> Epoch: 890, cost 22.98 s
2024-01-02 00:28:03,545	44k	INFO	====> Epoch: 891, cost 23.11 s
2024-01-02 00:28:26,716	44k	INFO	====> Epoch: 892, cost 23.17 s
2024-01-02 00:28:34,859	44k	INFO	Train Epoch: 893 [31%]
2024-01-02 00:28:34,861	44k	INFO	Losses: [2.119687795639038, 2.5726120471954346, 5.670839786529541, 17.35623550415039, 0.777836263179779], step: 23200, lr: 8.944851574185691e-05, reference_loss: 28.497211456298828
2024-01-02 00:28:41,119	44k	INFO	Saving model and optimizer state at iteration 893 to ./logs/44k/G_23200.pth
2024-01-02 00:28:42,254	44k	INFO	Saving model and optimizer state at iteration 893 to ./logs/44k/D_23200.pth
2024-01-02 00:28:42,795	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_20800.pth
2024-01-02 00:28:42,835	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_20800.pth
2024-01-02 00:28:57,693	44k	INFO	====> Epoch: 893, cost 30.98 s
2024-01-02 00:29:20,469	44k	INFO	====> Epoch: 894, cost 22.78 s
2024-01-02 00:29:43,411	44k	INFO	====> Epoch: 895, cost 22.94 s
2024-01-02 00:30:06,427	44k	INFO	====> Epoch: 896, cost 23.02 s
2024-01-02 00:30:29,493	44k	INFO	====> Epoch: 897, cost 23.07 s
2024-01-02 00:30:52,678	44k	INFO	====> Epoch: 898, cost 23.18 s
2024-01-02 00:31:15,889	44k	INFO	====> Epoch: 899, cost 23.21 s
2024-01-02 00:31:38,922	44k	INFO	====> Epoch: 900, cost 23.03 s
2024-01-02 00:31:39,823	44k	INFO	Train Epoch: 901 [0%]
2024-01-02 00:31:39,825	44k	INFO	Losses: [2.227898120880127, 2.7412078380584717, 6.671187400817871, 20.25956916809082, 0.5677411556243896], step: 23400, lr: 8.935910635005875e-05, reference_loss: 32.46760177612305
2024-01-02 00:32:02,315	44k	INFO	====> Epoch: 901, cost 23.39 s
2024-01-02 00:32:25,402	44k	INFO	====> Epoch: 902, cost 23.09 s
2024-01-02 00:32:48,431	44k	INFO	====> Epoch: 903, cost 23.03 s
2024-01-02 00:33:11,576	44k	INFO	====> Epoch: 904, cost 23.15 s
2024-01-02 00:33:34,742	44k	INFO	====> Epoch: 905, cost 23.17 s
2024-01-02 00:33:57,884	44k	INFO	====> Epoch: 906, cost 23.14 s
2024-01-02 00:34:21,034	44k	INFO	====> Epoch: 907, cost 23.15 s
2024-01-02 00:34:38,154	44k	INFO	Train Epoch: 908 [69%]
2024-01-02 00:34:38,156	44k	INFO	Losses: [2.4744136333465576, 2.3311588764190674, 5.7741007804870605, 20.63547706604004, 0.6315689086914062], step: 23600, lr: 8.928094644685142e-05, reference_loss: 31.84671974182129
2024-01-02 00:34:44,656	44k	INFO	====> Epoch: 908, cost 23.62 s
2024-01-02 00:35:07,858	44k	INFO	====> Epoch: 909, cost 23.20 s
2024-01-02 00:35:31,031	44k	INFO	====> Epoch: 910, cost 23.17 s
2024-01-02 00:35:54,248	44k	INFO	====> Epoch: 911, cost 23.22 s
2024-01-02 00:36:17,668	44k	INFO	====> Epoch: 912, cost 23.42 s
2024-01-02 00:36:40,693	44k	INFO	====> Epoch: 913, cost 23.03 s
2024-01-02 00:37:03,789	44k	INFO	====> Epoch: 914, cost 23.10 s
2024-01-02 00:37:27,008	44k	INFO	====> Epoch: 915, cost 23.22 s
2024-01-02 00:37:36,920	44k	INFO	Train Epoch: 916 [38%]
2024-01-02 00:37:36,923	44k	INFO	Losses: [2.354647636413574, 2.176536798477173, 6.142086029052734, 20.20996856689453, 0.630892276763916], step: 23800, lr: 8.919170455105502e-05, reference_loss: 31.514131546020508
2024-01-02 00:37:50,551	44k	INFO	====> Epoch: 916, cost 23.54 s
2024-01-02 00:38:13,757	44k	INFO	====> Epoch: 917, cost 23.21 s
2024-01-02 00:38:36,882	44k	INFO	====> Epoch: 918, cost 23.12 s
2024-01-02 00:38:59,850	44k	INFO	====> Epoch: 919, cost 22.97 s
2024-01-02 00:39:23,014	44k	INFO	====> Epoch: 920, cost 23.16 s
2024-01-02 00:39:46,374	44k	INFO	====> Epoch: 921, cost 23.36 s
2024-01-02 00:40:09,525	44k	INFO	====> Epoch: 922, cost 23.15 s
2024-01-02 00:40:32,661	44k	INFO	====> Epoch: 923, cost 23.14 s
2024-01-02 00:40:35,370	44k	INFO	Train Epoch: 924 [8%]
2024-01-02 00:40:35,372	44k	INFO	Losses: [2.142340660095215, 2.52248477935791, 6.9581074714660645, 22.786054611206055, 0.5097617506980896], step: 24000, lr: 8.910255185812085e-05, reference_loss: 34.91875076293945
2024-01-02 00:40:41,575	44k	INFO	Saving model and optimizer state at iteration 924 to ./logs/44k/G_24000.pth
2024-01-02 00:40:42,459	44k	INFO	Saving model and optimizer state at iteration 924 to ./logs/44k/D_24000.pth
2024-01-02 00:40:43,001	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_21600.pth
2024-01-02 00:40:43,040	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_21600.pth
2024-01-02 00:41:03,287	44k	INFO	====> Epoch: 924, cost 30.63 s
2024-01-02 00:41:26,329	44k	INFO	====> Epoch: 925, cost 23.04 s
2024-01-02 00:41:49,449	44k	INFO	====> Epoch: 926, cost 23.12 s
2024-01-02 00:42:12,467	44k	INFO	====> Epoch: 927, cost 23.02 s
2024-01-02 00:42:35,509	44k	INFO	====> Epoch: 928, cost 23.04 s
2024-01-02 00:42:58,878	44k	INFO	====> Epoch: 929, cost 23.37 s
2024-01-02 00:43:22,081	44k	INFO	====> Epoch: 930, cost 23.20 s
2024-01-02 00:43:40,977	44k	INFO	Train Epoch: 931 [77%]
2024-01-02 00:43:40,979	44k	INFO	Losses: [2.332061290740967, 2.329838991165161, 6.568911075592041, 19.650232315063477, 0.7251299619674683], step: 24200, lr: 8.902461635592956e-05, reference_loss: 31.60617446899414
2024-01-02 00:43:45,648	44k	INFO	====> Epoch: 931, cost 23.57 s
2024-01-02 00:44:08,773	44k	INFO	====> Epoch: 932, cost 23.13 s
2024-01-02 00:44:31,936	44k	INFO	====> Epoch: 933, cost 23.16 s
2024-01-02 00:44:55,120	44k	INFO	====> Epoch: 934, cost 23.18 s
2024-01-02 00:45:18,342	44k	INFO	====> Epoch: 935, cost 23.22 s
2024-01-02 00:45:41,487	44k	INFO	====> Epoch: 936, cost 23.14 s
2024-01-02 00:46:04,629	44k	INFO	====> Epoch: 937, cost 23.14 s
2024-01-02 00:46:27,787	44k	INFO	====> Epoch: 938, cost 23.16 s
2024-01-02 00:46:39,449	44k	INFO	Train Epoch: 939 [46%]
2024-01-02 00:46:39,452	44k	INFO	Losses: [2.5690343379974365, 2.0821480751037598, 4.460511207580566, 18.644311904907227, 0.52921062707901], step: 24400, lr: 8.893563067810772e-05, reference_loss: 28.285215377807617
2024-01-02 00:46:51,578	44k	INFO	====> Epoch: 939, cost 23.79 s
2024-01-02 00:47:14,632	44k	INFO	====> Epoch: 940, cost 23.05 s
2024-01-02 00:47:37,713	44k	INFO	====> Epoch: 941, cost 23.08 s
2024-01-02 00:48:00,866	44k	INFO	====> Epoch: 942, cost 23.15 s
2024-01-02 00:48:23,893	44k	INFO	====> Epoch: 943, cost 23.03 s
2024-01-02 00:48:46,935	44k	INFO	====> Epoch: 944, cost 23.04 s
2024-01-02 00:49:09,948	44k	INFO	====> Epoch: 945, cost 23.01 s
2024-01-02 00:49:32,966	44k	INFO	====> Epoch: 946, cost 23.02 s
2024-01-02 00:49:37,457	44k	INFO	Train Epoch: 947 [15%]
2024-01-02 00:49:37,460	44k	INFO	Losses: [2.3996410369873047, 2.443906784057617, 5.03065824508667, 18.32938575744629, 0.6487416625022888], step: 24600, lr: 8.884673394704218e-05, reference_loss: 28.852333068847656
2024-01-02 00:49:56,566	44k	INFO	====> Epoch: 947, cost 23.60 s
2024-01-02 00:50:19,692	44k	INFO	====> Epoch: 948, cost 23.13 s
2024-01-02 00:50:42,887	44k	INFO	====> Epoch: 949, cost 23.19 s
2024-01-02 00:51:06,036	44k	INFO	====> Epoch: 950, cost 23.15 s
2024-01-02 00:51:29,068	44k	INFO	====> Epoch: 951, cost 23.03 s
2024-01-02 00:51:52,091	44k	INFO	====> Epoch: 952, cost 23.02 s
2024-01-02 00:52:15,148	44k	INFO	====> Epoch: 953, cost 23.06 s
2024-01-02 00:52:35,693	44k	INFO	Train Epoch: 954 [85%]
2024-01-02 00:52:35,696	44k	INFO	Losses: [2.1402010917663574, 2.7744126319885254, 6.426413059234619, 20.20927619934082, 0.7636933326721191], step: 24800, lr: 8.876902220160032e-05, reference_loss: 32.313995361328125
2024-01-02 00:52:41,852	44k	INFO	Saving model and optimizer state at iteration 954 to ./logs/44k/G_24800.pth
2024-01-02 00:52:42,751	44k	INFO	Saving model and optimizer state at iteration 954 to ./logs/44k/D_24800.pth
2024-01-02 00:52:43,290	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_22400.pth
2024-01-02 00:52:43,330	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_22400.pth
2024-01-02 00:52:45,818	44k	INFO	====> Epoch: 954, cost 30.67 s
2024-01-02 00:53:08,969	44k	INFO	====> Epoch: 955, cost 23.15 s
2024-01-02 00:53:32,000	44k	INFO	====> Epoch: 956, cost 23.03 s
2024-01-02 00:53:54,998	44k	INFO	====> Epoch: 957, cost 23.00 s
2024-01-02 00:54:18,051	44k	INFO	====> Epoch: 958, cost 23.05 s
2024-01-02 00:54:40,989	44k	INFO	====> Epoch: 959, cost 22.94 s
2024-01-02 00:55:04,099	44k	INFO	====> Epoch: 960, cost 23.11 s
2024-01-02 00:55:27,259	44k	INFO	====> Epoch: 961, cost 23.16 s
2024-01-02 00:55:40,761	44k	INFO	Train Epoch: 962 [54%]
2024-01-02 00:55:40,764	44k	INFO	Losses: [2.4687442779541016, 2.3757681846618652, 6.2869791984558105, 19.528072357177734, 0.9874687790870667], step: 25000, lr: 8.868029200613832e-05, reference_loss: 31.64703369140625
2024-01-02 00:55:50,861	44k	INFO	====> Epoch: 962, cost 23.60 s
2024-01-02 00:56:13,884	44k	INFO	====> Epoch: 963, cost 23.02 s
2024-01-02 00:56:36,860	44k	INFO	====> Epoch: 964, cost 22.98 s
2024-01-02 00:57:00,063	44k	INFO	====> Epoch: 965, cost 23.20 s
2024-01-02 00:57:23,003	44k	INFO	====> Epoch: 966, cost 22.94 s
2024-01-02 00:57:46,304	44k	INFO	====> Epoch: 967, cost 23.30 s
2024-01-02 00:58:09,470	44k	INFO	====> Epoch: 968, cost 23.17 s
2024-01-02 00:58:32,505	44k	INFO	====> Epoch: 969, cost 23.03 s
2024-01-02 00:58:38,806	44k	INFO	Train Epoch: 970 [23%]
2024-01-02 00:58:38,808	44k	INFO	Losses: [2.7081007957458496, 1.900497555732727, 5.247799873352051, 17.400548934936523, 0.7210655212402344], step: 25200, lr: 8.8591650502062e-05, reference_loss: 27.978012084960938
2024-01-02 00:58:56,004	44k	INFO	====> Epoch: 970, cost 23.50 s
2024-01-02 00:59:18,958	44k	INFO	====> Epoch: 971, cost 22.95 s
2024-01-02 00:59:41,951	44k	INFO	====> Epoch: 972, cost 22.99 s
2024-01-02 01:00:04,935	44k	INFO	====> Epoch: 973, cost 22.98 s
2024-01-02 01:00:27,959	44k	INFO	====> Epoch: 974, cost 23.02 s
2024-01-02 01:00:50,992	44k	INFO	====> Epoch: 975, cost 23.03 s
2024-01-02 01:01:13,992	44k	INFO	====> Epoch: 976, cost 23.00 s
2024-01-02 01:01:36,496	44k	INFO	Train Epoch: 977 [92%]
2024-01-02 01:01:36,498	44k	INFO	Losses: [2.205357551574707, 2.5844693183898926, 6.256058692932129, 18.964797973632812, 0.6485614776611328], step: 25400, lr: 8.851416187095268e-05, reference_loss: 30.659244537353516
2024-01-02 01:01:37,720	44k	INFO	====> Epoch: 977, cost 23.73 s
2024-01-02 01:02:00,799	44k	INFO	====> Epoch: 978, cost 23.08 s
2024-01-02 01:02:23,859	44k	INFO	====> Epoch: 979, cost 23.06 s
2024-01-02 01:02:47,014	44k	INFO	====> Epoch: 980, cost 23.16 s
2024-01-02 01:03:10,158	44k	INFO	====> Epoch: 981, cost 23.14 s
2024-01-02 01:03:33,346	44k	INFO	====> Epoch: 982, cost 23.19 s
2024-01-02 01:03:56,532	44k	INFO	====> Epoch: 983, cost 23.19 s
2024-01-02 01:04:19,691	44k	INFO	====> Epoch: 984, cost 23.16 s
2024-01-02 01:04:34,973	44k	INFO	Train Epoch: 985 [62%]
2024-01-02 01:04:34,975	44k	INFO	Losses: [2.6056714057922363, 2.378222942352295, 5.39867639541626, 16.894454956054688, 0.5652897953987122], step: 25600, lr: 8.842568642434779e-05, reference_loss: 27.842315673828125
2024-01-02 01:04:41,466	44k	INFO	Saving model and optimizer state at iteration 985 to ./logs/44k/G_25600.pth
2024-01-02 01:04:42,377	44k	INFO	Saving model and optimizer state at iteration 985 to ./logs/44k/D_25600.pth
2024-01-02 01:04:42,920	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_23200.pth
2024-01-02 01:04:42,960	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_23200.pth
2024-01-02 01:04:50,783	44k	INFO	====> Epoch: 985, cost 31.09 s
2024-01-02 01:05:13,856	44k	INFO	====> Epoch: 986, cost 23.07 s
2024-01-02 01:05:36,802	44k	INFO	====> Epoch: 987, cost 22.95 s
2024-01-02 01:05:59,729	44k	INFO	====> Epoch: 988, cost 22.93 s
2024-01-02 01:06:22,633	44k	INFO	====> Epoch: 989, cost 22.90 s
2024-01-02 01:06:45,620	44k	INFO	====> Epoch: 990, cost 22.99 s
2024-01-02 01:07:08,525	44k	INFO	====> Epoch: 991, cost 22.90 s
2024-01-02 01:07:31,570	44k	INFO	====> Epoch: 992, cost 23.05 s
2024-01-02 01:07:39,702	44k	INFO	Train Epoch: 993 [31%]
2024-01-02 01:07:39,704	44k	INFO	Losses: [2.261425018310547, 2.7368218898773193, 6.169919013977051, 18.37094497680664, 0.621597945690155], step: 25800, lr: 8.833729941449117e-05, reference_loss: 30.160709381103516
2024-01-02 01:07:55,381	44k	INFO	====> Epoch: 993, cost 23.81 s
2024-01-02 01:08:18,558	44k	INFO	====> Epoch: 994, cost 23.18 s
2024-01-02 01:08:41,643	44k	INFO	====> Epoch: 995, cost 23.09 s
2024-01-02 01:09:04,776	44k	INFO	====> Epoch: 996, cost 23.13 s
2024-01-02 01:09:27,976	44k	INFO	====> Epoch: 997, cost 23.20 s
2024-01-02 01:09:50,984	44k	INFO	====> Epoch: 998, cost 23.01 s
2024-01-02 01:10:13,991	44k	INFO	====> Epoch: 999, cost 23.01 s
2024-01-02 01:10:36,961	44k	INFO	====> Epoch: 1000, cost 22.97 s
2024-01-02 01:10:37,863	44k	INFO	Train Epoch: 1001 [0%]
2024-01-02 01:10:37,865	44k	INFO	Losses: [2.3948168754577637, 2.658010482788086, 5.784332752227783, 18.893171310424805, 0.4752591848373413], step: 26000, lr: 8.824900075298475e-05, reference_loss: 30.205591201782227
2024-01-02 01:11:00,504	44k	INFO	====> Epoch: 1001, cost 23.54 s
2024-01-02 01:11:23,647	44k	INFO	====> Epoch: 1002, cost 23.14 s
2024-01-02 01:11:46,633	44k	INFO	====> Epoch: 1003, cost 22.99 s
2024-01-02 01:12:09,718	44k	INFO	====> Epoch: 1004, cost 23.08 s
2024-01-02 01:12:32,827	44k	INFO	====> Epoch: 1005, cost 23.11 s
2024-01-02 01:12:55,833	44k	INFO	====> Epoch: 1006, cost 23.01 s
2024-01-02 01:13:18,993	44k	INFO	====> Epoch: 1007, cost 23.16 s
2024-01-02 01:13:36,100	44k	INFO	Train Epoch: 1008 [69%]
2024-01-02 01:13:36,102	44k	INFO	Losses: [2.2516250610351562, 2.420452117919922, 6.854205131530762, 20.059019088745117, 0.5822920203208923], step: 26200, lr: 8.817181182799734e-05, reference_loss: 32.1675910949707
2024-01-02 01:13:42,579	44k	INFO	====> Epoch: 1008, cost 23.59 s
2024-01-02 01:14:05,629	44k	INFO	====> Epoch: 1009, cost 23.05 s
2024-01-02 01:14:28,740	44k	INFO	====> Epoch: 1010, cost 23.11 s
2024-01-02 01:14:52,025	44k	INFO	====> Epoch: 1011, cost 23.29 s
2024-01-02 01:15:14,960	44k	INFO	====> Epoch: 1012, cost 22.94 s
2024-01-02 01:15:37,880	44k	INFO	====> Epoch: 1013, cost 22.92 s
2024-01-02 01:16:00,899	44k	INFO	====> Epoch: 1014, cost 23.02 s
2024-01-02 01:16:23,897	44k	INFO	====> Epoch: 1015, cost 23.00 s
2024-01-02 01:16:33,750	44k	INFO	Train Epoch: 1016 [38%]
2024-01-02 01:16:33,752	44k	INFO	Losses: [2.258558511734009, 2.478583812713623, 5.857263565063477, 17.507936477661133, 0.6943399906158447], step: 26400, lr: 8.808367858169472e-05, reference_loss: 28.796682357788086
2024-01-02 01:16:40,101	44k	INFO	Saving model and optimizer state at iteration 1016 to ./logs/44k/G_26400.pth
2024-01-02 01:16:40,969	44k	INFO	Saving model and optimizer state at iteration 1016 to ./logs/44k/D_26400.pth
2024-01-02 01:16:41,507	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_24000.pth
2024-01-02 01:16:41,547	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_24000.pth
2024-01-02 01:16:54,603	44k	INFO	====> Epoch: 1016, cost 30.71 s
2024-01-02 01:17:17,537	44k	INFO	====> Epoch: 1017, cost 22.93 s
2024-01-02 01:17:40,624	44k	INFO	====> Epoch: 1018, cost 23.09 s
2024-01-02 01:18:03,824	44k	INFO	====> Epoch: 1019, cost 23.20 s
2024-01-02 01:18:26,865	44k	INFO	====> Epoch: 1020, cost 23.04 s
2024-01-02 01:18:49,974	44k	INFO	====> Epoch: 1021, cost 23.11 s
2024-01-02 01:19:13,151	44k	INFO	====> Epoch: 1022, cost 23.18 s
2024-01-02 01:19:36,353	44k	INFO	====> Epoch: 1023, cost 23.20 s
2024-01-02 01:19:39,073	44k	INFO	Train Epoch: 1024 [8%]
2024-01-02 01:19:39,075	44k	INFO	Losses: [2.5690834522247314, 2.3996195793151855, 5.440781116485596, 18.089149475097656, 0.49681586027145386], step: 26600, lr: 8.799563343008971e-05, reference_loss: 28.995450973510742
2024-01-02 01:19:59,903	44k	INFO	====> Epoch: 1024, cost 23.55 s
2024-01-02 01:20:23,032	44k	INFO	====> Epoch: 1025, cost 23.13 s
2024-01-02 01:20:46,195	44k	INFO	====> Epoch: 1026, cost 23.16 s
2024-01-02 01:21:09,311	44k	INFO	====> Epoch: 1027, cost 23.12 s
2024-01-02 01:21:32,448	44k	INFO	====> Epoch: 1028, cost 23.14 s
2024-01-02 01:21:55,406	44k	INFO	====> Epoch: 1029, cost 22.96 s
2024-01-02 01:22:18,573	44k	INFO	====> Epoch: 1030, cost 23.17 s
2024-01-02 01:22:37,443	44k	INFO	Train Epoch: 1031 [77%]
2024-01-02 01:22:37,445	44k	INFO	Losses: [2.2793641090393066, 2.591270685195923, 7.302781105041504, 21.229978561401367, 0.5743844509124756], step: 26800, lr: 8.7918666118391e-05, reference_loss: 33.977779388427734
2024-01-02 01:22:42,114	44k	INFO	====> Epoch: 1031, cost 23.54 s
2024-01-02 01:23:05,237	44k	INFO	====> Epoch: 1032, cost 23.12 s
2024-01-02 01:23:28,371	44k	INFO	====> Epoch: 1033, cost 23.13 s
2024-01-02 01:23:51,373	44k	INFO	====> Epoch: 1034, cost 23.00 s
2024-01-02 01:24:14,457	44k	INFO	====> Epoch: 1035, cost 23.08 s
2024-01-02 01:24:37,565	44k	INFO	====> Epoch: 1036, cost 23.11 s
2024-01-02 01:25:00,563	44k	INFO	====> Epoch: 1037, cost 23.00 s
2024-01-02 01:25:23,704	44k	INFO	====> Epoch: 1038, cost 23.14 s
2024-01-02 01:25:35,342	44k	INFO	Train Epoch: 1039 [46%]
2024-01-02 01:25:35,345	44k	INFO	Losses: [2.841350555419922, 2.5628483295440674, 5.455451965332031, 19.41072654724121, 0.618046224117279], step: 27000, lr: 8.783078590707442e-05, reference_loss: 30.888423919677734
2024-01-02 01:25:47,459	44k	INFO	====> Epoch: 1039, cost 23.76 s
2024-01-02 01:26:10,520	44k	INFO	====> Epoch: 1040, cost 23.06 s
2024-01-02 01:26:33,493	44k	INFO	====> Epoch: 1041, cost 22.97 s
2024-01-02 01:26:56,449	44k	INFO	====> Epoch: 1042, cost 22.96 s
2024-01-02 01:27:19,531	44k	INFO	====> Epoch: 1043, cost 23.08 s
2024-01-02 01:27:42,574	44k	INFO	====> Epoch: 1044, cost 23.04 s
2024-01-02 01:28:05,629	44k	INFO	====> Epoch: 1045, cost 23.05 s
2024-01-02 01:28:28,742	44k	INFO	====> Epoch: 1046, cost 23.11 s
2024-01-02 01:28:33,235	44k	INFO	Train Epoch: 1047 [15%]
2024-01-02 01:28:33,237	44k	INFO	Losses: [2.180276393890381, 2.433486223220825, 6.959776401519775, 19.813072204589844, 0.5454791784286499], step: 27200, lr: 8.774299353753115e-05, reference_loss: 31.932090759277344
2024-01-02 01:28:39,336	44k	INFO	Saving model and optimizer state at iteration 1047 to ./logs/44k/G_27200.pth
2024-01-02 01:28:40,478	44k	INFO	Saving model and optimizer state at iteration 1047 to ./logs/44k/D_27200.pth
2024-01-02 01:28:41,015	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_24800.pth
2024-01-02 01:28:41,055	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_24800.pth
2024-01-02 01:28:59,629	44k	INFO	====> Epoch: 1047, cost 30.89 s
2024-01-02 01:29:22,845	44k	INFO	====> Epoch: 1048, cost 23.22 s
2024-01-02 01:29:46,058	44k	INFO	====> Epoch: 1049, cost 23.21 s
2024-01-02 01:30:09,191	44k	INFO	====> Epoch: 1050, cost 23.13 s
2024-01-02 01:30:32,189	44k	INFO	====> Epoch: 1051, cost 23.00 s
2024-01-02 01:30:55,210	44k	INFO	====> Epoch: 1052, cost 23.02 s
2024-01-02 01:31:18,191	44k	INFO	====> Epoch: 1053, cost 22.98 s
2024-01-02 01:31:38,749	44k	INFO	Train Epoch: 1054 [85%]
2024-01-02 01:31:38,752	44k	INFO	Losses: [2.4892220497131348, 2.278979539871216, 4.623631954193115, 18.05289649963379, 0.6729249358177185], step: 27400, lr: 8.766624720285824e-05, reference_loss: 28.11765480041504
2024-01-02 01:31:41,682	44k	INFO	====> Epoch: 1054, cost 23.49 s
2024-01-02 01:32:04,965	44k	INFO	====> Epoch: 1055, cost 23.28 s
2024-01-02 01:32:28,076	44k	INFO	====> Epoch: 1056, cost 23.11 s
2024-01-02 01:32:51,235	44k	INFO	====> Epoch: 1057, cost 23.16 s
2024-01-02 01:33:14,304	44k	INFO	====> Epoch: 1058, cost 23.07 s
2024-01-02 01:33:37,427	44k	INFO	====> Epoch: 1059, cost 23.12 s
2024-01-02 01:34:00,400	44k	INFO	====> Epoch: 1060, cost 22.97 s
2024-01-02 01:34:23,488	44k	INFO	====> Epoch: 1061, cost 23.09 s
2024-01-02 01:34:36,867	44k	INFO	Train Epoch: 1062 [54%]
2024-01-02 01:34:36,869	44k	INFO	Losses: [2.1685800552368164, 2.5522377490997314, 6.507387161254883, 20.8704891204834, 0.6810100674629211], step: 27600, lr: 8.75786193000515e-05, reference_loss: 32.77970504760742
2024-01-02 01:34:46,919	44k	INFO	====> Epoch: 1062, cost 23.43 s
2024-01-02 01:35:10,071	44k	INFO	====> Epoch: 1063, cost 23.15 s
2024-01-02 01:35:33,193	44k	INFO	====> Epoch: 1064, cost 23.12 s
2024-01-02 01:35:56,483	44k	INFO	====> Epoch: 1065, cost 23.29 s
2024-01-02 01:36:19,608	44k	INFO	====> Epoch: 1066, cost 23.12 s
2024-01-02 01:36:42,686	44k	INFO	====> Epoch: 1067, cost 23.08 s
2024-01-02 01:37:05,606	44k	INFO	====> Epoch: 1068, cost 22.92 s
2024-01-02 01:37:28,536	44k	INFO	====> Epoch: 1069, cost 22.93 s
2024-01-02 01:37:34,839	44k	INFO	Train Epoch: 1070 [23%]
2024-01-02 01:37:34,842	44k	INFO	Losses: [2.5051796436309814, 2.1057846546173096, 5.672297954559326, 16.622163772583008, 0.938335657119751], step: 27800, lr: 8.749107898681995e-05, reference_loss: 27.843761444091797
2024-01-02 01:37:52,009	44k	INFO	====> Epoch: 1070, cost 23.47 s
2024-01-02 01:38:15,107	44k	INFO	====> Epoch: 1071, cost 23.10 s
2024-01-02 01:38:38,231	44k	INFO	====> Epoch: 1072, cost 23.12 s
2024-01-02 01:39:01,312	44k	INFO	====> Epoch: 1073, cost 23.08 s
2024-01-02 01:39:24,473	44k	INFO	====> Epoch: 1074, cost 23.16 s
2024-01-02 01:39:47,812	44k	INFO	====> Epoch: 1075, cost 23.34 s
2024-01-02 01:40:10,977	44k	INFO	====> Epoch: 1076, cost 23.17 s
2024-01-02 01:40:33,474	44k	INFO	Train Epoch: 1077 [92%]
2024-01-02 01:40:33,477	44k	INFO	Losses: [2.4757232666015625, 2.309924602508545, 5.810916900634766, 17.978832244873047, 0.6532689332962036], step: 28000, lr: 8.741455299473667e-05, reference_loss: 29.228666305541992
2024-01-02 01:40:39,567	44k	INFO	Saving model and optimizer state at iteration 1077 to ./logs/44k/G_28000.pth
2024-01-02 01:40:40,474	44k	INFO	Saving model and optimizer state at iteration 1077 to ./logs/44k/D_28000.pth
2024-01-02 01:40:41,005	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_25600.pth
2024-01-02 01:40:41,046	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_25600.pth
2024-01-02 01:40:41,744	44k	INFO	====> Epoch: 1077, cost 30.77 s
2024-01-02 01:41:04,828	44k	INFO	====> Epoch: 1078, cost 23.08 s
2024-01-02 01:41:28,005	44k	INFO	====> Epoch: 1079, cost 23.18 s
2024-01-02 01:41:51,260	44k	INFO	====> Epoch: 1080, cost 23.26 s
2024-01-02 01:42:14,284	44k	INFO	====> Epoch: 1081, cost 23.02 s
2024-01-02 01:42:37,522	44k	INFO	====> Epoch: 1082, cost 23.24 s
2024-01-02 01:43:00,597	44k	INFO	====> Epoch: 1083, cost 23.07 s
2024-01-02 01:43:23,791	44k	INFO	====> Epoch: 1084, cost 23.19 s
2024-01-02 01:43:38,964	44k	INFO	Train Epoch: 1085 [62%]
2024-01-02 01:43:38,966	44k	INFO	Losses: [2.6299984455108643, 1.9521126747131348, 4.271127700805664, 15.803545951843262, 0.8206398487091064], step: 28200, lr: 8.732717667604937e-05, reference_loss: 25.47742462158203
2024-01-02 01:43:47,239	44k	INFO	====> Epoch: 1085, cost 23.45 s
2024-01-02 01:44:10,301	44k	INFO	====> Epoch: 1086, cost 23.06 s
2024-01-02 01:44:33,362	44k	INFO	====> Epoch: 1087, cost 23.06 s
2024-01-02 01:44:56,421	44k	INFO	====> Epoch: 1088, cost 23.06 s
2024-01-02 01:45:19,464	44k	INFO	====> Epoch: 1089, cost 23.04 s
2024-01-02 01:45:42,405	44k	INFO	====> Epoch: 1090, cost 22.94 s
2024-01-02 01:46:05,352	44k	INFO	====> Epoch: 1091, cost 22.95 s
2024-01-02 01:46:28,451	44k	INFO	====> Epoch: 1092, cost 23.10 s
2024-01-02 01:46:36,748	44k	INFO	Train Epoch: 1093 [31%]
2024-01-02 01:46:36,750	44k	INFO	Losses: [2.5641024112701416, 2.176081895828247, 4.848580360412598, 16.490360260009766, 0.6736545562744141], step: 28400, lr: 8.723988769546315e-05, reference_loss: 26.752779006958008
2024-01-02 01:46:52,092	44k	INFO	====> Epoch: 1093, cost 23.64 s
2024-01-02 01:47:15,212	44k	INFO	====> Epoch: 1094, cost 23.12 s
2024-01-02 01:47:38,373	44k	INFO	====> Epoch: 1095, cost 23.16 s
2024-01-02 01:48:01,462	44k	INFO	====> Epoch: 1096, cost 23.09 s
2024-01-02 01:48:24,624	44k	INFO	====> Epoch: 1097, cost 23.16 s
2024-01-02 01:48:47,764	44k	INFO	====> Epoch: 1098, cost 23.14 s
2024-01-02 01:49:10,851	44k	INFO	====> Epoch: 1099, cost 23.09 s
2024-01-02 01:49:33,969	44k	INFO	====> Epoch: 1100, cost 23.12 s
2024-01-02 01:49:34,874	44k	INFO	Train Epoch: 1101 [0%]
2024-01-02 01:49:34,876	44k	INFO	Losses: [2.5724806785583496, 2.5653860569000244, 5.602853298187256, 16.968244552612305, 0.619710385799408], step: 28600, lr: 8.715268596567818e-05, reference_loss: 28.328676223754883
2024-01-02 01:49:57,733	44k	INFO	====> Epoch: 1101, cost 23.76 s
2024-01-02 01:50:20,893	44k	INFO	====> Epoch: 1102, cost 23.16 s
2024-01-02 01:50:44,048	44k	INFO	====> Epoch: 1103, cost 23.15 s
2024-01-02 01:51:07,181	44k	INFO	====> Epoch: 1104, cost 23.13 s
2024-01-02 01:51:30,251	44k	INFO	====> Epoch: 1105, cost 23.07 s
2024-01-02 01:51:53,286	44k	INFO	====> Epoch: 1106, cost 23.03 s
2024-01-02 01:52:16,451	44k	INFO	====> Epoch: 1107, cost 23.17 s
2024-01-02 01:52:33,567	44k	INFO	Train Epoch: 1108 [69%]
2024-01-02 01:52:33,569	44k	INFO	Losses: [2.376176357269287, 2.2804393768310547, 5.559442520141602, 16.52008056640625, 0.5644292235374451], step: 28800, lr: 8.707645595647632e-05, reference_loss: 27.300567626953125
2024-01-02 01:52:39,755	44k	INFO	Saving model and optimizer state at iteration 1108 to ./logs/44k/G_28800.pth
2024-01-02 01:52:40,868	44k	INFO	Saving model and optimizer state at iteration 1108 to ./logs/44k/D_28800.pth
2024-01-02 01:52:41,406	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_26400.pth
2024-01-02 01:52:41,445	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_26400.pth
2024-01-02 01:52:47,492	44k	INFO	====> Epoch: 1108, cost 31.04 s
2024-01-02 01:53:10,591	44k	INFO	====> Epoch: 1109, cost 23.10 s
2024-01-02 01:53:33,535	44k	INFO	====> Epoch: 1110, cost 22.94 s
2024-01-02 01:53:56,641	44k	INFO	====> Epoch: 1111, cost 23.11 s
2024-01-02 01:54:19,749	44k	INFO	====> Epoch: 1112, cost 23.11 s
2024-01-02 01:54:42,849	44k	INFO	====> Epoch: 1113, cost 23.10 s
2024-01-02 01:55:05,857	44k	INFO	====> Epoch: 1114, cost 23.01 s
2024-01-02 01:55:28,930	44k	INFO	====> Epoch: 1115, cost 23.07 s
2024-01-02 01:55:38,893	44k	INFO	Train Epoch: 1116 [38%]
2024-01-02 01:55:38,896	44k	INFO	Losses: [2.5498828887939453, 2.2157630920410156, 5.549143314361572, 19.382877349853516, 0.6050767302513123], step: 29000, lr: 8.698941758694681e-05, reference_loss: 30.30274200439453
2024-01-02 01:55:52,379	44k	INFO	====> Epoch: 1116, cost 23.45 s
2024-01-02 01:56:15,468	44k	INFO	====> Epoch: 1117, cost 23.09 s
2024-01-02 01:56:38,686	44k	INFO	====> Epoch: 1118, cost 23.22 s
2024-01-02 01:57:01,757	44k	INFO	====> Epoch: 1119, cost 23.07 s
2024-01-02 01:57:24,778	44k	INFO	====> Epoch: 1120, cost 23.02 s
2024-01-02 01:57:47,715	44k	INFO	====> Epoch: 1121, cost 22.94 s
2024-01-02 01:58:10,794	44k	INFO	====> Epoch: 1122, cost 23.08 s
2024-01-02 01:58:33,917	44k	INFO	====> Epoch: 1123, cost 23.12 s
2024-01-02 01:58:36,624	44k	INFO	Train Epoch: 1124 [8%]
2024-01-02 01:58:36,627	44k	INFO	Losses: [2.3387527465820312, 2.461184501647949, 5.91223669052124, 18.824127197265625, 0.526283860206604], step: 29200, lr: 8.690246621771705e-05, reference_loss: 30.062583923339844
2024-01-02 01:58:57,492	44k	INFO	====> Epoch: 1124, cost 23.58 s
2024-01-02 01:59:20,524	44k	INFO	====> Epoch: 1125, cost 23.03 s
2024-01-02 01:59:43,393	44k	INFO	====> Epoch: 1126, cost 22.87 s
2024-01-02 02:00:06,256	44k	INFO	====> Epoch: 1127, cost 22.86 s
2024-01-02 02:00:29,245	44k	INFO	====> Epoch: 1128, cost 22.99 s
2024-01-02 02:00:51,929	44k	INFO	====> Epoch: 1129, cost 22.68 s
2024-01-02 02:01:14,534	44k	INFO	====> Epoch: 1130, cost 22.61 s
2024-01-02 02:01:33,138	44k	INFO	Train Epoch: 1131 [77%]
2024-01-02 02:01:33,141	44k	INFO	Losses: [2.378110408782959, 2.1641058921813965, 6.812551498413086, 20.840559005737305, 0.5064784288406372], step: 29400, lr: 8.682645506870841e-05, reference_loss: 32.701805114746094
2024-01-02 02:01:37,696	44k	INFO	====> Epoch: 1131, cost 23.16 s
2024-01-02 02:02:00,530	44k	INFO	====> Epoch: 1132, cost 22.83 s
2024-01-02 02:02:23,307	44k	INFO	====> Epoch: 1133, cost 22.78 s
2024-01-02 02:02:46,237	44k	INFO	====> Epoch: 1134, cost 22.93 s
2024-01-02 02:03:09,153	44k	INFO	====> Epoch: 1135, cost 22.92 s
2024-01-02 02:03:32,066	44k	INFO	====> Epoch: 1136, cost 22.91 s
2024-01-02 02:03:55,115	44k	INFO	====> Epoch: 1137, cost 23.05 s
2024-01-02 02:04:17,972	44k	INFO	====> Epoch: 1138, cost 22.86 s
2024-01-02 02:04:29,488	44k	INFO	Train Epoch: 1139 [46%]
2024-01-02 02:04:29,491	44k	INFO	Losses: [2.7795636653900146, 1.9063283205032349, 3.9560680389404297, 15.489792823791504, 0.4617805480957031], step: 29600, lr: 8.67396665907186e-05, reference_loss: 24.59353256225586
2024-01-02 02:04:34,793	44k	INFO	Saving model and optimizer state at iteration 1139 to ./logs/44k/G_29600.pth
2024-01-02 02:04:35,664	44k	INFO	Saving model and optimizer state at iteration 1139 to ./logs/44k/D_29600.pth
2024-01-02 02:04:36,160	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_27200.pth
2024-01-02 02:04:36,199	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_27200.pth
2024-01-02 02:04:47,424	44k	INFO	====> Epoch: 1139, cost 29.45 s
2024-01-02 02:05:10,199	44k	INFO	====> Epoch: 1140, cost 22.78 s
2024-01-02 02:05:33,042	44k	INFO	====> Epoch: 1141, cost 22.84 s
2024-01-02 02:05:55,810	44k	INFO	====> Epoch: 1142, cost 22.77 s
2024-01-02 02:06:18,548	44k	INFO	====> Epoch: 1143, cost 22.74 s
2024-01-02 02:06:41,380	44k	INFO	====> Epoch: 1144, cost 22.83 s
2024-01-02 02:07:04,293	44k	INFO	====> Epoch: 1145, cost 22.91 s
2024-01-02 02:07:27,043	44k	INFO	====> Epoch: 1146, cost 22.75 s
2024-01-02 02:07:31,507	44k	INFO	Train Epoch: 1147 [15%]
2024-01-02 02:07:31,510	44k	INFO	Losses: [2.4717166423797607, 2.2799644470214844, 5.367680549621582, 16.37133026123047, 0.5244807004928589], step: 29800, lr: 8.665296486324633e-05, reference_loss: 27.015172958374023
2024-01-02 02:07:50,292	44k	INFO	====> Epoch: 1147, cost 23.25 s
2024-01-02 02:08:13,212	44k	INFO	====> Epoch: 1148, cost 22.92 s
2024-01-02 02:08:36,106	44k	INFO	====> Epoch: 1149, cost 22.89 s
2024-01-02 02:08:58,977	44k	INFO	====> Epoch: 1150, cost 22.87 s
2024-01-02 02:09:21,759	44k	INFO	====> Epoch: 1151, cost 22.78 s
2024-01-02 02:09:44,558	44k	INFO	====> Epoch: 1152, cost 22.80 s
2024-01-02 02:10:07,304	44k	INFO	====> Epoch: 1153, cost 22.75 s
2024-01-02 02:10:27,581	44k	INFO	Train Epoch: 1154 [85%]
2024-01-02 02:10:27,584	44k	INFO	Losses: [2.4446299076080322, 2.5525166988372803, 5.582879066467285, 18.332439422607422, 0.7862894535064697], step: 30000, lr: 8.657717194607226e-05, reference_loss: 29.698753356933594
2024-01-02 02:10:30,604	44k	INFO	====> Epoch: 1154, cost 23.30 s
2024-01-02 02:10:53,396	44k	INFO	====> Epoch: 1155, cost 22.79 s
2024-01-02 02:11:16,215	44k	INFO	====> Epoch: 1156, cost 22.82 s
2024-01-02 02:11:39,085	44k	INFO	====> Epoch: 1157, cost 22.87 s
2024-01-02 02:12:01,986	44k	INFO	====> Epoch: 1158, cost 22.90 s
2024-01-02 02:12:24,777	44k	INFO	====> Epoch: 1159, cost 22.79 s
2024-01-02 02:12:47,569	44k	INFO	====> Epoch: 1160, cost 22.79 s
2024-01-02 02:13:10,394	44k	INFO	====> Epoch: 1161, cost 22.82 s
2024-01-02 02:13:23,670	44k	INFO	Train Epoch: 1162 [54%]
2024-01-02 02:13:23,673	44k	INFO	Losses: [2.3780972957611084, 2.5052757263183594, 5.272429466247559, 16.841577529907227, 0.5431012511253357], step: 30200, lr: 8.649063264217098e-05, reference_loss: 27.54047966003418
2024-01-02 02:13:33,632	44k	INFO	====> Epoch: 1162, cost 23.24 s
2024-01-02 02:13:56,594	44k	INFO	====> Epoch: 1163, cost 22.96 s
2024-01-02 02:14:19,431	44k	INFO	====> Epoch: 1164, cost 22.84 s
2024-01-02 02:14:42,250	44k	INFO	====> Epoch: 1165, cost 22.82 s
2024-01-02 02:15:05,048	44k	INFO	====> Epoch: 1166, cost 22.80 s
2024-01-02 02:15:27,670	44k	INFO	====> Epoch: 1167, cost 22.62 s
2024-01-02 02:15:50,252	44k	INFO	====> Epoch: 1168, cost 22.58 s
2024-01-02 02:16:12,940	44k	INFO	====> Epoch: 1169, cost 22.69 s
2024-01-02 02:16:19,135	44k	INFO	Train Epoch: 1170 [23%]
2024-01-02 02:16:19,138	44k	INFO	Losses: [2.638812303543091, 2.077200174331665, 4.906172752380371, 17.504751205444336, 0.656196117401123], step: 30400, lr: 8.640417983972213e-05, reference_loss: 27.783132553100586
2024-01-02 02:16:24,497	44k	INFO	Saving model and optimizer state at iteration 1170 to ./logs/44k/G_30400.pth
2024-01-02 02:16:25,380	44k	INFO	Saving model and optimizer state at iteration 1170 to ./logs/44k/D_30400.pth
2024-01-02 02:16:25,867	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_28000.pth
2024-01-02 02:16:25,906	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_28000.pth
2024-01-02 02:16:42,321	44k	INFO	====> Epoch: 1170, cost 29.38 s
2024-01-02 02:17:05,218	44k	INFO	====> Epoch: 1171, cost 22.90 s
2024-01-02 02:17:27,941	44k	INFO	====> Epoch: 1172, cost 22.72 s
2024-01-02 02:17:50,597	44k	INFO	====> Epoch: 1173, cost 22.66 s
2024-01-02 02:18:13,248	44k	INFO	====> Epoch: 1174, cost 22.65 s
2024-01-02 02:18:35,969	44k	INFO	====> Epoch: 1175, cost 22.72 s
2024-01-02 02:18:58,659	44k	INFO	====> Epoch: 1176, cost 22.69 s
2024-01-02 02:19:20,597	44k	INFO	Train Epoch: 1177 [92%]
2024-01-02 02:19:20,600	44k	INFO	Losses: [2.263073682785034, 2.4840285778045654, 6.320624351501465, 18.467199325561523, 0.7011726498603821], step: 30600, lr: 8.632860452782808e-05, reference_loss: 30.23609733581543
2024-01-02 02:19:21,772	44k	INFO	====> Epoch: 1177, cost 23.11 s
2024-01-02 02:19:44,449	44k	INFO	====> Epoch: 1178, cost 22.68 s
2024-01-02 02:20:07,101	44k	INFO	====> Epoch: 1179, cost 22.65 s
2024-01-02 02:20:29,773	44k	INFO	====> Epoch: 1180, cost 22.67 s
2024-01-02 02:20:52,432	44k	INFO	====> Epoch: 1181, cost 22.66 s
2024-01-02 02:21:15,196	44k	INFO	====> Epoch: 1182, cost 22.76 s
2024-01-02 02:21:38,013	44k	INFO	====> Epoch: 1183, cost 22.82 s
2024-01-02 02:22:00,826	44k	INFO	====> Epoch: 1184, cost 22.81 s
2024-01-02 02:22:15,910	44k	INFO	Train Epoch: 1185 [62%]
2024-01-02 02:22:15,913	44k	INFO	Losses: [2.5517640113830566, 2.286998748779297, 6.125771999359131, 17.833709716796875, 0.50387042760849], step: 30800, lr: 8.624231368262399e-05, reference_loss: 29.302114486694336
2024-01-02 02:22:24,027	44k	INFO	====> Epoch: 1185, cost 23.20 s
2024-01-02 02:22:46,894	44k	INFO	====> Epoch: 1186, cost 22.87 s
2024-01-02 02:23:09,710	44k	INFO	====> Epoch: 1187, cost 22.82 s
2024-01-02 02:23:32,530	44k	INFO	====> Epoch: 1188, cost 22.82 s
2024-01-02 02:23:55,377	44k	INFO	====> Epoch: 1189, cost 22.85 s
2024-01-02 02:24:18,043	44k	INFO	====> Epoch: 1190, cost 22.67 s
2024-01-02 02:24:40,811	44k	INFO	====> Epoch: 1191, cost 22.77 s
2024-01-02 02:25:03,712	44k	INFO	====> Epoch: 1192, cost 22.90 s
2024-01-02 02:25:11,713	44k	INFO	Train Epoch: 1193 [31%]
2024-01-02 02:25:11,717	44k	INFO	Losses: [2.6044766902923584, 2.196826457977295, 5.080530643463135, 16.79440689086914, 0.5678061842918396], step: 31000, lr: 8.61561090905223e-05, reference_loss: 27.244047164916992
2024-01-02 02:25:26,869	44k	INFO	====> Epoch: 1193, cost 23.16 s
2024-01-02 02:25:49,552	44k	INFO	====> Epoch: 1194, cost 22.68 s
2024-01-02 02:26:12,186	44k	INFO	====> Epoch: 1195, cost 22.63 s
2024-01-02 02:26:34,951	44k	INFO	====> Epoch: 1196, cost 22.77 s
2024-01-02 02:26:57,710	44k	INFO	====> Epoch: 1197, cost 22.76 s
2024-01-02 02:27:20,324	44k	INFO	====> Epoch: 1198, cost 22.61 s
2024-01-02 02:27:43,061	44k	INFO	====> Epoch: 1199, cost 22.74 s
2024-01-02 02:28:05,833	44k	INFO	====> Epoch: 1200, cost 22.77 s
2024-01-02 02:28:06,723	44k	INFO	Train Epoch: 1201 [0%]
2024-01-02 02:28:06,726	44k	INFO	Losses: [2.284545421600342, 2.6325206756591797, 6.438628196716309, 18.271955490112305, 0.36354875564575195], step: 31200, lr: 8.60699906653076e-05, reference_loss: 29.99119758605957
2024-01-02 02:28:12,132	44k	INFO	Saving model and optimizer state at iteration 1201 to ./logs/44k/G_31200.pth
2024-01-02 02:28:13,020	44k	INFO	Saving model and optimizer state at iteration 1201 to ./logs/44k/D_31200.pth
2024-01-02 02:28:13,507	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_28800.pth
2024-01-02 02:28:13,546	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_28800.pth
2024-01-02 02:28:35,424	44k	INFO	====> Epoch: 1201, cost 29.59 s
2024-01-02 02:28:58,139	44k	INFO	====> Epoch: 1202, cost 22.72 s
2024-01-02 02:29:20,993	44k	INFO	====> Epoch: 1203, cost 22.85 s
2024-01-02 02:29:43,789	44k	INFO	====> Epoch: 1204, cost 22.80 s
2024-01-02 02:30:06,562	44k	INFO	====> Epoch: 1205, cost 22.77 s
2024-01-02 02:30:29,382	44k	INFO	====> Epoch: 1206, cost 22.82 s
2024-01-02 02:30:52,204	44k	INFO	====> Epoch: 1207, cost 22.82 s
2024-01-02 02:31:09,058	44k	INFO	Train Epoch: 1208 [69%]
2024-01-02 02:31:09,061	44k	INFO	Losses: [2.2025465965270996, 2.4085006713867188, 6.370284557342529, 18.42831039428711, 0.6422652006149292], step: 31400, lr: 8.599470765930816e-05, reference_loss: 30.05190658569336
2024-01-02 02:31:15,697	44k	INFO	====> Epoch: 1208, cost 23.49 s
2024-01-02 02:31:38,410	44k	INFO	====> Epoch: 1209, cost 22.71 s
2024-01-02 02:32:01,085	44k	INFO	====> Epoch: 1210, cost 22.67 s
2024-01-02 02:32:23,767	44k	INFO	====> Epoch: 1211, cost 22.68 s
2024-01-02 02:32:46,455	44k	INFO	====> Epoch: 1212, cost 22.69 s
2024-01-02 02:33:09,246	44k	INFO	====> Epoch: 1213, cost 22.79 s
2024-01-02 02:33:32,084	44k	INFO	====> Epoch: 1214, cost 22.84 s
2024-01-02 02:33:54,881	44k	INFO	====> Epoch: 1215, cost 22.80 s
2024-01-02 02:34:04,666	44k	INFO	Train Epoch: 1216 [38%]
2024-01-02 02:34:04,668	44k	INFO	Losses: [2.45162034034729, 2.1301605701446533, 6.462869644165039, 18.799606323242188, 0.46043169498443604], step: 31600, lr: 8.590875056492924e-05, reference_loss: 30.304689407348633
2024-01-02 02:34:18,048	44k	INFO	====> Epoch: 1216, cost 23.17 s
2024-01-02 02:34:40,782	44k	INFO	====> Epoch: 1217, cost 22.73 s
2024-01-02 02:35:03,635	44k	INFO	====> Epoch: 1218, cost 22.85 s
2024-01-02 02:35:26,506	44k	INFO	====> Epoch: 1219, cost 22.87 s
2024-01-02 02:35:49,366	44k	INFO	====> Epoch: 1220, cost 22.86 s
2024-01-02 02:36:12,217	44k	INFO	====> Epoch: 1221, cost 22.85 s
2024-01-02 02:36:35,021	44k	INFO	====> Epoch: 1222, cost 22.80 s
2024-01-02 02:36:57,854	44k	INFO	====> Epoch: 1223, cost 22.83 s
2024-01-02 02:37:00,526	44k	INFO	Train Epoch: 1224 [8%]
2024-01-02 02:37:00,530	44k	INFO	Losses: [2.5639514923095703, 1.9948623180389404, 5.658526420593262, 18.249191284179688, 0.654388427734375], step: 31800, lr: 8.582287939004785e-05, reference_loss: 29.120920181274414
2024-01-02 02:37:21,016	44k	INFO	====> Epoch: 1224, cost 23.16 s
2024-01-02 02:37:43,683	44k	INFO	====> Epoch: 1225, cost 22.67 s
2024-01-02 02:38:06,500	44k	INFO	====> Epoch: 1226, cost 22.82 s
2024-01-02 02:38:29,474	44k	INFO	====> Epoch: 1227, cost 22.97 s
2024-01-02 02:38:52,148	44k	INFO	====> Epoch: 1228, cost 22.67 s
2024-01-02 02:39:14,842	44k	INFO	====> Epoch: 1229, cost 22.69 s
2024-01-02 02:39:37,604	44k	INFO	====> Epoch: 1230, cost 22.76 s
2024-01-02 02:39:56,129	44k	INFO	Train Epoch: 1231 [77%]
2024-01-02 02:39:56,132	44k	INFO	Losses: [2.22412371635437, 2.4885926246643066, 7.046418190002441, 19.162660598754883, 0.8327012062072754], step: 32000, lr: 8.574781252534775e-05, reference_loss: 31.75449562072754
2024-01-02 02:40:01,429	44k	INFO	Saving model and optimizer state at iteration 1231 to ./logs/44k/G_32000.pth
2024-01-02 02:40:02,273	44k	INFO	Saving model and optimizer state at iteration 1231 to ./logs/44k/D_32000.pth
2024-01-02 02:40:02,759	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_29600.pth
2024-01-02 02:40:02,798	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_29600.pth
2024-01-02 02:40:06,941	44k	INFO	====> Epoch: 1231, cost 29.34 s
2024-01-02 02:40:29,585	44k	INFO	====> Epoch: 1232, cost 22.64 s
2024-01-02 02:40:52,375	44k	INFO	====> Epoch: 1233, cost 22.79 s
2024-01-02 02:41:15,182	44k	INFO	====> Epoch: 1234, cost 22.81 s
2024-01-02 02:41:38,073	44k	INFO	====> Epoch: 1235, cost 22.89 s
2024-01-02 02:42:00,745	44k	INFO	====> Epoch: 1236, cost 22.67 s
2024-01-02 02:42:23,537	44k	INFO	====> Epoch: 1237, cost 22.79 s
2024-01-02 02:42:46,326	44k	INFO	====> Epoch: 1238, cost 22.79 s
2024-01-02 02:42:57,740	44k	INFO	Train Epoch: 1239 [46%]
2024-01-02 02:42:57,744	44k	INFO	Losses: [2.249964952468872, 2.6512019634246826, 7.682488441467285, 20.258337020874023, 0.5228016972541809], step: 32200, lr: 8.566210221811315e-05, reference_loss: 33.36479187011719
2024-01-02 02:43:09,435	44k	INFO	====> Epoch: 1239, cost 23.11 s
2024-01-02 02:43:32,149	44k	INFO	====> Epoch: 1240, cost 22.71 s
2024-01-02 02:43:54,961	44k	INFO	====> Epoch: 1241, cost 22.81 s
2024-01-02 02:44:17,739	44k	INFO	====> Epoch: 1242, cost 22.78 s
2024-01-02 02:44:40,507	44k	INFO	====> Epoch: 1243, cost 22.77 s
2024-01-02 02:45:03,296	44k	INFO	====> Epoch: 1244, cost 22.79 s
2024-01-02 02:45:26,153	44k	INFO	====> Epoch: 1245, cost 22.86 s
2024-01-02 02:45:49,006	44k	INFO	====> Epoch: 1246, cost 22.85 s
2024-01-02 02:45:53,471	44k	INFO	Train Epoch: 1247 [15%]
2024-01-02 02:45:53,474	44k	INFO	Losses: [2.26654052734375, 2.4110019207000732, 6.799468994140625, 18.663183212280273, 0.4620717763900757], step: 32400, lr: 8.557647758369688e-05, reference_loss: 30.602266311645508
2024-01-02 02:46:12,216	44k	INFO	====> Epoch: 1247, cost 23.21 s
2024-01-02 02:46:34,880	44k	INFO	====> Epoch: 1248, cost 22.66 s
2024-01-02 02:46:57,522	44k	INFO	====> Epoch: 1249, cost 22.64 s
2024-01-02 02:47:20,189	44k	INFO	====> Epoch: 1250, cost 22.67 s
2024-01-02 02:47:42,789	44k	INFO	====> Epoch: 1251, cost 22.60 s
2024-01-02 02:48:05,405	44k	INFO	====> Epoch: 1252, cost 22.62 s
2024-01-02 02:48:28,055	44k	INFO	====> Epoch: 1253, cost 22.65 s
2024-01-02 02:48:48,256	44k	INFO	Train Epoch: 1254 [85%]
2024-01-02 02:48:48,259	44k	INFO	Losses: [2.5335402488708496, 2.2239420413970947, 5.50960111618042, 16.61624526977539, 0.7221196889877319], step: 32600, lr: 8.550162623974361e-05, reference_loss: 27.605449676513672
2024-01-02 02:48:51,271	44k	INFO	====> Epoch: 1254, cost 23.22 s
2024-01-02 02:49:13,919	44k	INFO	====> Epoch: 1255, cost 22.65 s
2024-01-02 02:49:36,539	44k	INFO	====> Epoch: 1256, cost 22.62 s
2024-01-02 02:49:59,166	44k	INFO	====> Epoch: 1257, cost 22.63 s
2024-01-02 02:50:21,780	44k	INFO	====> Epoch: 1258, cost 22.61 s
2024-01-02 02:50:44,429	44k	INFO	====> Epoch: 1259, cost 22.65 s
2024-01-02 02:51:07,061	44k	INFO	====> Epoch: 1260, cost 22.63 s
2024-01-02 02:51:29,687	44k	INFO	====> Epoch: 1261, cost 22.63 s
2024-01-02 02:51:42,861	44k	INFO	Train Epoch: 1262 [54%]
2024-01-02 02:51:42,864	44k	INFO	Losses: [2.380021095275879, 2.4201362133026123, 6.309925556182861, 17.910083770751953, 0.551832914352417], step: 32800, lr: 8.541616201111502e-05, reference_loss: 29.571998596191406
2024-01-02 02:51:48,064	44k	INFO	Saving model and optimizer state at iteration 1262 to ./logs/44k/G_32800.pth
2024-01-02 02:51:49,092	44k	INFO	Saving model and optimizer state at iteration 1262 to ./logs/44k/D_32800.pth
2024-01-02 02:51:49,582	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_30400.pth
2024-01-02 02:51:49,621	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_30400.pth
2024-01-02 02:51:59,123	44k	INFO	====> Epoch: 1262, cost 29.44 s
2024-01-02 02:52:21,970	44k	INFO	====> Epoch: 1263, cost 22.85 s
2024-01-02 02:52:44,874	44k	INFO	====> Epoch: 1264, cost 22.90 s
2024-01-02 02:53:07,716	44k	INFO	====> Epoch: 1265, cost 22.84 s
2024-01-02 02:53:30,499	44k	INFO	====> Epoch: 1266, cost 22.78 s
2024-01-02 02:53:53,155	44k	INFO	====> Epoch: 1267, cost 22.66 s
2024-01-02 02:54:15,955	44k	INFO	====> Epoch: 1268, cost 22.80 s
2024-01-02 02:54:38,571	44k	INFO	====> Epoch: 1269, cost 22.62 s
2024-01-02 02:54:44,754	44k	INFO	Train Epoch: 1270 [23%]
2024-01-02 02:54:44,757	44k	INFO	Losses: [2.55334734916687, 2.1279537677764893, 5.019504070281982, 16.31389045715332, 0.637808620929718], step: 33000, lr: 8.533078320933383e-05, reference_loss: 26.652503967285156
2024-01-02 02:55:01,687	44k	INFO	====> Epoch: 1270, cost 23.12 s
2024-01-02 02:55:24,561	44k	INFO	====> Epoch: 1271, cost 22.87 s
2024-01-02 02:55:47,445	44k	INFO	====> Epoch: 1272, cost 22.88 s
2024-01-02 02:56:10,300	44k	INFO	====> Epoch: 1273, cost 22.85 s
2024-01-02 02:56:33,136	44k	INFO	====> Epoch: 1274, cost 22.84 s
2024-01-02 02:56:55,974	44k	INFO	====> Epoch: 1275, cost 22.84 s
2024-01-02 02:57:18,639	44k	INFO	====> Epoch: 1276, cost 22.67 s
2024-01-02 02:57:40,610	44k	INFO	Train Epoch: 1277 [92%]
2024-01-02 02:57:40,613	44k	INFO	Losses: [2.3726744651794434, 2.243753433227539, 6.727160453796387, 20.53542137145996, 0.758307158946991], step: 33200, lr: 8.525614676735643e-05, reference_loss: 32.6373176574707
2024-01-02 02:57:41,777	44k	INFO	====> Epoch: 1277, cost 23.14 s
2024-01-02 02:58:04,388	44k	INFO	====> Epoch: 1278, cost 22.61 s
2024-01-02 02:58:27,057	44k	INFO	====> Epoch: 1279, cost 22.67 s
2024-01-02 02:58:49,715	44k	INFO	====> Epoch: 1280, cost 22.66 s
2024-01-02 02:59:12,586	44k	INFO	====> Epoch: 1281, cost 22.87 s
2024-01-02 02:59:35,405	44k	INFO	====> Epoch: 1282, cost 22.82 s
2024-01-02 02:59:58,205	44k	INFO	====> Epoch: 1283, cost 22.80 s
2024-01-02 03:00:21,003	44k	INFO	====> Epoch: 1284, cost 22.80 s
2024-01-02 03:00:36,074	44k	INFO	Train Epoch: 1285 [62%]
2024-01-02 03:00:36,077	44k	INFO	Losses: [2.3365495204925537, 2.419301986694336, 6.3870439529418945, 18.240825653076172, 0.38999155163764954], step: 33400, lr: 8.517092791082984e-05, reference_loss: 29.773712158203125
2024-01-02 03:00:44,315	44k	INFO	====> Epoch: 1285, cost 23.31 s
2024-01-02 03:01:07,066	44k	INFO	====> Epoch: 1286, cost 22.75 s
2024-01-02 03:01:29,876	44k	INFO	====> Epoch: 1287, cost 22.81 s
2024-01-02 03:01:52,645	44k	INFO	====> Epoch: 1288, cost 22.77 s
2024-01-02 03:02:15,479	44k	INFO	====> Epoch: 1289, cost 22.83 s
2024-01-02 03:02:38,307	44k	INFO	====> Epoch: 1290, cost 22.83 s
2024-01-02 03:03:01,266	44k	INFO	====> Epoch: 1291, cost 22.96 s
2024-01-02 03:03:23,943	44k	INFO	====> Epoch: 1292, cost 22.68 s
2024-01-02 03:03:31,928	44k	INFO	Train Epoch: 1293 [31%]
2024-01-02 03:03:31,931	44k	INFO	Losses: [2.386831283569336, 2.2581381797790527, 5.718206405639648, 17.428730010986328, 0.6175982356071472], step: 33600, lr: 8.50857942358858e-05, reference_loss: 28.409503936767578
2024-01-02 03:03:37,161	44k	INFO	Saving model and optimizer state at iteration 1293 to ./logs/44k/G_33600.pth
2024-01-02 03:03:38,022	44k	INFO	Saving model and optimizer state at iteration 1293 to ./logs/44k/D_33600.pth
2024-01-02 03:03:38,511	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_31200.pth
2024-01-02 03:03:38,549	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_31200.pth
2024-01-02 03:03:53,281	44k	INFO	====> Epoch: 1293, cost 29.34 s
2024-01-02 03:04:16,148	44k	INFO	====> Epoch: 1294, cost 22.87 s
2024-01-02 03:04:38,978	44k	INFO	====> Epoch: 1295, cost 22.83 s
2024-01-02 03:05:01,630	44k	INFO	====> Epoch: 1296, cost 22.65 s
2024-01-02 03:05:24,260	44k	INFO	====> Epoch: 1297, cost 22.63 s
2024-01-02 03:05:47,143	44k	INFO	====> Epoch: 1298, cost 22.88 s
2024-01-02 03:06:09,989	44k	INFO	====> Epoch: 1299, cost 22.85 s
2024-01-02 03:06:32,810	44k	INFO	====> Epoch: 1300, cost 22.82 s
2024-01-02 03:06:33,703	44k	INFO	Train Epoch: 1301 [0%]
2024-01-02 03:06:33,706	44k	INFO	Losses: [2.395631790161133, 2.411146402359009, 6.722590446472168, 18.311357498168945, 0.3380560278892517], step: 33800, lr: 8.500074565738009e-05, reference_loss: 30.178781509399414
2024-01-02 03:06:56,121	44k	INFO	====> Epoch: 1301, cost 23.31 s
2024-01-02 03:07:18,984	44k	INFO	====> Epoch: 1302, cost 22.86 s
2024-01-02 03:07:41,748	44k	INFO	====> Epoch: 1303, cost 22.76 s
2024-01-02 03:08:04,433	44k	INFO	====> Epoch: 1304, cost 22.69 s
2024-01-02 03:08:27,253	44k	INFO	====> Epoch: 1305, cost 22.82 s
2024-01-02 03:08:50,034	44k	INFO	====> Epoch: 1306, cost 22.78 s
2024-01-02 03:09:12,873	44k	INFO	====> Epoch: 1307, cost 22.84 s
2024-01-02 03:09:29,708	44k	INFO	Train Epoch: 1308 [69%]
2024-01-02 03:09:29,711	44k	INFO	Losses: [2.3900763988494873, 2.33967924118042, 6.118305683135986, 18.482961654663086, 0.6470694541931152], step: 34000, lr: 8.492639788998965e-05, reference_loss: 29.978092193603516
2024-01-02 03:09:36,262	44k	INFO	====> Epoch: 1308, cost 23.39 s
2024-01-02 03:09:59,056	44k	INFO	====> Epoch: 1309, cost 22.79 s
2024-01-02 03:10:21,870	44k	INFO	====> Epoch: 1310, cost 22.81 s
2024-01-02 03:10:44,675	44k	INFO	====> Epoch: 1311, cost 22.81 s
2024-01-02 03:11:07,439	44k	INFO	====> Epoch: 1312, cost 22.76 s
2024-01-02 03:11:30,276	44k	INFO	====> Epoch: 1313, cost 22.84 s
2024-01-02 03:11:53,080	44k	INFO	====> Epoch: 1314, cost 22.80 s
2024-01-02 03:12:15,912	44k	INFO	====> Epoch: 1315, cost 22.83 s
2024-01-02 03:12:25,722	44k	INFO	Train Epoch: 1316 [38%]
2024-01-02 03:12:25,724	44k	INFO	Losses: [2.4337892532348633, 2.117819309234619, 6.630450248718262, 18.275423049926758, 0.526296079158783], step: 34200, lr: 8.484150863811133e-05, reference_loss: 29.98377799987793
2024-01-02 03:12:39,117	44k	INFO	====> Epoch: 1316, cost 23.21 s
2024-01-02 03:13:01,996	44k	INFO	====> Epoch: 1317, cost 22.88 s
2024-01-02 03:13:24,683	44k	INFO	====> Epoch: 1318, cost 22.69 s
2024-01-02 03:13:47,369	44k	INFO	====> Epoch: 1319, cost 22.69 s
2024-01-02 03:14:10,194	44k	INFO	====> Epoch: 1320, cost 22.82 s
2024-01-02 03:14:32,900	44k	INFO	====> Epoch: 1321, cost 22.71 s
2024-01-02 03:14:55,583	44k	INFO	====> Epoch: 1322, cost 22.68 s
2024-01-02 03:15:18,423	44k	INFO	====> Epoch: 1323, cost 22.84 s
2024-01-02 03:15:21,100	44k	INFO	Train Epoch: 1324 [8%]
2024-01-02 03:15:21,103	44k	INFO	Losses: [2.358752965927124, 2.751638650894165, 6.829919338226318, 20.07991600036621, 0.4245965778827667], step: 34400, lr: 8.47567042383551e-05, reference_loss: 32.444820404052734
2024-01-02 03:15:26,498	44k	INFO	Saving model and optimizer state at iteration 1324 to ./logs/44k/G_34400.pth
2024-01-02 03:15:27,373	44k	INFO	Saving model and optimizer state at iteration 1324 to ./logs/44k/D_34400.pth
2024-01-02 03:15:27,860	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_32000.pth
2024-01-02 03:15:27,898	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_32000.pth
2024-01-02 03:15:48,161	44k	INFO	====> Epoch: 1324, cost 29.74 s
2024-01-02 03:16:11,058	44k	INFO	====> Epoch: 1325, cost 22.90 s
2024-01-02 03:16:33,929	44k	INFO	====> Epoch: 1326, cost 22.87 s
2024-01-02 03:16:56,623	44k	INFO	====> Epoch: 1327, cost 22.69 s
2024-01-02 03:17:19,332	44k	INFO	====> Epoch: 1328, cost 22.71 s
2024-01-02 03:17:42,134	44k	INFO	====> Epoch: 1329, cost 22.80 s
2024-01-02 03:18:04,891	44k	INFO	====> Epoch: 1330, cost 22.76 s
2024-01-02 03:18:23,393	44k	INFO	Train Epoch: 1331 [77%]
2024-01-02 03:18:23,396	44k	INFO	Losses: [2.36267352104187, 2.4034831523895264, 6.066029071807861, 17.56068229675293, 0.6520277857780457], step: 34600, lr: 8.468256992714691e-05, reference_loss: 29.04489517211914
2024-01-02 03:18:27,951	44k	INFO	====> Epoch: 1331, cost 23.06 s
2024-01-02 03:18:50,582	44k	INFO	====> Epoch: 1332, cost 22.63 s
2024-01-02 03:19:13,312	44k	INFO	====> Epoch: 1333, cost 22.73 s
2024-01-02 03:19:36,111	44k	INFO	====> Epoch: 1334, cost 22.80 s
2024-01-02 03:19:58,938	44k	INFO	====> Epoch: 1335, cost 22.83 s
2024-01-02 03:20:21,898	44k	INFO	====> Epoch: 1336, cost 22.96 s
2024-01-02 03:20:44,710	44k	INFO	====> Epoch: 1337, cost 22.81 s
2024-01-02 03:21:07,518	44k	INFO	====> Epoch: 1338, cost 22.81 s
2024-01-02 03:21:18,997	44k	INFO	Train Epoch: 1339 [46%]
2024-01-02 03:21:19,000	44k	INFO	Losses: [2.34787654876709, 2.650393486022949, 5.970956802368164, 17.26835060119629, 0.5203250646591187], step: 34800, lr: 8.459792439658338e-05, reference_loss: 28.757902145385742
2024-01-02 03:21:30,689	44k	INFO	====> Epoch: 1339, cost 23.17 s
2024-01-02 03:21:53,526	44k	INFO	====> Epoch: 1340, cost 22.84 s
2024-01-02 03:22:16,236	44k	INFO	====> Epoch: 1341, cost 22.71 s
2024-01-02 03:22:39,070	44k	INFO	====> Epoch: 1342, cost 22.83 s
2024-01-02 03:23:01,852	44k	INFO	====> Epoch: 1343, cost 22.78 s
2024-01-02 03:23:24,593	44k	INFO	====> Epoch: 1344, cost 22.74 s
2024-01-02 03:23:47,333	44k	INFO	====> Epoch: 1345, cost 22.74 s
2024-01-02 03:24:10,251	44k	INFO	====> Epoch: 1346, cost 22.92 s
2024-01-02 03:24:14,712	44k	INFO	Train Epoch: 1347 [15%]
2024-01-02 03:24:14,715	44k	INFO	Losses: [2.4367318153381348, 2.1264431476593018, 5.153464317321777, 17.083871841430664, 0.48075565695762634], step: 35000, lr: 8.451336347452725e-05, reference_loss: 27.281265258789062
2024-01-02 03:24:33,561	44k	INFO	====> Epoch: 1347, cost 23.31 s
2024-01-02 03:24:56,421	44k	INFO	====> Epoch: 1348, cost 22.86 s
2024-01-02 03:25:19,145	44k	INFO	====> Epoch: 1349, cost 22.72 s
2024-01-02 03:25:41,808	44k	INFO	====> Epoch: 1350, cost 22.66 s
2024-01-02 03:26:04,523	44k	INFO	====> Epoch: 1351, cost 22.72 s
2024-01-02 03:26:27,358	44k	INFO	====> Epoch: 1352, cost 22.84 s
2024-01-02 03:26:50,010	44k	INFO	====> Epoch: 1353, cost 22.65 s
2024-01-02 03:27:10,314	44k	INFO	Train Epoch: 1354 [85%]
2024-01-02 03:27:10,317	44k	INFO	Losses: [2.1601569652557373, 2.727372169494629, 6.697452068328857, 17.43531608581543, 0.6245196461677551], step: 35200, lr: 8.443944200665783e-05, reference_loss: 29.644817352294922
2024-01-02 03:27:15,747	44k	INFO	Saving model and optimizer state at iteration 1354 to ./logs/44k/G_35200.pth
2024-01-02 03:27:16,591	44k	INFO	Saving model and optimizer state at iteration 1354 to ./logs/44k/D_35200.pth
2024-01-02 03:27:17,085	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_32800.pth
2024-01-02 03:27:17,124	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_32800.pth
2024-01-02 03:27:19,572	44k	INFO	====> Epoch: 1354, cost 29.56 s
2024-01-02 03:27:42,247	44k	INFO	====> Epoch: 1355, cost 22.67 s
2024-01-02 03:28:05,067	44k	INFO	====> Epoch: 1356, cost 22.82 s
2024-01-02 03:28:27,828	44k	INFO	====> Epoch: 1357, cost 22.76 s
2024-01-02 03:28:50,491	44k	INFO	====> Epoch: 1358, cost 22.66 s
2024-01-02 03:29:13,193	44k	INFO	====> Epoch: 1359, cost 22.70 s
2024-01-02 03:29:35,940	44k	INFO	====> Epoch: 1360, cost 22.75 s
2024-01-02 03:29:58,715	44k	INFO	====> Epoch: 1361, cost 22.77 s
2024-01-02 03:30:11,960	44k	INFO	Train Epoch: 1362 [54%]
2024-01-02 03:30:11,963	44k	INFO	Losses: [2.507016181945801, 2.1558151245117188, 5.759687423706055, 17.74907875061035, 0.8876311779022217], step: 35400, lr: 8.43550394976729e-05, reference_loss: 29.059226989746094
2024-01-02 03:30:22,042	44k	INFO	====> Epoch: 1362, cost 23.33 s
2024-01-02 03:30:44,833	44k	INFO	====> Epoch: 1363, cost 22.79 s
2024-01-02 03:31:07,438	44k	INFO	====> Epoch: 1364, cost 22.61 s
2024-01-02 03:31:30,041	44k	INFO	====> Epoch: 1365, cost 22.60 s
2024-01-02 03:31:52,692	44k	INFO	====> Epoch: 1366, cost 22.65 s
2024-01-02 03:32:15,299	44k	INFO	====> Epoch: 1367, cost 22.61 s
2024-01-02 03:32:37,885	44k	INFO	====> Epoch: 1368, cost 22.59 s
2024-01-02 03:33:00,686	44k	INFO	====> Epoch: 1369, cost 22.80 s
2024-01-02 03:33:06,933	44k	INFO	Train Epoch: 1370 [23%]
2024-01-02 03:33:06,935	44k	INFO	Losses: [2.401181936264038, 2.556239366531372, 6.777824401855469, 16.1512508392334, 0.4568830132484436], step: 35600, lr: 8.427072135428007e-05, reference_loss: 28.343379974365234
2024-01-02 03:33:23,924	44k	INFO	====> Epoch: 1370, cost 23.24 s
2024-01-02 03:33:46,764	44k	INFO	====> Epoch: 1371, cost 22.84 s
2024-01-02 03:34:09,347	44k	INFO	====> Epoch: 1372, cost 22.58 s
2024-01-02 03:34:31,984	44k	INFO	====> Epoch: 1373, cost 22.64 s
2024-01-02 03:34:54,651	44k	INFO	====> Epoch: 1374, cost 22.67 s
2024-01-02 03:35:17,393	44k	INFO	====> Epoch: 1375, cost 22.74 s
2024-01-02 03:35:40,200	44k	INFO	====> Epoch: 1376, cost 22.81 s
2024-01-02 03:36:02,179	44k	INFO	Train Epoch: 1377 [92%]
2024-01-02 03:36:02,182	44k	INFO	Losses: [2.3325695991516113, 2.3148746490478516, 5.992058277130127, 17.184642791748047, 0.5517973899841309], step: 35800, lr: 8.419701211866551e-05, reference_loss: 28.375944137573242
2024-01-02 03:36:03,269	44k	INFO	====> Epoch: 1377, cost 23.07 s
2024-01-02 03:36:25,939	44k	INFO	====> Epoch: 1378, cost 22.67 s
2024-01-02 03:36:48,681	44k	INFO	====> Epoch: 1379, cost 22.74 s
2024-01-02 03:37:11,498	44k	INFO	====> Epoch: 1380, cost 22.82 s
2024-01-02 03:37:34,417	44k	INFO	====> Epoch: 1381, cost 22.92 s
2024-01-02 03:37:57,214	44k	INFO	====> Epoch: 1382, cost 22.80 s
2024-01-02 03:38:19,971	44k	INFO	====> Epoch: 1383, cost 22.76 s
2024-01-02 03:38:42,789	44k	INFO	====> Epoch: 1384, cost 22.82 s
2024-01-02 03:38:57,804	44k	INFO	Train Epoch: 1385 [62%]
2024-01-02 03:38:57,807	44k	INFO	Losses: [2.5718345642089844, 2.288546085357666, 5.693837642669678, 16.077608108520508, 0.5117983818054199], step: 36000, lr: 8.411285193353202e-05, reference_loss: 27.143625259399414
2024-01-02 03:39:03,093	44k	INFO	Saving model and optimizer state at iteration 1385 to ./logs/44k/G_36000.pth
2024-01-02 03:39:03,973	44k	INFO	Saving model and optimizer state at iteration 1385 to ./logs/44k/D_36000.pth
2024-01-02 03:39:04,466	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_33600.pth
2024-01-02 03:39:04,505	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_33600.pth
2024-01-02 03:39:12,169	44k	INFO	====> Epoch: 1385, cost 29.38 s
2024-01-02 03:39:34,834	44k	INFO	====> Epoch: 1386, cost 22.66 s
2024-01-02 03:39:57,562	44k	INFO	====> Epoch: 1387, cost 22.73 s
2024-01-02 03:40:20,498	44k	INFO	====> Epoch: 1388, cost 22.94 s
2024-01-02 03:40:43,214	44k	INFO	====> Epoch: 1389, cost 22.72 s
2024-01-02 03:41:05,991	44k	INFO	====> Epoch: 1390, cost 22.78 s
2024-01-02 03:41:28,788	44k	INFO	====> Epoch: 1391, cost 22.80 s
2024-01-02 03:41:51,624	44k	INFO	====> Epoch: 1392, cost 22.84 s
2024-01-02 03:41:59,637	44k	INFO	Train Epoch: 1393 [31%]
2024-01-02 03:41:59,641	44k	INFO	Losses: [2.4315123558044434, 2.279106855392456, 6.34987211227417, 17.325830459594727, 0.5993741154670715], step: 36200, lr: 8.40287758717728e-05, reference_loss: 28.98569679260254
2024-01-02 03:42:14,845	44k	INFO	====> Epoch: 1393, cost 23.22 s
2024-01-02 03:42:37,493	44k	INFO	====> Epoch: 1394, cost 22.65 s
2024-01-02 03:43:00,142	44k	INFO	====> Epoch: 1395, cost 22.65 s
2024-01-02 03:43:22,767	44k	INFO	====> Epoch: 1396, cost 22.63 s
2024-01-02 03:43:45,423	44k	INFO	====> Epoch: 1397, cost 22.66 s
2024-01-02 03:44:08,217	44k	INFO	====> Epoch: 1398, cost 22.79 s
2024-01-02 03:44:31,156	44k	INFO	====> Epoch: 1399, cost 22.94 s
2024-01-02 03:44:53,988	44k	INFO	====> Epoch: 1400, cost 22.83 s
2024-01-02 03:44:54,880	44k	INFO	Train Epoch: 1401 [0%]
2024-01-02 03:44:54,883	44k	INFO	Losses: [2.431737184524536, 2.524885892868042, 6.433837413787842, 17.52056121826172, 0.3755508363246918], step: 36400, lr: 8.394478384930123e-05, reference_loss: 29.28657341003418
2024-01-02 03:45:17,284	44k	INFO	====> Epoch: 1401, cost 23.30 s
2024-01-02 03:45:40,093	44k	INFO	====> Epoch: 1402, cost 22.81 s
2024-01-02 03:46:02,905	44k	INFO	====> Epoch: 1403, cost 22.81 s
2024-01-02 03:46:25,724	44k	INFO	====> Epoch: 1404, cost 22.82 s
2024-01-02 03:46:48,523	44k	INFO	====> Epoch: 1405, cost 22.80 s
2024-01-02 03:47:11,295	44k	INFO	====> Epoch: 1406, cost 22.77 s
2024-01-02 03:47:34,056	44k	INFO	====> Epoch: 1407, cost 22.76 s
2024-01-02 03:47:50,859	44k	INFO	Train Epoch: 1408 [69%]
2024-01-02 03:47:50,862	44k	INFO	Losses: [2.0221948623657227, 2.861729860305786, 8.111154556274414, 20.088973999023438, 0.5684797167778015], step: 36600, lr: 8.387135970207758e-05, reference_loss: 33.65253448486328
2024-01-02 03:47:57,484	44k	INFO	====> Epoch: 1408, cost 23.43 s
2024-01-02 03:48:20,142	44k	INFO	====> Epoch: 1409, cost 22.66 s
2024-01-02 03:48:42,838	44k	INFO	====> Epoch: 1410, cost 22.70 s
2024-01-02 03:49:05,641	44k	INFO	====> Epoch: 1411, cost 22.80 s
2024-01-02 03:49:28,428	44k	INFO	====> Epoch: 1412, cost 22.79 s
2024-01-02 03:49:51,178	44k	INFO	====> Epoch: 1413, cost 22.75 s
2024-01-02 03:50:13,945	44k	INFO	====> Epoch: 1414, cost 22.77 s
2024-01-02 03:50:36,704	44k	INFO	====> Epoch: 1415, cost 22.76 s
2024-01-02 03:50:46,502	44k	INFO	Train Epoch: 1416 [38%]
2024-01-02 03:50:46,505	44k	INFO	Losses: [1.9641597270965576, 3.668994903564453, 8.162793159484863, 16.921968460083008, 0.7378225922584534], step: 36800, lr: 8.378752502692335e-05, reference_loss: 31.455739974975586
2024-01-02 03:50:51,772	44k	INFO	Saving model and optimizer state at iteration 1416 to ./logs/44k/G_36800.pth
2024-01-02 03:50:52,829	44k	INFO	Saving model and optimizer state at iteration 1416 to ./logs/44k/D_36800.pth
2024-01-02 03:50:53,318	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_34400.pth
2024-01-02 03:50:53,357	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_34400.pth
2024-01-02 03:51:06,368	44k	INFO	====> Epoch: 1416, cost 29.66 s
2024-01-02 03:51:29,227	44k	INFO	====> Epoch: 1417, cost 22.86 s
2024-01-02 03:51:51,924	44k	INFO	====> Epoch: 1418, cost 22.70 s
2024-01-02 03:52:14,735	44k	INFO	====> Epoch: 1419, cost 22.81 s
2024-01-02 03:52:37,412	44k	INFO	====> Epoch: 1420, cost 22.68 s
2024-01-02 03:53:00,088	44k	INFO	====> Epoch: 1421, cost 22.68 s
2024-01-02 03:53:22,699	44k	INFO	====> Epoch: 1422, cost 22.61 s
2024-01-02 03:53:45,381	44k	INFO	====> Epoch: 1423, cost 22.68 s
2024-01-02 03:53:48,024	44k	INFO	Train Epoch: 1424 [8%]
2024-01-02 03:53:48,027	44k	INFO	Losses: [2.4810562133789062, 2.25087571144104, 5.336428165435791, 17.089168548583984, 0.3963342010974884], step: 37000, lr: 8.370377414977579e-05, reference_loss: 27.553861618041992
2024-01-02 03:54:08,426	44k	INFO	====> Epoch: 1424, cost 23.05 s
2024-01-02 03:54:31,290	44k	INFO	====> Epoch: 1425, cost 22.86 s
2024-01-02 03:54:54,116	44k	INFO	====> Epoch: 1426, cost 22.83 s
2024-01-02 03:55:16,951	44k	INFO	====> Epoch: 1427, cost 22.83 s
2024-01-02 03:55:39,760	44k	INFO	====> Epoch: 1428, cost 22.81 s
2024-01-02 03:56:02,444	44k	INFO	====> Epoch: 1429, cost 22.68 s
2024-01-02 03:56:25,130	44k	INFO	====> Epoch: 1430, cost 22.69 s
2024-01-02 03:56:43,613	44k	INFO	Train Epoch: 1431 [77%]
2024-01-02 03:56:43,616	44k	INFO	Losses: [2.2973861694335938, 2.297447681427002, 7.48189640045166, 19.858734130859375, 0.5981725454330444], step: 37200, lr: 8.363056080697438e-05, reference_loss: 32.53363800048828
2024-01-02 03:56:48,160	44k	INFO	====> Epoch: 1431, cost 23.03 s
2024-01-02 03:57:10,745	44k	INFO	====> Epoch: 1432, cost 22.58 s
2024-01-02 03:57:33,455	44k	INFO	====> Epoch: 1433, cost 22.71 s
2024-01-02 03:57:56,364	44k	INFO	====> Epoch: 1434, cost 22.91 s
2024-01-02 03:58:19,159	44k	INFO	====> Epoch: 1435, cost 22.79 s
2024-01-02 03:58:41,989	44k	INFO	====> Epoch: 1436, cost 22.83 s
2024-01-02 03:59:04,825	44k	INFO	====> Epoch: 1437, cost 22.84 s
2024-01-02 03:59:27,668	44k	INFO	====> Epoch: 1438, cost 22.84 s
2024-01-02 03:59:39,166	44k	INFO	Train Epoch: 1439 [46%]
2024-01-02 03:59:39,169	44k	INFO	Losses: [2.430522918701172, 2.2694427967071533, 6.664377689361572, 18.254215240478516, 0.5655428767204285], step: 37400, lr: 8.354696682539207e-05, reference_loss: 30.184101104736328
2024-01-02 03:59:50,862	44k	INFO	====> Epoch: 1439, cost 23.19 s
2024-01-02 04:00:13,656	44k	INFO	====> Epoch: 1440, cost 22.79 s
2024-01-02 04:00:36,333	44k	INFO	====> Epoch: 1441, cost 22.68 s
2024-01-02 04:00:58,981	44k	INFO	====> Epoch: 1442, cost 22.65 s
2024-01-02 04:01:21,796	44k	INFO	====> Epoch: 1443, cost 22.82 s
2024-01-02 04:01:44,706	44k	INFO	====> Epoch: 1444, cost 22.91 s
2024-01-02 04:02:07,522	44k	INFO	====> Epoch: 1445, cost 22.82 s
2024-01-02 04:02:30,325	44k	INFO	====> Epoch: 1446, cost 22.80 s
2024-01-02 04:02:34,776	44k	INFO	Train Epoch: 1447 [15%]
2024-01-02 04:02:34,779	44k	INFO	Losses: [2.479576826095581, 2.179145097732544, 7.096952438354492, 19.076223373413086, 0.3703753650188446], step: 37600, lr: 8.346345640122811e-05, reference_loss: 31.202272415161133
2024-01-02 04:02:40,023	44k	INFO	Saving model and optimizer state at iteration 1447 to ./logs/44k/G_37600.pth
2024-01-02 04:02:40,897	44k	INFO	Saving model and optimizer state at iteration 1447 to ./logs/44k/D_37600.pth
2024-01-02 04:02:41,384	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_35200.pth
2024-01-02 04:02:41,423	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_35200.pth
2024-01-02 04:02:59,723	44k	INFO	====> Epoch: 1447, cost 29.40 s
2024-01-02 04:03:22,545	44k	INFO	====> Epoch: 1448, cost 22.82 s
2024-01-02 04:03:45,409	44k	INFO	====> Epoch: 1449, cost 22.86 s
2024-01-02 04:04:08,230	44k	INFO	====> Epoch: 1450, cost 22.82 s
2024-01-02 04:04:31,237	44k	INFO	====> Epoch: 1451, cost 23.01 s
2024-01-02 04:04:54,054	44k	INFO	====> Epoch: 1452, cost 22.82 s
2024-01-02 04:05:16,888	44k	INFO	====> Epoch: 1453, cost 22.83 s
2024-01-02 04:05:37,257	44k	INFO	Train Epoch: 1454 [85%]
2024-01-02 04:05:37,260	44k	INFO	Losses: [2.700197696685791, 2.3096063137054443, 5.0698442459106445, 16.498685836791992, 0.5661051869392395], step: 37800, lr: 8.339045325761886e-05, reference_loss: 27.144439697265625
2024-01-02 04:05:40,128	44k	INFO	====> Epoch: 1454, cost 23.24 s
2024-01-02 04:06:02,950	44k	INFO	====> Epoch: 1455, cost 22.82 s
2024-01-02 04:06:25,626	44k	INFO	====> Epoch: 1456, cost 22.68 s
2024-01-02 04:06:48,283	44k	INFO	====> Epoch: 1457, cost 22.66 s
2024-01-02 04:07:10,902	44k	INFO	====> Epoch: 1458, cost 22.62 s
2024-01-02 04:07:33,695	44k	INFO	====> Epoch: 1459, cost 22.79 s
2024-01-02 04:07:56,459	44k	INFO	====> Epoch: 1460, cost 22.76 s
2024-01-02 04:08:19,305	44k	INFO	====> Epoch: 1461, cost 22.85 s
2024-01-02 04:08:32,700	44k	INFO	Train Epoch: 1462 [54%]
2024-01-02 04:08:32,703	44k	INFO	Losses: [2.5370700359344482, 2.1605892181396484, 6.05945348739624, 18.532922744750977, 0.5518667101860046], step: 38000, lr: 8.330709927856511e-05, reference_loss: 29.841901779174805
2024-01-02 04:08:42,615	44k	INFO	====> Epoch: 1462, cost 23.31 s
2024-01-02 04:09:05,472	44k	INFO	====> Epoch: 1463, cost 22.86 s
2024-01-02 04:09:28,290	44k	INFO	====> Epoch: 1464, cost 22.82 s
2024-01-02 04:09:51,027	44k	INFO	====> Epoch: 1465, cost 22.74 s
2024-01-02 04:10:13,793	44k	INFO	====> Epoch: 1466, cost 22.77 s
2024-01-02 04:10:36,625	44k	INFO	====> Epoch: 1467, cost 22.83 s
2024-01-02 04:10:59,409	44k	INFO	====> Epoch: 1468, cost 22.78 s
2024-01-02 04:11:22,252	44k	INFO	====> Epoch: 1469, cost 22.84 s
2024-01-02 04:11:28,481	44k	INFO	Train Epoch: 1470 [23%]
2024-01-02 04:11:28,484	44k	INFO	Losses: [2.5220861434936523, 2.3487625122070312, 6.3545756340026855, 16.530933380126953, 0.4856301248073578], step: 38200, lr: 8.322382861703215e-05, reference_loss: 28.241987228393555
2024-01-02 04:11:45,584	44k	INFO	====> Epoch: 1470, cost 23.33 s
2024-01-02 04:12:08,403	44k	INFO	====> Epoch: 1471, cost 22.82 s
2024-01-02 04:12:31,238	44k	INFO	====> Epoch: 1472, cost 22.84 s
2024-01-02 04:12:53,900	44k	INFO	====> Epoch: 1473, cost 22.66 s
2024-01-02 04:13:16,714	44k	INFO	====> Epoch: 1474, cost 22.81 s
2024-01-02 04:13:39,536	44k	INFO	====> Epoch: 1475, cost 22.82 s
2024-01-02 04:14:02,299	44k	INFO	====> Epoch: 1476, cost 22.76 s
2024-01-02 04:14:24,336	44k	INFO	Train Epoch: 1477 [92%]
2024-01-02 04:14:24,339	44k	INFO	Losses: [2.426734447479248, 2.2903594970703125, 5.700412750244141, 17.034893035888672, 0.6360788345336914], step: 38400, lr: 8.315103506912256e-05, reference_loss: 28.088478088378906
2024-01-02 04:14:29,567	44k	INFO	Saving model and optimizer state at iteration 1477 to ./logs/44k/G_38400.pth
2024-01-02 04:14:30,610	44k	INFO	Saving model and optimizer state at iteration 1477 to ./logs/44k/D_38400.pth
2024-01-02 04:14:31,098	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_36000.pth
2024-01-02 04:14:31,137	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_36000.pth
2024-01-02 04:14:31,827	44k	INFO	====> Epoch: 1477, cost 29.53 s
2024-01-02 04:14:54,612	44k	INFO	====> Epoch: 1478, cost 22.79 s
2024-01-02 04:15:17,404	44k	INFO	====> Epoch: 1479, cost 22.79 s
2024-01-02 04:15:40,064	44k	INFO	====> Epoch: 1480, cost 22.66 s
2024-01-02 04:16:02,708	44k	INFO	====> Epoch: 1481, cost 22.64 s
2024-01-02 04:16:25,392	44k	INFO	====> Epoch: 1482, cost 22.68 s
2024-01-02 04:16:48,210	44k	INFO	====> Epoch: 1483, cost 22.82 s
2024-01-02 04:17:10,927	44k	INFO	====> Epoch: 1484, cost 22.72 s
2024-01-02 04:17:25,879	44k	INFO	Train Epoch: 1485 [62%]
2024-01-02 04:17:25,882	44k	INFO	Losses: [2.5739779472351074, 2.343674421310425, 4.917351245880127, 15.056805610656738, 0.7842262983322144], step: 38600, lr: 8.306792040353804e-05, reference_loss: 25.67603302001953
2024-01-02 04:17:34,000	44k	INFO	====> Epoch: 1485, cost 23.07 s
2024-01-02 04:17:56,735	44k	INFO	====> Epoch: 1486, cost 22.73 s
2024-01-02 04:18:19,650	44k	INFO	====> Epoch: 1487, cost 22.91 s
2024-01-02 04:18:42,363	44k	INFO	====> Epoch: 1488, cost 22.71 s
2024-01-02 04:19:05,179	44k	INFO	====> Epoch: 1489, cost 22.82 s
2024-01-02 04:19:27,953	44k	INFO	====> Epoch: 1490, cost 22.77 s
2024-01-02 04:19:50,745	44k	INFO	====> Epoch: 1491, cost 22.79 s
2024-01-02 04:20:13,544	44k	INFO	====> Epoch: 1492, cost 22.80 s
2024-01-02 04:20:21,567	44k	INFO	Train Epoch: 1493 [31%]
2024-01-02 04:20:21,570	44k	INFO	Losses: [2.3685762882232666, 2.5784637928009033, 6.094056129455566, 16.677160263061523, 0.5208932757377625], step: 38800, lr: 8.29848888162655e-05, reference_loss: 28.23914909362793
2024-01-02 04:20:36,685	44k	INFO	====> Epoch: 1493, cost 23.14 s
2024-01-02 04:20:59,503	44k	INFO	====> Epoch: 1494, cost 22.82 s
2024-01-02 04:21:22,290	44k	INFO	====> Epoch: 1495, cost 22.79 s
2024-01-02 04:21:45,083	44k	INFO	====> Epoch: 1496, cost 22.79 s
2024-01-02 04:22:07,903	44k	INFO	====> Epoch: 1497, cost 22.82 s
2024-01-02 04:22:30,716	44k	INFO	====> Epoch: 1498, cost 22.81 s
2024-01-02 04:22:53,485	44k	INFO	====> Epoch: 1499, cost 22.77 s
2024-01-02 04:23:16,141	44k	INFO	====> Epoch: 1500, cost 22.66 s
2024-01-02 04:23:17,031	44k	INFO	Train Epoch: 1501 [0%]
2024-01-02 04:23:17,034	44k	INFO	Losses: [2.392430305480957, 2.563858985900879, 5.915061950683594, 15.208742141723633, 0.5373291969299316], step: 39000, lr: 8.290194022426301e-05, reference_loss: 26.617422103881836
2024-01-02 04:23:39,277	44k	INFO	====> Epoch: 1501, cost 23.14 s
2024-01-02 04:24:01,929	44k	INFO	====> Epoch: 1502, cost 22.65 s
2024-01-02 04:24:24,585	44k	INFO	====> Epoch: 1503, cost 22.66 s
2024-01-02 04:24:47,241	44k	INFO	====> Epoch: 1504, cost 22.66 s
2024-01-02 04:25:09,905	44k	INFO	====> Epoch: 1505, cost 22.66 s
2024-01-02 04:25:32,764	44k	INFO	====> Epoch: 1506, cost 22.86 s
2024-01-02 04:25:55,539	44k	INFO	====> Epoch: 1507, cost 22.77 s
2024-01-02 04:26:12,352	44k	INFO	Train Epoch: 1508 [69%]
2024-01-02 04:26:12,355	44k	INFO	Losses: [2.65757155418396, 1.9128544330596924, 5.161363124847412, 15.708003997802734, 0.5197807550430298], step: 39200, lr: 8.282942822309947e-05, reference_loss: 25.95957374572754
2024-01-02 04:26:17,603	44k	INFO	Saving model and optimizer state at iteration 1508 to ./logs/44k/G_39200.pth
2024-01-02 04:26:18,481	44k	INFO	Saving model and optimizer state at iteration 1508 to ./logs/44k/D_39200.pth
2024-01-02 04:26:18,971	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_36800.pth
2024-01-02 04:26:19,010	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_36800.pth
2024-01-02 04:26:24,972	44k	INFO	====> Epoch: 1508, cost 29.43 s
2024-01-02 04:26:47,792	44k	INFO	====> Epoch: 1509, cost 22.82 s
2024-01-02 04:27:10,689	44k	INFO	====> Epoch: 1510, cost 22.90 s
2024-01-02 04:27:33,531	44k	INFO	====> Epoch: 1511, cost 22.84 s
2024-01-02 04:27:56,345	44k	INFO	====> Epoch: 1512, cost 22.81 s
2024-01-02 04:28:19,152	44k	INFO	====> Epoch: 1513, cost 22.81 s
2024-01-02 04:28:42,093	44k	INFO	====> Epoch: 1514, cost 22.94 s
2024-01-02 04:29:04,788	44k	INFO	====> Epoch: 1515, cost 22.70 s
2024-01-02 04:29:14,551	44k	INFO	Train Epoch: 1516 [38%]
2024-01-02 04:29:14,554	44k	INFO	Losses: [2.5072078704833984, 2.3364439010620117, 6.182792663574219, 17.91448402404785, 0.48602455854415894], step: 39400, lr: 8.274663502369312e-05, reference_loss: 29.42695426940918
2024-01-02 04:29:27,859	44k	INFO	====> Epoch: 1516, cost 23.07 s
2024-01-02 04:29:50,531	44k	INFO	====> Epoch: 1517, cost 22.67 s
2024-01-02 04:30:13,239	44k	INFO	====> Epoch: 1518, cost 22.71 s
2024-01-02 04:30:35,890	44k	INFO	====> Epoch: 1519, cost 22.65 s
2024-01-02 04:30:58,551	44k	INFO	====> Epoch: 1520, cost 22.66 s
2024-01-02 04:31:21,151	44k	INFO	====> Epoch: 1521, cost 22.60 s
2024-01-02 04:31:43,926	44k	INFO	====> Epoch: 1522, cost 22.78 s
2024-01-02 04:32:06,603	44k	INFO	====> Epoch: 1523, cost 22.68 s
2024-01-02 04:32:09,258	44k	INFO	Train Epoch: 1524 [8%]
2024-01-02 04:32:09,261	44k	INFO	Losses: [2.326437473297119, 2.603116512298584, 6.86650276184082, 18.6910400390625, 0.43047064542770386], step: 39600, lr: 8.266392458127321e-05, reference_loss: 30.91756820678711
2024-01-02 04:32:29,850	44k	INFO	====> Epoch: 1524, cost 23.25 s
2024-01-02 04:32:52,562	44k	INFO	====> Epoch: 1525, cost 22.71 s
2024-01-02 04:33:15,309	44k	INFO	====> Epoch: 1526, cost 22.75 s
2024-01-02 04:33:38,083	44k	INFO	====> Epoch: 1527, cost 22.77 s
2024-01-02 04:34:00,857	44k	INFO	====> Epoch: 1528, cost 22.77 s
2024-01-02 04:34:23,690	44k	INFO	====> Epoch: 1529, cost 22.83 s
2024-01-02 04:34:46,497	44k	INFO	====> Epoch: 1530, cost 22.81 s
2024-01-02 04:35:05,022	44k	INFO	Train Epoch: 1531 [77%]
2024-01-02 04:35:05,025	44k	INFO	Losses: [2.112874746322632, 2.572563648223877, 8.9072265625, 20.60590934753418, 0.5417086482048035], step: 39800, lr: 8.259162076571468e-05, reference_loss: 34.74028396606445
2024-01-02 04:35:09,564	44k	INFO	====> Epoch: 1531, cost 23.07 s
2024-01-02 04:35:32,287	44k	INFO	====> Epoch: 1532, cost 22.72 s
2024-01-02 04:35:55,241	44k	INFO	====> Epoch: 1533, cost 22.95 s
2024-01-02 04:36:18,051	44k	INFO	====> Epoch: 1534, cost 22.81 s
2024-01-02 04:36:40,879	44k	INFO	====> Epoch: 1535, cost 22.83 s
2024-01-02 04:37:03,697	44k	INFO	====> Epoch: 1536, cost 22.82 s
2024-01-02 04:37:26,538	44k	INFO	====> Epoch: 1537, cost 22.84 s
2024-01-02 04:37:49,370	44k	INFO	====> Epoch: 1538, cost 22.83 s
2024-01-02 04:38:00,867	44k	INFO	Train Epoch: 1539 [46%]
2024-01-02 04:38:00,871	44k	INFO	Losses: [2.4490082263946533, 2.3194751739501953, 5.115832805633545, 15.608625411987305, 0.4384476840496063], step: 40000, lr: 8.250906526975097e-05, reference_loss: 25.93138885498047
2024-01-02 04:38:06,160	44k	INFO	Saving model and optimizer state at iteration 1539 to ./logs/44k/G_40000.pth
2024-01-02 04:38:07,030	44k	INFO	Saving model and optimizer state at iteration 1539 to ./logs/44k/D_40000.pth
2024-01-02 04:38:07,519	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_37600.pth
2024-01-02 04:38:07,557	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_37600.pth
2024-01-02 04:38:18,872	44k	INFO	====> Epoch: 1539, cost 29.50 s
2024-01-02 04:38:41,699	44k	INFO	====> Epoch: 1540, cost 22.83 s
2024-01-02 04:39:04,448	44k	INFO	====> Epoch: 1541, cost 22.75 s
2024-01-02 04:39:27,259	44k	INFO	====> Epoch: 1542, cost 22.81 s
2024-01-02 04:39:50,054	44k	INFO	====> Epoch: 1543, cost 22.80 s
2024-01-02 04:40:12,891	44k	INFO	====> Epoch: 1544, cost 22.84 s
2024-01-02 04:40:35,727	44k	INFO	====> Epoch: 1545, cost 22.84 s
2024-01-02 04:40:58,554	44k	INFO	====> Epoch: 1546, cost 22.83 s
2024-01-02 04:41:02,996	44k	INFO	Train Epoch: 1547 [15%]
2024-01-02 04:41:02,999	44k	INFO	Losses: [2.4195284843444824, 2.5288360118865967, 5.972497463226318, 15.958473205566406, 0.4748607277870178], step: 40200, lr: 8.242659229317421e-05, reference_loss: 27.354196548461914
2024-01-02 04:41:21,709	44k	INFO	====> Epoch: 1547, cost 23.16 s
2024-01-02 04:41:44,534	44k	INFO	====> Epoch: 1548, cost 22.83 s
2024-01-02 04:42:07,361	44k	INFO	====> Epoch: 1549, cost 22.83 s
2024-01-02 04:42:30,186	44k	INFO	====> Epoch: 1550, cost 22.82 s
2024-01-02 04:42:52,973	44k	INFO	====> Epoch: 1551, cost 22.79 s
2024-01-02 04:43:15,946	44k	INFO	====> Epoch: 1552, cost 22.97 s
2024-01-02 04:43:38,767	44k	INFO	====> Epoch: 1553, cost 22.82 s
2024-01-02 04:43:59,076	44k	INFO	Train Epoch: 1554 [85%]
2024-01-02 04:43:59,079	44k	INFO	Losses: [2.511857509613037, 2.612583637237549, 6.068475246429443, 17.728580474853516, 0.6945764422416687], step: 40400, lr: 8.235449606550931e-05, reference_loss: 29.616073608398438
2024-01-02 04:44:01,944	44k	INFO	====> Epoch: 1554, cost 23.18 s
2024-01-02 04:44:24,726	44k	INFO	====> Epoch: 1555, cost 22.78 s
2024-01-02 04:44:47,398	44k	INFO	====> Epoch: 1556, cost 22.67 s
2024-01-02 04:45:10,198	44k	INFO	====> Epoch: 1557, cost 22.80 s
2024-01-02 04:45:32,898	44k	INFO	====> Epoch: 1558, cost 22.70 s
2024-01-02 04:45:55,584	44k	INFO	====> Epoch: 1559, cost 22.69 s
2024-01-02 04:46:18,339	44k	INFO	====> Epoch: 1560, cost 22.76 s
2024-01-02 04:46:41,032	44k	INFO	====> Epoch: 1561, cost 22.69 s
2024-01-02 04:46:54,355	44k	INFO	Train Epoch: 1562 [54%]
2024-01-02 04:46:54,358	44k	INFO	Losses: [2.2360358238220215, 2.9935972690582275, 6.8985090255737305, 17.38499641418457, 0.531990647315979], step: 40600, lr: 8.227217759052969e-05, reference_loss: 30.045127868652344
2024-01-02 04:47:04,322	44k	INFO	====> Epoch: 1562, cost 23.29 s
2024-01-02 04:47:26,931	44k	INFO	====> Epoch: 1563, cost 22.61 s
2024-01-02 04:47:49,582	44k	INFO	====> Epoch: 1564, cost 22.65 s
2024-01-02 04:48:12,243	44k	INFO	====> Epoch: 1565, cost 22.66 s
2024-01-02 04:48:34,857	44k	INFO	====> Epoch: 1566, cost 22.61 s
2024-01-02 04:48:57,513	44k	INFO	====> Epoch: 1567, cost 22.66 s
2024-01-02 04:49:20,347	44k	INFO	====> Epoch: 1568, cost 22.83 s
2024-01-02 04:49:43,154	44k	INFO	====> Epoch: 1569, cost 22.81 s
2024-01-02 04:49:49,374	44k	INFO	Train Epoch: 1570 [23%]
2024-01-02 04:49:49,377	44k	INFO	Losses: [2.4351296424865723, 2.3800485134124756, 5.73482084274292, 15.89887809753418, 0.6800000071525574], step: 40800, lr: 8.21899413980197e-05, reference_loss: 27.128877639770508
2024-01-02 04:49:54,803	44k	INFO	Saving model and optimizer state at iteration 1570 to ./logs/44k/G_40800.pth
2024-01-02 04:49:55,680	44k	INFO	Saving model and optimizer state at iteration 1570 to ./logs/44k/D_40800.pth
2024-01-02 04:49:56,175	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_38400.pth
2024-01-02 04:49:56,214	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_38400.pth
2024-01-02 04:50:12,712	44k	INFO	====> Epoch: 1570, cost 29.56 s
2024-01-02 04:50:35,635	44k	INFO	====> Epoch: 1571, cost 22.92 s
2024-01-02 04:50:58,441	44k	INFO	====> Epoch: 1572, cost 22.81 s
2024-01-02 04:51:21,242	44k	INFO	====> Epoch: 1573, cost 22.80 s
2024-01-02 04:51:44,062	44k	INFO	====> Epoch: 1574, cost 22.82 s
2024-01-02 04:52:06,887	44k	INFO	====> Epoch: 1575, cost 22.82 s
2024-01-02 04:52:29,731	44k	INFO	====> Epoch: 1576, cost 22.84 s
2024-01-02 04:52:51,807	44k	INFO	Train Epoch: 1577 [92%]
2024-01-02 04:52:51,810	44k	INFO	Losses: [2.37632417678833, 2.5471742153167725, 6.1616291999816895, 17.246932983398438, 0.6844437718391418], step: 41000, lr: 8.211805216225318e-05, reference_loss: 29.016504287719727
2024-01-02 04:52:53,049	44k	INFO	====> Epoch: 1577, cost 23.32 s
2024-01-02 04:53:15,833	44k	INFO	====> Epoch: 1578, cost 22.78 s
2024-01-02 04:53:38,669	44k	INFO	====> Epoch: 1579, cost 22.84 s
2024-01-02 04:54:01,499	44k	INFO	====> Epoch: 1580, cost 22.83 s
2024-01-02 04:54:24,214	44k	INFO	====> Epoch: 1581, cost 22.72 s
2024-01-02 04:54:46,841	44k	INFO	====> Epoch: 1582, cost 22.63 s
2024-01-02 04:55:09,516	44k	INFO	====> Epoch: 1583, cost 22.67 s
2024-01-02 04:55:32,273	44k	INFO	====> Epoch: 1584, cost 22.76 s
2024-01-02 04:55:47,345	44k	INFO	Train Epoch: 1585 [62%]
2024-01-02 04:55:47,348	44k	INFO	Losses: [2.7063517570495605, 2.4947240352630615, 6.916563034057617, 16.962369918823242, 0.38066500425338745], step: 41200, lr: 8.203597002775846e-05, reference_loss: 29.460674285888672
2024-01-02 04:55:55,504	44k	INFO	====> Epoch: 1585, cost 23.23 s
2024-01-02 04:56:18,331	44k	INFO	====> Epoch: 1586, cost 22.83 s
2024-01-02 04:56:41,275	44k	INFO	====> Epoch: 1587, cost 22.94 s
2024-01-02 04:57:03,926	44k	INFO	====> Epoch: 1588, cost 22.65 s
2024-01-02 04:57:26,585	44k	INFO	====> Epoch: 1589, cost 22.66 s
2024-01-02 04:57:49,345	44k	INFO	====> Epoch: 1590, cost 22.76 s
2024-01-02 04:58:12,171	44k	INFO	====> Epoch: 1591, cost 22.83 s
2024-01-02 04:58:34,980	44k	INFO	====> Epoch: 1592, cost 22.81 s
2024-01-02 04:58:42,996	44k	INFO	Train Epoch: 1593 [31%]
2024-01-02 04:58:42,999	44k	INFO	Losses: [2.6636078357696533, 2.042917490005493, 5.023623943328857, 14.980416297912598, 0.44404157996177673], step: 41400, lr: 8.195396993949628e-05, reference_loss: 25.15460777282715
2024-01-02 04:58:58,086	44k	INFO	====> Epoch: 1593, cost 23.11 s
2024-01-02 04:59:20,713	44k	INFO	====> Epoch: 1594, cost 22.63 s
2024-01-02 04:59:43,407	44k	INFO	====> Epoch: 1595, cost 22.69 s
2024-01-02 05:00:06,195	44k	INFO	====> Epoch: 1596, cost 22.79 s
2024-01-02 05:00:29,090	44k	INFO	====> Epoch: 1597, cost 22.89 s
2024-01-02 05:00:51,766	44k	INFO	====> Epoch: 1598, cost 22.68 s
2024-01-02 05:01:14,388	44k	INFO	====> Epoch: 1599, cost 22.62 s
2024-01-02 05:01:37,067	44k	INFO	====> Epoch: 1600, cost 22.68 s
2024-01-02 05:01:37,956	44k	INFO	Train Epoch: 1601 [0%]
2024-01-02 05:01:37,959	44k	INFO	Losses: [2.3873536586761475, 2.441208839416504, 6.019933223724365, 16.973752975463867, 0.2770794630050659], step: 41600, lr: 8.18720518154563e-05, reference_loss: 28.099327087402344
2024-01-02 05:01:43,255	44k	INFO	Saving model and optimizer state at iteration 1601 to ./logs/44k/G_41600.pth
2024-01-02 05:01:44,118	44k	INFO	Saving model and optimizer state at iteration 1601 to ./logs/44k/D_41600.pth
2024-01-02 05:01:44,611	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_39200.pth
2024-01-02 05:01:44,650	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_39200.pth
2024-01-02 05:02:06,568	44k	INFO	====> Epoch: 1601, cost 29.50 s
2024-01-02 05:02:29,444	44k	INFO	====> Epoch: 1602, cost 22.88 s
2024-01-02 05:02:52,276	44k	INFO	====> Epoch: 1603, cost 22.83 s
2024-01-02 05:03:15,192	44k	INFO	====> Epoch: 1604, cost 22.92 s
2024-01-02 05:03:37,909	44k	INFO	====> Epoch: 1605, cost 22.72 s
2024-01-02 05:04:00,677	44k	INFO	====> Epoch: 1606, cost 22.77 s
2024-01-02 05:04:23,351	44k	INFO	====> Epoch: 1607, cost 22.67 s
2024-01-02 05:04:40,075	44k	INFO	Train Epoch: 1608 [69%]
2024-01-02 05:04:40,078	44k	INFO	Losses: [2.3630683422088623, 2.356438159942627, 6.204142093658447, 17.503238677978516, 0.626579225063324], step: 41800, lr: 8.180044062878873e-05, reference_loss: 29.053466796875
2024-01-02 05:04:46,508	44k	INFO	====> Epoch: 1608, cost 23.16 s
2024-01-02 05:05:09,317	44k	INFO	====> Epoch: 1609, cost 22.81 s
2024-01-02 05:05:32,037	44k	INFO	====> Epoch: 1610, cost 22.72 s
2024-01-02 05:05:54,612	44k	INFO	====> Epoch: 1611, cost 22.58 s
2024-01-02 05:06:17,418	44k	INFO	====> Epoch: 1612, cost 22.81 s
2024-01-02 05:06:40,269	44k	INFO	====> Epoch: 1613, cost 22.85 s
2024-01-02 05:07:02,925	44k	INFO	====> Epoch: 1614, cost 22.66 s
2024-01-02 05:07:25,716	44k	INFO	====> Epoch: 1615, cost 22.79 s
2024-01-02 05:07:35,448	44k	INFO	Train Epoch: 1616 [38%]
2024-01-02 05:07:35,451	44k	INFO	Losses: [2.700925350189209, 2.257845640182495, 6.6326904296875, 18.218456268310547, 0.4649035334587097], step: 42000, lr: 8.171867596690716e-05, reference_loss: 30.27482032775879
2024-01-02 05:07:48,876	44k	INFO	====> Epoch: 1616, cost 23.16 s
2024-01-02 05:08:11,651	44k	INFO	====> Epoch: 1617, cost 22.78 s
2024-01-02 05:08:34,462	44k	INFO	====> Epoch: 1618, cost 22.81 s
2024-01-02 05:08:57,227	44k	INFO	====> Epoch: 1619, cost 22.77 s
2024-01-02 05:09:19,910	44k	INFO	====> Epoch: 1620, cost 22.68 s
2024-01-02 05:09:42,509	44k	INFO	====> Epoch: 1621, cost 22.60 s
2024-01-02 05:10:05,183	44k	INFO	====> Epoch: 1622, cost 22.67 s
2024-01-02 05:10:27,819	44k	INFO	====> Epoch: 1623, cost 22.64 s
2024-01-02 05:10:30,473	44k	INFO	Train Epoch: 1624 [8%]
2024-01-02 05:10:30,476	44k	INFO	Losses: [2.3400678634643555, 2.492723226547241, 6.540772438049316, 17.57599639892578, 0.5914970636367798], step: 42200, lr: 8.16369930339244e-05, reference_loss: 29.541057586669922
2024-01-02 05:10:51,140	44k	INFO	====> Epoch: 1624, cost 23.32 s
2024-01-02 05:11:13,779	44k	INFO	====> Epoch: 1625, cost 22.64 s
2024-01-02 05:11:36,439	44k	INFO	====> Epoch: 1626, cost 22.66 s
2024-01-02 05:11:59,111	44k	INFO	====> Epoch: 1627, cost 22.67 s
2024-01-02 05:12:21,768	44k	INFO	====> Epoch: 1628, cost 22.66 s
2024-01-02 05:12:44,405	44k	INFO	====> Epoch: 1629, cost 22.64 s
2024-01-02 05:13:07,133	44k	INFO	====> Epoch: 1630, cost 22.73 s
2024-01-02 05:13:25,645	44k	INFO	Train Epoch: 1631 [77%]
2024-01-02 05:13:25,648	44k	INFO	Losses: [2.1942100524902344, 2.675147533416748, 8.04677963256836, 19.165029525756836, 0.7464995384216309], step: 42400, lr: 8.156558744657806e-05, reference_loss: 32.827667236328125
2024-01-02 05:13:30,921	44k	INFO	Saving model and optimizer state at iteration 1631 to ./logs/44k/G_42400.pth
2024-01-02 05:13:31,962	44k	INFO	Saving model and optimizer state at iteration 1631 to ./logs/44k/D_42400.pth
2024-01-02 05:13:32,455	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_40000.pth
2024-01-02 05:13:32,494	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_40000.pth
2024-01-02 05:13:36,643	44k	INFO	====> Epoch: 1631, cost 29.51 s
2024-01-02 05:13:59,363	44k	INFO	====> Epoch: 1632, cost 22.72 s
2024-01-02 05:14:22,201	44k	INFO	====> Epoch: 1633, cost 22.84 s
2024-01-02 05:14:44,999	44k	INFO	====> Epoch: 1634, cost 22.80 s
2024-01-02 05:15:07,774	44k	INFO	====> Epoch: 1635, cost 22.78 s
2024-01-02 05:15:30,514	44k	INFO	====> Epoch: 1636, cost 22.74 s
2024-01-02 05:15:53,325	44k	INFO	====> Epoch: 1637, cost 22.81 s
2024-01-02 05:16:16,146	44k	INFO	====> Epoch: 1638, cost 22.82 s
2024-01-02 05:16:27,575	44k	INFO	Train Epoch: 1639 [46%]
2024-01-02 05:16:27,578	44k	INFO	Losses: [2.415433645248413, 2.3878350257873535, 7.337335586547852, 19.044612884521484, 0.45013555884361267], step: 42600, lr: 8.148405753515612e-05, reference_loss: 31.635353088378906
2024-01-02 05:16:39,165	44k	INFO	====> Epoch: 1639, cost 23.02 s
2024-01-02 05:17:01,859	44k	INFO	====> Epoch: 1640, cost 22.69 s
2024-01-02 05:17:24,737	44k	INFO	====> Epoch: 1641, cost 22.88 s
2024-01-02 05:17:47,541	44k	INFO	====> Epoch: 1642, cost 22.80 s
2024-01-02 05:18:10,364	44k	INFO	====> Epoch: 1643, cost 22.82 s
2024-01-02 05:18:33,042	44k	INFO	====> Epoch: 1644, cost 22.68 s
2024-01-02 05:18:55,720	44k	INFO	====> Epoch: 1645, cost 22.68 s
2024-01-02 05:19:18,388	44k	INFO	====> Epoch: 1646, cost 22.67 s
2024-01-02 05:19:22,809	44k	INFO	Train Epoch: 1647 [15%]
2024-01-02 05:19:22,812	44k	INFO	Losses: [2.403590679168701, 2.2634098529815674, 7.160855770111084, 18.8660888671875, 0.4176839292049408], step: 42800, lr: 8.14026091179852e-05, reference_loss: 31.111629486083984
2024-01-02 05:19:41,404	44k	INFO	====> Epoch: 1647, cost 23.02 s
2024-01-02 05:20:04,112	44k	INFO	====> Epoch: 1648, cost 22.71 s
2024-01-02 05:20:26,866	44k	INFO	====> Epoch: 1649, cost 22.75 s
2024-01-02 05:20:49,645	44k	INFO	====> Epoch: 1650, cost 22.78 s
2024-01-02 05:21:12,386	44k	INFO	====> Epoch: 1651, cost 22.74 s
2024-01-02 05:21:35,137	44k	INFO	====> Epoch: 1652, cost 22.75 s
2024-01-02 05:21:57,758	44k	INFO	====> Epoch: 1653, cost 22.62 s
2024-01-02 05:22:17,935	44k	INFO	Train Epoch: 1654 [85%]
2024-01-02 05:22:17,938	44k	INFO	Losses: [2.160299301147461, 2.5948567390441895, 7.369344234466553, 16.466615676879883, 0.6337329745292664], step: 43000, lr: 8.133140853967411e-05, reference_loss: 29.224849700927734
2024-01-02 05:22:20,778	44k	INFO	====> Epoch: 1654, cost 23.02 s
2024-01-02 05:22:43,430	44k	INFO	====> Epoch: 1655, cost 22.65 s
2024-01-02 05:23:06,152	44k	INFO	====> Epoch: 1656, cost 22.72 s
2024-01-02 05:23:28,927	44k	INFO	====> Epoch: 1657, cost 22.77 s
2024-01-02 05:23:51,635	44k	INFO	====> Epoch: 1658, cost 22.71 s
2024-01-02 05:24:14,280	44k	INFO	====> Epoch: 1659, cost 22.64 s
2024-01-02 05:24:36,990	44k	INFO	====> Epoch: 1660, cost 22.71 s
2024-01-02 05:24:59,482	44k	INFO	====> Epoch: 1661, cost 22.49 s
2024-01-02 05:25:12,651	44k	INFO	Train Epoch: 1662 [54%]
2024-01-02 05:25:12,654	44k	INFO	Losses: [2.4978203773498535, 2.3568148612976074, 6.317318439483643, 16.910783767700195, 0.3617437481880188], step: 43200, lr: 8.125011270473142e-05, reference_loss: 28.444480895996094
2024-01-02 05:25:17,920	44k	INFO	Saving model and optimizer state at iteration 1662 to ./logs/44k/G_43200.pth
2024-01-02 05:25:18,746	44k	INFO	Saving model and optimizer state at iteration 1662 to ./logs/44k/D_43200.pth
2024-01-02 05:25:19,234	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_40800.pth
2024-01-02 05:25:19,273	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_40800.pth
2024-01-02 05:25:28,714	44k	INFO	====> Epoch: 1662, cost 29.23 s
2024-01-02 05:25:51,411	44k	INFO	====> Epoch: 1663, cost 22.70 s
2024-01-02 05:26:14,192	44k	INFO	====> Epoch: 1664, cost 22.78 s
2024-01-02 05:26:37,015	44k	INFO	====> Epoch: 1665, cost 22.82 s
2024-01-02 05:26:59,699	44k	INFO	====> Epoch: 1666, cost 22.68 s
2024-01-02 05:27:22,506	44k	INFO	====> Epoch: 1667, cost 22.81 s
2024-01-02 05:27:45,147	44k	INFO	====> Epoch: 1668, cost 22.64 s
2024-01-02 05:28:07,961	44k	INFO	====> Epoch: 1669, cost 22.81 s
2024-01-02 05:28:14,199	44k	INFO	Train Epoch: 1670 [23%]
2024-01-02 05:28:14,202	44k	INFO	Losses: [2.319467306137085, 2.5981497764587402, 5.869995594024658, 15.798943519592285, 0.4814753532409668], step: 43400, lr: 8.116889813006563e-05, reference_loss: 27.068031311035156
2024-01-02 05:28:31,182	44k	INFO	====> Epoch: 1670, cost 23.22 s
2024-01-02 05:28:54,018	44k	INFO	====> Epoch: 1671, cost 22.84 s
2024-01-02 05:29:16,781	44k	INFO	====> Epoch: 1672, cost 22.76 s
2024-01-02 05:29:39,603	44k	INFO	====> Epoch: 1673, cost 22.82 s
2024-01-02 05:30:02,400	44k	INFO	====> Epoch: 1674, cost 22.80 s
2024-01-02 05:30:25,241	44k	INFO	====> Epoch: 1675, cost 22.84 s
2024-01-02 05:30:48,079	44k	INFO	====> Epoch: 1676, cost 22.84 s
2024-01-02 05:31:10,164	44k	INFO	Train Epoch: 1677 [92%]
2024-01-02 05:31:10,167	44k	INFO	Losses: [2.435823440551758, 2.371408700942993, 6.4437079429626465, 19.01626205444336, 0.7665976881980896], step: 43600, lr: 8.109790197219855e-05, reference_loss: 31.03380012512207
2024-01-02 05:31:11,412	44k	INFO	====> Epoch: 1677, cost 23.33 s
2024-01-02 05:31:34,085	44k	INFO	====> Epoch: 1678, cost 22.67 s
2024-01-02 05:31:56,954	44k	INFO	====> Epoch: 1679, cost 22.87 s
2024-01-02 05:32:19,603	44k	INFO	====> Epoch: 1680, cost 22.65 s
2024-01-02 05:32:42,339	44k	INFO	====> Epoch: 1681, cost 22.74 s
2024-01-02 05:33:05,172	44k	INFO	====> Epoch: 1682, cost 22.83 s
2024-01-02 05:33:27,916	44k	INFO	====> Epoch: 1683, cost 22.74 s
2024-01-02 05:33:50,712	44k	INFO	====> Epoch: 1684, cost 22.80 s
2024-01-02 05:34:05,736	44k	INFO	Train Epoch: 1685 [62%]
2024-01-02 05:34:05,739	44k	INFO	Losses: [2.218339443206787, 2.6267991065979004, 6.7032012939453125, 17.608335494995117, 0.368151992559433], step: 43800, lr: 8.101683954168975e-05, reference_loss: 29.52482795715332
2024-01-02 05:34:13,875	44k	INFO	====> Epoch: 1685, cost 23.16 s
2024-01-02 05:34:36,856	44k	INFO	====> Epoch: 1686, cost 22.98 s
2024-01-02 05:34:59,709	44k	INFO	====> Epoch: 1687, cost 22.85 s
2024-01-02 05:35:22,539	44k	INFO	====> Epoch: 1688, cost 22.83 s
2024-01-02 05:35:45,341	44k	INFO	====> Epoch: 1689, cost 22.80 s
2024-01-02 05:36:08,067	44k	INFO	====> Epoch: 1690, cost 22.73 s
2024-01-02 05:36:30,887	44k	INFO	====> Epoch: 1691, cost 22.82 s
2024-01-02 05:36:53,659	44k	INFO	====> Epoch: 1692, cost 22.77 s
2024-01-02 05:37:01,684	44k	INFO	Train Epoch: 1693 [31%]
2024-01-02 05:37:01,687	44k	INFO	Losses: [2.2978384494781494, 2.7867372035980225, 6.5650105476379395, 16.249074935913086, 0.6055404543876648], step: 44000, lr: 8.09358581381555e-05, reference_loss: 28.504201889038086
2024-01-02 05:37:06,975	44k	INFO	Saving model and optimizer state at iteration 1693 to ./logs/44k/G_44000.pth
2024-01-02 05:37:07,851	44k	INFO	Saving model and optimizer state at iteration 1693 to ./logs/44k/D_44000.pth
2024-01-02 05:37:08,338	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_41600.pth
2024-01-02 05:37:08,377	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_41600.pth
2024-01-02 05:37:23,214	44k	INFO	====> Epoch: 1693, cost 29.55 s
2024-01-02 05:37:45,944	44k	INFO	====> Epoch: 1694, cost 22.73 s
2024-01-02 05:38:08,610	44k	INFO	====> Epoch: 1695, cost 22.67 s
2024-01-02 05:38:31,259	44k	INFO	====> Epoch: 1696, cost 22.65 s
2024-01-02 05:38:53,908	44k	INFO	====> Epoch: 1697, cost 22.65 s
2024-01-02 05:39:16,686	44k	INFO	====> Epoch: 1698, cost 22.78 s
2024-01-02 05:39:39,506	44k	INFO	====> Epoch: 1699, cost 22.82 s
2024-01-02 05:40:01,978	44k	INFO	====> Epoch: 1700, cost 22.47 s
2024-01-02 05:40:02,853	44k	INFO	Train Epoch: 1701 [0%]
2024-01-02 05:40:02,856	44k	INFO	Losses: [2.2666938304901123, 2.550184965133667, 6.97939395904541, 17.60350799560547, 0.33140426874160767], step: 44200, lr: 8.085495768060427e-05, reference_loss: 29.731184005737305
2024-01-02 05:40:24,953	44k	INFO	====> Epoch: 1701, cost 22.98 s
2024-01-02 05:40:47,671	44k	INFO	====> Epoch: 1702, cost 22.72 s
2024-01-02 05:41:10,345	44k	INFO	====> Epoch: 1703, cost 22.67 s
2024-01-02 05:41:33,014	44k	INFO	====> Epoch: 1704, cost 22.67 s
2024-01-02 05:41:55,951	44k	INFO	====> Epoch: 1705, cost 22.94 s
2024-01-02 05:42:18,786	44k	INFO	====> Epoch: 1706, cost 22.83 s
2024-01-02 05:42:41,622	44k	INFO	====> Epoch: 1707, cost 22.84 s
2024-01-02 05:42:58,395	44k	INFO	Train Epoch: 1708 [69%]
2024-01-02 05:42:58,398	44k	INFO	Losses: [2.382514238357544, 2.3396477699279785, 6.610203266143799, 17.673654556274414, 0.509242057800293], step: 44400, lr: 8.078423611764021e-05, reference_loss: 29.515262603759766
2024-01-02 05:43:04,713	44k	INFO	====> Epoch: 1708, cost 23.09 s
2024-01-02 05:43:27,407	44k	INFO	====> Epoch: 1709, cost 22.69 s
2024-01-02 05:43:50,190	44k	INFO	====> Epoch: 1710, cost 22.78 s
2024-01-02 05:44:12,957	44k	INFO	====> Epoch: 1711, cost 22.77 s
2024-01-02 05:44:35,774	44k	INFO	====> Epoch: 1712, cost 22.82 s
2024-01-02 05:44:58,594	44k	INFO	====> Epoch: 1713, cost 22.82 s
2024-01-02 05:45:21,428	44k	INFO	====> Epoch: 1714, cost 22.83 s
2024-01-02 05:45:44,294	44k	INFO	====> Epoch: 1715, cost 22.87 s
2024-01-02 05:45:54,013	44k	INFO	Train Epoch: 1716 [38%]
2024-01-02 05:45:54,016	44k	INFO	Losses: [2.4869143962860107, 2.31508731842041, 7.190695762634277, 17.625288009643555, 0.39093735814094543], step: 44600, lr: 8.070348721579148e-05, reference_loss: 30.008922576904297
2024-01-02 05:46:07,331	44k	INFO	====> Epoch: 1716, cost 23.04 s
2024-01-02 05:46:30,017	44k	INFO	====> Epoch: 1717, cost 22.69 s
2024-01-02 05:46:52,691	44k	INFO	====> Epoch: 1718, cost 22.67 s
2024-01-02 05:47:15,356	44k	INFO	====> Epoch: 1719, cost 22.67 s
2024-01-02 05:47:38,109	44k	INFO	====> Epoch: 1720, cost 22.75 s
2024-01-02 05:48:00,924	44k	INFO	====> Epoch: 1721, cost 22.82 s
2024-01-02 05:48:23,790	44k	INFO	====> Epoch: 1722, cost 22.87 s
2024-01-02 05:48:46,322	44k	INFO	====> Epoch: 1723, cost 22.53 s
2024-01-02 05:48:48,954	44k	INFO	Train Epoch: 1724 [8%]
2024-01-02 05:48:48,957	44k	INFO	Losses: [2.188065528869629, 2.7948803901672363, 7.924997329711914, 19.916032791137695, 0.30054986476898193], step: 44800, lr: 8.062281902752576e-05, reference_loss: 33.1245231628418
2024-01-02 05:48:54,408	44k	INFO	Saving model and optimizer state at iteration 1724 to ./logs/44k/G_44800.pth
2024-01-02 05:48:55,259	44k	INFO	Saving model and optimizer state at iteration 1724 to ./logs/44k/D_44800.pth
2024-01-02 05:48:55,748	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_42400.pth
2024-01-02 05:48:55,787	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_42400.pth
2024-01-02 05:49:15,919	44k	INFO	====> Epoch: 1724, cost 29.60 s
2024-01-02 05:49:38,823	44k	INFO	====> Epoch: 1725, cost 22.90 s
2024-01-02 05:50:01,613	44k	INFO	====> Epoch: 1726, cost 22.79 s
2024-01-02 05:50:24,430	44k	INFO	====> Epoch: 1727, cost 22.82 s
2024-01-02 05:50:47,072	44k	INFO	====> Epoch: 1728, cost 22.64 s
2024-01-02 05:51:09,756	44k	INFO	====> Epoch: 1729, cost 22.68 s
2024-01-02 05:51:32,433	44k	INFO	====> Epoch: 1730, cost 22.68 s
2024-01-02 05:51:50,916	44k	INFO	Train Epoch: 1731 [77%]
2024-01-02 05:51:50,919	44k	INFO	Losses: [2.300880193710327, 2.3998358249664307, 6.410467624664307, 17.00674819946289, 0.6019824147224426], step: 45000, lr: 8.055230050972852e-05, reference_loss: 28.719913482666016
2024-01-02 05:51:55,628	44k	INFO	====> Epoch: 1731, cost 23.19 s
2024-01-02 05:52:18,382	44k	INFO	====> Epoch: 1732, cost 22.75 s
2024-01-02 05:52:41,190	44k	INFO	====> Epoch: 1733, cost 22.81 s
2024-01-02 05:53:03,971	44k	INFO	====> Epoch: 1734, cost 22.78 s
2024-01-02 05:53:26,748	44k	INFO	====> Epoch: 1735, cost 22.78 s
2024-01-02 05:53:49,556	44k	INFO	====> Epoch: 1736, cost 22.81 s
2024-01-02 05:54:12,375	44k	INFO	====> Epoch: 1737, cost 22.82 s
2024-01-02 05:54:35,156	44k	INFO	====> Epoch: 1738, cost 22.78 s
2024-01-02 05:54:46,664	44k	INFO	Train Epoch: 1739 [46%]
2024-01-02 05:54:46,666	44k	INFO	Losses: [2.4177229404449463, 2.535534620285034, 5.940756797790527, 16.70655059814453, 0.3582976758480072], step: 45200, lr: 8.047178344204122e-05, reference_loss: 27.9588623046875
2024-01-02 05:54:58,354	44k	INFO	====> Epoch: 1739, cost 23.20 s
2024-01-02 05:55:21,356	44k	INFO	====> Epoch: 1740, cost 23.00 s
2024-01-02 05:55:44,212	44k	INFO	====> Epoch: 1741, cost 22.86 s
2024-01-02 05:56:07,048	44k	INFO	====> Epoch: 1742, cost 22.84 s
2024-01-02 05:56:29,912	44k	INFO	====> Epoch: 1743, cost 22.86 s
2024-01-02 05:56:52,688	44k	INFO	====> Epoch: 1744, cost 22.78 s
2024-01-02 05:57:15,367	44k	INFO	====> Epoch: 1745, cost 22.68 s
2024-01-02 05:57:38,154	44k	INFO	====> Epoch: 1746, cost 22.79 s
2024-01-02 05:57:42,572	44k	INFO	Train Epoch: 1747 [15%]
2024-01-02 05:57:42,575	44k	INFO	Losses: [2.3521668910980225, 2.631031036376953, 6.287642002105713, 16.368810653686523, 0.42521387338638306], step: 45400, lr: 8.039134685620418e-05, reference_loss: 28.064865112304688
2024-01-02 05:58:01,327	44k	INFO	====> Epoch: 1747, cost 23.17 s
2024-01-02 05:58:24,179	44k	INFO	====> Epoch: 1748, cost 22.85 s
2024-01-02 05:58:47,018	44k	INFO	====> Epoch: 1749, cost 22.84 s
2024-01-02 05:59:09,982	44k	INFO	====> Epoch: 1750, cost 22.96 s
2024-01-02 05:59:32,837	44k	INFO	====> Epoch: 1751, cost 22.86 s
2024-01-02 05:59:55,587	44k	INFO	====> Epoch: 1752, cost 22.75 s
2024-01-02 06:00:18,339	44k	INFO	====> Epoch: 1753, cost 22.75 s
2024-01-02 06:00:38,693	44k	INFO	Train Epoch: 1754 [85%]
2024-01-02 06:00:38,696	44k	INFO	Losses: [2.2615551948547363, 2.552130699157715, 6.749855995178223, 17.454322814941406, 0.6146488785743713], step: 45600, lr: 8.032103080062085e-05, reference_loss: 29.63251304626465
2024-01-02 06:00:43,955	44k	INFO	Saving model and optimizer state at iteration 1754 to ./logs/44k/G_45600.pth
2024-01-02 06:00:44,836	44k	INFO	Saving model and optimizer state at iteration 1754 to ./logs/44k/D_45600.pth
2024-01-02 06:00:45,327	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_43200.pth
2024-01-02 06:00:45,366	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_43200.pth
2024-01-02 06:00:47,833	44k	INFO	====> Epoch: 1754, cost 29.49 s
2024-01-02 06:01:10,555	44k	INFO	====> Epoch: 1755, cost 22.72 s
2024-01-02 06:01:33,267	44k	INFO	====> Epoch: 1756, cost 22.71 s
2024-01-02 06:01:56,062	44k	INFO	====> Epoch: 1757, cost 22.80 s
2024-01-02 06:02:18,694	44k	INFO	====> Epoch: 1758, cost 22.63 s
2024-01-02 06:02:41,258	44k	INFO	====> Epoch: 1759, cost 22.56 s
2024-01-02 06:03:03,915	44k	INFO	====> Epoch: 1760, cost 22.66 s
2024-01-02 06:03:26,586	44k	INFO	====> Epoch: 1761, cost 22.67 s
2024-01-02 06:03:39,767	44k	INFO	Train Epoch: 1762 [54%]
2024-01-02 06:03:39,770	44k	INFO	Losses: [2.325415849685669, 2.5198330879211426, 7.198047637939453, 16.60869598388672, 0.8055066466331482], step: 45800, lr: 8.024074490148745e-05, reference_loss: 29.45749855041504
2024-01-02 06:03:49,617	44k	INFO	====> Epoch: 1762, cost 23.03 s
2024-01-02 06:04:12,374	44k	INFO	====> Epoch: 1763, cost 22.76 s
2024-01-02 06:04:35,187	44k	INFO	====> Epoch: 1764, cost 22.81 s
2024-01-02 06:04:57,874	44k	INFO	====> Epoch: 1765, cost 22.69 s
2024-01-02 06:05:20,585	44k	INFO	====> Epoch: 1766, cost 22.71 s
2024-01-02 06:05:43,309	44k	INFO	====> Epoch: 1767, cost 22.72 s
2024-01-02 06:06:06,116	44k	INFO	====> Epoch: 1768, cost 22.81 s
2024-01-02 06:06:29,121	44k	INFO	====> Epoch: 1769, cost 23.01 s
2024-01-02 06:06:35,363	44k	INFO	Train Epoch: 1770 [23%]
2024-01-02 06:06:35,366	44k	INFO	Losses: [2.47475528717041, 2.5343620777130127, 6.007894515991211, 14.786452293395996, 0.4726347029209137], step: 46000, lr: 8.016053925313687e-05, reference_loss: 26.276098251342773
2024-01-02 06:06:52,346	44k	INFO	====> Epoch: 1770, cost 23.23 s
2024-01-02 06:07:15,013	44k	INFO	====> Epoch: 1771, cost 22.67 s
2024-01-02 06:07:37,674	44k	INFO	====> Epoch: 1772, cost 22.66 s
2024-01-02 06:08:00,349	44k	INFO	====> Epoch: 1773, cost 22.67 s
2024-01-02 06:08:23,171	44k	INFO	====> Epoch: 1774, cost 22.82 s
2024-01-02 06:08:45,979	44k	INFO	====> Epoch: 1775, cost 22.81 s
2024-01-02 06:09:08,817	44k	INFO	====> Epoch: 1776, cost 22.84 s
2024-01-02 06:09:30,953	44k	INFO	Train Epoch: 1777 [92%]
2024-01-02 06:09:30,956	44k	INFO	Losses: [2.424699544906616, 2.2753355503082275, 5.951377868652344, 17.160430908203125, 0.4816336929798126], step: 46200, lr: 8.009042507848826e-05, reference_loss: 28.29347801208496
2024-01-02 06:09:32,203	44k	INFO	====> Epoch: 1777, cost 23.39 s
2024-01-02 06:09:55,014	44k	INFO	====> Epoch: 1778, cost 22.81 s
2024-01-02 06:10:17,657	44k	INFO	====> Epoch: 1779, cost 22.64 s
2024-01-02 06:10:40,324	44k	INFO	====> Epoch: 1780, cost 22.67 s
2024-01-02 06:11:03,181	44k	INFO	====> Epoch: 1781, cost 22.86 s
2024-01-02 06:11:26,028	44k	INFO	====> Epoch: 1782, cost 22.85 s
2024-01-02 06:11:48,871	44k	INFO	====> Epoch: 1783, cost 22.84 s
2024-01-02 06:12:11,724	44k	INFO	====> Epoch: 1784, cost 22.85 s
2024-01-02 06:12:26,793	44k	INFO	Train Epoch: 1785 [62%]
2024-01-02 06:12:26,796	44k	INFO	Losses: [2.441279172897339, 2.261033296585083, 6.23473596572876, 15.623336791992188, 0.5087012648582458], step: 46400, lr: 8.00103696842122e-05, reference_loss: 27.0690860748291
2024-01-02 06:12:32,070	44k	INFO	Saving model and optimizer state at iteration 1785 to ./logs/44k/G_46400.pth
2024-01-02 06:12:33,111	44k	INFO	Saving model and optimizer state at iteration 1785 to ./logs/44k/D_46400.pth
2024-01-02 06:12:33,600	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_44000.pth
2024-01-02 06:12:33,639	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_44000.pth
2024-01-02 06:12:41,373	44k	INFO	====> Epoch: 1785, cost 29.65 s
2024-01-02 06:13:04,231	44k	INFO	====> Epoch: 1786, cost 22.86 s
2024-01-02 06:13:27,156	44k	INFO	====> Epoch: 1787, cost 22.92 s
2024-01-02 06:13:50,007	44k	INFO	====> Epoch: 1788, cost 22.85 s
2024-01-02 06:14:12,736	44k	INFO	====> Epoch: 1789, cost 22.73 s
2024-01-02 06:14:35,553	44k	INFO	====> Epoch: 1790, cost 22.82 s
2024-01-02 06:14:58,382	44k	INFO	====> Epoch: 1791, cost 22.83 s
2024-01-02 06:15:21,198	44k	INFO	====> Epoch: 1792, cost 22.82 s
2024-01-02 06:15:29,228	44k	INFO	Train Epoch: 1793 [31%]
2024-01-02 06:15:29,231	44k	INFO	Losses: [2.3539936542510986, 2.5972113609313965, 7.363542079925537, 18.053998947143555, 0.48997634649276733], step: 46600, lr: 7.993039431031494e-05, reference_loss: 30.858722686767578
2024-01-02 06:15:44,449	44k	INFO	====> Epoch: 1793, cost 23.25 s
2024-01-02 06:16:07,230	44k	INFO	====> Epoch: 1794, cost 22.78 s
2024-01-02 06:16:29,914	44k	INFO	====> Epoch: 1795, cost 22.68 s
2024-01-02 06:16:52,605	44k	INFO	====> Epoch: 1796, cost 22.69 s
2024-01-02 06:17:15,417	44k	INFO	====> Epoch: 1797, cost 22.81 s
2024-01-02 06:17:38,188	44k	INFO	====> Epoch: 1798, cost 22.77 s
2024-01-02 06:18:01,008	44k	INFO	====> Epoch: 1799, cost 22.82 s
2024-01-02 06:18:23,803	44k	INFO	====> Epoch: 1800, cost 22.80 s
2024-01-02 06:18:24,699	44k	INFO	Train Epoch: 1801 [0%]
2024-01-02 06:18:24,702	44k	INFO	Losses: [2.5183379650115967, 2.459501028060913, 6.127089023590088, 16.810293197631836, 0.37893036007881165], step: 46800, lr: 7.98504988768111e-05, reference_loss: 28.294153213500977
2024-01-02 06:18:47,076	44k	INFO	====> Epoch: 1801, cost 23.27 s
2024-01-02 06:19:09,925	44k	INFO	====> Epoch: 1802, cost 22.85 s
2024-01-02 06:19:32,903	44k	INFO	====> Epoch: 1803, cost 22.98 s
2024-01-02 06:19:55,726	44k	INFO	====> Epoch: 1804, cost 22.82 s
2024-01-02 06:20:18,562	44k	INFO	====> Epoch: 1805, cost 22.84 s
2024-01-02 06:20:41,419	44k	INFO	====> Epoch: 1806, cost 22.86 s
2024-01-02 06:21:04,259	44k	INFO	====> Epoch: 1807, cost 22.84 s
2024-01-02 06:21:21,117	44k	INFO	Train Epoch: 1808 [69%]
2024-01-02 06:21:21,121	44k	INFO	Losses: [2.2482759952545166, 2.4856371879577637, 7.435361862182617, 19.05106544494629, 0.44441723823547363], step: 47000, lr: 7.978065588578095e-05, reference_loss: 31.664758682250977
2024-01-02 06:21:27,490	44k	INFO	====> Epoch: 1808, cost 23.23 s
2024-01-02 06:21:50,274	44k	INFO	====> Epoch: 1809, cost 22.78 s
2024-01-02 06:22:12,906	44k	INFO	====> Epoch: 1810, cost 22.63 s
2024-01-02 06:22:35,686	44k	INFO	====> Epoch: 1811, cost 22.78 s
2024-01-02 06:22:58,510	44k	INFO	====> Epoch: 1812, cost 22.82 s
2024-01-02 06:23:21,456	44k	INFO	====> Epoch: 1813, cost 22.95 s
2024-01-02 06:23:44,287	44k	INFO	====> Epoch: 1814, cost 22.83 s
2024-01-02 06:24:07,119	44k	INFO	====> Epoch: 1815, cost 22.83 s
2024-01-02 06:24:16,876	44k	INFO	Train Epoch: 1816 [38%]
2024-01-02 06:24:16,879	44k	INFO	Losses: [2.3756749629974365, 2.296631336212158, 6.261090278625488, 15.05753231048584, 0.579568088054657], step: 47200, lr: 7.970091012520744e-05, reference_loss: 26.570497512817383
2024-01-02 06:24:22,241	44k	INFO	Saving model and optimizer state at iteration 1816 to ./logs/44k/G_47200.pth
2024-01-02 06:24:23,074	44k	INFO	Saving model and optimizer state at iteration 1816 to ./logs/44k/D_47200.pth
2024-01-02 06:24:23,561	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_44800.pth
2024-01-02 06:24:23,600	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_44800.pth
2024-01-02 06:24:36,543	44k	INFO	====> Epoch: 1816, cost 29.42 s
2024-01-02 06:24:59,339	44k	INFO	====> Epoch: 1817, cost 22.80 s
2024-01-02 06:25:21,992	44k	INFO	====> Epoch: 1818, cost 22.65 s
2024-01-02 06:25:44,468	44k	INFO	====> Epoch: 1819, cost 22.48 s
2024-01-02 06:26:07,408	44k	INFO	====> Epoch: 1820, cost 22.94 s
2024-01-02 06:26:30,238	44k	INFO	====> Epoch: 1821, cost 22.83 s
2024-01-02 06:26:53,096	44k	INFO	====> Epoch: 1822, cost 22.86 s
2024-01-02 06:27:15,829	44k	INFO	====> Epoch: 1823, cost 22.73 s
2024-01-02 06:27:18,478	44k	INFO	Train Epoch: 1824 [8%]
2024-01-02 06:27:18,481	44k	INFO	Losses: [2.6469082832336426, 1.956275224685669, 5.549000263214111, 16.631011962890625, 0.37045612931251526], step: 47400, lr: 7.962124407551444e-05, reference_loss: 27.15365219116211
2024-01-02 06:27:39,030	44k	INFO	====> Epoch: 1824, cost 23.20 s
2024-01-02 06:28:01,821	44k	INFO	====> Epoch: 1825, cost 22.79 s
2024-01-02 06:28:24,618	44k	INFO	====> Epoch: 1826, cost 22.80 s
2024-01-02 06:28:47,352	44k	INFO	====> Epoch: 1827, cost 22.73 s
2024-01-02 06:29:10,131	44k	INFO	====> Epoch: 1828, cost 22.78 s
2024-01-02 06:29:32,892	44k	INFO	====> Epoch: 1829, cost 22.76 s
2024-01-02 06:29:55,652	44k	INFO	====> Epoch: 1830, cost 22.76 s
2024-01-02 06:30:14,309	44k	INFO	Train Epoch: 1831 [77%]
2024-01-02 06:30:14,312	44k	INFO	Losses: [2.1960670948028564, 2.5955393314361572, 8.095090866088867, 18.897205352783203, 0.5228383541107178], step: 47600, lr: 7.955160160722687e-05, reference_loss: 32.306739807128906
2024-01-02 06:30:18,965	44k	INFO	====> Epoch: 1831, cost 23.31 s
2024-01-02 06:30:41,657	44k	INFO	====> Epoch: 1832, cost 22.69 s
2024-01-02 06:31:04,368	44k	INFO	====> Epoch: 1833, cost 22.71 s
2024-01-02 06:31:27,086	44k	INFO	====> Epoch: 1834, cost 22.72 s
2024-01-02 06:31:49,863	44k	INFO	====> Epoch: 1835, cost 22.78 s
2024-01-02 06:32:12,450	44k	INFO	====> Epoch: 1836, cost 22.59 s
2024-01-02 06:32:35,085	44k	INFO	====> Epoch: 1837, cost 22.63 s
2024-01-02 06:32:57,757	44k	INFO	====> Epoch: 1838, cost 22.67 s
2024-01-02 06:33:09,241	44k	INFO	Train Epoch: 1839 [46%]
2024-01-02 06:33:09,243	44k	INFO	Losses: [2.4361751079559326, 2.451608657836914, 7.1011576652526855, 17.395008087158203, 0.6063944101333618], step: 47800, lr: 7.947208480074573e-05, reference_loss: 29.99034309387207
2024-01-02 06:33:21,158	44k	INFO	====> Epoch: 1839, cost 23.40 s
2024-01-02 06:33:43,837	44k	INFO	====> Epoch: 1840, cost 22.68 s
2024-01-02 06:34:06,476	44k	INFO	====> Epoch: 1841, cost 22.64 s
2024-01-02 06:34:29,071	44k	INFO	====> Epoch: 1842, cost 22.59 s
2024-01-02 06:34:51,644	44k	INFO	====> Epoch: 1843, cost 22.57 s
2024-01-02 06:35:14,293	44k	INFO	====> Epoch: 1844, cost 22.65 s
2024-01-02 06:35:36,910	44k	INFO	====> Epoch: 1845, cost 22.62 s
2024-01-02 06:35:59,541	44k	INFO	====> Epoch: 1846, cost 22.63 s
2024-01-02 06:36:03,958	44k	INFO	Train Epoch: 1847 [15%]
2024-01-02 06:36:03,961	44k	INFO	Losses: [2.37623929977417, 2.6856887340545654, 7.948718547821045, 18.234487533569336, 0.3162023425102234], step: 48000, lr: 7.939264747629116e-05, reference_loss: 31.561336517333984
2024-01-02 06:36:09,200	44k	INFO	Saving model and optimizer state at iteration 1847 to ./logs/44k/G_48000.pth
2024-01-02 06:36:10,248	44k	INFO	Saving model and optimizer state at iteration 1847 to ./logs/44k/D_48000.pth
2024-01-02 06:36:10,740	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_45600.pth
2024-01-02 06:36:10,779	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_45600.pth
2024-01-02 06:36:29,039	44k	INFO	====> Epoch: 1847, cost 29.50 s
2024-01-02 06:36:51,921	44k	INFO	====> Epoch: 1848, cost 22.88 s
2024-01-02 06:37:14,763	44k	INFO	====> Epoch: 1849, cost 22.84 s
2024-01-02 06:37:37,412	44k	INFO	====> Epoch: 1850, cost 22.65 s
2024-01-02 06:38:00,135	44k	INFO	====> Epoch: 1851, cost 22.72 s
2024-01-02 06:38:22,810	44k	INFO	====> Epoch: 1852, cost 22.68 s
2024-01-02 06:38:45,475	44k	INFO	====> Epoch: 1853, cost 22.66 s
2024-01-02 06:39:05,675	44k	INFO	Train Epoch: 1854 [85%]
2024-01-02 06:39:05,678	44k	INFO	Losses: [2.410020112991333, 2.559696912765503, 5.393969535827637, 15.874835014343262, 0.5973923206329346], step: 48200, lr: 7.932320495503528e-05, reference_loss: 26.835914611816406
2024-01-02 06:39:08,525	44k	INFO	====> Epoch: 1854, cost 23.05 s
2024-01-02 06:39:31,134	44k	INFO	====> Epoch: 1855, cost 22.61 s
2024-01-02 06:39:53,927	44k	INFO	====> Epoch: 1856, cost 22.79 s
2024-01-02 06:40:16,577	44k	INFO	====> Epoch: 1857, cost 22.65 s
2024-01-02 06:40:39,292	44k	INFO	====> Epoch: 1858, cost 22.72 s
2024-01-02 06:41:02,158	44k	INFO	====> Epoch: 1859, cost 22.87 s
2024-01-02 06:41:24,946	44k	INFO	====> Epoch: 1860, cost 22.79 s
2024-01-02 06:41:47,625	44k	INFO	====> Epoch: 1861, cost 22.68 s
2024-01-02 06:42:00,829	44k	INFO	Train Epoch: 1862 [54%]
2024-01-02 06:42:00,832	44k	INFO	Losses: [2.700289249420166, 2.2394046783447266, 6.202600002288818, 16.97150230407715, 0.5422042012214661], step: 48400, lr: 7.924391644530778e-05, reference_loss: 28.6560001373291
2024-01-02 06:42:10,670	44k	INFO	====> Epoch: 1862, cost 23.05 s
2024-01-02 06:42:33,446	44k	INFO	====> Epoch: 1863, cost 22.78 s
2024-01-02 06:42:56,317	44k	INFO	====> Epoch: 1864, cost 22.87 s
2024-01-02 06:43:19,158	44k	INFO	====> Epoch: 1865, cost 22.84 s
2024-01-02 06:43:42,062	44k	INFO	====> Epoch: 1866, cost 22.90 s
2024-01-02 06:44:04,888	44k	INFO	====> Epoch: 1867, cost 22.83 s
2024-01-02 06:44:27,612	44k	INFO	====> Epoch: 1868, cost 22.72 s
2024-01-02 06:44:50,304	44k	INFO	====> Epoch: 1869, cost 22.69 s
2024-01-02 06:44:56,503	44k	INFO	Train Epoch: 1870 [23%]
2024-01-02 06:44:56,506	44k	INFO	Losses: [2.7625412940979004, 1.9873296022415161, 5.184361934661865, 14.613405227661133, 0.42660459876060486], step: 48600, lr: 7.916470718940995e-05, reference_loss: 24.9742431640625
2024-01-02 06:45:13,349	44k	INFO	====> Epoch: 1870, cost 23.05 s
2024-01-02 06:45:36,058	44k	INFO	====> Epoch: 1871, cost 22.71 s
2024-01-02 06:45:58,725	44k	INFO	====> Epoch: 1872, cost 22.67 s
2024-01-02 06:46:21,456	44k	INFO	====> Epoch: 1873, cost 22.73 s
2024-01-02 06:46:44,265	44k	INFO	====> Epoch: 1874, cost 22.81 s
2024-01-02 06:47:06,970	44k	INFO	====> Epoch: 1875, cost 22.70 s
2024-01-02 06:47:29,938	44k	INFO	====> Epoch: 1876, cost 22.97 s
2024-01-02 06:47:51,924	44k	INFO	Train Epoch: 1877 [92%]
2024-01-02 06:47:51,927	44k	INFO	Losses: [2.3123695850372314, 2.8063597679138184, 6.480170249938965, 16.587255477905273, 0.6126646995544434], step: 48800, lr: 7.909546404112776e-05, reference_loss: 28.79882049560547
2024-01-02 06:47:57,196	44k	INFO	Saving model and optimizer state at iteration 1877 to ./logs/44k/G_48800.pth
2024-01-02 06:47:58,073	44k	INFO	Saving model and optimizer state at iteration 1877 to ./logs/44k/D_48800.pth
2024-01-02 06:47:58,561	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_46400.pth
2024-01-02 06:47:58,600	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_46400.pth
2024-01-02 06:47:59,287	44k	INFO	====> Epoch: 1877, cost 29.35 s
2024-01-02 06:48:21,927	44k	INFO	====> Epoch: 1878, cost 22.64 s
2024-01-02 06:48:44,634	44k	INFO	====> Epoch: 1879, cost 22.71 s
2024-01-02 06:49:07,361	44k	INFO	====> Epoch: 1880, cost 22.73 s
2024-01-02 06:49:30,150	44k	INFO	====> Epoch: 1881, cost 22.79 s
2024-01-02 06:49:52,903	44k	INFO	====> Epoch: 1882, cost 22.75 s
2024-01-02 06:50:15,812	44k	INFO	====> Epoch: 1883, cost 22.91 s
2024-01-02 06:50:38,648	44k	INFO	====> Epoch: 1884, cost 22.84 s
2024-01-02 06:50:53,635	44k	INFO	Train Epoch: 1885 [62%]
2024-01-02 06:50:53,638	44k	INFO	Losses: [2.511777400970459, 2.4101040363311768, 5.5670247077941895, 14.803118705749512, 0.7570706605911255], step: 49000, lr: 7.901640317270241e-05, reference_loss: 26.049097061157227
2024-01-02 06:51:01,724	44k	INFO	====> Epoch: 1885, cost 23.08 s
2024-01-02 06:51:24,363	44k	INFO	====> Epoch: 1886, cost 22.64 s
2024-01-02 06:51:47,165	44k	INFO	====> Epoch: 1887, cost 22.80 s
2024-01-02 06:52:09,966	44k	INFO	====> Epoch: 1888, cost 22.80 s
2024-01-02 06:52:32,788	44k	INFO	====> Epoch: 1889, cost 22.82 s
2024-01-02 06:52:55,386	44k	INFO	====> Epoch: 1890, cost 22.60 s
2024-01-02 06:53:18,050	44k	INFO	====> Epoch: 1891, cost 22.66 s
2024-01-02 06:53:40,927	44k	INFO	====> Epoch: 1892, cost 22.88 s
2024-01-02 06:53:48,949	44k	INFO	Train Epoch: 1893 [31%]
2024-01-02 06:53:48,952	44k	INFO	Losses: [2.2833516597747803, 2.5330185890197754, 6.957827568054199, 16.075050354003906, 0.4437048137187958], step: 49200, lr: 7.8937421330565e-05, reference_loss: 28.292951583862305
2024-01-02 06:54:04,256	44k	INFO	====> Epoch: 1893, cost 23.33 s
2024-01-02 06:54:26,982	44k	INFO	====> Epoch: 1894, cost 22.73 s
2024-01-02 06:54:49,804	44k	INFO	====> Epoch: 1895, cost 22.82 s
2024-01-02 06:55:12,597	44k	INFO	====> Epoch: 1896, cost 22.79 s
2024-01-02 06:55:35,297	44k	INFO	====> Epoch: 1897, cost 22.70 s
2024-01-02 06:55:58,126	44k	INFO	====> Epoch: 1898, cost 22.83 s
2024-01-02 06:56:20,810	44k	INFO	====> Epoch: 1899, cost 22.68 s
2024-01-02 06:56:43,509	44k	INFO	====> Epoch: 1900, cost 22.70 s
2024-01-02 06:56:44,395	44k	INFO	Train Epoch: 1901 [0%]
2024-01-02 06:56:44,398	44k	INFO	Losses: [2.491948127746582, 2.4934468269348145, 6.0599775314331055, 14.712162017822266, 0.49393969774246216], step: 49400, lr: 7.88585184357238e-05, reference_loss: 26.251474380493164
2024-01-02 06:57:06,561	44k	INFO	====> Epoch: 1901, cost 23.05 s
2024-01-02 06:57:29,372	44k	INFO	====> Epoch: 1902, cost 22.81 s
2024-01-02 06:57:52,004	44k	INFO	====> Epoch: 1903, cost 22.63 s
2024-01-02 06:58:14,657	44k	INFO	====> Epoch: 1904, cost 22.65 s
2024-01-02 06:58:37,281	44k	INFO	====> Epoch: 1905, cost 22.62 s
2024-01-02 06:58:59,952	44k	INFO	====> Epoch: 1906, cost 22.67 s
2024-01-02 06:59:22,596	44k	INFO	====> Epoch: 1907, cost 22.64 s
2024-01-02 06:59:39,437	44k	INFO	Train Epoch: 1908 [69%]
2024-01-02 06:59:39,440	44k	INFO	Losses: [2.4695851802825928, 2.2344346046447754, 5.998629093170166, 14.98419189453125, 0.443321168422699], step: 49600, lr: 7.878954310215385e-05, reference_loss: 26.13016128540039
2024-01-02 06:59:44,678	44k	INFO	Saving model and optimizer state at iteration 1908 to ./logs/44k/G_49600.pth
2024-01-02 06:59:45,557	44k	INFO	Saving model and optimizer state at iteration 1908 to ./logs/44k/D_49600.pth
2024-01-02 06:59:46,049	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_47200.pth
2024-01-02 06:59:46,088	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_47200.pth
2024-01-02 06:59:52,059	44k	INFO	====> Epoch: 1908, cost 29.46 s
2024-01-02 07:00:15,101	44k	INFO	====> Epoch: 1909, cost 23.04 s
2024-01-02 07:00:37,946	44k	INFO	====> Epoch: 1910, cost 22.84 s
2024-01-02 07:01:00,813	44k	INFO	====> Epoch: 1911, cost 22.87 s
2024-01-02 07:01:23,630	44k	INFO	====> Epoch: 1912, cost 22.82 s
2024-01-02 07:01:46,328	44k	INFO	====> Epoch: 1913, cost 22.70 s
2024-01-02 07:02:09,102	44k	INFO	====> Epoch: 1914, cost 22.77 s
2024-01-02 07:02:31,921	44k	INFO	====> Epoch: 1915, cost 22.82 s
2024-01-02 07:02:41,736	44k	INFO	Train Epoch: 1916 [38%]
2024-01-02 07:02:41,739	44k	INFO	Losses: [2.35970139503479, 2.706163167953491, 7.57442569732666, 17.932498931884766, 0.4469316005706787], step: 49800, lr: 7.87107880208605e-05, reference_loss: 31.01972007751465
2024-01-02 07:02:55,209	44k	INFO	====> Epoch: 1916, cost 23.29 s
2024-01-02 07:03:18,041	44k	INFO	====> Epoch: 1917, cost 22.83 s
2024-01-02 07:03:40,840	44k	INFO	====> Epoch: 1918, cost 22.80 s
2024-01-02 07:04:03,548	44k	INFO	====> Epoch: 1919, cost 22.71 s
2024-01-02 07:04:26,375	44k	INFO	====> Epoch: 1920, cost 22.83 s
2024-01-02 07:04:49,299	44k	INFO	====> Epoch: 1921, cost 22.92 s
2024-01-02 07:05:12,002	44k	INFO	====> Epoch: 1922, cost 22.70 s
2024-01-02 07:05:34,842	44k	INFO	====> Epoch: 1923, cost 22.84 s
2024-01-02 07:05:37,514	44k	INFO	Train Epoch: 1924 [8%]
2024-01-02 07:05:37,517	44k	INFO	Losses: [2.3615260124206543, 2.2889933586120605, 6.640616416931152, 17.578733444213867, 0.441511869430542], step: 50000, lr: 7.863211166020172e-05, reference_loss: 29.31138038635254
2024-01-02 07:05:58,045	44k	INFO	====> Epoch: 1924, cost 23.20 s
2024-01-02 07:06:20,877	44k	INFO	====> Epoch: 1925, cost 22.83 s
2024-01-02 07:06:43,739	44k	INFO	====> Epoch: 1926, cost 22.86 s
2024-01-02 07:07:06,569	44k	INFO	====> Epoch: 1927, cost 22.83 s
2024-01-02 07:07:29,408	44k	INFO	====> Epoch: 1928, cost 22.84 s
2024-01-02 07:07:52,260	44k	INFO	====> Epoch: 1929, cost 22.85 s
2024-01-02 07:08:15,106	44k	INFO	====> Epoch: 1930, cost 22.85 s
2024-01-02 07:08:33,810	44k	INFO	Train Epoch: 1931 [77%]
2024-01-02 07:08:33,813	44k	INFO	Losses: [2.2412261962890625, 2.365727663040161, 7.844735622406006, 20.059656143188477, 0.42348814010620117], step: 50200, lr: 7.856333435828608e-05, reference_loss: 32.93483352661133
2024-01-02 07:08:38,334	44k	INFO	====> Epoch: 1931, cost 23.23 s
2024-01-02 07:09:01,147	44k	INFO	====> Epoch: 1932, cost 22.81 s
2024-01-02 07:09:23,965	44k	INFO	====> Epoch: 1933, cost 22.82 s
2024-01-02 07:09:46,707	44k	INFO	====> Epoch: 1934, cost 22.74 s
2024-01-02 07:10:09,388	44k	INFO	====> Epoch: 1935, cost 22.68 s
2024-01-02 07:10:31,884	44k	INFO	====> Epoch: 1936, cost 22.50 s
2024-01-02 07:10:54,591	44k	INFO	====> Epoch: 1937, cost 22.71 s
2024-01-02 07:11:17,402	44k	INFO	====> Epoch: 1938, cost 22.81 s
2024-01-02 07:11:28,898	44k	INFO	Train Epoch: 1939 [46%]
2024-01-02 07:11:28,901	44k	INFO	Losses: [2.6042613983154297, 2.0503664016723633, 4.504114151000977, 14.544610023498535, 0.37292829155921936], step: 50400, lr: 7.848480538679502e-05, reference_loss: 24.07628059387207
2024-01-02 07:11:34,336	44k	INFO	Saving model and optimizer state at iteration 1939 to ./logs/44k/G_50400.pth
2024-01-02 07:11:35,208	44k	INFO	Saving model and optimizer state at iteration 1939 to ./logs/44k/D_50400.pth
2024-01-02 07:11:35,697	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_48000.pth
2024-01-02 07:11:35,736	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_48000.pth
2024-01-02 07:11:47,016	44k	INFO	====> Epoch: 1939, cost 29.61 s
2024-01-02 07:12:09,856	44k	INFO	====> Epoch: 1940, cost 22.84 s
2024-01-02 07:12:32,710	44k	INFO	====> Epoch: 1941, cost 22.85 s
2024-01-02 07:12:55,391	44k	INFO	====> Epoch: 1942, cost 22.68 s
2024-01-02 07:13:18,077	44k	INFO	====> Epoch: 1943, cost 22.69 s
2024-01-02 07:13:40,836	44k	INFO	====> Epoch: 1944, cost 22.76 s
2024-01-02 07:14:03,490	44k	INFO	====> Epoch: 1945, cost 22.65 s
2024-01-02 07:14:26,288	44k	INFO	====> Epoch: 1946, cost 22.80 s
2024-01-02 07:14:30,739	44k	INFO	Train Epoch: 1947 [15%]
2024-01-02 07:14:30,742	44k	INFO	Losses: [2.415297746658325, 2.264035224914551, 5.939525127410889, 15.324210166931152, 0.3882915675640106], step: 50600, lr: 7.84063549099276e-05, reference_loss: 26.331361770629883
2024-01-02 07:14:49,629	44k	INFO	====> Epoch: 1947, cost 23.34 s
2024-01-02 07:15:12,438	44k	INFO	====> Epoch: 1948, cost 22.81 s
2024-01-02 07:15:35,198	44k	INFO	====> Epoch: 1949, cost 22.76 s
2024-01-02 07:15:57,875	44k	INFO	====> Epoch: 1950, cost 22.68 s
2024-01-02 07:16:20,556	44k	INFO	====> Epoch: 1951, cost 22.68 s
2024-01-02 07:16:43,340	44k	INFO	====> Epoch: 1952, cost 22.78 s
2024-01-02 07:17:06,138	44k	INFO	====> Epoch: 1953, cost 22.80 s
2024-01-02 07:17:26,456	44k	INFO	Train Epoch: 1954 [85%]
2024-01-02 07:17:26,459	44k	INFO	Losses: [2.426511287689209, 2.520010232925415, 6.475517749786377, 17.322734832763672, 0.7214077711105347], step: 50800, lr: 7.833777507110747e-05, reference_loss: 29.4661808013916
2024-01-02 07:17:29,312	44k	INFO	====> Epoch: 1954, cost 23.17 s
2024-01-02 07:17:52,086	44k	INFO	====> Epoch: 1955, cost 22.77 s
2024-01-02 07:18:15,020	44k	INFO	====> Epoch: 1956, cost 22.93 s
2024-01-02 07:18:37,829	44k	INFO	====> Epoch: 1957, cost 22.81 s
2024-01-02 07:19:00,512	44k	INFO	====> Epoch: 1958, cost 22.68 s
2024-01-02 07:19:23,224	44k	INFO	====> Epoch: 1959, cost 22.71 s
2024-01-02 07:19:46,015	44k	INFO	====> Epoch: 1960, cost 22.79 s
2024-01-02 07:20:08,792	44k	INFO	====> Epoch: 1961, cost 22.78 s
2024-01-02 07:20:22,073	44k	INFO	Train Epoch: 1962 [54%]
2024-01-02 07:20:22,076	44k	INFO	Losses: [2.4503135681152344, 2.3771543502807617, 6.189497470855713, 16.512853622436523, 0.4769898056983948], step: 51000, lr: 7.825947156024605e-05, reference_loss: 28.00680923461914
2024-01-02 07:20:31,991	44k	INFO	====> Epoch: 1962, cost 23.20 s
2024-01-02 07:20:54,793	44k	INFO	====> Epoch: 1963, cost 22.80 s
2024-01-02 07:21:17,609	44k	INFO	====> Epoch: 1964, cost 22.82 s
2024-01-02 07:21:40,426	44k	INFO	====> Epoch: 1965, cost 22.82 s
2024-01-02 07:22:03,341	44k	INFO	====> Epoch: 1966, cost 22.91 s
2024-01-02 07:22:25,992	44k	INFO	====> Epoch: 1967, cost 22.65 s
2024-01-02 07:22:48,603	44k	INFO	====> Epoch: 1968, cost 22.61 s
2024-01-02 07:23:11,395	44k	INFO	====> Epoch: 1969, cost 22.79 s
2024-01-02 07:23:17,637	44k	INFO	Train Epoch: 1970 [23%]
2024-01-02 07:23:17,640	44k	INFO	Losses: [2.4189867973327637, 2.3257863521575928, 6.5225419998168945, 15.559473037719727, 0.5517116785049438], step: 51200, lr: 7.81812463186463e-05, reference_loss: 27.37849998474121
2024-01-02 07:23:22,906	44k	INFO	Saving model and optimizer state at iteration 1970 to ./logs/44k/G_51200.pth
2024-01-02 07:23:23,767	44k	INFO	Saving model and optimizer state at iteration 1970 to ./logs/44k/D_51200.pth
2024-01-02 07:23:24,258	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_48800.pth
2024-01-02 07:23:24,297	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_48800.pth
2024-01-02 07:23:40,851	44k	INFO	====> Epoch: 1970, cost 29.46 s
2024-01-02 07:24:03,694	44k	INFO	====> Epoch: 1971, cost 22.84 s
2024-01-02 07:24:26,503	44k	INFO	====> Epoch: 1972, cost 22.81 s
2024-01-02 07:24:49,466	44k	INFO	====> Epoch: 1973, cost 22.96 s
2024-01-02 07:25:12,293	44k	INFO	====> Epoch: 1974, cost 22.83 s
2024-01-02 07:25:35,105	44k	INFO	====> Epoch: 1975, cost 22.81 s
2024-01-02 07:25:57,876	44k	INFO	====> Epoch: 1976, cost 22.77 s
2024-01-02 07:26:20,022	44k	INFO	Train Epoch: 1977 [92%]
2024-01-02 07:26:20,025	44k	INFO	Losses: [2.476957321166992, 2.4523792266845703, 6.071220874786377, 16.54311752319336, 0.6054868698120117], step: 51400, lr: 7.811286337599514e-05, reference_loss: 28.14916229248047
2024-01-02 07:26:21,106	44k	INFO	====> Epoch: 1977, cost 23.23 s
2024-01-02 07:26:43,912	44k	INFO	====> Epoch: 1978, cost 22.81 s
2024-01-02 07:27:06,745	44k	INFO	====> Epoch: 1979, cost 22.83 s
2024-01-02 07:27:29,571	44k	INFO	====> Epoch: 1980, cost 22.83 s
2024-01-02 07:27:52,308	44k	INFO	====> Epoch: 1981, cost 22.74 s
2024-01-02 07:28:15,146	44k	INFO	====> Epoch: 1982, cost 22.84 s
2024-01-02 07:28:37,940	44k	INFO	====> Epoch: 1983, cost 22.79 s
2024-01-02 07:29:00,762	44k	INFO	====> Epoch: 1984, cost 22.82 s
2024-01-02 07:29:15,831	44k	INFO	Train Epoch: 1985 [62%]
2024-01-02 07:29:15,834	44k	INFO	Losses: [2.396881341934204, 2.4762258529663086, 6.936523914337158, 15.59024715423584, 0.41298702359199524], step: 51600, lr: 7.80347846784546e-05, reference_loss: 27.8128662109375
2024-01-02 07:29:23,970	44k	INFO	====> Epoch: 1985, cost 23.21 s
2024-01-02 07:29:46,811	44k	INFO	====> Epoch: 1986, cost 22.84 s
2024-01-02 07:30:09,581	44k	INFO	====> Epoch: 1987, cost 22.77 s
2024-01-02 07:30:32,375	44k	INFO	====> Epoch: 1988, cost 22.79 s
2024-01-02 07:30:55,178	44k	INFO	====> Epoch: 1989, cost 22.80 s
2024-01-02 07:31:17,941	44k	INFO	====> Epoch: 1990, cost 22.76 s
2024-01-02 07:31:40,677	44k	INFO	====> Epoch: 1991, cost 22.74 s
2024-01-02 07:32:03,461	44k	INFO	====> Epoch: 1992, cost 22.78 s
2024-01-02 07:32:11,429	44k	INFO	Train Epoch: 1993 [31%]
2024-01-02 07:32:11,432	44k	INFO	Losses: [2.549882173538208, 2.252711534500122, 6.029355049133301, 15.718741416931152, 0.45308902859687805], step: 51800, lr: 7.79567840254607e-05, reference_loss: 27.0037784576416
2024-01-02 07:32:26,757	44k	INFO	====> Epoch: 1993, cost 23.30 s
2024-01-02 07:32:49,632	44k	INFO	====> Epoch: 1994, cost 22.88 s
2024-01-02 07:33:12,455	44k	INFO	====> Epoch: 1995, cost 22.82 s
2024-01-02 07:33:35,296	44k	INFO	====> Epoch: 1996, cost 22.84 s
2024-01-02 07:33:58,149	44k	INFO	====> Epoch: 1997, cost 22.85 s
2024-01-02 07:34:20,941	44k	INFO	====> Epoch: 1998, cost 22.79 s
2024-01-02 07:34:43,755	44k	INFO	====> Epoch: 1999, cost 22.81 s
2024-01-02 07:35:06,557	44k	INFO	====> Epoch: 2000, cost 22.80 s
2024-01-02 07:35:07,449	44k	INFO	Train Epoch: 2001 [0%]
2024-01-02 07:35:07,452	44k	INFO	Losses: [2.541703701019287, 2.1665258407592773, 6.076670169830322, 16.243080139160156, 0.28514423966407776], step: 52000, lr: 7.787886133900303e-05, reference_loss: 27.313125610351562
2024-01-02 07:35:12,691	44k	INFO	Saving model and optimizer state at iteration 2001 to ./logs/44k/G_52000.pth
2024-01-02 07:35:13,722	44k	INFO	Saving model and optimizer state at iteration 2001 to ./logs/44k/D_52000.pth
2024-01-02 07:35:14,218	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_49600.pth
2024-01-02 07:35:14,257	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_49600.pth
2024-01-02 07:35:36,087	44k	INFO	====> Epoch: 2001, cost 29.53 s
2024-01-02 07:35:58,935	44k	INFO	====> Epoch: 2002, cost 22.85 s
2024-01-02 07:36:21,766	44k	INFO	====> Epoch: 2003, cost 22.83 s
2024-01-02 07:36:44,585	44k	INFO	====> Epoch: 2004, cost 22.82 s
2024-01-02 07:37:07,410	44k	INFO	====> Epoch: 2005, cost 22.82 s
2024-01-02 07:37:30,222	44k	INFO	====> Epoch: 2006, cost 22.81 s
2024-01-02 07:37:53,033	44k	INFO	====> Epoch: 2007, cost 22.81 s
2024-01-02 07:38:09,829	44k	INFO	Train Epoch: 2008 [69%]
2024-01-02 07:38:09,832	44k	INFO	Losses: [2.3406009674072266, 2.8400840759277344, 8.069287300109863, 17.603925704956055, 0.5825091004371643], step: 52200, lr: 7.781074288400968e-05, reference_loss: 31.4364070892334
2024-01-02 07:38:16,146	44k	INFO	====> Epoch: 2008, cost 23.11 s
2024-01-02 07:38:38,792	44k	INFO	====> Epoch: 2009, cost 22.65 s
2024-01-02 07:39:01,691	44k	INFO	====> Epoch: 2010, cost 22.90 s
2024-01-02 07:39:24,432	44k	INFO	====> Epoch: 2011, cost 22.74 s
2024-01-02 07:39:47,078	44k	INFO	====> Epoch: 2012, cost 22.65 s
2024-01-02 07:40:09,847	44k	INFO	====> Epoch: 2013, cost 22.77 s
2024-01-02 07:40:32,685	44k	INFO	====> Epoch: 2014, cost 22.84 s
2024-01-02 07:40:55,500	44k	INFO	====> Epoch: 2015, cost 22.82 s
2024-01-02 07:41:05,309	44k	INFO	Train Epoch: 2016 [38%]
2024-01-02 07:41:05,312	44k	INFO	Losses: [2.3473968505859375, 2.3997061252593994, 7.515629291534424, 17.374921798706055, 0.4408579468727112], step: 52400, lr: 7.773296617481642e-05, reference_loss: 30.07851219177246
2024-01-02 07:41:18,702	44k	INFO	====> Epoch: 2016, cost 23.20 s
2024-01-02 07:41:41,542	44k	INFO	====> Epoch: 2017, cost 22.84 s
2024-01-02 07:42:04,330	44k	INFO	====> Epoch: 2018, cost 22.79 s
2024-01-02 07:42:27,270	44k	INFO	====> Epoch: 2019, cost 22.94 s
2024-01-02 07:42:49,933	44k	INFO	====> Epoch: 2020, cost 22.66 s
2024-01-02 07:43:12,592	44k	INFO	====> Epoch: 2021, cost 22.66 s
2024-01-02 07:43:35,417	44k	INFO	====> Epoch: 2022, cost 22.82 s
2024-01-02 07:43:58,242	44k	INFO	====> Epoch: 2023, cost 22.83 s
2024-01-02 07:44:00,895	44k	INFO	Train Epoch: 2024 [8%]
2024-01-02 07:44:00,898	44k	INFO	Losses: [2.4668362140655518, 2.3550987243652344, 6.829991340637207, 17.158985137939453, 0.4848628342151642], step: 52600, lr: 7.765526720831357e-05, reference_loss: 29.295774459838867
2024-01-02 07:44:21,411	44k	INFO	====> Epoch: 2024, cost 23.17 s
2024-01-02 07:44:44,109	44k	INFO	====> Epoch: 2025, cost 22.70 s
2024-01-02 07:45:06,754	44k	INFO	====> Epoch: 2026, cost 22.65 s
2024-01-02 07:45:29,453	44k	INFO	====> Epoch: 2027, cost 22.70 s
2024-01-02 07:45:52,304	44k	INFO	====> Epoch: 2028, cost 22.85 s
2024-01-02 07:46:15,309	44k	INFO	====> Epoch: 2029, cost 23.01 s
2024-01-02 07:46:38,185	44k	INFO	====> Epoch: 2030, cost 22.88 s
2024-01-02 07:46:56,855	44k	INFO	Train Epoch: 2031 [77%]
2024-01-02 07:46:56,858	44k	INFO	Losses: [2.225539445877075, 2.600219488143921, 8.024070739746094, 18.119487762451172, 0.7655511498451233], step: 52800, lr: 7.758734432483304e-05, reference_loss: 31.7348690032959
2024-01-02 07:47:02,087	44k	INFO	Saving model and optimizer state at iteration 2031 to ./logs/44k/G_52800.pth
2024-01-02 07:47:02,974	44k	INFO	Saving model and optimizer state at iteration 2031 to ./logs/44k/D_52800.pth
2024-01-02 07:47:03,461	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_50400.pth
2024-01-02 07:47:03,500	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_50400.pth
2024-01-02 07:47:07,681	44k	INFO	====> Epoch: 2031, cost 29.50 s
2024-01-02 07:47:30,554	44k	INFO	====> Epoch: 2032, cost 22.87 s
2024-01-02 07:47:53,354	44k	INFO	====> Epoch: 2033, cost 22.80 s
2024-01-02 07:48:16,162	44k	INFO	====> Epoch: 2034, cost 22.81 s
2024-01-02 07:48:38,936	44k	INFO	====> Epoch: 2035, cost 22.77 s
2024-01-02 07:49:01,905	44k	INFO	====> Epoch: 2036, cost 22.97 s
2024-01-02 07:49:24,722	44k	INFO	====> Epoch: 2037, cost 22.82 s
2024-01-02 07:49:47,532	44k	INFO	====> Epoch: 2038, cost 22.81 s
2024-01-02 07:49:59,032	44k	INFO	Train Epoch: 2039 [46%]
2024-01-02 07:49:59,035	44k	INFO	Losses: [2.333914041519165, 2.4517664909362793, 7.757589817047119, 18.70711898803711, 0.4399195611476898], step: 53000, lr: 7.750979091648653e-05, reference_loss: 31.690309524536133
2024-01-02 07:50:10,685	44k	INFO	====> Epoch: 2039, cost 23.15 s
2024-01-02 07:50:33,423	44k	INFO	====> Epoch: 2040, cost 22.74 s
2024-01-02 07:50:56,206	44k	INFO	====> Epoch: 2041, cost 22.78 s
2024-01-02 07:51:18,854	44k	INFO	====> Epoch: 2042, cost 22.65 s
2024-01-02 07:51:41,529	44k	INFO	====> Epoch: 2043, cost 22.67 s
2024-01-02 07:52:04,197	44k	INFO	====> Epoch: 2044, cost 22.67 s
2024-01-02 07:52:26,867	44k	INFO	====> Epoch: 2045, cost 22.67 s
2024-01-02 07:52:49,496	44k	INFO	====> Epoch: 2046, cost 22.63 s
2024-01-02 07:52:53,909	44k	INFO	Train Epoch: 2047 [15%]
2024-01-02 07:52:53,912	44k	INFO	Losses: [2.4194159507751465, 2.256641387939453, 7.596012115478516, 17.740333557128906, 0.4013834595680237], step: 53200, lr: 7.743231502762723e-05, reference_loss: 30.413787841796875
2024-01-02 07:53:12,792	44k	INFO	====> Epoch: 2047, cost 23.30 s
2024-01-02 07:53:35,494	44k	INFO	====> Epoch: 2048, cost 22.70 s
2024-01-02 07:53:58,194	44k	INFO	====> Epoch: 2049, cost 22.70 s
2024-01-02 07:54:21,013	44k	INFO	====> Epoch: 2050, cost 22.82 s
2024-01-02 07:54:43,822	44k	INFO	====> Epoch: 2051, cost 22.81 s
2024-01-02 07:55:06,532	44k	INFO	====> Epoch: 2052, cost 22.71 s
2024-01-02 07:55:29,392	44k	INFO	====> Epoch: 2053, cost 22.86 s
2024-01-02 07:55:49,773	44k	INFO	Train Epoch: 2054 [85%]
2024-01-02 07:55:49,776	44k	INFO	Losses: [2.3963918685913086, 2.4504668712615967, 7.28472375869751, 15.911893844604492, 0.6283177733421326], step: 53400, lr: 7.736458715416383e-05, reference_loss: 28.67179298400879
2024-01-02 07:55:52,648	44k	INFO	====> Epoch: 2054, cost 23.26 s
2024-01-02 07:56:15,632	44k	INFO	====> Epoch: 2055, cost 22.98 s
2024-01-02 07:56:38,471	44k	INFO	====> Epoch: 2056, cost 22.84 s
2024-01-02 07:57:01,288	44k	INFO	====> Epoch: 2057, cost 22.82 s
2024-01-02 07:57:24,134	44k	INFO	====> Epoch: 2058, cost 22.85 s
2024-01-02 07:57:46,971	44k	INFO	====> Epoch: 2059, cost 22.84 s
2024-01-02 07:58:09,810	44k	INFO	====> Epoch: 2060, cost 22.84 s
2024-01-02 07:58:32,671	44k	INFO	====> Epoch: 2061, cost 22.86 s
2024-01-02 07:58:45,987	44k	INFO	Train Epoch: 2062 [54%]
2024-01-02 07:58:45,990	44k	INFO	Losses: [2.3125131130218506, 2.5457558631896973, 6.8394999504089355, 16.120908737182617, 0.3101654350757599], step: 53600, lr: 7.728725640555607e-05, reference_loss: 28.128843307495117
2024-01-02 07:58:51,197	44k	INFO	Saving model and optimizer state at iteration 2062 to ./logs/44k/G_53600.pth
2024-01-02 07:58:52,081	44k	INFO	Saving model and optimizer state at iteration 2062 to ./logs/44k/D_53600.pth
2024-01-02 07:58:52,578	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_51200.pth
2024-01-02 07:58:52,617	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_51200.pth
2024-01-02 07:59:02,244	44k	INFO	====> Epoch: 2062, cost 29.57 s
2024-01-02 07:59:25,059	44k	INFO	====> Epoch: 2063, cost 22.82 s
2024-01-02 07:59:47,909	44k	INFO	====> Epoch: 2064, cost 22.85 s
2024-01-02 08:00:10,632	44k	INFO	====> Epoch: 2065, cost 22.72 s
2024-01-02 08:00:33,417	44k	INFO	====> Epoch: 2066, cost 22.78 s
2024-01-02 08:00:56,213	44k	INFO	====> Epoch: 2067, cost 22.80 s
2024-01-02 08:01:19,031	44k	INFO	====> Epoch: 2068, cost 22.82 s
2024-01-02 08:01:41,825	44k	INFO	====> Epoch: 2069, cost 22.79 s
2024-01-02 08:01:48,043	44k	INFO	Train Epoch: 2070 [23%]
2024-01-02 08:01:48,046	44k	INFO	Losses: [2.508579730987549, 2.3881771564483643, 5.957972049713135, 15.541094779968262, 0.46580860018730164], step: 53800, lr: 7.721000295387318e-05, reference_loss: 26.86163330078125
2024-01-02 08:02:04,903	44k	INFO	====> Epoch: 2070, cost 23.08 s
2024-01-02 08:02:27,516	44k	INFO	====> Epoch: 2071, cost 22.61 s
2024-01-02 08:02:50,321	44k	INFO	====> Epoch: 2072, cost 22.80 s
2024-01-02 08:03:13,087	44k	INFO	====> Epoch: 2073, cost 22.77 s
2024-01-02 08:03:35,882	44k	INFO	====> Epoch: 2074, cost 22.80 s
2024-01-02 08:03:58,829	44k	INFO	====> Epoch: 2075, cost 22.95 s
2024-01-02 08:04:21,495	44k	INFO	====> Epoch: 2076, cost 22.67 s
2024-01-02 08:04:43,426	44k	INFO	Train Epoch: 2077 [92%]
2024-01-02 08:04:43,429	44k	INFO	Losses: [2.3228166103363037, 2.239757537841797, 7.381408214569092, 19.264352798461914, 0.6549907326698303], step: 54000, lr: 7.714246953054337e-05, reference_loss: 31.863327026367188
2024-01-02 08:04:44,508	44k	INFO	====> Epoch: 2077, cost 23.01 s
2024-01-02 08:05:07,119	44k	INFO	====> Epoch: 2078, cost 22.61 s
2024-01-02 08:05:29,735	44k	INFO	====> Epoch: 2079, cost 22.62 s
2024-01-02 08:05:52,432	44k	INFO	====> Epoch: 2080, cost 22.70 s
2024-01-02 08:06:15,177	44k	INFO	====> Epoch: 2081, cost 22.75 s
2024-01-02 08:06:37,998	44k	INFO	====> Epoch: 2082, cost 22.82 s
2024-01-02 08:07:00,843	44k	INFO	====> Epoch: 2083, cost 22.85 s
2024-01-02 08:07:23,800	44k	INFO	====> Epoch: 2084, cost 22.96 s
2024-01-02 08:07:38,759	44k	INFO	Train Epoch: 2085 [62%]
2024-01-02 08:07:38,762	44k	INFO	Losses: [2.348235607147217, 2.3966474533081055, 6.643535614013672, 17.085391998291016, 0.34074679017066956], step: 54200, lr: 7.706536080240708e-05, reference_loss: 28.814556121826172
2024-01-02 08:07:46,950	44k	INFO	====> Epoch: 2085, cost 23.15 s
2024-01-02 08:08:09,618	44k	INFO	====> Epoch: 2086, cost 22.67 s
2024-01-02 08:08:32,256	44k	INFO	====> Epoch: 2087, cost 22.64 s
2024-01-02 08:08:55,033	44k	INFO	====> Epoch: 2088, cost 22.78 s
2024-01-02 08:09:17,779	44k	INFO	====> Epoch: 2089, cost 22.75 s
2024-01-02 08:09:40,548	44k	INFO	====> Epoch: 2090, cost 22.77 s
2024-01-02 08:10:03,368	44k	INFO	====> Epoch: 2091, cost 22.82 s
2024-01-02 08:10:26,097	44k	INFO	====> Epoch: 2092, cost 22.73 s
2024-01-02 08:10:34,050	44k	INFO	Train Epoch: 2093 [31%]
2024-01-02 08:10:34,053	44k	INFO	Losses: [2.443965435028076, 2.584256410598755, 6.354473114013672, 16.395139694213867, 0.5502203106880188], step: 54400, lr: 7.698832914927228e-05, reference_loss: 28.32805633544922
2024-01-02 08:10:39,502	44k	INFO	Saving model and optimizer state at iteration 2093 to ./logs/44k/G_54400.pth
2024-01-02 08:10:40,372	44k	INFO	Saving model and optimizer state at iteration 2093 to ./logs/44k/D_54400.pth
2024-01-02 08:10:40,862	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_52000.pth
2024-01-02 08:10:40,901	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_52000.pth
2024-01-02 08:10:55,658	44k	INFO	====> Epoch: 2093, cost 29.56 s
2024-01-02 08:11:18,537	44k	INFO	====> Epoch: 2094, cost 22.88 s
2024-01-02 08:11:41,402	44k	INFO	====> Epoch: 2095, cost 22.87 s
2024-01-02 08:12:04,198	44k	INFO	====> Epoch: 2096, cost 22.80 s
2024-01-02 08:12:26,783	44k	INFO	====> Epoch: 2097, cost 22.58 s
2024-01-02 08:12:49,428	44k	INFO	====> Epoch: 2098, cost 22.64 s
2024-01-02 08:13:12,222	44k	INFO	====> Epoch: 2099, cost 22.79 s
2024-01-02 08:13:35,027	44k	INFO	====> Epoch: 2100, cost 22.80 s
2024-01-02 08:13:35,920	44k	INFO	Train Epoch: 2101 [0%]
2024-01-02 08:13:35,923	44k	INFO	Losses: [2.3330771923065186, 2.3805925846099854, 6.3844499588012695, 15.655516624450684, 0.28083735704421997], step: 54600, lr: 7.691137449409772e-05, reference_loss: 27.034473419189453
2024-01-02 08:13:58,388	44k	INFO	====> Epoch: 2101, cost 23.36 s
2024-01-02 08:14:21,231	44k	INFO	====> Epoch: 2102, cost 22.84 s
2024-01-02 08:14:43,923	44k	INFO	====> Epoch: 2103, cost 22.69 s
2024-01-02 08:15:06,586	44k	INFO	====> Epoch: 2104, cost 22.66 s
2024-01-02 08:15:29,203	44k	INFO	====> Epoch: 2105, cost 22.62 s
2024-01-02 08:15:51,955	44k	INFO	====> Epoch: 2106, cost 22.75 s
2024-01-02 08:16:14,644	44k	INFO	====> Epoch: 2107, cost 22.69 s
2024-01-02 08:16:31,359	44k	INFO	Train Epoch: 2108 [69%]
2024-01-02 08:16:31,361	44k	INFO	Losses: [2.3171257972717285, 2.718571901321411, 7.195432662963867, 17.19989776611328, 0.44615697860717773], step: 54800, lr: 7.684410227270316e-05, reference_loss: 29.877185821533203
2024-01-02 08:16:37,800	44k	INFO	====> Epoch: 2108, cost 23.16 s
2024-01-02 08:17:00,761	44k	INFO	====> Epoch: 2109, cost 22.96 s
2024-01-02 08:17:23,624	44k	INFO	====> Epoch: 2110, cost 22.86 s
2024-01-02 08:17:46,458	44k	INFO	====> Epoch: 2111, cost 22.83 s
2024-01-02 08:18:09,287	44k	INFO	====> Epoch: 2112, cost 22.83 s
2024-01-02 08:18:32,142	44k	INFO	====> Epoch: 2113, cost 22.85 s
2024-01-02 08:18:54,847	44k	INFO	====> Epoch: 2114, cost 22.71 s
2024-01-02 08:19:17,504	44k	INFO	====> Epoch: 2115, cost 22.66 s
2024-01-02 08:19:27,288	44k	INFO	Train Epoch: 2116 [38%]
2024-01-02 08:19:27,291	44k	INFO	Losses: [2.4304583072662354, 2.2319672107696533, 7.021501541137695, 16.96697235107422, 0.39983752369880676], step: 55000, lr: 7.676729178132168e-05, reference_loss: 29.050737380981445
2024-01-02 08:19:40,710	44k	INFO	====> Epoch: 2116, cost 23.21 s
2024-01-02 08:20:03,586	44k	INFO	====> Epoch: 2117, cost 22.88 s
2024-01-02 08:20:26,455	44k	INFO	====> Epoch: 2118, cost 22.87 s
2024-01-02 08:20:49,455	44k	INFO	====> Epoch: 2119, cost 23.00 s
2024-01-02 08:21:12,337	44k	INFO	====> Epoch: 2120, cost 22.88 s
2024-01-02 08:21:35,214	44k	INFO	====> Epoch: 2121, cost 22.88 s
2024-01-02 08:21:58,096	44k	INFO	====> Epoch: 2122, cost 22.88 s
2024-01-02 08:22:20,916	44k	INFO	====> Epoch: 2123, cost 22.82 s
2024-01-02 08:22:23,576	44k	INFO	Train Epoch: 2124 [8%]
2024-01-02 08:22:23,579	44k	INFO	Losses: [2.2749369144439697, 2.6510438919067383, 7.936432361602783, 19.398868560791016, 0.3312663733959198], step: 55200, lr: 7.669055806683539e-05, reference_loss: 32.59254837036133
2024-01-02 08:22:28,828	44k	INFO	Saving model and optimizer state at iteration 2124 to ./logs/44k/G_55200.pth
2024-01-02 08:22:29,702	44k	INFO	Saving model and optimizer state at iteration 2124 to ./logs/44k/D_55200.pth
2024-01-02 08:22:30,195	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_52800.pth
2024-01-02 08:22:30,234	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_52800.pth
2024-01-02 08:22:50,413	44k	INFO	====> Epoch: 2124, cost 29.50 s
2024-01-02 08:23:13,350	44k	INFO	====> Epoch: 2125, cost 22.94 s
2024-01-02 08:23:36,319	44k	INFO	====> Epoch: 2126, cost 22.97 s
2024-01-02 08:23:58,986	44k	INFO	====> Epoch: 2127, cost 22.67 s
2024-01-02 08:24:21,680	44k	INFO	====> Epoch: 2128, cost 22.69 s
2024-01-02 08:24:44,512	44k	INFO	====> Epoch: 2129, cost 22.83 s
2024-01-02 08:25:07,286	44k	INFO	====> Epoch: 2130, cost 22.77 s
2024-01-02 08:25:25,913	44k	INFO	Train Epoch: 2131 [77%]
2024-01-02 08:25:25,916	44k	INFO	Losses: [2.684760570526123, 2.1340250968933105, 6.175159931182861, 16.80411148071289, 0.5428712368011475], step: 55400, lr: 7.662347898737438e-05, reference_loss: 28.34092903137207
2024-01-02 08:25:30,503	44k	INFO	====> Epoch: 2131, cost 23.22 s
2024-01-02 08:25:53,241	44k	INFO	====> Epoch: 2132, cost 22.74 s
2024-01-02 08:26:16,051	44k	INFO	====> Epoch: 2133, cost 22.81 s
2024-01-02 08:26:38,733	44k	INFO	====> Epoch: 2134, cost 22.68 s
2024-01-02 08:27:01,497	44k	INFO	====> Epoch: 2135, cost 22.76 s
2024-01-02 08:27:24,267	44k	INFO	====> Epoch: 2136, cost 22.77 s
2024-01-02 08:27:46,995	44k	INFO	====> Epoch: 2137, cost 22.73 s
2024-01-02 08:28:09,889	44k	INFO	====> Epoch: 2138, cost 22.89 s
2024-01-02 08:28:21,383	44k	INFO	Train Epoch: 2139 [46%]
2024-01-02 08:28:21,386	44k	INFO	Losses: [2.5248522758483887, 2.2942960262298584, 6.223743915557861, 16.256458282470703, 0.3824044466018677], step: 55600, lr: 7.654688902277966e-05, reference_loss: 27.68175506591797
2024-01-02 08:28:33,162	44k	INFO	====> Epoch: 2139, cost 23.27 s
2024-01-02 08:28:55,990	44k	INFO	====> Epoch: 2140, cost 22.83 s
2024-01-02 08:29:18,795	44k	INFO	====> Epoch: 2141, cost 22.80 s
2024-01-02 08:29:41,599	44k	INFO	====> Epoch: 2142, cost 22.80 s
2024-01-02 08:30:04,265	44k	INFO	====> Epoch: 2143, cost 22.67 s
2024-01-02 08:30:26,931	44k	INFO	====> Epoch: 2144, cost 22.67 s
2024-01-02 08:30:49,518	44k	INFO	====> Epoch: 2145, cost 22.59 s
2024-01-02 08:31:12,157	44k	INFO	====> Epoch: 2146, cost 22.64 s
2024-01-02 08:31:16,579	44k	INFO	Train Epoch: 2147 [15%]
2024-01-02 08:31:16,582	44k	INFO	Losses: [2.4856252670288086, 2.379971504211426, 5.953273773193359, 15.627381324768066, 0.39554500579833984], step: 55800, lr: 7.64703756146498e-05, reference_loss: 26.841796875
2024-01-02 08:31:35,477	44k	INFO	====> Epoch: 2147, cost 23.32 s
2024-01-02 08:31:58,233	44k	INFO	====> Epoch: 2148, cost 22.76 s
2024-01-02 08:32:20,921	44k	INFO	====> Epoch: 2149, cost 22.69 s
2024-01-02 08:32:43,652	44k	INFO	====> Epoch: 2150, cost 22.73 s
2024-01-02 08:33:06,225	44k	INFO	====> Epoch: 2151, cost 22.57 s
2024-01-02 08:33:28,873	44k	INFO	====> Epoch: 2152, cost 22.65 s
2024-01-02 08:33:51,539	44k	INFO	====> Epoch: 2153, cost 22.67 s
2024-01-02 08:34:11,752	44k	INFO	Train Epoch: 2154 [85%]
2024-01-02 08:34:11,755	44k	INFO	Losses: [2.4691038131713867, 2.325455665588379, 6.486289024353027, 16.419618606567383, 0.5673298239707947], step: 56000, lr: 7.640348912260213e-05, reference_loss: 28.26779556274414
2024-01-02 08:34:17,141	44k	INFO	Saving model and optimizer state at iteration 2154 to ./logs/44k/G_56000.pth
2024-01-02 08:34:18,195	44k	INFO	Saving model and optimizer state at iteration 2154 to ./logs/44k/D_56000.pth
2024-01-02 08:34:18,692	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_53600.pth
2024-01-02 08:34:18,731	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_53600.pth
2024-01-02 08:34:21,187	44k	INFO	====> Epoch: 2154, cost 29.65 s
2024-01-02 08:34:43,873	44k	INFO	====> Epoch: 2155, cost 22.69 s
2024-01-02 08:35:06,604	44k	INFO	====> Epoch: 2156, cost 22.73 s
2024-01-02 08:35:29,271	44k	INFO	====> Epoch: 2157, cost 22.67 s
2024-01-02 08:35:51,911	44k	INFO	====> Epoch: 2158, cost 22.64 s
2024-01-02 08:36:14,679	44k	INFO	====> Epoch: 2159, cost 22.77 s
2024-01-02 08:36:37,531	44k	INFO	====> Epoch: 2160, cost 22.85 s
2024-01-02 08:37:00,123	44k	INFO	====> Epoch: 2161, cost 22.59 s
2024-01-02 08:37:13,343	44k	INFO	Train Epoch: 2162 [54%]
2024-01-02 08:37:13,346	44k	INFO	Losses: [2.3897528648376465, 2.5456385612487793, 7.639853477478027, 16.95713996887207, 0.7701525688171387], step: 56200, lr: 7.632711905165067e-05, reference_loss: 30.30253791809082
2024-01-02 08:37:23,269	44k	INFO	====> Epoch: 2162, cost 23.15 s
2024-01-02 08:37:46,211	44k	INFO	====> Epoch: 2163, cost 22.94 s
2024-01-02 08:38:09,010	44k	INFO	====> Epoch: 2164, cost 22.80 s
2024-01-02 08:38:31,791	44k	INFO	====> Epoch: 2165, cost 22.78 s
2024-01-02 08:38:54,589	44k	INFO	====> Epoch: 2166, cost 22.80 s
2024-01-02 08:39:17,414	44k	INFO	====> Epoch: 2167, cost 22.83 s
2024-01-02 08:39:40,254	44k	INFO	====> Epoch: 2168, cost 22.84 s
2024-01-02 08:40:03,071	44k	INFO	====> Epoch: 2169, cost 22.82 s
2024-01-02 08:40:09,293	44k	INFO	Train Epoch: 2170 [23%]
2024-01-02 08:40:09,296	44k	INFO	Losses: [2.753571033477783, 2.0974349975585938, 6.353965759277344, 14.427581787109375, 0.4512132704257965], step: 56400, lr: 7.625082531736662e-05, reference_loss: 26.08376693725586
2024-01-02 08:40:26,297	44k	INFO	====> Epoch: 2170, cost 23.23 s
2024-01-02 08:40:49,172	44k	INFO	====> Epoch: 2171, cost 22.87 s
2024-01-02 08:41:12,016	44k	INFO	====> Epoch: 2172, cost 22.84 s
2024-01-02 08:41:34,830	44k	INFO	====> Epoch: 2173, cost 22.81 s
2024-01-02 08:41:57,528	44k	INFO	====> Epoch: 2174, cost 22.70 s
2024-01-02 08:42:20,374	44k	INFO	====> Epoch: 2175, cost 22.85 s
2024-01-02 08:42:43,246	44k	INFO	====> Epoch: 2176, cost 22.87 s
2024-01-02 08:43:05,308	44k	INFO	Train Epoch: 2177 [92%]
2024-01-02 08:43:05,311	44k	INFO	Losses: [2.3442208766937256, 2.5051276683807373, 6.699381351470947, 16.809223175048828, 0.57061767578125], step: 56600, lr: 7.618413085980415e-05, reference_loss: 28.928569793701172
2024-01-02 08:43:06,398	44k	INFO	====> Epoch: 2177, cost 23.15 s
2024-01-02 08:43:29,070	44k	INFO	====> Epoch: 2178, cost 22.67 s
2024-01-02 08:43:51,734	44k	INFO	====> Epoch: 2179, cost 22.66 s
2024-01-02 08:44:14,419	44k	INFO	====> Epoch: 2180, cost 22.68 s
2024-01-02 08:44:37,073	44k	INFO	====> Epoch: 2181, cost 22.65 s
2024-01-02 08:44:59,836	44k	INFO	====> Epoch: 2182, cost 22.76 s
2024-01-02 08:45:22,439	44k	INFO	====> Epoch: 2183, cost 22.60 s
2024-01-02 08:45:45,257	44k	INFO	====> Epoch: 2184, cost 22.82 s
2024-01-02 08:46:00,342	44k	INFO	Train Epoch: 2185 [62%]
2024-01-02 08:46:00,345	44k	INFO	Losses: [2.425201177597046, 2.4560928344726562, 6.1879353523254395, 14.993574142456055, 0.47306424379348755], step: 56800, lr: 7.610798005117023e-05, reference_loss: 26.53586769104004
2024-01-02 08:46:05,587	44k	INFO	Saving model and optimizer state at iteration 2185 to ./logs/44k/G_56800.pth
2024-01-02 08:46:06,473	44k	INFO	Saving model and optimizer state at iteration 2185 to ./logs/44k/D_56800.pth
2024-01-02 08:46:06,962	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_54400.pth
2024-01-02 08:46:07,001	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_54400.pth
2024-01-02 08:46:14,727	44k	INFO	====> Epoch: 2185, cost 29.47 s
2024-01-02 08:46:37,552	44k	INFO	====> Epoch: 2186, cost 22.82 s
2024-01-02 08:47:00,394	44k	INFO	====> Epoch: 2187, cost 22.84 s
2024-01-02 08:47:23,096	44k	INFO	====> Epoch: 2188, cost 22.70 s
2024-01-02 08:47:45,760	44k	INFO	====> Epoch: 2189, cost 22.66 s
2024-01-02 08:48:08,721	44k	INFO	====> Epoch: 2190, cost 22.96 s
2024-01-02 08:48:31,459	44k	INFO	====> Epoch: 2191, cost 22.74 s
2024-01-02 08:48:54,094	44k	INFO	====> Epoch: 2192, cost 22.64 s
2024-01-02 08:49:02,052	44k	INFO	Train Epoch: 2193 [31%]
2024-01-02 08:49:02,055	44k	INFO	Losses: [2.3840279579162598, 2.245114803314209, 6.487520694732666, 15.8552885055542, 0.45865583419799805], step: 57000, lr: 7.603190536003728e-05, reference_loss: 27.430606842041016
2024-01-02 08:49:17,223	44k	INFO	====> Epoch: 2193, cost 23.13 s
2024-01-02 08:49:39,880	44k	INFO	====> Epoch: 2194, cost 22.66 s
2024-01-02 08:50:02,632	44k	INFO	====> Epoch: 2195, cost 22.75 s
2024-01-02 08:50:25,363	44k	INFO	====> Epoch: 2196, cost 22.73 s
2024-01-02 08:50:48,118	44k	INFO	====> Epoch: 2197, cost 22.75 s
2024-01-02 08:51:10,851	44k	INFO	====> Epoch: 2198, cost 22.73 s
2024-01-02 08:51:33,459	44k	INFO	====> Epoch: 2199, cost 22.61 s
2024-01-02 08:51:56,290	44k	INFO	====> Epoch: 2200, cost 22.83 s
2024-01-02 08:51:57,182	44k	INFO	Train Epoch: 2201 [0%]
2024-01-02 08:51:57,185	44k	INFO	Losses: [2.3053245544433594, 2.504500150680542, 6.8113203048706055, 16.061033248901367, 0.3757198750972748], step: 57200, lr: 7.595590671032112e-05, reference_loss: 28.057897567749023
2024-01-02 08:52:19,486	44k	INFO	====> Epoch: 2201, cost 23.20 s
2024-01-02 08:52:42,158	44k	INFO	====> Epoch: 2202, cost 22.67 s
2024-01-02 08:53:04,970	44k	INFO	====> Epoch: 2203, cost 22.81 s
2024-01-02 08:53:27,775	44k	INFO	====> Epoch: 2204, cost 22.81 s
2024-01-02 08:53:50,440	44k	INFO	====> Epoch: 2205, cost 22.67 s
2024-01-02 08:54:13,085	44k	INFO	====> Epoch: 2206, cost 22.64 s
2024-01-02 08:54:35,736	44k	INFO	====> Epoch: 2207, cost 22.65 s
2024-01-02 08:54:52,445	44k	INFO	Train Epoch: 2208 [69%]
2024-01-02 08:54:52,447	44k	INFO	Losses: [2.3046512603759766, 2.6372573375701904, 8.141547203063965, 18.165781021118164, 0.3945392668247223], step: 57400, lr: 7.588947020978982e-05, reference_loss: 31.643775939941406
2024-01-02 08:54:58,986	44k	INFO	====> Epoch: 2208, cost 23.25 s
2024-01-02 08:55:21,624	44k	INFO	====> Epoch: 2209, cost 22.64 s
2024-01-02 08:55:44,149	44k	INFO	====> Epoch: 2210, cost 22.53 s
2024-01-02 08:56:06,893	44k	INFO	====> Epoch: 2211, cost 22.74 s
2024-01-02 08:56:29,625	44k	INFO	====> Epoch: 2212, cost 22.73 s
2024-01-02 08:56:52,340	44k	INFO	====> Epoch: 2213, cost 22.71 s
2024-01-02 08:57:15,154	44k	INFO	====> Epoch: 2214, cost 22.81 s
2024-01-02 08:57:37,914	44k	INFO	====> Epoch: 2215, cost 22.76 s
2024-01-02 08:57:47,638	44k	INFO	Train Epoch: 2216 [38%]
2024-01-02 08:57:47,642	44k	INFO	Losses: [2.220795154571533, 2.620408058166504, 7.244648456573486, 15.891401290893555, 0.5326917171478271], step: 57600, lr: 7.58136139329241e-05, reference_loss: 28.509944915771484
2024-01-02 08:57:52,870	44k	INFO	Saving model and optimizer state at iteration 2216 to ./logs/44k/G_57600.pth
2024-01-02 08:57:53,940	44k	INFO	Saving model and optimizer state at iteration 2216 to ./logs/44k/D_57600.pth
2024-01-02 08:57:54,427	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_55200.pth
2024-01-02 08:57:54,466	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_55200.pth
2024-01-02 08:58:07,402	44k	INFO	====> Epoch: 2216, cost 29.49 s
2024-01-02 08:58:30,191	44k	INFO	====> Epoch: 2217, cost 22.79 s
2024-01-02 08:58:52,893	44k	INFO	====> Epoch: 2218, cost 22.70 s
2024-01-02 08:59:15,543	44k	INFO	====> Epoch: 2219, cost 22.65 s
2024-01-02 08:59:38,218	44k	INFO	====> Epoch: 2220, cost 22.68 s
2024-01-02 09:00:00,978	44k	INFO	====> Epoch: 2221, cost 22.76 s
2024-01-02 09:00:23,606	44k	INFO	====> Epoch: 2222, cost 22.63 s
2024-01-02 09:00:46,348	44k	INFO	====> Epoch: 2223, cost 22.74 s
2024-01-02 09:00:49,020	44k	INFO	Train Epoch: 2224 [8%]
2024-01-02 09:00:49,023	44k	INFO	Losses: [2.5630922317504883, 1.972588300704956, 5.370899200439453, 16.21016502380371, 0.32209232449531555], step: 57800, lr: 7.573783347915643e-05, reference_loss: 26.4388370513916
2024-01-02 09:01:09,581	44k	INFO	====> Epoch: 2224, cost 23.23 s
2024-01-02 09:01:32,413	44k	INFO	====> Epoch: 2225, cost 22.83 s
2024-01-02 09:01:55,353	44k	INFO	====> Epoch: 2226, cost 22.94 s
2024-01-02 09:02:18,183	44k	INFO	====> Epoch: 2227, cost 22.83 s
2024-01-02 09:02:41,017	44k	INFO	====> Epoch: 2228, cost 22.83 s
2024-01-02 09:03:03,854	44k	INFO	====> Epoch: 2229, cost 22.84 s
2024-01-02 09:03:26,687	44k	INFO	====> Epoch: 2230, cost 22.83 s
2024-01-02 09:03:45,261	44k	INFO	Train Epoch: 2231 [77%]
2024-01-02 09:03:45,265	44k	INFO	Losses: [2.083343744277954, 2.5102951526641846, 9.108280181884766, 18.65753936767578, 0.42800745368003845], step: 58000, lr: 7.5671587721162e-05, reference_loss: 32.78746795654297
2024-01-02 09:03:49,811	44k	INFO	====> Epoch: 2231, cost 23.12 s
2024-01-02 09:04:12,463	44k	INFO	====> Epoch: 2232, cost 22.65 s
2024-01-02 09:04:35,151	44k	INFO	====> Epoch: 2233, cost 22.69 s
2024-01-02 09:04:57,944	44k	INFO	====> Epoch: 2234, cost 22.79 s
2024-01-02 09:05:20,857	44k	INFO	====> Epoch: 2235, cost 22.91 s
2024-01-02 09:05:43,642	44k	INFO	====> Epoch: 2236, cost 22.78 s
2024-01-02 09:06:06,427	44k	INFO	====> Epoch: 2237, cost 22.78 s
2024-01-02 09:06:29,164	44k	INFO	====> Epoch: 2238, cost 22.74 s
2024-01-02 09:06:40,674	44k	INFO	Train Epoch: 2239 [46%]
2024-01-02 09:06:40,677	44k	INFO	Losses: [2.381650686264038, 2.476046085357666, 6.923453330993652, 16.792142868041992, 0.4757707715034485], step: 58200, lr: 7.559594923148515e-05, reference_loss: 29.049062728881836
2024-01-02 09:06:52,372	44k	INFO	====> Epoch: 2239, cost 23.21 s
2024-01-02 09:07:15,224	44k	INFO	====> Epoch: 2240, cost 22.85 s
2024-01-02 09:07:38,109	44k	INFO	====> Epoch: 2241, cost 22.88 s
2024-01-02 09:08:00,723	44k	INFO	====> Epoch: 2242, cost 22.61 s
2024-01-02 09:08:23,320	44k	INFO	====> Epoch: 2243, cost 22.60 s
2024-01-02 09:08:45,919	44k	INFO	====> Epoch: 2244, cost 22.60 s
2024-01-02 09:09:08,715	44k	INFO	====> Epoch: 2245, cost 22.80 s
2024-01-02 09:09:31,568	44k	INFO	====> Epoch: 2246, cost 22.85 s
2024-01-02 09:09:36,026	44k	INFO	Train Epoch: 2247 [15%]
2024-01-02 09:09:36,029	44k	INFO	Losses: [2.516172170639038, 2.288367986679077, 7.803682804107666, 17.59727668762207, 0.33749040961265564], step: 58400, lr: 7.552038634721442e-05, reference_loss: 30.54298973083496
2024-01-02 09:09:41,260	44k	INFO	Saving model and optimizer state at iteration 2247 to ./logs/44k/G_58400.pth
2024-01-02 09:09:42,110	44k	INFO	Saving model and optimizer state at iteration 2247 to ./logs/44k/D_58400.pth
2024-01-02 09:09:42,604	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_56000.pth
2024-01-02 09:09:42,643	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_56000.pth
2024-01-02 09:10:01,003	44k	INFO	====> Epoch: 2247, cost 29.44 s
2024-01-02 09:10:23,757	44k	INFO	====> Epoch: 2248, cost 22.75 s
2024-01-02 09:10:46,442	44k	INFO	====> Epoch: 2249, cost 22.68 s
2024-01-02 09:11:09,081	44k	INFO	====> Epoch: 2250, cost 22.64 s
2024-01-02 09:11:31,725	44k	INFO	====> Epoch: 2251, cost 22.64 s
2024-01-02 09:11:54,583	44k	INFO	====> Epoch: 2252, cost 22.86 s
2024-01-02 09:12:17,418	44k	INFO	====> Epoch: 2253, cost 22.83 s
2024-01-02 09:12:37,745	44k	INFO	Train Epoch: 2254 [85%]
2024-01-02 09:12:37,748	44k	INFO	Losses: [2.6453943252563477, 1.9633138179779053, 5.397374629974365, 16.22212791442871, 0.571243405342102], step: 58600, lr: 7.545433078412547e-05, reference_loss: 26.799453735351562
2024-01-02 09:12:40,690	44k	INFO	====> Epoch: 2254, cost 23.27 s
2024-01-02 09:13:03,311	44k	INFO	====> Epoch: 2255, cost 22.62 s
2024-01-02 09:13:25,983	44k	INFO	====> Epoch: 2256, cost 22.67 s
2024-01-02 09:13:48,638	44k	INFO	====> Epoch: 2257, cost 22.66 s
2024-01-02 09:14:11,378	44k	INFO	====> Epoch: 2258, cost 22.74 s
2024-01-02 09:14:34,052	44k	INFO	====> Epoch: 2259, cost 22.67 s
2024-01-02 09:14:56,721	44k	INFO	====> Epoch: 2260, cost 22.67 s
2024-01-02 09:15:19,506	44k	INFO	====> Epoch: 2261, cost 22.78 s
2024-01-02 09:15:32,731	44k	INFO	Train Epoch: 2262 [54%]
2024-01-02 09:15:32,734	44k	INFO	Losses: [2.335482358932495, 2.5916974544525146, 7.793488502502441, 18.338632583618164, 0.5387325882911682], step: 58800, lr: 7.537890945635951e-05, reference_loss: 31.598033905029297
2024-01-02 09:15:42,864	44k	INFO	====> Epoch: 2262, cost 23.36 s
2024-01-02 09:16:05,542	44k	INFO	====> Epoch: 2263, cost 22.68 s
2024-01-02 09:16:28,221	44k	INFO	====> Epoch: 2264, cost 22.68 s
2024-01-02 09:16:50,834	44k	INFO	====> Epoch: 2265, cost 22.61 s
2024-01-02 09:17:13,519	44k	INFO	====> Epoch: 2266, cost 22.68 s
2024-01-02 09:17:36,342	44k	INFO	====> Epoch: 2267, cost 22.82 s
2024-01-02 09:17:59,024	44k	INFO	====> Epoch: 2268, cost 22.68 s
2024-01-02 09:18:21,808	44k	INFO	====> Epoch: 2269, cost 22.78 s
2024-01-02 09:18:28,054	44k	INFO	Train Epoch: 2270 [23%]
2024-01-02 09:18:28,057	44k	INFO	Losses: [2.3816003799438477, 2.474395275115967, 7.08409309387207, 14.245133399963379, 0.41075244545936584], step: 59000, lr: 7.530356351693274e-05, reference_loss: 26.595975875854492
2024-01-02 09:18:45,053	44k	INFO	====> Epoch: 2270, cost 23.25 s
2024-01-02 09:19:08,051	44k	INFO	====> Epoch: 2271, cost 23.00 s
2024-01-02 09:19:30,883	44k	INFO	====> Epoch: 2272, cost 22.83 s
2024-01-02 09:19:53,698	44k	INFO	====> Epoch: 2273, cost 22.81 s
2024-01-02 09:20:16,384	44k	INFO	====> Epoch: 2274, cost 22.69 s
2024-01-02 09:20:39,051	44k	INFO	====> Epoch: 2275, cost 22.67 s
2024-01-02 09:21:01,807	44k	INFO	====> Epoch: 2276, cost 22.76 s
2024-01-02 09:21:23,843	44k	INFO	Train Epoch: 2277 [92%]
2024-01-02 09:21:23,846	44k	INFO	Losses: [2.4890732765197754, 2.23164439201355, 6.340702056884766, 16.399965286254883, 0.5685858726501465], step: 59200, lr: 7.523769760269012e-05, reference_loss: 28.029970169067383
2024-01-02 09:21:29,149	44k	INFO	Saving model and optimizer state at iteration 2277 to ./logs/44k/G_59200.pth
2024-01-02 09:21:30,015	44k	INFO	Saving model and optimizer state at iteration 2277 to ./logs/44k/D_59200.pth
2024-01-02 09:21:30,504	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_56800.pth
2024-01-02 09:21:30,543	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_56800.pth
2024-01-02 09:21:31,232	44k	INFO	====> Epoch: 2277, cost 29.42 s
2024-01-02 09:21:54,253	44k	INFO	====> Epoch: 2278, cost 23.02 s
2024-01-02 09:22:17,041	44k	INFO	====> Epoch: 2279, cost 22.79 s
2024-01-02 09:22:39,659	44k	INFO	====> Epoch: 2280, cost 22.62 s
2024-01-02 09:23:02,309	44k	INFO	====> Epoch: 2281, cost 22.65 s
2024-01-02 09:23:24,976	44k	INFO	====> Epoch: 2282, cost 22.67 s
2024-01-02 09:23:47,664	44k	INFO	====> Epoch: 2283, cost 22.69 s
2024-01-02 09:24:10,427	44k	INFO	====> Epoch: 2284, cost 22.76 s
2024-01-02 09:24:25,421	44k	INFO	Train Epoch: 2285 [62%]
2024-01-02 09:24:25,424	44k	INFO	Losses: [2.4780569076538086, 2.1531481742858887, 5.41992712020874, 13.962088584899902, 0.704605758190155], step: 59400, lr: 7.516249281335227e-05, reference_loss: 24.71782684326172
2024-01-02 09:24:33,628	44k	INFO	====> Epoch: 2285, cost 23.20 s
2024-01-02 09:24:56,423	44k	INFO	====> Epoch: 2286, cost 22.79 s
2024-01-02 09:25:19,134	44k	INFO	====> Epoch: 2287, cost 22.71 s
2024-01-02 09:25:41,808	44k	INFO	====> Epoch: 2288, cost 22.67 s
2024-01-02 09:26:04,599	44k	INFO	====> Epoch: 2289, cost 22.79 s
2024-01-02 09:26:27,580	44k	INFO	====> Epoch: 2290, cost 22.98 s
2024-01-02 09:26:50,329	44k	INFO	====> Epoch: 2291, cost 22.75 s
2024-01-02 09:27:13,036	44k	INFO	====> Epoch: 2292, cost 22.71 s
2024-01-02 09:27:21,032	44k	INFO	Train Epoch: 2293 [31%]
2024-01-02 09:27:21,035	44k	INFO	Losses: [2.2754640579223633, 2.6133830547332764, 6.499743461608887, 15.345609664916992, 0.4507371783256531], step: 59600, lr: 7.508736319590988e-05, reference_loss: 27.1849365234375
2024-01-02 09:27:36,119	44k	INFO	====> Epoch: 2293, cost 23.08 s
2024-01-02 09:27:58,802	44k	INFO	====> Epoch: 2294, cost 22.68 s
2024-01-02 09:28:21,483	44k	INFO	====> Epoch: 2295, cost 22.68 s
2024-01-02 09:28:44,117	44k	INFO	====> Epoch: 2296, cost 22.63 s
2024-01-02 09:29:06,785	44k	INFO	====> Epoch: 2297, cost 22.67 s
2024-01-02 09:29:29,562	44k	INFO	====> Epoch: 2298, cost 22.78 s
2024-01-02 09:29:52,188	44k	INFO	====> Epoch: 2299, cost 22.63 s
2024-01-02 09:30:15,011	44k	INFO	====> Epoch: 2300, cost 22.82 s
2024-01-02 09:30:15,896	44k	INFO	Train Epoch: 2301 [0%]
2024-01-02 09:30:15,899	44k	INFO	Losses: [2.4796509742736816, 2.3067564964294434, 6.347143650054932, 14.01791763305664, 0.4516950845718384], step: 59800, lr: 7.501230867522394e-05, reference_loss: 25.60316276550293
2024-01-02 09:30:38,041	44k	INFO	====> Epoch: 2301, cost 23.03 s
2024-01-02 09:31:00,789	44k	INFO	====> Epoch: 2302, cost 22.75 s
2024-01-02 09:31:23,469	44k	INFO	====> Epoch: 2303, cost 22.68 s
2024-01-02 09:31:46,215	44k	INFO	====> Epoch: 2304, cost 22.75 s
2024-01-02 09:32:09,072	44k	INFO	====> Epoch: 2305, cost 22.86 s
2024-01-02 09:32:31,923	44k	INFO	====> Epoch: 2306, cost 22.85 s
2024-01-02 09:32:54,607	44k	INFO	====> Epoch: 2307, cost 22.68 s
2024-01-02 09:33:11,358	44k	INFO	Train Epoch: 2308 [69%]
2024-01-02 09:33:11,361	44k	INFO	Losses: [2.3430540561676025, 2.464099884033203, 6.64811897277832, 15.324625968933105, 0.4268363118171692], step: 60000, lr: 7.494669751341973e-05, reference_loss: 27.206735610961914
2024-01-02 09:33:16,747	44k	INFO	Saving model and optimizer state at iteration 2308 to ./logs/44k/G_60000.pth
2024-01-02 09:33:17,619	44k	INFO	Saving model and optimizer state at iteration 2308 to ./logs/44k/D_60000.pth
2024-01-02 09:33:18,110	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_57600.pth
2024-01-02 09:33:18,149	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_57600.pth
2024-01-02 09:33:24,113	44k	INFO	====> Epoch: 2308, cost 29.51 s
2024-01-02 09:33:46,981	44k	INFO	====> Epoch: 2309, cost 22.87 s
2024-01-02 09:34:09,877	44k	INFO	====> Epoch: 2310, cost 22.90 s
2024-01-02 09:34:32,638	44k	INFO	====> Epoch: 2311, cost 22.76 s
2024-01-02 09:34:55,229	44k	INFO	====> Epoch: 2312, cost 22.59 s
2024-01-02 09:35:17,918	44k	INFO	====> Epoch: 2313, cost 22.69 s
2024-01-02 09:35:40,728	44k	INFO	====> Epoch: 2314, cost 22.81 s
2024-01-02 09:36:03,552	44k	INFO	====> Epoch: 2315, cost 22.82 s
2024-01-02 09:36:13,352	44k	INFO	Train Epoch: 2316 [38%]
2024-01-02 09:36:13,355	44k	INFO	Losses: [2.525949239730835, 2.327831745147705, 7.25453519821167, 17.713932037353516, 0.44485849142074585], step: 60200, lr: 7.487178359689043e-05, reference_loss: 30.267107009887695
2024-01-02 09:36:26,859	44k	INFO	====> Epoch: 2316, cost 23.31 s
2024-01-02 09:36:49,611	44k	INFO	====> Epoch: 2317, cost 22.75 s
2024-01-02 09:37:12,371	44k	INFO	====> Epoch: 2318, cost 22.76 s
2024-01-02 09:37:35,111	44k	INFO	====> Epoch: 2319, cost 22.74 s
2024-01-02 09:37:57,889	44k	INFO	====> Epoch: 2320, cost 22.78 s
2024-01-02 09:38:20,568	44k	INFO	====> Epoch: 2321, cost 22.68 s
2024-01-02 09:38:43,113	44k	INFO	====> Epoch: 2322, cost 22.55 s
2024-01-02 09:39:05,798	44k	INFO	====> Epoch: 2323, cost 22.68 s
2024-01-02 09:39:08,472	44k	INFO	Train Epoch: 2324 [8%]
2024-01-02 09:39:08,475	44k	INFO	Losses: [2.1853530406951904, 2.473059892654419, 7.730483055114746, 16.91507911682129, 0.41565024852752686], step: 60400, lr: 7.479694456151102e-05, reference_loss: 29.719623565673828
2024-01-02 09:39:29,099	44k	INFO	====> Epoch: 2324, cost 23.30 s
2024-01-02 09:39:52,077	44k	INFO	====> Epoch: 2325, cost 22.98 s
2024-01-02 09:40:14,886	44k	INFO	====> Epoch: 2326, cost 22.81 s
2024-01-02 09:40:37,652	44k	INFO	====> Epoch: 2327, cost 22.77 s
2024-01-02 09:41:00,306	44k	INFO	====> Epoch: 2328, cost 22.65 s
2024-01-02 09:41:22,947	44k	INFO	====> Epoch: 2329, cost 22.64 s
2024-01-02 09:41:45,597	44k	INFO	====> Epoch: 2330, cost 22.65 s
2024-01-02 09:42:04,063	44k	INFO	Train Epoch: 2331 [77%]
2024-01-02 09:42:04,066	44k	INFO	Losses: [2.4057745933532715, 2.5336310863494873, 8.514328956604004, 19.084312438964844, 0.41765591502189636], step: 60600, lr: 7.473152177265468e-05, reference_loss: 32.95570373535156
2024-01-02 09:42:08,617	44k	INFO	====> Epoch: 2331, cost 23.02 s
2024-01-02 09:42:31,256	44k	INFO	====> Epoch: 2332, cost 22.64 s
2024-01-02 09:42:53,899	44k	INFO	====> Epoch: 2333, cost 22.64 s
2024-01-02 09:43:16,535	44k	INFO	====> Epoch: 2334, cost 22.64 s
2024-01-02 09:43:39,324	44k	INFO	====> Epoch: 2335, cost 22.79 s
2024-01-02 09:44:01,994	44k	INFO	====> Epoch: 2336, cost 22.67 s
2024-01-02 09:44:24,668	44k	INFO	====> Epoch: 2337, cost 22.67 s
2024-01-02 09:44:47,350	44k	INFO	====> Epoch: 2338, cost 22.68 s
2024-01-02 09:44:58,852	44k	INFO	Train Epoch: 2339 [46%]
2024-01-02 09:44:58,855	44k	INFO	Losses: [2.4647836685180664, 2.302241325378418, 5.562092304229736, 14.320878982543945, 0.34823036193847656], step: 60800, lr: 7.465682293775028e-05, reference_loss: 24.998226165771484
2024-01-02 09:45:04,211	44k	INFO	Saving model and optimizer state at iteration 2339 to ./logs/44k/G_60800.pth
2024-01-02 09:45:05,069	44k	INFO	Saving model and optimizer state at iteration 2339 to ./logs/44k/D_60800.pth
2024-01-02 09:45:05,559	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_58400.pth
2024-01-02 09:45:05,598	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_58400.pth
2024-01-02 09:45:16,881	44k	INFO	====> Epoch: 2339, cost 29.53 s
2024-01-02 09:45:39,723	44k	INFO	====> Epoch: 2340, cost 22.84 s
2024-01-02 09:46:02,470	44k	INFO	====> Epoch: 2341, cost 22.75 s
2024-01-02 09:46:25,279	44k	INFO	====> Epoch: 2342, cost 22.81 s
2024-01-02 09:46:47,940	44k	INFO	====> Epoch: 2343, cost 22.66 s
2024-01-02 09:47:10,591	44k	INFO	====> Epoch: 2344, cost 22.65 s
2024-01-02 09:47:33,261	44k	INFO	====> Epoch: 2345, cost 22.67 s
2024-01-02 09:47:55,910	44k	INFO	====> Epoch: 2346, cost 22.65 s
2024-01-02 09:48:00,332	44k	INFO	Train Epoch: 2347 [15%]
2024-01-02 09:48:00,335	44k	INFO	Losses: [2.3329925537109375, 2.4422082901000977, 6.457335948944092, 14.894575119018555, 0.38650062680244446], step: 61000, lr: 7.458219876900821e-05, reference_loss: 26.513612747192383
2024-01-02 09:48:18,982	44k	INFO	====> Epoch: 2347, cost 23.07 s
2024-01-02 09:48:41,660	44k	INFO	====> Epoch: 2348, cost 22.68 s
2024-01-02 09:49:04,497	44k	INFO	====> Epoch: 2349, cost 22.84 s
2024-01-02 09:49:27,140	44k	INFO	====> Epoch: 2350, cost 22.64 s
2024-01-02 09:49:49,786	44k	INFO	====> Epoch: 2351, cost 22.65 s
2024-01-02 09:50:12,434	44k	INFO	====> Epoch: 2352, cost 22.65 s
2024-01-02 09:50:35,110	44k	INFO	====> Epoch: 2353, cost 22.68 s
2024-01-02 09:50:55,622	44k	INFO	Train Epoch: 2354 [85%]
2024-01-02 09:50:55,625	44k	INFO	Losses: [2.116196632385254, 2.9673588275909424, 7.918805122375488, 17.312929153442383, 0.6168256998062134], step: 61200, lr: 7.451696381227153e-05, reference_loss: 30.932113647460938
2024-01-02 09:50:58,495	44k	INFO	====> Epoch: 2354, cost 23.39 s
2024-01-02 09:51:21,332	44k	INFO	====> Epoch: 2355, cost 22.84 s
2024-01-02 09:51:44,074	44k	INFO	====> Epoch: 2356, cost 22.74 s
2024-01-02 09:52:06,766	44k	INFO	====> Epoch: 2357, cost 22.69 s
2024-01-02 09:52:29,517	44k	INFO	====> Epoch: 2358, cost 22.75 s
2024-01-02 09:52:52,323	44k	INFO	====> Epoch: 2359, cost 22.81 s
2024-01-02 09:53:15,000	44k	INFO	====> Epoch: 2360, cost 22.68 s
2024-01-02 09:53:37,752	44k	INFO	====> Epoch: 2361, cost 22.75 s
2024-01-02 09:53:51,027	44k	INFO	Train Epoch: 2362 [54%]
2024-01-02 09:53:51,030	44k	INFO	Losses: [2.5675711631774902, 2.357659101486206, 6.134613513946533, 15.661519050598145, 0.4350053668022156], step: 61400, lr: 7.444247944148188e-05, reference_loss: 27.156368255615234
2024-01-02 09:54:01,072	44k	INFO	====> Epoch: 2362, cost 23.32 s
2024-01-02 09:54:23,862	44k	INFO	====> Epoch: 2363, cost 22.79 s
2024-01-02 09:54:46,707	44k	INFO	====> Epoch: 2364, cost 22.84 s
2024-01-02 09:55:09,501	44k	INFO	====> Epoch: 2365, cost 22.79 s
2024-01-02 09:55:32,235	44k	INFO	====> Epoch: 2366, cost 22.73 s
2024-01-02 09:55:54,878	44k	INFO	====> Epoch: 2367, cost 22.64 s
2024-01-02 09:56:17,546	44k	INFO	====> Epoch: 2368, cost 22.67 s
2024-01-02 09:56:40,309	44k	INFO	====> Epoch: 2369, cost 22.76 s
2024-01-02 09:56:46,544	44k	INFO	Train Epoch: 2370 [23%]
2024-01-02 09:56:46,547	44k	INFO	Losses: [2.359999179840088, 2.7964625358581543, 7.037349700927734, 15.125568389892578, 0.5484124422073364], step: 61600, lr: 7.436806952248426e-05, reference_loss: 27.8677921295166
2024-01-02 09:56:51,801	44k	INFO	Saving model and optimizer state at iteration 2370 to ./logs/44k/G_61600.pth
2024-01-02 09:56:52,839	44k	INFO	Saving model and optimizer state at iteration 2370 to ./logs/44k/D_61600.pth
2024-01-02 09:56:53,335	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_59200.pth
2024-01-02 09:56:53,373	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_59200.pth
2024-01-02 09:57:09,956	44k	INFO	====> Epoch: 2370, cost 29.65 s
2024-01-02 09:57:32,882	44k	INFO	====> Epoch: 2371, cost 22.93 s
2024-01-02 09:57:55,720	44k	INFO	====> Epoch: 2372, cost 22.84 s
2024-01-02 09:58:18,514	44k	INFO	====> Epoch: 2373, cost 22.79 s
2024-01-02 09:58:41,357	44k	INFO	====> Epoch: 2374, cost 22.84 s
2024-01-02 09:59:04,245	44k	INFO	====> Epoch: 2375, cost 22.89 s
2024-01-02 09:59:27,140	44k	INFO	====> Epoch: 2376, cost 22.90 s
2024-01-02 09:59:49,208	44k	INFO	Train Epoch: 2377 [92%]
2024-01-02 09:59:49,211	44k	INFO	Losses: [2.382310152053833, 2.4978113174438477, 6.664401531219482, 16.371740341186523, 0.5936232209205627], step: 61800, lr: 7.430302185859177e-05, reference_loss: 28.5098876953125
2024-01-02 09:59:50,295	44k	INFO	====> Epoch: 2377, cost 23.16 s
2024-01-02 10:00:12,979	44k	INFO	====> Epoch: 2378, cost 22.68 s
2024-01-02 10:00:35,935	44k	INFO	====> Epoch: 2379, cost 22.96 s
2024-01-02 10:00:58,775	44k	INFO	====> Epoch: 2380, cost 22.84 s
2024-01-02 10:01:21,554	44k	INFO	====> Epoch: 2381, cost 22.78 s
2024-01-02 10:01:44,374	44k	INFO	====> Epoch: 2382, cost 22.82 s
2024-01-02 10:02:07,154	44k	INFO	====> Epoch: 2383, cost 22.78 s
2024-01-02 10:02:29,845	44k	INFO	====> Epoch: 2384, cost 22.69 s
2024-01-02 10:02:44,795	44k	INFO	Train Epoch: 2385 [62%]
2024-01-02 10:02:44,798	44k	INFO	Losses: [2.5022597312927246, 2.307645559310913, 6.658817291259766, 15.573690414428711, 0.45826664566993713], step: 62000, lr: 7.42287513361796e-05, reference_loss: 27.50067901611328
2024-01-02 10:02:53,010	44k	INFO	====> Epoch: 2385, cost 23.16 s
2024-01-02 10:03:15,826	44k	INFO	====> Epoch: 2386, cost 22.82 s
2024-01-02 10:03:38,684	44k	INFO	====> Epoch: 2387, cost 22.86 s
2024-01-02 10:04:01,503	44k	INFO	====> Epoch: 2388, cost 22.82 s
2024-01-02 10:04:24,442	44k	INFO	====> Epoch: 2389, cost 22.94 s
2024-01-02 10:04:47,182	44k	INFO	====> Epoch: 2390, cost 22.74 s
2024-01-02 10:05:10,087	44k	INFO	====> Epoch: 2391, cost 22.90 s
2024-01-02 10:05:33,001	44k	INFO	====> Epoch: 2392, cost 22.91 s
2024-01-02 10:05:41,055	44k	INFO	Train Epoch: 2393 [31%]
2024-01-02 10:05:41,058	44k	INFO	Losses: [2.3999745845794678, 2.3955302238464355, 6.375716686248779, 14.000065803527832, 0.5522847175598145], step: 62200, lr: 7.41545550518046e-05, reference_loss: 25.72357177734375
2024-01-02 10:05:56,326	44k	INFO	====> Epoch: 2393, cost 23.33 s
2024-01-02 10:06:19,107	44k	INFO	====> Epoch: 2394, cost 22.78 s
2024-01-02 10:06:41,870	44k	INFO	====> Epoch: 2395, cost 22.76 s
2024-01-02 10:07:04,617	44k	INFO	====> Epoch: 2396, cost 22.75 s
2024-01-02 10:07:27,346	44k	INFO	====> Epoch: 2397, cost 22.73 s
2024-01-02 10:07:50,226	44k	INFO	====> Epoch: 2398, cost 22.88 s
2024-01-02 10:08:12,972	44k	INFO	====> Epoch: 2399, cost 22.75 s
2024-01-02 10:08:35,739	44k	INFO	====> Epoch: 2400, cost 22.77 s
2024-01-02 10:08:36,631	44k	INFO	Train Epoch: 2401 [0%]
2024-01-02 10:08:36,634	44k	INFO	Losses: [2.5721588134765625, 2.0971689224243164, 6.687295436859131, 16.645200729370117, 0.2623777985572815], step: 62400, lr: 7.408043293126123e-05, reference_loss: 28.264202117919922
2024-01-02 10:08:42,081	44k	INFO	Saving model and optimizer state at iteration 2401 to ./logs/44k/G_62400.pth
2024-01-02 10:08:42,943	44k	INFO	Saving model and optimizer state at iteration 2401 to ./logs/44k/D_62400.pth
2024-01-02 10:08:43,447	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_60000.pth
2024-01-02 10:08:43,486	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_60000.pth
2024-01-02 10:09:05,348	44k	INFO	====> Epoch: 2401, cost 29.61 s
2024-01-02 10:09:28,328	44k	INFO	====> Epoch: 2402, cost 22.98 s
2024-01-02 10:09:51,271	44k	INFO	====> Epoch: 2403, cost 22.94 s
2024-01-02 10:10:14,158	44k	INFO	====> Epoch: 2404, cost 22.89 s
2024-01-02 10:10:37,038	44k	INFO	====> Epoch: 2405, cost 22.88 s
2024-01-02 10:11:00,145	44k	INFO	====> Epoch: 2406, cost 23.11 s
2024-01-02 10:11:23,088	44k	INFO	====> Epoch: 2407, cost 22.94 s
2024-01-02 10:11:40,019	44k	INFO	Train Epoch: 2408 [69%]
2024-01-02 10:11:40,021	44k	INFO	Losses: [2.223048448562622, 2.7729334831237793, 8.584178924560547, 17.781810760498047, 0.6883856654167175], step: 62600, lr: 7.401563685502496e-05, reference_loss: 32.050357818603516
2024-01-02 10:11:46,417	44k	INFO	====> Epoch: 2408, cost 23.33 s
2024-01-02 10:12:09,360	44k	INFO	====> Epoch: 2409, cost 22.94 s
2024-01-02 10:12:32,290	44k	INFO	====> Epoch: 2410, cost 22.93 s
2024-01-02 10:12:55,185	44k	INFO	====> Epoch: 2411, cost 22.89 s
2024-01-02 10:13:18,071	44k	INFO	====> Epoch: 2412, cost 22.89 s
2024-01-02 10:13:40,823	44k	INFO	====> Epoch: 2413, cost 22.75 s
2024-01-02 10:14:03,653	44k	INFO	====> Epoch: 2414, cost 22.83 s
2024-01-02 10:14:26,338	44k	INFO	====> Epoch: 2415, cost 22.69 s
2024-01-02 10:14:36,073	44k	INFO	Train Epoch: 2416 [38%]
2024-01-02 10:14:36,075	44k	INFO	Losses: [2.495675802230835, 2.0200753211975098, 7.332531452178955, 16.74445915222168, 0.3196517825126648], step: 62800, lr: 7.394165359191684e-05, reference_loss: 28.91239356994629
2024-01-02 10:14:49,549	44k	INFO	====> Epoch: 2416, cost 23.21 s
2024-01-02 10:15:12,242	44k	INFO	====> Epoch: 2417, cost 22.69 s
2024-01-02 10:15:34,964	44k	INFO	====> Epoch: 2418, cost 22.72 s
2024-01-02 10:15:57,624	44k	INFO	====> Epoch: 2419, cost 22.66 s
2024-01-02 10:16:20,484	44k	INFO	====> Epoch: 2420, cost 22.86 s
2024-01-02 10:16:43,388	44k	INFO	====> Epoch: 2421, cost 22.90 s
2024-01-02 10:17:06,245	44k	INFO	====> Epoch: 2422, cost 22.86 s
2024-01-02 10:17:29,001	44k	INFO	====> Epoch: 2423, cost 22.76 s
2024-01-02 10:17:31,690	44k	INFO	Train Epoch: 2424 [8%]
2024-01-02 10:17:31,693	44k	INFO	Losses: [2.416799545288086, 2.4259543418884277, 7.1816253662109375, 16.900043487548828, 0.485521525144577], step: 63000, lr: 7.386774427971223e-05, reference_loss: 29.409944534301758
2024-01-02 10:17:52,507	44k	INFO	====> Epoch: 2424, cost 23.51 s
2024-01-02 10:18:15,506	44k	INFO	====> Epoch: 2425, cost 23.00 s
2024-01-02 10:18:38,378	44k	INFO	====> Epoch: 2426, cost 22.87 s
2024-01-02 10:19:01,155	44k	INFO	====> Epoch: 2427, cost 22.78 s
2024-01-02 10:19:23,917	44k	INFO	====> Epoch: 2428, cost 22.76 s
2024-01-02 10:19:46,606	44k	INFO	====> Epoch: 2429, cost 22.69 s
2024-01-02 10:20:09,415	44k	INFO	====> Epoch: 2430, cost 22.81 s
2024-01-02 10:20:28,128	44k	INFO	Train Epoch: 2431 [77%]
2024-01-02 10:20:28,131	44k	INFO	Losses: [2.230286121368408, 2.496114730834961, 8.097772598266602, 17.329315185546875, 0.8301292657852173], step: 63200, lr: 7.380313423627215e-05, reference_loss: 30.983617782592773
2024-01-02 10:20:33,619	44k	INFO	Saving model and optimizer state at iteration 2431 to ./logs/44k/G_63200.pth
2024-01-02 10:20:34,493	44k	INFO	Saving model and optimizer state at iteration 2431 to ./logs/44k/D_63200.pth
2024-01-02 10:20:34,988	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_60800.pth
2024-01-02 10:20:35,027	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_60800.pth
2024-01-02 10:20:39,219	44k	INFO	====> Epoch: 2431, cost 29.80 s
2024-01-02 10:21:02,308	44k	INFO	====> Epoch: 2432, cost 23.09 s
2024-01-02 10:21:25,110	44k	INFO	====> Epoch: 2433, cost 22.80 s
2024-01-02 10:21:47,851	44k	INFO	====> Epoch: 2434, cost 22.74 s
2024-01-02 10:22:10,637	44k	INFO	====> Epoch: 2435, cost 22.79 s
2024-01-02 10:22:33,374	44k	INFO	====> Epoch: 2436, cost 22.74 s
2024-01-02 10:22:56,191	44k	INFO	====> Epoch: 2437, cost 22.82 s
2024-01-02 10:23:18,970	44k	INFO	====> Epoch: 2438, cost 22.78 s
2024-01-02 10:23:30,340	44k	INFO	Train Epoch: 2439 [46%]
2024-01-02 10:23:30,343	44k	INFO	Losses: [2.2982301712036133, 2.459939479827881, 8.43613052368164, 18.168378829956055, 0.3394116461277008], step: 63400, lr: 7.372936338283611e-05, reference_loss: 31.702089309692383
2024-01-02 10:23:42,047	44k	INFO	====> Epoch: 2439, cost 23.08 s
2024-01-02 10:24:04,688	44k	INFO	====> Epoch: 2440, cost 22.64 s
2024-01-02 10:24:27,450	44k	INFO	====> Epoch: 2441, cost 22.76 s
2024-01-02 10:24:50,216	44k	INFO	====> Epoch: 2442, cost 22.77 s
2024-01-02 10:25:13,034	44k	INFO	====> Epoch: 2443, cost 22.82 s
2024-01-02 10:25:35,970	44k	INFO	====> Epoch: 2444, cost 22.94 s
2024-01-02 10:25:58,705	44k	INFO	====> Epoch: 2445, cost 22.74 s
2024-01-02 10:26:21,410	44k	INFO	====> Epoch: 2446, cost 22.70 s
2024-01-02 10:26:25,841	44k	INFO	Train Epoch: 2447 [15%]
2024-01-02 10:26:25,844	44k	INFO	Losses: [2.3232405185699463, 2.451355218887329, 8.207399368286133, 17.127477645874023, 0.36526957154273987], step: 63600, lr: 7.365566626798684e-05, reference_loss: 30.474740982055664
2024-01-02 10:26:44,547	44k	INFO	====> Epoch: 2447, cost 23.14 s
2024-01-02 10:27:07,403	44k	INFO	====> Epoch: 2448, cost 22.86 s
2024-01-02 10:27:30,548	44k	INFO	====> Epoch: 2449, cost 23.14 s
2024-01-02 10:27:53,724	44k	INFO	====> Epoch: 2450, cost 23.18 s
2024-01-02 10:28:16,840	44k	INFO	====> Epoch: 2451, cost 23.12 s
2024-01-02 10:28:39,986	44k	INFO	====> Epoch: 2452, cost 23.15 s
2024-01-02 10:29:03,111	44k	INFO	====> Epoch: 2453, cost 23.13 s
2024-01-02 10:29:23,896	44k	INFO	Train Epoch: 2454 [85%]
2024-01-02 10:29:23,898	44k	INFO	Losses: [2.4039077758789062, 2.581390857696533, 7.0399489402771, 15.31023120880127, 0.5660356283187866], step: 63800, lr: 7.35912417232334e-05, reference_loss: 27.90151596069336
2024-01-02 10:29:26,914	44k	INFO	====> Epoch: 2454, cost 23.80 s
2024-01-02 10:29:49,873	44k	INFO	====> Epoch: 2455, cost 22.96 s
2024-01-02 10:30:12,800	44k	INFO	====> Epoch: 2456, cost 22.93 s
2024-01-02 10:30:35,816	44k	INFO	====> Epoch: 2457, cost 23.02 s
2024-01-02 10:30:58,832	44k	INFO	====> Epoch: 2458, cost 23.02 s
2024-01-02 10:31:21,979	44k	INFO	====> Epoch: 2459, cost 23.15 s
2024-01-02 10:31:45,108	44k	INFO	====> Epoch: 2460, cost 23.13 s
2024-01-02 10:32:08,199	44k	INFO	====> Epoch: 2461, cost 23.09 s
2024-01-02 10:32:21,635	44k	INFO	Train Epoch: 2462 [54%]
2024-01-02 10:32:21,637	44k	INFO	Losses: [2.5921099185943604, 2.1751036643981934, 7.221231460571289, 15.891879081726074, 0.25905415415763855], step: 64000, lr: 7.351768266963059e-05, reference_loss: 28.139379501342773
2024-01-02 10:32:28,110	44k	INFO	Saving model and optimizer state at iteration 2462 to ./logs/44k/G_64000.pth
2024-01-02 10:32:29,004	44k	INFO	Saving model and optimizer state at iteration 2462 to ./logs/44k/D_64000.pth
2024-01-02 10:32:29,531	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_61600.pth
2024-01-02 10:32:29,571	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_61600.pth
2024-01-02 10:32:39,163	44k	INFO	====> Epoch: 2462, cost 30.96 s
2024-01-02 10:33:02,356	44k	INFO	====> Epoch: 2463, cost 23.19 s
2024-01-02 10:33:25,618	44k	INFO	====> Epoch: 2464, cost 23.26 s
2024-01-02 10:33:48,808	44k	INFO	====> Epoch: 2465, cost 23.19 s
2024-01-02 10:34:11,978	44k	INFO	====> Epoch: 2466, cost 23.17 s
2024-01-02 10:34:35,071	44k	INFO	====> Epoch: 2467, cost 23.09 s
2024-01-02 10:34:58,208	44k	INFO	====> Epoch: 2468, cost 23.14 s
2024-01-02 10:35:21,235	44k	INFO	====> Epoch: 2469, cost 23.03 s
2024-01-02 10:35:27,465	44k	INFO	Train Epoch: 2470 [23%]
2024-01-02 10:35:27,468	44k	INFO	Losses: [2.5697901248931885, 2.104656219482422, 5.65993595123291, 15.041606903076172, 0.4246177673339844], step: 64200, lr: 7.344419714290738e-05, reference_loss: 25.80060577392578
2024-01-02 10:35:44,513	44k	INFO	====> Epoch: 2470, cost 23.28 s
2024-01-02 10:36:07,316	44k	INFO	====> Epoch: 2471, cost 22.80 s
2024-01-02 10:36:30,116	44k	INFO	====> Epoch: 2472, cost 22.80 s
2024-01-02 10:36:52,690	44k	INFO	====> Epoch: 2473, cost 22.57 s
2024-01-02 10:37:15,339	44k	INFO	====> Epoch: 2474, cost 22.65 s
2024-01-02 10:37:38,110	44k	INFO	====> Epoch: 2475, cost 22.77 s
2024-01-02 10:38:00,953	44k	INFO	====> Epoch: 2476, cost 22.84 s
2024-01-02 10:38:23,086	44k	INFO	Train Epoch: 2477 [92%]
2024-01-02 10:38:23,089	44k	INFO	Losses: [2.3495306968688965, 2.518888473510742, 7.946533679962158, 18.95905113220215, 0.6216686367988586], step: 64400, lr: 7.337995756426454e-05, reference_loss: 32.39567184448242
2024-01-02 10:38:24,262	44k	INFO	====> Epoch: 2477, cost 23.31 s
2024-01-02 10:38:47,020	44k	INFO	====> Epoch: 2478, cost 22.76 s
2024-01-02 10:39:09,921	44k	INFO	====> Epoch: 2479, cost 22.90 s
2024-01-02 10:39:32,733	44k	INFO	====> Epoch: 2480, cost 22.81 s
2024-01-02 10:39:55,569	44k	INFO	====> Epoch: 2481, cost 22.84 s
2024-01-02 10:40:18,263	44k	INFO	====> Epoch: 2482, cost 22.69 s
2024-01-02 10:40:41,125	44k	INFO	====> Epoch: 2483, cost 22.86 s
2024-01-02 10:41:03,767	44k	INFO	====> Epoch: 2484, cost 22.64 s
2024-01-02 10:41:18,713	44k	INFO	Train Epoch: 2485 [62%]
2024-01-02 10:41:18,716	44k	INFO	Losses: [2.187451124191284, 2.547790050506592, 7.22214412689209, 16.555644989013672, 0.2925868630409241], step: 64600, lr: 7.3306609702407e-05, reference_loss: 28.805618286132812
2024-01-02 10:41:26,835	44k	INFO	====> Epoch: 2485, cost 23.07 s
2024-01-02 10:41:49,587	44k	INFO	====> Epoch: 2486, cost 22.75 s
2024-01-02 10:42:12,334	44k	INFO	====> Epoch: 2487, cost 22.75 s
2024-01-02 10:42:35,207	44k	INFO	====> Epoch: 2488, cost 22.87 s
2024-01-02 10:42:57,835	44k	INFO	====> Epoch: 2489, cost 22.63 s
2024-01-02 10:43:20,520	44k	INFO	====> Epoch: 2490, cost 22.69 s
2024-01-02 10:43:43,090	44k	INFO	====> Epoch: 2491, cost 22.57 s
2024-01-02 10:44:05,771	44k	INFO	====> Epoch: 2492, cost 22.68 s
2024-01-02 10:44:13,740	44k	INFO	Train Epoch: 2493 [31%]
2024-01-02 10:44:13,743	44k	INFO	Losses: [2.5020346641540527, 2.3887922763824463, 6.177003383636475, 14.744715690612793, 0.4997510612010956], step: 64800, lr: 7.323333515632967e-05, reference_loss: 26.31229591369629
2024-01-02 10:44:19,019	44k	INFO	Saving model and optimizer state at iteration 2493 to ./logs/44k/G_64800.pth
2024-01-02 10:44:19,886	44k	INFO	Saving model and optimizer state at iteration 2493 to ./logs/44k/D_64800.pth
2024-01-02 10:44:20,374	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_62400.pth
2024-01-02 10:44:20,413	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_62400.pth
2024-01-02 10:44:35,216	44k	INFO	====> Epoch: 2493, cost 29.44 s
2024-01-02 10:44:58,090	44k	INFO	====> Epoch: 2494, cost 22.87 s
2024-01-02 10:45:20,966	44k	INFO	====> Epoch: 2495, cost 22.88 s
2024-01-02 10:45:43,921	44k	INFO	====> Epoch: 2496, cost 22.95 s
2024-01-02 10:46:06,754	44k	INFO	====> Epoch: 2497, cost 22.83 s
2024-01-02 10:46:29,567	44k	INFO	====> Epoch: 2498, cost 22.81 s
2024-01-02 10:46:52,410	44k	INFO	====> Epoch: 2499, cost 22.84 s
2024-01-02 10:47:15,095	44k	INFO	====> Epoch: 2500, cost 22.68 s
2024-01-02 10:47:15,981	44k	INFO	Train Epoch: 2501 [0%]
2024-01-02 10:47:15,984	44k	INFO	Losses: [2.3815486431121826, 2.4361159801483154, 7.4697699546813965, 16.72479820251465, 0.3239542245864868], step: 65000, lr: 7.316013385274879e-05, reference_loss: 29.3361873626709
2024-01-02 10:47:38,232	44k	INFO	====> Epoch: 2501, cost 23.14 s
2024-01-02 10:48:00,963	44k	INFO	====> Epoch: 2502, cost 22.73 s
2024-01-02 10:48:23,578	44k	INFO	====> Epoch: 2503, cost 22.62 s
2024-01-02 10:48:46,247	44k	INFO	====> Epoch: 2504, cost 22.67 s
2024-01-02 10:49:08,990	44k	INFO	====> Epoch: 2505, cost 22.74 s
2024-01-02 10:49:31,815	44k	INFO	====> Epoch: 2506, cost 22.83 s
2024-01-02 10:49:54,744	44k	INFO	====> Epoch: 2507, cost 22.93 s
2024-01-02 10:50:11,567	44k	INFO	Train Epoch: 2508 [69%]
2024-01-02 10:50:11,570	44k	INFO	Losses: [2.4452855587005615, 2.4483232498168945, 7.20951509475708, 16.726900100708008, 0.42569097876548767], step: 65200, lr: 7.309614273629596e-05, reference_loss: 29.25571632385254
2024-01-02 10:50:17,983	44k	INFO	====> Epoch: 2508, cost 23.24 s
2024-01-02 10:50:40,670	44k	INFO	====> Epoch: 2509, cost 22.69 s
2024-01-02 10:51:03,300	44k	INFO	====> Epoch: 2510, cost 22.63 s
2024-01-02 10:51:25,969	44k	INFO	====> Epoch: 2511, cost 22.67 s
2024-01-02 10:51:48,615	44k	INFO	====> Epoch: 2512, cost 22.65 s
2024-01-02 10:52:11,293	44k	INFO	====> Epoch: 2513, cost 22.68 s
2024-01-02 10:52:34,141	44k	INFO	====> Epoch: 2514, cost 22.85 s
2024-01-02 10:52:56,986	44k	INFO	====> Epoch: 2515, cost 22.85 s
2024-01-02 10:53:06,787	44k	INFO	Train Epoch: 2516 [38%]
2024-01-02 10:53:06,790	44k	INFO	Losses: [2.2042832374572754, 2.492506504058838, 8.311543464660645, 16.83901023864746, 0.35237064957618713], step: 65400, lr: 7.302307856512844e-05, reference_loss: 30.19971466064453
2024-01-02 10:53:20,321	44k	INFO	====> Epoch: 2516, cost 23.33 s
2024-01-02 10:53:43,166	44k	INFO	====> Epoch: 2517, cost 22.85 s
2024-01-02 10:54:06,035	44k	INFO	====> Epoch: 2518, cost 22.87 s
2024-01-02 10:54:28,788	44k	INFO	====> Epoch: 2519, cost 22.75 s
2024-01-02 10:54:51,429	44k	INFO	====> Epoch: 2520, cost 22.64 s
2024-01-02 10:55:14,195	44k	INFO	====> Epoch: 2521, cost 22.77 s
2024-01-02 10:55:36,877	44k	INFO	====> Epoch: 2522, cost 22.68 s
2024-01-02 10:55:59,705	44k	INFO	====> Epoch: 2523, cost 22.83 s
2024-01-02 10:56:02,382	44k	INFO	Train Epoch: 2524 [8%]
2024-01-02 10:56:02,384	44k	INFO	Losses: [2.1796913146972656, 2.533933162689209, 7.789185523986816, 19.102651596069336, 0.287852942943573], step: 65600, lr: 7.29500874261745e-05, reference_loss: 31.893314361572266
2024-01-02 10:56:07,694	44k	INFO	Saving model and optimizer state at iteration 2524 to ./logs/44k/G_65600.pth
2024-01-02 10:56:08,728	44k	INFO	Saving model and optimizer state at iteration 2524 to ./logs/44k/D_65600.pth
2024-01-02 10:56:09,218	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_63200.pth
2024-01-02 10:56:09,257	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_63200.pth
2024-01-02 10:56:29,378	44k	INFO	====> Epoch: 2524, cost 29.67 s
2024-01-02 10:56:52,258	44k	INFO	====> Epoch: 2525, cost 22.88 s
2024-01-02 10:57:15,106	44k	INFO	====> Epoch: 2526, cost 22.85 s
2024-01-02 10:57:37,923	44k	INFO	====> Epoch: 2527, cost 22.82 s
2024-01-02 10:58:00,713	44k	INFO	====> Epoch: 2528, cost 22.79 s
2024-01-02 10:58:23,535	44k	INFO	====> Epoch: 2529, cost 22.82 s
2024-01-02 10:58:46,351	44k	INFO	====> Epoch: 2530, cost 22.82 s
2024-01-02 10:59:04,976	44k	INFO	Train Epoch: 2531 [77%]
2024-01-02 10:59:04,979	44k	INFO	Losses: [2.2729828357696533, 2.4058356285095215, 6.994659900665283, 16.03859519958496, 0.5246687531471252], step: 65800, lr: 7.288628003143781e-05, reference_loss: 28.236743927001953
2024-01-02 10:59:09,557	44k	INFO	====> Epoch: 2531, cost 23.21 s
2024-01-02 10:59:32,333	44k	INFO	====> Epoch: 2532, cost 22.78 s
2024-01-02 10:59:54,995	44k	INFO	====> Epoch: 2533, cost 22.66 s
2024-01-02 11:00:17,650	44k	INFO	====> Epoch: 2534, cost 22.66 s
2024-01-02 11:00:40,436	44k	INFO	====> Epoch: 2535, cost 22.79 s
2024-01-02 11:01:03,288	44k	INFO	====> Epoch: 2536, cost 22.85 s
2024-01-02 11:01:25,979	44k	INFO	====> Epoch: 2537, cost 22.69 s
2024-01-02 11:01:48,707	44k	INFO	====> Epoch: 2538, cost 22.73 s
2024-01-02 11:02:00,211	44k	INFO	Train Epoch: 2539 [46%]
2024-01-02 11:02:00,215	44k	INFO	Losses: [2.45147442817688, 2.2825679779052734, 6.530593395233154, 15.97535514831543, 0.3076464831829071], step: 66000, lr: 7.281342563118317e-05, reference_loss: 27.547636032104492
2024-01-02 11:02:11,925	44k	INFO	====> Epoch: 2539, cost 23.22 s
2024-01-02 11:02:34,652	44k	INFO	====> Epoch: 2540, cost 22.73 s
2024-01-02 11:02:57,321	44k	INFO	====> Epoch: 2541, cost 22.67 s
2024-01-02 11:03:20,127	44k	INFO	====> Epoch: 2542, cost 22.81 s
2024-01-02 11:03:42,718	44k	INFO	====> Epoch: 2543, cost 22.59 s
2024-01-02 11:04:05,457	44k	INFO	====> Epoch: 2544, cost 22.74 s
2024-01-02 11:04:28,271	44k	INFO	====> Epoch: 2545, cost 22.81 s
2024-01-02 11:04:51,028	44k	INFO	====> Epoch: 2546, cost 22.76 s
2024-01-02 11:04:55,490	44k	INFO	Train Epoch: 2547 [15%]
2024-01-02 11:04:55,492	44k	INFO	Losses: [2.349323034286499, 2.3716630935668945, 6.764401435852051, 15.649049758911133, 0.4020790159702301], step: 66200, lr: 7.274064405346296e-05, reference_loss: 27.536516189575195
2024-01-02 11:05:14,272	44k	INFO	====> Epoch: 2547, cost 23.24 s
2024-01-02 11:05:37,149	44k	INFO	====> Epoch: 2548, cost 22.88 s
2024-01-02 11:06:00,052	44k	INFO	====> Epoch: 2549, cost 22.90 s
2024-01-02 11:06:22,950	44k	INFO	====> Epoch: 2550, cost 22.90 s
2024-01-02 11:06:45,808	44k	INFO	====> Epoch: 2551, cost 22.86 s
2024-01-02 11:07:08,779	44k	INFO	====> Epoch: 2552, cost 22.97 s
2024-01-02 11:07:31,475	44k	INFO	====> Epoch: 2553, cost 22.70 s
2024-01-02 11:07:51,732	44k	INFO	Train Epoch: 2554 [85%]
2024-01-02 11:07:51,735	44k	INFO	Losses: [2.4343066215515137, 2.2443313598632812, 6.746060848236084, 15.988492012023926, 0.5136208534240723], step: 66400, lr: 7.26770198529681e-05, reference_loss: 27.92681121826172
2024-01-02 11:07:57,026	44k	INFO	Saving model and optimizer state at iteration 2554 to ./logs/44k/G_66400.pth
2024-01-02 11:07:57,907	44k	INFO	Saving model and optimizer state at iteration 2554 to ./logs/44k/D_66400.pth
2024-01-02 11:07:58,399	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_64000.pth
2024-01-02 11:07:58,438	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_64000.pth
2024-01-02 11:08:00,916	44k	INFO	====> Epoch: 2554, cost 29.44 s
2024-01-02 11:08:23,575	44k	INFO	====> Epoch: 2555, cost 22.66 s
2024-01-02 11:08:46,410	44k	INFO	====> Epoch: 2556, cost 22.84 s
2024-01-02 11:09:09,240	44k	INFO	====> Epoch: 2557, cost 22.83 s
2024-01-02 11:09:32,033	44k	INFO	====> Epoch: 2558, cost 22.79 s
2024-01-02 11:09:54,826	44k	INFO	====> Epoch: 2559, cost 22.79 s
2024-01-02 11:10:17,478	44k	INFO	====> Epoch: 2560, cost 22.65 s
2024-01-02 11:10:40,243	44k	INFO	====> Epoch: 2561, cost 22.77 s
2024-01-02 11:10:53,521	44k	INFO	Train Epoch: 2562 [54%]
2024-01-02 11:10:53,524	44k	INFO	Losses: [2.364614963531494, 2.4836068153381348, 7.232832431793213, 16.51181411743164, 0.6849860548973083], step: 66600, lr: 7.260437462136348e-05, reference_loss: 29.277854919433594
2024-01-02 11:11:03,515	44k	INFO	====> Epoch: 2562, cost 23.27 s
2024-01-02 11:11:26,303	44k	INFO	====> Epoch: 2563, cost 22.79 s
2024-01-02 11:11:49,094	44k	INFO	====> Epoch: 2564, cost 22.79 s
2024-01-02 11:12:11,828	44k	INFO	====> Epoch: 2565, cost 22.73 s
2024-01-02 11:12:34,489	44k	INFO	====> Epoch: 2566, cost 22.66 s
2024-01-02 11:12:57,138	44k	INFO	====> Epoch: 2567, cost 22.65 s
2024-01-02 11:13:19,788	44k	INFO	====> Epoch: 2568, cost 22.65 s
2024-01-02 11:13:42,410	44k	INFO	====> Epoch: 2569, cost 22.62 s
2024-01-02 11:13:48,714	44k	INFO	Train Epoch: 2570 [23%]
2024-01-02 11:13:48,717	44k	INFO	Losses: [2.5105345249176025, 2.4373908042907715, 6.590206623077393, 14.834577560424805, 0.3523821532726288], step: 66800, lr: 7.253180200321613e-05, reference_loss: 26.7250919342041
2024-01-02 11:14:05,652	44k	INFO	====> Epoch: 2570, cost 23.24 s
2024-01-02 11:14:28,432	44k	INFO	====> Epoch: 2571, cost 22.78 s
2024-01-02 11:14:51,079	44k	INFO	====> Epoch: 2572, cost 22.65 s
2024-01-02 11:15:13,799	44k	INFO	====> Epoch: 2573, cost 22.72 s
2024-01-02 11:15:36,592	44k	INFO	====> Epoch: 2574, cost 22.79 s
2024-01-02 11:15:59,248	44k	INFO	====> Epoch: 2575, cost 22.66 s
2024-01-02 11:16:21,937	44k	INFO	====> Epoch: 2576, cost 22.69 s
2024-01-02 11:16:43,878	44k	INFO	Train Epoch: 2577 [92%]
2024-01-02 11:16:43,881	44k	INFO	Losses: [2.350404739379883, 2.555440664291382, 6.954496383666992, 16.446298599243164, 0.4421550929546356], step: 67000, lr: 7.246836047100322e-05, reference_loss: 28.748796463012695
2024-01-02 11:16:45,052	44k	INFO	====> Epoch: 2577, cost 23.11 s
2024-01-02 11:17:07,836	44k	INFO	====> Epoch: 2578, cost 22.78 s
2024-01-02 11:17:30,439	44k	INFO	====> Epoch: 2579, cost 22.60 s
2024-01-02 11:17:53,099	44k	INFO	====> Epoch: 2580, cost 22.66 s
2024-01-02 11:18:15,752	44k	INFO	====> Epoch: 2581, cost 22.65 s
2024-01-02 11:18:38,490	44k	INFO	====> Epoch: 2582, cost 22.74 s
2024-01-02 11:19:01,123	44k	INFO	====> Epoch: 2583, cost 22.63 s
2024-01-02 11:19:23,791	44k	INFO	====> Epoch: 2584, cost 22.67 s
2024-01-02 11:19:38,835	44k	INFO	Train Epoch: 2585 [62%]
2024-01-02 11:19:38,838	44k	INFO	Losses: [2.5008599758148193, 2.1208882331848145, 6.345038414001465, 14.78243350982666, 0.43539682030677795], step: 67200, lr: 7.23959238075149e-05, reference_loss: 26.184616088867188
2024-01-02 11:19:44,076	44k	INFO	Saving model and optimizer state at iteration 2585 to ./logs/44k/G_67200.pth
2024-01-02 11:19:45,119	44k	INFO	Saving model and optimizer state at iteration 2585 to ./logs/44k/D_67200.pth
2024-01-02 11:19:45,609	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_64800.pth
2024-01-02 11:19:45,648	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_64800.pth
2024-01-02 11:19:53,363	44k	INFO	====> Epoch: 2585, cost 29.57 s
2024-01-02 11:20:16,202	44k	INFO	====> Epoch: 2586, cost 22.84 s
2024-01-02 11:20:38,940	44k	INFO	====> Epoch: 2587, cost 22.74 s
2024-01-02 11:21:01,597	44k	INFO	====> Epoch: 2588, cost 22.66 s
2024-01-02 11:21:24,243	44k	INFO	====> Epoch: 2589, cost 22.65 s
2024-01-02 11:21:46,968	44k	INFO	====> Epoch: 2590, cost 22.73 s
2024-01-02 11:22:09,784	44k	INFO	====> Epoch: 2591, cost 22.82 s
2024-01-02 11:22:32,606	44k	INFO	====> Epoch: 2592, cost 22.82 s
2024-01-02 11:22:40,621	44k	INFO	Train Epoch: 2593 [31%]
2024-01-02 11:22:40,625	44k	INFO	Losses: [2.424481153488159, 2.408566474914551, 6.774172782897949, 16.66257095336914, 0.44592493772506714], step: 67400, lr: 7.232355954900696e-05, reference_loss: 28.715715408325195
2024-01-02 11:22:55,800	44k	INFO	====> Epoch: 2593, cost 23.19 s
2024-01-02 11:23:18,627	44k	INFO	====> Epoch: 2594, cost 22.83 s
2024-01-02 11:23:41,605	44k	INFO	====> Epoch: 2595, cost 22.98 s
2024-01-02 11:24:04,443	44k	INFO	====> Epoch: 2596, cost 22.84 s
2024-01-02 11:24:27,268	44k	INFO	====> Epoch: 2597, cost 22.83 s
2024-01-02 11:24:50,080	44k	INFO	====> Epoch: 2598, cost 22.81 s
2024-01-02 11:25:12,876	44k	INFO	====> Epoch: 2599, cost 22.80 s
2024-01-02 11:25:35,705	44k	INFO	====> Epoch: 2600, cost 22.83 s
2024-01-02 11:25:36,597	44k	INFO	Train Epoch: 2601 [0%]
2024-01-02 11:25:36,600	44k	INFO	Losses: [2.213498830795288, 2.679593563079834, 8.074498176574707, 16.053503036499023, 0.2994897961616516], step: 67600, lr: 7.225126762310609e-05, reference_loss: 29.32058334350586
2024-01-02 11:25:58,937	44k	INFO	====> Epoch: 2601, cost 23.23 s
2024-01-02 11:26:21,766	44k	INFO	====> Epoch: 2602, cost 22.83 s
2024-01-02 11:26:44,492	44k	INFO	====> Epoch: 2603, cost 22.73 s
2024-01-02 11:27:07,101	44k	INFO	====> Epoch: 2604, cost 22.61 s
2024-01-02 11:27:29,890	44k	INFO	====> Epoch: 2605, cost 22.79 s
2024-01-02 11:27:52,555	44k	INFO	====> Epoch: 2606, cost 22.66 s
2024-01-02 11:28:15,229	44k	INFO	====> Epoch: 2607, cost 22.67 s
2024-01-02 11:28:31,964	44k	INFO	Train Epoch: 2608 [69%]
2024-01-02 11:28:31,967	44k	INFO	Losses: [2.213716506958008, 2.55902099609375, 9.035321235656738, 19.177631378173828, 0.4218292832374573], step: 67800, lr: 7.21880714664446e-05, reference_loss: 33.40752029418945
2024-01-02 11:28:38,283	44k	INFO	====> Epoch: 2608, cost 23.05 s
2024-01-02 11:29:00,957	44k	INFO	====> Epoch: 2609, cost 22.67 s
2024-01-02 11:29:23,599	44k	INFO	====> Epoch: 2610, cost 22.64 s
2024-01-02 11:29:46,169	44k	INFO	====> Epoch: 2611, cost 22.57 s
2024-01-02 11:30:08,847	44k	INFO	====> Epoch: 2612, cost 22.68 s
2024-01-02 11:30:31,518	44k	INFO	====> Epoch: 2613, cost 22.67 s
2024-01-02 11:30:54,318	44k	INFO	====> Epoch: 2614, cost 22.80 s
2024-01-02 11:31:17,083	44k	INFO	====> Epoch: 2615, cost 22.77 s
2024-01-02 11:31:26,894	44k	INFO	Train Epoch: 2616 [38%]
2024-01-02 11:31:26,897	44k	INFO	Losses: [2.2841718196868896, 2.7331736087799072, 6.939103603363037, 15.213859558105469, 0.4923669397830963], step: 68000, lr: 7.211591496936508e-05, reference_loss: 27.662675857543945
2024-01-02 11:31:32,118	44k	INFO	Saving model and optimizer state at iteration 2616 to ./logs/44k/G_68000.pth
2024-01-02 11:31:33,010	44k	INFO	Saving model and optimizer state at iteration 2616 to ./logs/44k/D_68000.pth
2024-01-02 11:31:33,501	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_65600.pth
2024-01-02 11:31:33,540	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_65600.pth
2024-01-02 11:31:46,535	44k	INFO	====> Epoch: 2616, cost 29.45 s
2024-01-02 11:32:09,396	44k	INFO	====> Epoch: 2617, cost 22.86 s
2024-01-02 11:32:32,244	44k	INFO	====> Epoch: 2618, cost 22.85 s
2024-01-02 11:32:55,060	44k	INFO	====> Epoch: 2619, cost 22.82 s
2024-01-02 11:33:17,715	44k	INFO	====> Epoch: 2620, cost 22.65 s
2024-01-02 11:33:40,402	44k	INFO	====> Epoch: 2621, cost 22.69 s
2024-01-02 11:34:03,248	44k	INFO	====> Epoch: 2622, cost 22.85 s
2024-01-02 11:34:25,974	44k	INFO	====> Epoch: 2623, cost 22.73 s
2024-01-02 11:34:28,627	44k	INFO	Train Epoch: 2624 [8%]
2024-01-02 11:34:28,630	44k	INFO	Losses: [2.4451751708984375, 2.5211963653564453, 6.6272759437561035, 15.987916946411133, 0.37254849076271057], step: 68200, lr: 7.204383059722204e-05, reference_loss: 27.954113006591797
2024-01-02 11:34:49,034	44k	INFO	====> Epoch: 2624, cost 23.06 s
2024-01-02 11:35:11,672	44k	INFO	====> Epoch: 2625, cost 22.64 s
2024-01-02 11:35:34,354	44k	INFO	====> Epoch: 2626, cost 22.68 s
2024-01-02 11:35:57,062	44k	INFO	====> Epoch: 2627, cost 22.71 s
2024-01-02 11:36:19,878	44k	INFO	====> Epoch: 2628, cost 22.82 s
2024-01-02 11:36:42,703	44k	INFO	====> Epoch: 2629, cost 22.82 s
2024-01-02 11:37:05,524	44k	INFO	====> Epoch: 2630, cost 22.82 s
2024-01-02 11:37:24,138	44k	INFO	Train Epoch: 2631 [77%]
2024-01-02 11:37:24,141	44k	INFO	Losses: [2.1810009479522705, 2.8230679035186768, 9.082677841186523, 18.721269607543945, 0.4898472726345062], step: 68400, lr: 7.19808158799071e-05, reference_loss: 33.2978630065918
2024-01-02 11:37:28,883	44k	INFO	====> Epoch: 2631, cost 23.36 s
2024-01-02 11:37:51,725	44k	INFO	====> Epoch: 2632, cost 22.84 s
2024-01-02 11:38:14,515	44k	INFO	====> Epoch: 2633, cost 22.79 s
2024-01-02 11:38:37,244	44k	INFO	====> Epoch: 2634, cost 22.73 s
2024-01-02 11:38:59,971	44k	INFO	====> Epoch: 2635, cost 22.73 s
2024-01-02 11:39:22,770	44k	INFO	====> Epoch: 2636, cost 22.80 s
2024-01-02 11:39:45,600	44k	INFO	====> Epoch: 2637, cost 22.83 s
2024-01-02 11:40:08,267	44k	INFO	====> Epoch: 2638, cost 22.67 s
2024-01-02 11:40:19,663	44k	INFO	Train Epoch: 2639 [46%]
2024-01-02 11:40:19,666	44k	INFO	Losses: [2.3503992557525635, 2.4727041721343994, 7.400489807128906, 16.55872344970703, 0.45979076623916626], step: 68600, lr: 7.190886654776244e-05, reference_loss: 29.242107391357422
2024-01-02 11:40:31,300	44k	INFO	====> Epoch: 2639, cost 23.03 s
2024-01-02 11:40:54,115	44k	INFO	====> Epoch: 2640, cost 22.82 s
2024-01-02 11:41:16,780	44k	INFO	====> Epoch: 2641, cost 22.67 s
2024-01-02 11:41:39,616	44k	INFO	====> Epoch: 2642, cost 22.84 s
2024-01-02 11:42:02,296	44k	INFO	====> Epoch: 2643, cost 22.68 s
2024-01-02 11:42:24,979	44k	INFO	====> Epoch: 2644, cost 22.68 s
2024-01-02 11:42:47,776	44k	INFO	====> Epoch: 2645, cost 22.80 s
2024-01-02 11:43:10,537	44k	INFO	====> Epoch: 2646, cost 22.76 s
2024-01-02 11:43:14,987	44k	INFO	Train Epoch: 2647 [15%]
2024-01-02 11:43:14,990	44k	INFO	Losses: [2.2662248611450195, 2.4908628463745117, 8.750978469848633, 17.323041915893555, 0.22687698900699615], step: 68800, lr: 7.183698913347996e-05, reference_loss: 31.057985305786133
2024-01-02 11:43:20,365	44k	INFO	Saving model and optimizer state at iteration 2647 to ./logs/44k/G_68800.pth
2024-01-02 11:43:21,210	44k	INFO	Saving model and optimizer state at iteration 2647 to ./logs/44k/D_68800.pth
2024-01-02 11:43:21,699	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_66400.pth
2024-01-02 11:43:21,738	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_66400.pth
2024-01-02 11:43:40,025	44k	INFO	====> Epoch: 2647, cost 29.49 s
2024-01-02 11:44:02,918	44k	INFO	====> Epoch: 2648, cost 22.89 s
2024-01-02 11:44:25,649	44k	INFO	====> Epoch: 2649, cost 22.73 s
2024-01-02 11:44:48,328	44k	INFO	====> Epoch: 2650, cost 22.68 s
2024-01-02 11:45:10,999	44k	INFO	====> Epoch: 2651, cost 22.67 s
2024-01-02 11:45:33,692	44k	INFO	====> Epoch: 2652, cost 22.69 s
2024-01-02 11:45:56,385	44k	INFO	====> Epoch: 2653, cost 22.69 s
2024-01-02 11:46:16,609	44k	INFO	Train Epoch: 2654 [85%]
2024-01-02 11:46:16,612	44k	INFO	Losses: [2.3805415630340576, 2.4423584938049316, 5.902746200561523, 15.500240325927734, 0.47866320610046387], step: 69000, lr: 7.17741553345901e-05, reference_loss: 26.70454978942871
2024-01-02 11:46:19,472	44k	INFO	====> Epoch: 2654, cost 23.09 s
2024-01-02 11:46:42,281	44k	INFO	====> Epoch: 2655, cost 22.81 s
2024-01-02 11:47:04,945	44k	INFO	====> Epoch: 2656, cost 22.66 s
2024-01-02 11:47:27,668	44k	INFO	====> Epoch: 2657, cost 22.72 s
2024-01-02 11:47:50,547	44k	INFO	====> Epoch: 2658, cost 22.88 s
2024-01-02 11:48:13,405	44k	INFO	====> Epoch: 2659, cost 22.86 s
2024-01-02 11:48:36,306	44k	INFO	====> Epoch: 2660, cost 22.90 s
2024-01-02 11:48:59,103	44k	INFO	====> Epoch: 2661, cost 22.80 s
2024-01-02 11:49:12,305	44k	INFO	Train Epoch: 2662 [54%]
2024-01-02 11:49:12,308	44k	INFO	Losses: [2.345803737640381, 2.4877147674560547, 7.409656047821045, 17.141483306884766, 0.493091344833374], step: 69200, lr: 7.170241257259936e-05, reference_loss: 29.877750396728516
2024-01-02 11:49:22,154	44k	INFO	====> Epoch: 2662, cost 23.05 s
2024-01-02 11:49:44,854	44k	INFO	====> Epoch: 2663, cost 22.70 s
2024-01-02 11:50:07,565	44k	INFO	====> Epoch: 2664, cost 22.71 s
2024-01-02 11:50:30,305	44k	INFO	====> Epoch: 2665, cost 22.74 s
2024-01-02 11:50:53,163	44k	INFO	====> Epoch: 2666, cost 22.86 s
2024-01-02 11:51:16,014	44k	INFO	====> Epoch: 2667, cost 22.85 s
2024-01-02 11:51:38,877	44k	INFO	====> Epoch: 2668, cost 22.86 s
2024-01-02 11:52:01,781	44k	INFO	====> Epoch: 2669, cost 22.90 s
2024-01-02 11:52:07,970	44k	INFO	Train Epoch: 2670 [23%]
2024-01-02 11:52:07,973	44k	INFO	Losses: [2.4098005294799805, 2.4620513916015625, 7.006900787353516, 14.154470443725586, 0.39072754979133606], step: 69400, lr: 7.163074152199102e-05, reference_loss: 26.4239501953125
2024-01-02 11:52:24,851	44k	INFO	====> Epoch: 2670, cost 23.07 s
2024-01-02 11:52:47,725	44k	INFO	====> Epoch: 2671, cost 22.87 s
2024-01-02 11:53:10,543	44k	INFO	====> Epoch: 2672, cost 22.82 s
2024-01-02 11:53:33,378	44k	INFO	====> Epoch: 2673, cost 22.84 s
2024-01-02 11:53:56,081	44k	INFO	====> Epoch: 2674, cost 22.70 s
2024-01-02 11:54:18,799	44k	INFO	====> Epoch: 2675, cost 22.72 s
2024-01-02 11:54:41,489	44k	INFO	====> Epoch: 2676, cost 22.69 s
2024-01-02 11:55:03,547	44k	INFO	Train Epoch: 2677 [92%]
2024-01-02 11:55:03,550	44k	INFO	Losses: [2.158363103866577, 3.1244325637817383, 7.580085754394531, 15.854766845703125, 0.5642189979553223], step: 69600, lr: 7.15680881221003e-05, reference_loss: 29.2818660736084
2024-01-02 11:55:08,943	44k	INFO	Saving model and optimizer state at iteration 2677 to ./logs/44k/G_69600.pth
2024-01-02 11:55:09,815	44k	INFO	Saving model and optimizer state at iteration 2677 to ./logs/44k/D_69600.pth
2024-01-02 11:55:10,310	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_67200.pth
2024-01-02 11:55:10,350	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_67200.pth
2024-01-02 11:55:11,039	44k	INFO	====> Epoch: 2677, cost 29.55 s
2024-01-02 11:55:33,862	44k	INFO	====> Epoch: 2678, cost 22.82 s
2024-01-02 11:55:56,624	44k	INFO	====> Epoch: 2679, cost 22.76 s
2024-01-02 11:56:19,455	44k	INFO	====> Epoch: 2680, cost 22.83 s
2024-01-02 11:56:42,254	44k	INFO	====> Epoch: 2681, cost 22.80 s
2024-01-02 11:57:05,081	44k	INFO	====> Epoch: 2682, cost 22.83 s
2024-01-02 11:57:27,912	44k	INFO	====> Epoch: 2683, cost 22.83 s
2024-01-02 11:57:50,698	44k	INFO	====> Epoch: 2684, cost 22.79 s
2024-01-02 11:58:05,749	44k	INFO	Train Epoch: 2685 [62%]
2024-01-02 11:58:05,752	44k	INFO	Losses: [2.4517664909362793, 2.4134042263031006, 5.994473934173584, 14.101195335388184, 0.6832293272018433], step: 69800, lr: 7.149655133719018e-05, reference_loss: 25.644067764282227
2024-01-02 11:58:14,049	44k	INFO	====> Epoch: 2685, cost 23.35 s
2024-01-02 11:58:36,701	44k	INFO	====> Epoch: 2686, cost 22.65 s
2024-01-02 11:58:59,377	44k	INFO	====> Epoch: 2687, cost 22.68 s
2024-01-02 11:59:22,032	44k	INFO	====> Epoch: 2688, cost 22.66 s
2024-01-02 11:59:44,716	44k	INFO	====> Epoch: 2689, cost 22.68 s
2024-01-02 12:00:07,559	44k	INFO	====> Epoch: 2690, cost 22.84 s
2024-01-02 12:00:30,249	44k	INFO	====> Epoch: 2691, cost 22.69 s
2024-01-02 12:00:53,039	44k	INFO	====> Epoch: 2692, cost 22.79 s
2024-01-02 12:01:01,072	44k	INFO	Train Epoch: 2693 [31%]
2024-01-02 12:01:01,074	44k	INFO	Losses: [2.555619955062866, 2.146136522293091, 6.192617416381836, 14.513153076171875, 0.4061480462551117], step: 70000, lr: 7.142508605777546e-05, reference_loss: 25.813676834106445
2024-01-02 12:01:16,038	44k	INFO	====> Epoch: 2693, cost 23.00 s
2024-01-02 12:01:38,708	44k	INFO	====> Epoch: 2694, cost 22.67 s
2024-01-02 12:02:01,553	44k	INFO	====> Epoch: 2695, cost 22.84 s
2024-01-02 12:02:24,402	44k	INFO	====> Epoch: 2696, cost 22.85 s
2024-01-02 12:02:47,177	44k	INFO	====> Epoch: 2697, cost 22.77 s
2024-01-02 12:03:09,955	44k	INFO	====> Epoch: 2698, cost 22.78 s
2024-01-02 12:03:32,758	44k	INFO	====> Epoch: 2699, cost 22.80 s
2024-01-02 12:03:55,361	44k	INFO	====> Epoch: 2700, cost 22.60 s
2024-01-02 12:03:56,249	44k	INFO	Train Epoch: 2701 [0%]
2024-01-02 12:03:56,252	44k	INFO	Losses: [2.4290990829467773, 2.6007862091064453, 6.653118133544922, 13.778401374816895, 0.4126037657260895], step: 70200, lr: 7.135369221238192e-05, reference_loss: 25.874008178710938
2024-01-02 12:04:18,371	44k	INFO	====> Epoch: 2701, cost 23.01 s
2024-01-02 12:04:41,108	44k	INFO	====> Epoch: 2702, cost 22.74 s
2024-01-02 12:05:03,754	44k	INFO	====> Epoch: 2703, cost 22.65 s
2024-01-02 12:05:26,498	44k	INFO	====> Epoch: 2704, cost 22.74 s
2024-01-02 12:05:49,107	44k	INFO	====> Epoch: 2705, cost 22.61 s
2024-01-02 12:06:11,763	44k	INFO	====> Epoch: 2706, cost 22.66 s
2024-01-02 12:06:34,421	44k	INFO	====> Epoch: 2707, cost 22.66 s
2024-01-02 12:06:51,082	44k	INFO	Train Epoch: 2708 [69%]
2024-01-02 12:06:51,085	44k	INFO	Losses: [2.3337583541870117, 2.6295323371887207, 7.0894365310668945, 15.395851135253906, 0.36990368366241455], step: 70400, lr: 7.129128113974924e-05, reference_loss: 27.8184814453125
2024-01-02 12:06:56,359	44k	INFO	Saving model and optimizer state at iteration 2708 to ./logs/44k/G_70400.pth
2024-01-02 12:06:57,229	44k	INFO	Saving model and optimizer state at iteration 2708 to ./logs/44k/D_70400.pth
2024-01-02 12:06:57,718	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_68000.pth
2024-01-02 12:06:57,757	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_68000.pth
2024-01-02 12:07:03,660	44k	INFO	====> Epoch: 2708, cost 29.24 s
2024-01-02 12:07:26,418	44k	INFO	====> Epoch: 2709, cost 22.76 s
2024-01-02 12:07:49,314	44k	INFO	====> Epoch: 2710, cost 22.90 s
2024-01-02 12:08:12,158	44k	INFO	====> Epoch: 2711, cost 22.84 s
2024-01-02 12:08:35,148	44k	INFO	====> Epoch: 2712, cost 22.99 s
2024-01-02 12:08:57,964	44k	INFO	====> Epoch: 2713, cost 22.82 s
2024-01-02 12:09:20,817	44k	INFO	====> Epoch: 2714, cost 22.85 s
2024-01-02 12:09:43,671	44k	INFO	====> Epoch: 2715, cost 22.85 s
2024-01-02 12:09:53,497	44k	INFO	Train Epoch: 2716 [38%]
2024-01-02 12:09:53,500	44k	INFO	Losses: [2.154303789138794, 2.5228514671325684, 7.8690619468688965, 16.45146369934082, 0.4115130603313446], step: 70600, lr: 7.12200210407487e-05, reference_loss: 29.40919303894043
2024-01-02 12:10:06,903	44k	INFO	====> Epoch: 2716, cost 23.23 s
2024-01-02 12:10:29,675	44k	INFO	====> Epoch: 2717, cost 22.77 s
2024-01-02 12:10:52,340	44k	INFO	====> Epoch: 2718, cost 22.67 s
2024-01-02 12:11:15,055	44k	INFO	====> Epoch: 2719, cost 22.71 s
2024-01-02 12:11:37,690	44k	INFO	====> Epoch: 2720, cost 22.64 s
2024-01-02 12:12:00,315	44k	INFO	====> Epoch: 2721, cost 22.62 s
2024-01-02 12:12:22,983	44k	INFO	====> Epoch: 2722, cost 22.67 s
2024-01-02 12:12:45,932	44k	INFO	====> Epoch: 2723, cost 22.95 s
2024-01-02 12:12:48,592	44k	INFO	Train Epoch: 2724 [8%]
2024-01-02 12:12:48,595	44k	INFO	Losses: [2.4808530807495117, 2.31665301322937, 7.506425857543945, 16.815834045410156, 0.3979249596595764], step: 70800, lr: 7.114883217067864e-05, reference_loss: 29.517690658569336
2024-01-02 12:13:09,082	44k	INFO	====> Epoch: 2724, cost 23.15 s
2024-01-02 12:13:31,761	44k	INFO	====> Epoch: 2725, cost 22.68 s
2024-01-02 12:13:54,451	44k	INFO	====> Epoch: 2726, cost 22.69 s
2024-01-02 12:14:17,129	44k	INFO	====> Epoch: 2727, cost 22.68 s
2024-01-02 12:14:39,816	44k	INFO	====> Epoch: 2728, cost 22.69 s
2024-01-02 12:15:02,500	44k	INFO	====> Epoch: 2729, cost 22.68 s
2024-01-02 12:15:25,172	44k	INFO	====> Epoch: 2730, cost 22.67 s
2024-01-02 12:15:43,835	44k	INFO	Train Epoch: 2731 [77%]
2024-01-02 12:15:43,838	44k	INFO	Losses: [2.214649200439453, 2.6531431674957275, 8.600266456604004, 18.33271026611328, 0.34701675176620483], step: 71000, lr: 7.108660028337677e-05, reference_loss: 32.14778518676758
2024-01-02 12:15:48,603	44k	INFO	====> Epoch: 2731, cost 23.43 s
2024-01-02 12:16:11,450	44k	INFO	====> Epoch: 2732, cost 22.85 s
2024-01-02 12:16:34,241	44k	INFO	====> Epoch: 2733, cost 22.79 s
2024-01-02 12:16:57,110	44k	INFO	====> Epoch: 2734, cost 22.87 s
2024-01-02 12:17:19,959	44k	INFO	====> Epoch: 2735, cost 22.85 s
2024-01-02 12:17:42,825	44k	INFO	====> Epoch: 2736, cost 22.87 s
2024-01-02 12:18:05,550	44k	INFO	====> Epoch: 2737, cost 22.72 s
2024-01-02 12:18:28,378	44k	INFO	====> Epoch: 2738, cost 22.83 s
2024-01-02 12:18:39,880	44k	INFO	Train Epoch: 2739 [46%]
2024-01-02 12:18:39,883	44k	INFO	Losses: [2.453299045562744, 2.331425666809082, 5.5007219314575195, 14.065996170043945, 0.32542529702186584], step: 71200, lr: 7.101554477570713e-05, reference_loss: 24.676868438720703
2024-01-02 12:18:45,182	44k	INFO	Saving model and optimizer state at iteration 2739 to ./logs/44k/G_71200.pth
2024-01-02 12:18:46,230	44k	INFO	Saving model and optimizer state at iteration 2739 to ./logs/44k/D_71200.pth
2024-01-02 12:18:46,721	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_68800.pth
2024-01-02 12:18:46,760	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_68800.pth
2024-01-02 12:18:58,075	44k	INFO	====> Epoch: 2739, cost 29.70 s
2024-01-02 12:19:20,881	44k	INFO	====> Epoch: 2740, cost 22.81 s
2024-01-02 12:19:43,586	44k	INFO	====> Epoch: 2741, cost 22.71 s
2024-01-02 12:20:06,238	44k	INFO	====> Epoch: 2742, cost 22.65 s
2024-01-02 12:20:28,900	44k	INFO	====> Epoch: 2743, cost 22.66 s
2024-01-02 12:20:51,565	44k	INFO	====> Epoch: 2744, cost 22.67 s
2024-01-02 12:21:14,240	44k	INFO	====> Epoch: 2745, cost 22.67 s
2024-01-02 12:21:36,896	44k	INFO	====> Epoch: 2746, cost 22.66 s
2024-01-02 12:21:41,318	44k	INFO	Train Epoch: 2747 [15%]
2024-01-02 12:21:41,322	44k	INFO	Losses: [2.315168619155884, 2.406019926071167, 6.889332294464111, 14.870295524597168, 0.4107721745967865], step: 71400, lr: 7.094456029246614e-05, reference_loss: 26.89158821105957
2024-01-02 12:22:00,048	44k	INFO	====> Epoch: 2747, cost 23.15 s
2024-01-02 12:22:22,952	44k	INFO	====> Epoch: 2748, cost 22.90 s
2024-01-02 12:22:45,721	44k	INFO	====> Epoch: 2749, cost 22.77 s
2024-01-02 12:23:08,392	44k	INFO	====> Epoch: 2750, cost 22.67 s
2024-01-02 12:23:31,066	44k	INFO	====> Epoch: 2751, cost 22.67 s
2024-01-02 12:23:53,748	44k	INFO	====> Epoch: 2752, cost 22.68 s
2024-01-02 12:24:16,536	44k	INFO	====> Epoch: 2753, cost 22.79 s
2024-01-02 12:24:36,762	44k	INFO	Train Epoch: 2754 [85%]
2024-01-02 12:24:36,766	44k	INFO	Losses: [2.3150153160095215, 2.906721591949463, 7.730794906616211, 16.598491668701172, 0.6996894478797913], step: 71600, lr: 7.088250707604492e-05, reference_loss: 30.250713348388672
2024-01-02 12:24:39,703	44k	INFO	====> Epoch: 2754, cost 23.17 s
2024-01-02 12:25:02,465	44k	INFO	====> Epoch: 2755, cost 22.76 s
2024-01-02 12:25:25,265	44k	INFO	====> Epoch: 2756, cost 22.80 s
2024-01-02 12:25:47,926	44k	INFO	====> Epoch: 2757, cost 22.66 s
2024-01-02 12:26:10,768	44k	INFO	====> Epoch: 2758, cost 22.84 s
2024-01-02 12:26:33,486	44k	INFO	====> Epoch: 2759, cost 22.72 s
2024-01-02 12:26:56,158	44k	INFO	====> Epoch: 2760, cost 22.67 s
2024-01-02 12:27:18,920	44k	INFO	====> Epoch: 2761, cost 22.76 s
2024-01-02 12:27:32,220	44k	INFO	Train Epoch: 2762 [54%]
2024-01-02 12:27:32,224	44k	INFO	Losses: [2.4914650917053223, 2.3676846027374268, 6.510916233062744, 16.13161849975586, 0.4859828054904938], step: 71800, lr: 7.081165557231414e-05, reference_loss: 27.987667083740234
2024-01-02 12:27:42,144	44k	INFO	====> Epoch: 2762, cost 23.22 s
2024-01-02 12:28:04,857	44k	INFO	====> Epoch: 2763, cost 22.71 s
2024-01-02 12:28:27,553	44k	INFO	====> Epoch: 2764, cost 22.70 s
2024-01-02 12:28:50,211	44k	INFO	====> Epoch: 2765, cost 22.66 s
2024-01-02 12:29:12,895	44k	INFO	====> Epoch: 2766, cost 22.68 s
2024-01-02 12:29:35,714	44k	INFO	====> Epoch: 2767, cost 22.82 s
2024-01-02 12:29:58,549	44k	INFO	====> Epoch: 2768, cost 22.83 s
2024-01-02 12:30:21,362	44k	INFO	====> Epoch: 2769, cost 22.81 s
2024-01-02 12:30:27,596	44k	INFO	Train Epoch: 2770 [23%]
2024-01-02 12:30:27,599	44k	INFO	Losses: [2.2685372829437256, 2.5306763648986816, 7.156400203704834, 15.509012222290039, 0.46886304020881653], step: 72000, lr: 7.074087488909732e-05, reference_loss: 27.933488845825195
2024-01-02 12:30:32,955	44k	INFO	Saving model and optimizer state at iteration 2770 to ./logs/44k/G_72000.pth
2024-01-02 12:30:33,840	44k	INFO	Saving model and optimizer state at iteration 2770 to ./logs/44k/D_72000.pth
2024-01-02 12:30:34,334	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_69600.pth
2024-01-02 12:30:34,373	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_69600.pth
2024-01-02 12:30:50,936	44k	INFO	====> Epoch: 2770, cost 29.57 s
2024-01-02 12:31:13,777	44k	INFO	====> Epoch: 2771, cost 22.84 s
2024-01-02 12:31:36,610	44k	INFO	====> Epoch: 2772, cost 22.83 s
2024-01-02 12:31:59,415	44k	INFO	====> Epoch: 2773, cost 22.80 s
2024-01-02 12:32:22,107	44k	INFO	====> Epoch: 2774, cost 22.69 s
2024-01-02 12:32:44,985	44k	INFO	====> Epoch: 2775, cost 22.88 s
2024-01-02 12:33:07,699	44k	INFO	====> Epoch: 2776, cost 22.71 s
2024-01-02 12:33:29,765	44k	INFO	Train Epoch: 2777 [92%]
2024-01-02 12:33:29,768	44k	INFO	Losses: [2.447316884994507, 2.4195024967193604, 6.439188480377197, 15.337014198303223, 0.5115925073623657], step: 72200, lr: 7.067899983058371e-05, reference_loss: 27.154613494873047
2024-01-02 12:33:30,868	44k	INFO	====> Epoch: 2777, cost 23.17 s
2024-01-02 12:33:53,752	44k	INFO	====> Epoch: 2778, cost 22.88 s
2024-01-02 12:34:16,662	44k	INFO	====> Epoch: 2779, cost 22.91 s
2024-01-02 12:34:39,477	44k	INFO	====> Epoch: 2780, cost 22.81 s
2024-01-02 12:35:02,109	44k	INFO	====> Epoch: 2781, cost 22.63 s
2024-01-02 12:35:24,830	44k	INFO	====> Epoch: 2782, cost 22.72 s
2024-01-02 12:35:47,625	44k	INFO	====> Epoch: 2783, cost 22.80 s
2024-01-02 12:36:10,466	44k	INFO	====> Epoch: 2784, cost 22.84 s
2024-01-02 12:36:25,487	44k	INFO	Train Epoch: 2785 [62%]
2024-01-02 12:36:25,490	44k	INFO	Losses: [2.3687915802001953, 2.327147960662842, 7.393834114074707, 15.335453987121582, 0.393507719039917], step: 72400, lr: 7.060835174508622e-05, reference_loss: 27.818735122680664
2024-01-02 12:36:33,810	44k	INFO	====> Epoch: 2785, cost 23.34 s
2024-01-02 12:36:56,684	44k	INFO	====> Epoch: 2786, cost 22.87 s
2024-01-02 12:37:19,485	44k	INFO	====> Epoch: 2787, cost 22.80 s
2024-01-02 12:37:42,226	44k	INFO	====> Epoch: 2788, cost 22.74 s
2024-01-02 12:38:04,939	44k	INFO	====> Epoch: 2789, cost 22.71 s
2024-01-02 12:38:27,659	44k	INFO	====> Epoch: 2790, cost 22.72 s
2024-01-02 12:38:50,368	44k	INFO	====> Epoch: 2791, cost 22.71 s
2024-01-02 12:39:13,049	44k	INFO	====> Epoch: 2792, cost 22.68 s
2024-01-02 12:39:21,064	44k	INFO	Train Epoch: 2793 [31%]
2024-01-02 12:39:21,067	44k	INFO	Losses: [2.565243721008301, 2.3474416732788086, 6.155204772949219, 14.800832748413086, 0.46617674827575684], step: 72600, lr: 7.053777427677343e-05, reference_loss: 26.33489990234375
2024-01-02 12:39:36,268	44k	INFO	====> Epoch: 2793, cost 23.22 s
2024-01-02 12:39:59,095	44k	INFO	====> Epoch: 2794, cost 22.83 s
2024-01-02 12:40:21,792	44k	INFO	====> Epoch: 2795, cost 22.70 s
2024-01-02 12:40:44,488	44k	INFO	====> Epoch: 2796, cost 22.70 s
2024-01-02 12:41:07,307	44k	INFO	====> Epoch: 2797, cost 22.82 s
2024-01-02 12:41:30,146	44k	INFO	====> Epoch: 2798, cost 22.84 s
2024-01-02 12:41:52,961	44k	INFO	====> Epoch: 2799, cost 22.82 s
2024-01-02 12:42:15,853	44k	INFO	====> Epoch: 2800, cost 22.89 s
2024-01-02 12:42:16,749	44k	INFO	Train Epoch: 2801 [0%]
2024-01-02 12:42:16,752	44k	INFO	Losses: [2.345642566680908, 2.3690757751464844, 7.029681205749512, 15.091604232788086, 0.16434407234191895], step: 72800, lr: 7.046726735505902e-05, reference_loss: 27.000349044799805
2024-01-02 12:42:22,114	44k	INFO	Saving model and optimizer state at iteration 2801 to ./logs/44k/G_72800.pth
2024-01-02 12:42:22,998	44k	INFO	Saving model and optimizer state at iteration 2801 to ./logs/44k/D_72800.pth
2024-01-02 12:42:23,486	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_70400.pth
2024-01-02 12:42:23,525	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_70400.pth
2024-01-02 12:42:45,621	44k	INFO	====> Epoch: 2801, cost 29.77 s
2024-01-02 12:43:08,406	44k	INFO	====> Epoch: 2802, cost 22.78 s
2024-01-02 12:43:31,180	44k	INFO	====> Epoch: 2803, cost 22.77 s
2024-01-02 12:43:53,932	44k	INFO	====> Epoch: 2804, cost 22.75 s
2024-01-02 12:44:16,614	44k	INFO	====> Epoch: 2805, cost 22.68 s
2024-01-02 12:44:39,228	44k	INFO	====> Epoch: 2806, cost 22.61 s
2024-01-02 12:45:01,880	44k	INFO	====> Epoch: 2807, cost 22.65 s
2024-01-02 12:45:18,643	44k	INFO	Train Epoch: 2808 [69%]
2024-01-02 12:45:18,647	44k	INFO	Losses: [2.2991209030151367, 2.4835102558135986, 8.572439193725586, 16.819067001342773, 0.5292366743087769], step: 73000, lr: 7.040563161337892e-05, reference_loss: 30.703372955322266
2024-01-02 12:45:24,957	44k	INFO	====> Epoch: 2808, cost 23.08 s
2024-01-02 12:45:47,576	44k	INFO	====> Epoch: 2809, cost 22.62 s
2024-01-02 12:46:10,191	44k	INFO	====> Epoch: 2810, cost 22.61 s
2024-01-02 12:46:32,968	44k	INFO	====> Epoch: 2811, cost 22.78 s
2024-01-02 12:46:55,741	44k	INFO	====> Epoch: 2812, cost 22.77 s
2024-01-02 12:47:18,622	44k	INFO	====> Epoch: 2813, cost 22.88 s
2024-01-02 12:47:41,328	44k	INFO	====> Epoch: 2814, cost 22.71 s
2024-01-02 12:48:04,076	44k	INFO	====> Epoch: 2815, cost 22.75 s
2024-01-02 12:48:13,842	44k	INFO	Train Epoch: 2816 [38%]
2024-01-02 12:48:13,845	44k	INFO	Losses: [2.496706962585449, 2.1979002952575684, 7.888894081115723, 16.606922149658203, 0.30257928371429443], step: 73200, lr: 7.033525677652995e-05, reference_loss: 29.493003845214844
2024-01-02 12:48:27,204	44k	INFO	====> Epoch: 2816, cost 23.13 s
2024-01-02 12:48:50,006	44k	INFO	====> Epoch: 2817, cost 22.80 s
2024-01-02 12:49:12,785	44k	INFO	====> Epoch: 2818, cost 22.78 s
2024-01-02 12:49:35,591	44k	INFO	====> Epoch: 2819, cost 22.81 s
2024-01-02 12:49:58,403	44k	INFO	====> Epoch: 2820, cost 22.81 s
2024-01-02 12:50:21,207	44k	INFO	====> Epoch: 2821, cost 22.80 s
2024-01-02 12:50:43,877	44k	INFO	====> Epoch: 2822, cost 22.67 s
2024-01-02 12:51:06,645	44k	INFO	====> Epoch: 2823, cost 22.77 s
2024-01-02 12:51:09,295	44k	INFO	Train Epoch: 2824 [8%]
2024-01-02 12:51:09,299	44k	INFO	Losses: [2.3617348670959473, 2.4687557220458984, 7.642411231994629, 16.142803192138672, 0.538908839225769], step: 73400, lr: 7.02649522837365e-05, reference_loss: 29.154613494873047
2024-01-02 12:51:29,677	44k	INFO	====> Epoch: 2824, cost 23.03 s
2024-01-02 12:51:52,362	44k	INFO	====> Epoch: 2825, cost 22.69 s
2024-01-02 12:52:15,008	44k	INFO	====> Epoch: 2826, cost 22.65 s
2024-01-02 12:52:37,753	44k	INFO	====> Epoch: 2827, cost 22.74 s
2024-01-02 12:53:00,473	44k	INFO	====> Epoch: 2828, cost 22.72 s
2024-01-02 12:53:23,269	44k	INFO	====> Epoch: 2829, cost 22.80 s
2024-01-02 12:53:45,992	44k	INFO	====> Epoch: 2830, cost 22.72 s
2024-01-02 12:54:04,544	44k	INFO	Train Epoch: 2831 [77%]
2024-01-02 12:54:04,547	44k	INFO	Losses: [2.324861764907837, 2.356011390686035, 8.646589279174805, 16.930782318115234, 0.6792894005775452], step: 73600, lr: 7.020349350137303e-05, reference_loss: 30.937532424926758
2024-01-02 12:54:09,935	44k	INFO	Saving model and optimizer state at iteration 2831 to ./logs/44k/G_73600.pth
2024-01-02 12:54:10,812	44k	INFO	Saving model and optimizer state at iteration 2831 to ./logs/44k/D_73600.pth
2024-01-02 12:54:11,301	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_71200.pth
2024-01-02 12:54:11,340	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_71200.pth
2024-01-02 12:54:15,520	44k	INFO	====> Epoch: 2831, cost 29.53 s
2024-01-02 12:54:38,358	44k	INFO	====> Epoch: 2832, cost 22.84 s
2024-01-02 12:55:01,230	44k	INFO	====> Epoch: 2833, cost 22.87 s
2024-01-02 12:55:24,021	44k	INFO	====> Epoch: 2834, cost 22.79 s
2024-01-02 12:55:46,717	44k	INFO	====> Epoch: 2835, cost 22.70 s
2024-01-02 12:56:09,216	44k	INFO	====> Epoch: 2836, cost 22.50 s
2024-01-02 12:56:31,884	44k	INFO	====> Epoch: 2837, cost 22.67 s
2024-01-02 12:56:54,598	44k	INFO	====> Epoch: 2838, cost 22.71 s
2024-01-02 12:57:06,096	44k	INFO	Train Epoch: 2839 [46%]
2024-01-02 12:57:06,099	44k	INFO	Losses: [2.2467122077941895, 2.468153476715088, 8.85353946685791, 17.629440307617188, 0.33837810158729553], step: 73800, lr: 7.013332071422273e-05, reference_loss: 31.536224365234375
2024-01-02 12:57:17,957	44k	INFO	====> Epoch: 2839, cost 23.36 s
2024-01-02 12:57:40,776	44k	INFO	====> Epoch: 2840, cost 22.82 s
2024-01-02 12:58:03,572	44k	INFO	====> Epoch: 2841, cost 22.80 s
2024-01-02 12:58:26,368	44k	INFO	====> Epoch: 2842, cost 22.80 s
2024-01-02 12:58:49,191	44k	INFO	====> Epoch: 2843, cost 22.82 s
2024-01-02 12:59:12,004	44k	INFO	====> Epoch: 2844, cost 22.81 s
2024-01-02 12:59:34,782	44k	INFO	====> Epoch: 2845, cost 22.78 s
2024-01-02 12:59:57,616	44k	INFO	====> Epoch: 2846, cost 22.83 s
2024-01-02 13:00:02,076	44k	INFO	Train Epoch: 2847 [15%]
2024-01-02 13:00:02,078	44k	INFO	Losses: [2.321831464767456, 2.4787511825561523, 8.563722610473633, 16.85196304321289, 0.323971688747406], step: 74000, lr: 7.006321806916664e-05, reference_loss: 30.540239334106445
2024-01-02 13:00:20,841	44k	INFO	====> Epoch: 2847, cost 23.23 s
2024-01-02 13:00:43,659	44k	INFO	====> Epoch: 2848, cost 22.82 s
2024-01-02 13:01:06,333	44k	INFO	====> Epoch: 2849, cost 22.67 s
2024-01-02 13:01:28,990	44k	INFO	====> Epoch: 2850, cost 22.66 s
2024-01-02 13:01:51,743	44k	INFO	====> Epoch: 2851, cost 22.75 s
2024-01-02 13:02:14,551	44k	INFO	====> Epoch: 2852, cost 22.81 s
2024-01-02 13:02:37,361	44k	INFO	====> Epoch: 2853, cost 22.81 s
2024-01-02 13:02:57,745	44k	INFO	Train Epoch: 2854 [85%]
2024-01-02 13:02:57,748	44k	INFO	Losses: [2.3238792419433594, 2.5483620166778564, 8.083712577819824, 15.385913848876953, 0.5815182328224182], step: 74200, lr: 7.000193573806065e-05, reference_loss: 28.923385620117188
2024-01-02 13:03:00,608	44k	INFO	====> Epoch: 2854, cost 23.25 s
2024-01-02 13:03:23,451	44k	INFO	====> Epoch: 2855, cost 22.84 s
2024-01-02 13:03:46,249	44k	INFO	====> Epoch: 2856, cost 22.80 s
2024-01-02 13:04:09,207	44k	INFO	====> Epoch: 2857, cost 22.96 s
2024-01-02 13:04:31,976	44k	INFO	====> Epoch: 2858, cost 22.77 s
2024-01-02 13:04:54,663	44k	INFO	====> Epoch: 2859, cost 22.69 s
2024-01-02 13:05:17,340	44k	INFO	====> Epoch: 2860, cost 22.68 s
2024-01-02 13:05:40,011	44k	INFO	====> Epoch: 2861, cost 22.67 s
2024-01-02 13:05:53,219	44k	INFO	Train Epoch: 2862 [54%]
2024-01-02 13:05:53,222	44k	INFO	Losses: [2.197873115539551, 2.744838237762451, 8.569345474243164, 16.17354965209961, 0.32835254073143005], step: 74400, lr: 6.993196442051418e-05, reference_loss: 30.013957977294922
2024-01-02 13:05:58,486	44k	INFO	Saving model and optimizer state at iteration 2862 to ./logs/44k/G_74400.pth
2024-01-02 13:05:59,376	44k	INFO	Saving model and optimizer state at iteration 2862 to ./logs/44k/D_74400.pth
2024-01-02 13:05:59,871	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_72000.pth
2024-01-02 13:05:59,910	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_72000.pth
2024-01-02 13:06:09,419	44k	INFO	====> Epoch: 2862, cost 29.41 s
2024-01-02 13:06:32,091	44k	INFO	====> Epoch: 2863, cost 22.67 s
2024-01-02 13:06:54,819	44k	INFO	====> Epoch: 2864, cost 22.73 s
2024-01-02 13:07:17,651	44k	INFO	====> Epoch: 2865, cost 22.83 s
2024-01-02 13:07:40,408	44k	INFO	====> Epoch: 2866, cost 22.76 s
2024-01-02 13:08:03,242	44k	INFO	====> Epoch: 2867, cost 22.83 s
2024-01-02 13:08:25,918	44k	INFO	====> Epoch: 2868, cost 22.68 s
2024-01-02 13:08:48,566	44k	INFO	====> Epoch: 2869, cost 22.65 s
2024-01-02 13:08:54,760	44k	INFO	Train Epoch: 2870 [23%]
2024-01-02 13:08:54,763	44k	INFO	Losses: [2.447240114212036, 2.422532796859741, 6.058957576751709, 14.562907218933105, 0.3668811023235321], step: 74600, lr: 6.986206304368045e-05, reference_loss: 25.858518600463867
2024-01-02 13:09:11,620	44k	INFO	====> Epoch: 2870, cost 23.05 s
2024-01-02 13:09:34,271	44k	INFO	====> Epoch: 2871, cost 22.65 s
2024-01-02 13:09:56,962	44k	INFO	====> Epoch: 2872, cost 22.69 s
2024-01-02 13:10:19,713	44k	INFO	====> Epoch: 2873, cost 22.75 s
2024-01-02 13:10:42,556	44k	INFO	====> Epoch: 2874, cost 22.84 s
2024-01-02 13:11:05,271	44k	INFO	====> Epoch: 2875, cost 22.71 s
2024-01-02 13:11:28,201	44k	INFO	====> Epoch: 2876, cost 22.93 s
2024-01-02 13:11:50,339	44k	INFO	Train Epoch: 2877 [92%]
2024-01-02 13:11:50,342	44k	INFO	Losses: [2.421269655227661, 2.4691410064697266, 7.462527751922607, 18.375, 0.600301206111908], step: 74800, lr: 6.980095665723153e-05, reference_loss: 31.32823944091797
2024-01-02 13:11:51,423	44k	INFO	====> Epoch: 2877, cost 23.22 s
2024-01-02 13:12:14,131	44k	INFO	====> Epoch: 2878, cost 22.71 s
2024-01-02 13:12:36,991	44k	INFO	====> Epoch: 2879, cost 22.86 s
2024-01-02 13:12:59,865	44k	INFO	====> Epoch: 2880, cost 22.87 s
2024-01-02 13:13:22,734	44k	INFO	====> Epoch: 2881, cost 22.87 s
2024-01-02 13:13:45,553	44k	INFO	====> Epoch: 2882, cost 22.82 s
2024-01-02 13:14:08,248	44k	INFO	====> Epoch: 2883, cost 22.69 s
2024-01-02 13:14:30,936	44k	INFO	====> Epoch: 2884, cost 22.69 s
2024-01-02 13:14:45,922	44k	INFO	Train Epoch: 2885 [62%]
2024-01-02 13:14:45,925	44k	INFO	Losses: [2.1979362964630127, 2.7799606323242188, 7.825122356414795, 16.267677307128906, 0.362392395734787], step: 75000, lr: 6.973118623085952e-05, reference_loss: 29.433088302612305
2024-01-02 13:14:54,312	44k	INFO	====> Epoch: 2885, cost 23.38 s
2024-01-02 13:15:17,164	44k	INFO	====> Epoch: 2886, cost 22.85 s
2024-01-02 13:15:40,019	44k	INFO	====> Epoch: 2887, cost 22.86 s
2024-01-02 13:16:02,853	44k	INFO	====> Epoch: 2888, cost 22.83 s
2024-01-02 13:16:25,705	44k	INFO	====> Epoch: 2889, cost 22.85 s
2024-01-02 13:16:48,533	44k	INFO	====> Epoch: 2890, cost 22.83 s
2024-01-02 13:17:11,326	44k	INFO	====> Epoch: 2891, cost 22.79 s
2024-01-02 13:17:34,197	44k	INFO	====> Epoch: 2892, cost 22.87 s
2024-01-02 13:17:42,224	44k	INFO	Train Epoch: 2893 [31%]
2024-01-02 13:17:42,227	44k	INFO	Losses: [2.4974749088287354, 2.2461230754852295, 6.2172346115112305, 15.41530990600586, 0.5263716578483582], step: 75200, lr: 6.966148554439696e-05, reference_loss: 26.90251350402832
2024-01-02 13:17:47,456	44k	INFO	Saving model and optimizer state at iteration 2893 to ./logs/44k/G_75200.pth
2024-01-02 13:17:48,513	44k	INFO	Saving model and optimizer state at iteration 2893 to ./logs/44k/D_75200.pth
2024-01-02 13:17:49,005	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_72800.pth
2024-01-02 13:17:49,044	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_72800.pth
2024-01-02 13:18:03,827	44k	INFO	====> Epoch: 2893, cost 29.63 s
2024-01-02 13:18:26,597	44k	INFO	====> Epoch: 2894, cost 22.77 s
2024-01-02 13:18:49,292	44k	INFO	====> Epoch: 2895, cost 22.70 s
2024-01-02 13:19:12,066	44k	INFO	====> Epoch: 2896, cost 22.77 s
2024-01-02 13:19:34,850	44k	INFO	====> Epoch: 2897, cost 22.78 s
2024-01-02 13:19:57,657	44k	INFO	====> Epoch: 2898, cost 22.81 s
2024-01-02 13:20:20,480	44k	INFO	====> Epoch: 2899, cost 22.82 s
2024-01-02 13:20:43,214	44k	INFO	====> Epoch: 2900, cost 22.73 s
2024-01-02 13:20:44,099	44k	INFO	Train Epoch: 2901 [0%]
2024-01-02 13:20:44,103	44k	INFO	Losses: [2.396695375442505, 2.288154125213623, 7.463076591491699, 16.007177352905273, 0.23399372398853302], step: 75400, lr: 6.959185452813443e-05, reference_loss: 28.389097213745117
2024-01-02 13:21:06,510	44k	INFO	====> Epoch: 2901, cost 23.30 s
2024-01-02 13:21:29,312	44k	INFO	====> Epoch: 2902, cost 22.80 s
2024-01-02 13:21:52,077	44k	INFO	====> Epoch: 2903, cost 22.76 s
2024-01-02 13:22:14,899	44k	INFO	====> Epoch: 2904, cost 22.82 s
2024-01-02 13:22:37,735	44k	INFO	====> Epoch: 2905, cost 22.84 s
2024-01-02 13:23:00,525	44k	INFO	====> Epoch: 2906, cost 22.79 s
2024-01-02 13:23:23,264	44k	INFO	====> Epoch: 2907, cost 22.74 s
2024-01-02 13:23:39,960	44k	INFO	Train Epoch: 2908 [69%]
2024-01-02 13:23:39,963	44k	INFO	Losses: [2.4008307456970215, 2.4000723361968994, 7.525257587432861, 16.444076538085938, 0.37631967663764954], step: 75600, lr: 6.953098448549289e-05, reference_loss: 29.146556854248047
2024-01-02 13:23:46,324	44k	INFO	====> Epoch: 2908, cost 23.06 s
2024-01-02 13:24:09,005	44k	INFO	====> Epoch: 2909, cost 22.68 s
2024-01-02 13:24:31,824	44k	INFO	====> Epoch: 2910, cost 22.82 s
2024-01-02 13:24:54,814	44k	INFO	====> Epoch: 2911, cost 22.99 s
2024-01-02 13:25:17,628	44k	INFO	====> Epoch: 2912, cost 22.81 s
2024-01-02 13:25:40,421	44k	INFO	====> Epoch: 2913, cost 22.79 s
2024-01-02 13:26:03,279	44k	INFO	====> Epoch: 2914, cost 22.86 s
2024-01-02 13:26:26,110	44k	INFO	====> Epoch: 2915, cost 22.83 s
2024-01-02 13:26:35,911	44k	INFO	Train Epoch: 2916 [38%]
2024-01-02 13:26:35,914	44k	INFO	Losses: [2.310805320739746, 2.370393991470337, 8.485712051391602, 16.470624923706055, 0.3305968642234802], step: 75800, lr: 6.946148391320931e-05, reference_loss: 29.96813201904297
2024-01-02 13:26:49,295	44k	INFO	====> Epoch: 2916, cost 23.18 s
2024-01-02 13:27:12,113	44k	INFO	====> Epoch: 2917, cost 22.82 s
2024-01-02 13:27:34,925	44k	INFO	====> Epoch: 2918, cost 22.81 s
2024-01-02 13:27:57,724	44k	INFO	====> Epoch: 2919, cost 22.80 s
2024-01-02 13:28:20,516	44k	INFO	====> Epoch: 2920, cost 22.79 s
2024-01-02 13:28:43,464	44k	INFO	====> Epoch: 2921, cost 22.95 s
2024-01-02 13:29:06,285	44k	INFO	====> Epoch: 2922, cost 22.82 s
2024-01-02 13:29:29,122	44k	INFO	====> Epoch: 2923, cost 22.84 s
2024-01-02 13:29:31,794	44k	INFO	Train Epoch: 2924 [8%]
2024-01-02 13:29:31,797	44k	INFO	Losses: [2.28098726272583, 2.608213186264038, 8.442756652832031, 18.344120025634766, 0.28222182393074036], step: 76000, lr: 6.939205281109914e-05, reference_loss: 31.95829963684082
2024-01-02 13:29:37,163	44k	INFO	Saving model and optimizer state at iteration 2924 to ./logs/44k/G_76000.pth
2024-01-02 13:29:38,041	44k	INFO	Saving model and optimizer state at iteration 2924 to ./logs/44k/D_76000.pth
2024-01-02 13:29:38,536	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_73600.pth
2024-01-02 13:29:38,575	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_73600.pth
2024-01-02 13:29:58,611	44k	INFO	====> Epoch: 2924, cost 29.49 s
2024-01-02 13:30:21,325	44k	INFO	====> Epoch: 2925, cost 22.71 s
2024-01-02 13:30:44,176	44k	INFO	====> Epoch: 2926, cost 22.85 s
2024-01-02 13:31:06,969	44k	INFO	====> Epoch: 2927, cost 22.79 s
2024-01-02 13:31:29,901	44k	INFO	====> Epoch: 2928, cost 22.93 s
2024-01-02 13:31:52,678	44k	INFO	====> Epoch: 2929, cost 22.78 s
2024-01-02 13:32:15,457	44k	INFO	====> Epoch: 2930, cost 22.78 s
2024-01-02 13:32:33,869	44k	INFO	Train Epoch: 2931 [77%]
2024-01-02 13:32:33,872	44k	INFO	Losses: [2.1723580360412598, 2.731703996658325, 8.039523124694824, 16.48662757873535, 0.5447590351104736], step: 76200, lr: 6.933135752941374e-05, reference_loss: 29.974973678588867
2024-01-02 13:32:38,421	44k	INFO	====> Epoch: 2931, cost 22.96 s
2024-01-02 13:33:01,069	44k	INFO	====> Epoch: 2932, cost 22.65 s
2024-01-02 13:33:23,752	44k	INFO	====> Epoch: 2933, cost 22.68 s
2024-01-02 13:33:46,454	44k	INFO	====> Epoch: 2934, cost 22.70 s
2024-01-02 13:34:09,166	44k	INFO	====> Epoch: 2935, cost 22.71 s
2024-01-02 13:34:31,785	44k	INFO	====> Epoch: 2936, cost 22.62 s
2024-01-02 13:34:54,461	44k	INFO	====> Epoch: 2937, cost 22.68 s
2024-01-02 13:35:17,253	44k	INFO	====> Epoch: 2938, cost 22.79 s
2024-01-02 13:35:28,909	44k	INFO	Train Epoch: 2939 [46%]
2024-01-02 13:35:28,912	44k	INFO	Losses: [2.1557657718658447, 3.0662999153137207, 8.054088592529297, 15.927680015563965, 0.34620627760887146], step: 76400, lr: 6.926205649677128e-05, reference_loss: 29.55004119873047
2024-01-02 13:35:40,708	44k	INFO	====> Epoch: 2939, cost 23.45 s
2024-01-02 13:36:03,548	44k	INFO	====> Epoch: 2940, cost 22.84 s
2024-01-02 13:36:26,374	44k	INFO	====> Epoch: 2941, cost 22.83 s
2024-01-02 13:36:49,166	44k	INFO	====> Epoch: 2942, cost 22.79 s
2024-01-02 13:37:11,947	44k	INFO	====> Epoch: 2943, cost 22.78 s
2024-01-02 13:37:34,774	44k	INFO	====> Epoch: 2944, cost 22.83 s
2024-01-02 13:37:57,479	44k	INFO	====> Epoch: 2945, cost 22.71 s
2024-01-02 13:38:20,120	44k	INFO	====> Epoch: 2946, cost 22.64 s
2024-01-02 13:38:24,542	44k	INFO	Train Epoch: 2947 [15%]
2024-01-02 13:38:24,545	44k	INFO	Losses: [2.2274904251098633, 2.4341297149658203, 7.495794296264648, 15.174336433410645, 0.35262441635131836], step: 76600, lr: 6.919282473484986e-05, reference_loss: 27.684375762939453
2024-01-02 13:38:43,381	44k	INFO	====> Epoch: 2947, cost 23.26 s
2024-01-02 13:39:06,031	44k	INFO	====> Epoch: 2948, cost 22.65 s
2024-01-02 13:39:28,759	44k	INFO	====> Epoch: 2949, cost 22.73 s
2024-01-02 13:39:51,497	44k	INFO	====> Epoch: 2950, cost 22.74 s
2024-01-02 13:40:14,143	44k	INFO	====> Epoch: 2951, cost 22.65 s
2024-01-02 13:40:36,772	44k	INFO	====> Epoch: 2952, cost 22.63 s
2024-01-02 13:40:59,385	44k	INFO	====> Epoch: 2953, cost 22.61 s
2024-01-02 13:41:19,556	44k	INFO	Train Epoch: 2954 [85%]
2024-01-02 13:41:19,559	44k	INFO	Losses: [2.0329902172088623, 3.1856460571289062, 9.75198745727539, 16.944671630859375, 0.5784258842468262], step: 76800, lr: 6.913230371237306e-05, reference_loss: 32.49372100830078
2024-01-02 13:41:24,837	44k	INFO	Saving model and optimizer state at iteration 2954 to ./logs/44k/G_76800.pth
2024-01-02 13:41:25,873	44k	INFO	Saving model and optimizer state at iteration 2954 to ./logs/44k/D_76800.pth
2024-01-02 13:41:26,362	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_74400.pth
2024-01-02 13:41:26,401	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_74400.pth
2024-01-02 13:41:28,874	44k	INFO	====> Epoch: 2954, cost 29.49 s
2024-01-02 13:41:51,571	44k	INFO	====> Epoch: 2955, cost 22.70 s
2024-01-02 13:42:14,392	44k	INFO	====> Epoch: 2956, cost 22.82 s
2024-01-02 13:42:37,327	44k	INFO	====> Epoch: 2957, cost 22.93 s
2024-01-02 13:43:00,192	44k	INFO	====> Epoch: 2958, cost 22.87 s
2024-01-02 13:43:23,012	44k	INFO	====> Epoch: 2959, cost 22.82 s
2024-01-02 13:43:45,856	44k	INFO	====> Epoch: 2960, cost 22.84 s
2024-01-02 13:44:08,737	44k	INFO	====> Epoch: 2961, cost 22.88 s
2024-01-02 13:44:22,041	44k	INFO	Train Epoch: 2962 [54%]
2024-01-02 13:44:22,045	44k	INFO	Losses: [2.3569912910461426, 2.4173648357391357, 7.830164909362793, 15.390006065368652, 0.66848224401474], step: 77000, lr: 6.906320164648336e-05, reference_loss: 28.663007736206055
2024-01-02 13:44:31,982	44k	INFO	====> Epoch: 2962, cost 23.25 s
2024-01-02 13:44:54,803	44k	INFO	====> Epoch: 2963, cost 22.82 s
2024-01-02 13:45:17,734	44k	INFO	====> Epoch: 2964, cost 22.93 s
2024-01-02 13:45:40,610	44k	INFO	====> Epoch: 2965, cost 22.88 s
2024-01-02 13:46:03,469	44k	INFO	====> Epoch: 2966, cost 22.86 s
2024-01-02 13:46:26,327	44k	INFO	====> Epoch: 2967, cost 22.86 s
2024-01-02 13:46:49,019	44k	INFO	====> Epoch: 2968, cost 22.69 s
2024-01-02 13:47:11,701	44k	INFO	====> Epoch: 2969, cost 22.68 s
2024-01-02 13:47:17,897	44k	INFO	Train Epoch: 2970 [23%]
2024-01-02 13:47:17,900	44k	INFO	Losses: [2.5135984420776367, 2.639578104019165, 7.568676948547363, 14.59753131866455, 0.3329067528247833], step: 77200, lr: 6.899416865243498e-05, reference_loss: 27.652292251586914
2024-01-02 13:47:34,777	44k	INFO	====> Epoch: 2970, cost 23.08 s
2024-01-02 13:47:57,499	44k	INFO	====> Epoch: 2971, cost 22.72 s
2024-01-02 13:48:20,260	44k	INFO	====> Epoch: 2972, cost 22.76 s
2024-01-02 13:48:42,950	44k	INFO	====> Epoch: 2973, cost 22.69 s
2024-01-02 13:49:05,835	44k	INFO	====> Epoch: 2974, cost 22.89 s
2024-01-02 13:49:28,528	44k	INFO	====> Epoch: 2975, cost 22.69 s
2024-01-02 13:49:51,156	44k	INFO	====> Epoch: 2976, cost 22.63 s
2024-01-02 13:50:13,138	44k	INFO	Train Epoch: 2977 [92%]
2024-01-02 13:50:13,141	44k	INFO	Losses: [2.340873956680298, 2.4412591457366943, 7.290493011474609, 16.420358657836914, 0.40833780169487], step: 77400, lr: 6.893382138885987e-05, reference_loss: 28.901323318481445
2024-01-02 13:50:14,231	44k	INFO	====> Epoch: 2977, cost 23.08 s
2024-01-02 13:50:36,904	44k	INFO	====> Epoch: 2978, cost 22.67 s
2024-01-02 13:50:59,680	44k	INFO	====> Epoch: 2979, cost 22.78 s
2024-01-02 13:51:22,522	44k	INFO	====> Epoch: 2980, cost 22.84 s
2024-01-02 13:51:45,355	44k	INFO	====> Epoch: 2981, cost 22.83 s
2024-01-02 13:52:08,216	44k	INFO	====> Epoch: 2982, cost 22.86 s
2024-01-02 13:52:31,168	44k	INFO	====> Epoch: 2983, cost 22.95 s
2024-01-02 13:52:54,040	44k	INFO	====> Epoch: 2984, cost 22.87 s
2024-01-02 13:53:09,147	44k	INFO	Train Epoch: 2985 [62%]
2024-01-02 13:53:09,150	44k	INFO	Losses: [2.330869197845459, 2.479626417160034, 6.833492279052734, 14.16624641418457, 0.3998374938964844], step: 77600, lr: 6.886491771847937e-05, reference_loss: 26.210071563720703
2024-01-02 13:53:14,439	44k	INFO	Saving model and optimizer state at iteration 2985 to ./logs/44k/G_77600.pth
2024-01-02 13:53:15,334	44k	INFO	Saving model and optimizer state at iteration 2985 to ./logs/44k/D_77600.pth
2024-01-02 13:53:15,822	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_75200.pth
2024-01-02 13:53:15,861	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_75200.pth
2024-01-02 13:53:23,543	44k	INFO	====> Epoch: 2985, cost 29.50 s
2024-01-02 13:53:46,228	44k	INFO	====> Epoch: 2986, cost 22.68 s
2024-01-02 13:54:09,039	44k	INFO	====> Epoch: 2987, cost 22.81 s
2024-01-02 13:54:31,841	44k	INFO	====> Epoch: 2988, cost 22.80 s
2024-01-02 13:54:54,550	44k	INFO	====> Epoch: 2989, cost 22.71 s
2024-01-02 13:55:17,360	44k	INFO	====> Epoch: 2990, cost 22.81 s
2024-01-02 13:55:40,347	44k	INFO	====> Epoch: 2991, cost 22.99 s
2024-01-02 13:56:03,169	44k	INFO	====> Epoch: 2992, cost 22.82 s
2024-01-02 13:56:11,143	44k	INFO	Train Epoch: 2993 [31%]
2024-01-02 13:56:11,146	44k	INFO	Losses: [2.3367435932159424, 2.903916120529175, 8.296897888183594, 16.45832061767578, 0.40941065549850464], step: 77800, lr: 6.879608292163143e-05, reference_loss: 30.405288696289062
2024-01-02 13:56:26,219	44k	INFO	====> Epoch: 2993, cost 23.05 s
2024-01-02 13:56:48,884	44k	INFO	====> Epoch: 2994, cost 22.67 s
2024-01-02 13:57:11,510	44k	INFO	====> Epoch: 2995, cost 22.63 s
2024-01-02 13:57:34,207	44k	INFO	====> Epoch: 2996, cost 22.70 s
2024-01-02 13:57:56,954	44k	INFO	====> Epoch: 2997, cost 22.75 s
2024-01-02 13:58:19,585	44k	INFO	====> Epoch: 2998, cost 22.63 s
2024-01-02 13:58:42,209	44k	INFO	====> Epoch: 2999, cost 22.62 s
2024-01-02 13:59:04,941	44k	INFO	====> Epoch: 3000, cost 22.73 s
2024-01-02 13:59:05,834	44k	INFO	Train Epoch: 3001 [0%]
2024-01-02 13:59:05,836	44k	INFO	Losses: [2.1505231857299805, 2.6232807636260986, 7.787064552307129, 15.8944730758667, 0.29097577929496765], step: 78000, lr: 6.872731692947266e-05, reference_loss: 28.74631690979004
2024-01-02 13:59:28,283	44k	INFO	====> Epoch: 3001, cost 23.34 s
2024-01-02 13:59:51,152	44k	INFO	====> Epoch: 3002, cost 22.87 s
2024-01-02 14:00:14,018	44k	INFO	====> Epoch: 3003, cost 22.87 s
2024-01-02 14:00:36,750	44k	INFO	====> Epoch: 3004, cost 22.73 s
2024-01-02 14:00:59,426	44k	INFO	====> Epoch: 3005, cost 22.68 s
2024-01-02 14:01:22,083	44k	INFO	====> Epoch: 3006, cost 22.66 s
2024-01-02 14:01:44,764	44k	INFO	====> Epoch: 3007, cost 22.68 s
2024-01-02 14:02:01,534	44k	INFO	Train Epoch: 3008 [69%]
2024-01-02 14:02:01,536	44k	INFO	Losses: [2.139691114425659, 2.691805839538574, 9.412612915039062, 18.259172439575195, 0.36332833766937256], step: 78200, lr: 6.866720307361265e-05, reference_loss: 32.866607666015625
2024-01-02 14:02:07,901	44k	INFO	====> Epoch: 3008, cost 23.14 s
2024-01-02 14:02:30,832	44k	INFO	====> Epoch: 3009, cost 22.93 s
2024-01-02 14:02:53,661	44k	INFO	====> Epoch: 3010, cost 22.83 s
2024-01-02 14:03:16,507	44k	INFO	====> Epoch: 3011, cost 22.85 s
2024-01-02 14:03:39,348	44k	INFO	====> Epoch: 3012, cost 22.84 s
2024-01-02 14:04:02,176	44k	INFO	====> Epoch: 3013, cost 22.83 s
2024-01-02 14:04:25,002	44k	INFO	====> Epoch: 3014, cost 22.83 s
2024-01-02 14:04:47,744	44k	INFO	====> Epoch: 3015, cost 22.74 s
2024-01-02 14:04:57,553	44k	INFO	Train Epoch: 3016 [38%]
2024-01-02 14:04:57,556	44k	INFO	Losses: [2.2260313034057617, 2.886629819869995, 7.7854413986206055, 14.82702922821045, 0.48829957842826843], step: 78400, lr: 6.859856590493108e-05, reference_loss: 28.21343231201172
2024-01-02 14:05:02,800	44k	INFO	Saving model and optimizer state at iteration 3016 to ./logs/44k/G_78400.pth
2024-01-02 14:05:03,677	44k	INFO	Saving model and optimizer state at iteration 3016 to ./logs/44k/D_78400.pth
2024-01-02 14:05:04,171	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_76000.pth
2024-01-02 14:05:04,210	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_76000.pth
2024-01-02 14:05:17,207	44k	INFO	====> Epoch: 3016, cost 29.46 s
2024-01-02 14:05:40,239	44k	INFO	====> Epoch: 3017, cost 23.03 s
2024-01-02 14:06:03,112	44k	INFO	====> Epoch: 3018, cost 22.87 s
2024-01-02 14:06:25,936	44k	INFO	====> Epoch: 3019, cost 22.82 s
2024-01-02 14:06:48,719	44k	INFO	====> Epoch: 3020, cost 22.78 s
2024-01-02 14:07:11,439	44k	INFO	====> Epoch: 3021, cost 22.72 s
2024-01-02 14:07:34,255	44k	INFO	====> Epoch: 3022, cost 22.82 s
2024-01-02 14:07:57,086	44k	INFO	====> Epoch: 3023, cost 22.83 s
2024-01-02 14:07:59,765	44k	INFO	Train Epoch: 3024 [8%]
2024-01-02 14:07:59,768	44k	INFO	Losses: [2.3545584678649902, 2.4436213970184326, 7.098546028137207, 15.707030296325684, 0.35501718521118164], step: 78600, lr: 6.852999734339691e-05, reference_loss: 27.958772659301758
2024-01-02 14:08:20,324	44k	INFO	====> Epoch: 3024, cost 23.24 s
2024-01-02 14:08:43,011	44k	INFO	====> Epoch: 3025, cost 22.69 s
2024-01-02 14:09:05,777	44k	INFO	====> Epoch: 3026, cost 22.77 s
2024-01-02 14:09:28,632	44k	INFO	====> Epoch: 3027, cost 22.85 s
2024-01-02 14:09:51,479	44k	INFO	====> Epoch: 3028, cost 22.85 s
2024-01-02 14:10:14,462	44k	INFO	====> Epoch: 3029, cost 22.98 s
2024-01-02 14:10:37,290	44k	INFO	====> Epoch: 3030, cost 22.83 s
2024-01-02 14:10:55,922	44k	INFO	Train Epoch: 3031 [77%]
2024-01-02 14:10:55,925	44k	INFO	Losses: [2.3141016960144043, 2.5442652702331543, 9.567489624023438, 18.414615631103516, 0.48753124475479126], step: 78800, lr: 6.847005607744271e-05, reference_loss: 33.3280029296875
2024-01-02 14:11:00,591	44k	INFO	====> Epoch: 3031, cost 23.30 s
2024-01-02 14:11:23,414	44k	INFO	====> Epoch: 3032, cost 22.82 s
2024-01-02 14:11:46,086	44k	INFO	====> Epoch: 3033, cost 22.67 s
2024-01-02 14:12:08,740	44k	INFO	====> Epoch: 3034, cost 22.65 s
2024-01-02 14:12:31,528	44k	INFO	====> Epoch: 3035, cost 22.79 s
2024-01-02 14:12:54,200	44k	INFO	====> Epoch: 3036, cost 22.67 s
2024-01-02 14:13:16,952	44k	INFO	====> Epoch: 3037, cost 22.75 s
2024-01-02 14:13:39,743	44k	INFO	====> Epoch: 3038, cost 22.79 s
2024-01-02 14:13:51,363	44k	INFO	Train Epoch: 3039 [46%]
2024-01-02 14:13:51,366	44k	INFO	Losses: [2.146951675415039, 2.7704782485961914, 8.632899284362793, 16.47127342224121, 0.43245166540145874], step: 79000, lr: 6.840161596952704e-05, reference_loss: 30.45405387878418
2024-01-02 14:14:03,058	44k	INFO	====> Epoch: 3039, cost 23.31 s
2024-01-02 14:14:25,852	44k	INFO	====> Epoch: 3040, cost 22.79 s
2024-01-02 14:14:48,640	44k	INFO	====> Epoch: 3041, cost 22.79 s
2024-01-02 14:15:11,426	44k	INFO	====> Epoch: 3042, cost 22.79 s
2024-01-02 14:15:34,092	44k	INFO	====> Epoch: 3043, cost 22.67 s
2024-01-02 14:15:56,947	44k	INFO	====> Epoch: 3044, cost 22.86 s
2024-01-02 14:16:19,698	44k	INFO	====> Epoch: 3045, cost 22.75 s
2024-01-02 14:16:42,409	44k	INFO	====> Epoch: 3046, cost 22.71 s
2024-01-02 14:16:46,838	44k	INFO	Train Epoch: 3047 [15%]
2024-01-02 14:16:46,841	44k	INFO	Losses: [2.2866883277893066, 2.512995481491089, 9.054842948913574, 17.625812530517578, 0.2387748807668686], step: 79200, lr: 6.833324427178422e-05, reference_loss: 31.719114303588867
2024-01-02 14:16:52,354	44k	INFO	Saving model and optimizer state at iteration 3047 to ./logs/44k/G_79200.pth
2024-01-02 14:16:53,221	44k	INFO	Saving model and optimizer state at iteration 3047 to ./logs/44k/D_79200.pth
2024-01-02 14:16:53,710	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_76800.pth
2024-01-02 14:16:53,749	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_76800.pth
2024-01-02 14:17:11,994	44k	INFO	====> Epoch: 3047, cost 29.58 s
2024-01-02 14:17:34,836	44k	INFO	====> Epoch: 3048, cost 22.84 s
2024-01-02 14:17:57,619	44k	INFO	====> Epoch: 3049, cost 22.78 s
2024-01-02 14:18:20,343	44k	INFO	====> Epoch: 3050, cost 22.72 s
2024-01-02 14:18:42,976	44k	INFO	====> Epoch: 3051, cost 22.63 s
2024-01-02 14:19:05,626	44k	INFO	====> Epoch: 3052, cost 22.65 s
2024-01-02 14:19:28,184	44k	INFO	====> Epoch: 3053, cost 22.56 s
2024-01-02 14:19:48,373	44k	INFO	Train Epoch: 3054 [85%]
2024-01-02 14:19:48,376	44k	INFO	Losses: [2.397239923477173, 2.5515689849853516, 6.508700370788574, 15.366333961486816, 0.5086271166801453], step: 79400, lr: 6.827347510022155e-05, reference_loss: 27.332469940185547
2024-01-02 14:19:51,385	44k	INFO	====> Epoch: 3054, cost 23.20 s
2024-01-02 14:20:14,116	44k	INFO	====> Epoch: 3055, cost 22.73 s
2024-01-02 14:20:36,833	44k	INFO	====> Epoch: 3056, cost 22.72 s
2024-01-02 14:20:59,573	44k	INFO	====> Epoch: 3057, cost 22.74 s
2024-01-02 14:21:22,262	44k	INFO	====> Epoch: 3058, cost 22.69 s
2024-01-02 14:21:45,099	44k	INFO	====> Epoch: 3059, cost 22.84 s
2024-01-02 14:22:07,947	44k	INFO	====> Epoch: 3060, cost 22.85 s
2024-01-02 14:22:30,789	44k	INFO	====> Epoch: 3061, cost 22.84 s
2024-01-02 14:22:44,088	44k	INFO	Train Epoch: 3062 [54%]
2024-01-02 14:22:44,091	44k	INFO	Losses: [2.288557529449463, 2.5455856323242188, 7.865224838256836, 16.854822158813477, 0.5734133720397949], step: 79600, lr: 6.820523148730044e-05, reference_loss: 30.12760353088379
2024-01-02 14:22:53,950	44k	INFO	====> Epoch: 3062, cost 23.16 s
2024-01-02 14:23:16,708	44k	INFO	====> Epoch: 3063, cost 22.76 s
2024-01-02 14:23:39,613	44k	INFO	====> Epoch: 3064, cost 22.91 s
2024-01-02 14:24:02,434	44k	INFO	====> Epoch: 3065, cost 22.82 s
2024-01-02 14:24:25,241	44k	INFO	====> Epoch: 3066, cost 22.81 s
2024-01-02 14:24:47,869	44k	INFO	====> Epoch: 3067, cost 22.63 s
2024-01-02 14:25:10,488	44k	INFO	====> Epoch: 3068, cost 22.62 s
2024-01-02 14:25:33,232	44k	INFO	====> Epoch: 3069, cost 22.74 s
2024-01-02 14:25:39,468	44k	INFO	Train Epoch: 3070 [23%]
2024-01-02 14:25:39,471	44k	INFO	Losses: [2.5674514770507812, 2.22812819480896, 6.876245498657227, 13.505188941955566, 0.367006778717041], step: 79800, lr: 6.813705608814312e-05, reference_loss: 25.54401969909668
2024-01-02 14:25:56,414	44k	INFO	====> Epoch: 3070, cost 23.18 s
2024-01-02 14:26:19,238	44k	INFO	====> Epoch: 3071, cost 22.82 s
2024-01-02 14:26:41,978	44k	INFO	====> Epoch: 3072, cost 22.74 s
2024-01-02 14:27:04,562	44k	INFO	====> Epoch: 3073, cost 22.58 s
2024-01-02 14:27:27,293	44k	INFO	====> Epoch: 3074, cost 22.73 s
2024-01-02 14:27:49,955	44k	INFO	====> Epoch: 3075, cost 22.66 s
2024-01-02 14:28:12,599	44k	INFO	====> Epoch: 3076, cost 22.64 s
2024-01-02 14:28:34,674	44k	INFO	Train Epoch: 3077 [92%]
2024-01-02 14:28:34,678	44k	INFO	Losses: [2.378293991088867, 2.340778112411499, 6.88623046875, 15.52575397491455, 0.5203807353973389], step: 80000, lr: 6.807745851688029e-05, reference_loss: 27.651437759399414
2024-01-02 14:28:39,908	44k	INFO	Saving model and optimizer state at iteration 3077 to ./logs/44k/G_80000.pth
2024-01-02 14:28:40,789	44k	INFO	Saving model and optimizer state at iteration 3077 to ./logs/44k/D_80000.pth
2024-01-02 14:28:41,282	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_77600.pth
2024-01-02 14:28:41,321	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_77600.pth
2024-01-02 14:28:42,015	44k	INFO	====> Epoch: 3077, cost 29.42 s
2024-01-02 14:29:04,747	44k	INFO	====> Epoch: 3078, cost 22.73 s
2024-01-02 14:29:27,563	44k	INFO	====> Epoch: 3079, cost 22.82 s
2024-01-02 14:29:50,311	44k	INFO	====> Epoch: 3080, cost 22.75 s
2024-01-02 14:30:13,151	44k	INFO	====> Epoch: 3081, cost 22.84 s
2024-01-02 14:30:35,901	44k	INFO	====> Epoch: 3082, cost 22.75 s
2024-01-02 14:30:58,545	44k	INFO	====> Epoch: 3083, cost 22.64 s
2024-01-02 14:31:21,238	44k	INFO	====> Epoch: 3084, cost 22.69 s
2024-01-02 14:31:36,244	44k	INFO	Train Epoch: 3085 [62%]
2024-01-02 14:31:36,247	44k	INFO	Losses: [2.4354724884033203, 2.4377031326293945, 6.505941867828369, 13.855077743530273, 0.6331521272659302], step: 80200, lr: 6.800941083480668e-05, reference_loss: 25.867347717285156
2024-01-02 14:31:44,382	44k	INFO	====> Epoch: 3085, cost 23.14 s
2024-01-02 14:32:07,216	44k	INFO	====> Epoch: 3086, cost 22.83 s
2024-01-02 14:32:30,089	44k	INFO	====> Epoch: 3087, cost 22.87 s
2024-01-02 14:32:52,947	44k	INFO	====> Epoch: 3088, cost 22.86 s
2024-01-02 14:33:15,767	44k	INFO	====> Epoch: 3089, cost 22.82 s
2024-01-02 14:33:38,620	44k	INFO	====> Epoch: 3090, cost 22.85 s
2024-01-02 14:34:01,395	44k	INFO	====> Epoch: 3091, cost 22.77 s
2024-01-02 14:34:24,294	44k	INFO	====> Epoch: 3092, cost 22.90 s
2024-01-02 14:34:32,307	44k	INFO	Train Epoch: 3093 [31%]
2024-01-02 14:34:32,310	44k	INFO	Losses: [2.401095390319824, 2.41725754737854, 6.883358955383301, 14.470951080322266, 0.3850732743740082], step: 80400, lr: 6.794143117065172e-05, reference_loss: 26.557735443115234
2024-01-02 14:34:47,419	44k	INFO	====> Epoch: 3093, cost 23.13 s
2024-01-02 14:35:10,249	44k	INFO	====> Epoch: 3094, cost 22.83 s
2024-01-02 14:35:33,022	44k	INFO	====> Epoch: 3095, cost 22.77 s
2024-01-02 14:35:55,842	44k	INFO	====> Epoch: 3096, cost 22.82 s
2024-01-02 14:36:18,635	44k	INFO	====> Epoch: 3097, cost 22.79 s
2024-01-02 14:36:41,304	44k	INFO	====> Epoch: 3098, cost 22.67 s
2024-01-02 14:37:03,952	44k	INFO	====> Epoch: 3099, cost 22.65 s
2024-01-02 14:37:26,777	44k	INFO	====> Epoch: 3100, cost 22.83 s
2024-01-02 14:37:27,671	44k	INFO	Train Epoch: 3101 [0%]
2024-01-02 14:37:27,674	44k	INFO	Losses: [2.3363780975341797, 2.491793632507324, 7.321318626403809, 13.488975524902344, 0.437642365694046], step: 80600, lr: 6.787351945642725e-05, reference_loss: 26.076108932495117
2024-01-02 14:37:50,169	44k	INFO	====> Epoch: 3101, cost 23.39 s
2024-01-02 14:38:12,992	44k	INFO	====> Epoch: 3102, cost 22.82 s
2024-01-02 14:38:35,774	44k	INFO	====> Epoch: 3103, cost 22.78 s
2024-01-02 14:38:58,642	44k	INFO	====> Epoch: 3104, cost 22.87 s
2024-01-02 14:39:21,504	44k	INFO	====> Epoch: 3105, cost 22.86 s
2024-01-02 14:39:44,334	44k	INFO	====> Epoch: 3106, cost 22.83 s
2024-01-02 14:40:07,128	44k	INFO	====> Epoch: 3107, cost 22.79 s
2024-01-02 14:40:23,986	44k	INFO	Train Epoch: 3108 [69%]
2024-01-02 14:40:23,989	44k	INFO	Losses: [2.3351118564605713, 2.6100127696990967, 7.401446342468262, 15.059171676635742, 0.4357874393463135], step: 80800, lr: 6.78141523932622e-05, reference_loss: 27.841529846191406
2024-01-02 14:40:29,264	44k	INFO	Saving model and optimizer state at iteration 3108 to ./logs/44k/G_80800.pth
2024-01-02 14:40:30,312	44k	INFO	Saving model and optimizer state at iteration 3108 to ./logs/44k/D_80800.pth
2024-01-02 14:40:30,803	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_78400.pth
2024-01-02 14:40:30,842	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_78400.pth
2024-01-02 14:40:36,776	44k	INFO	====> Epoch: 3108, cost 29.65 s
2024-01-02 14:40:59,514	44k	INFO	====> Epoch: 3109, cost 22.74 s
2024-01-02 14:41:22,280	44k	INFO	====> Epoch: 3110, cost 22.77 s
2024-01-02 14:41:45,011	44k	INFO	====> Epoch: 3111, cost 22.73 s
2024-01-02 14:42:07,816	44k	INFO	====> Epoch: 3112, cost 22.80 s
2024-01-02 14:42:30,634	44k	INFO	====> Epoch: 3113, cost 22.82 s
2024-01-02 14:42:53,439	44k	INFO	====> Epoch: 3114, cost 22.80 s
2024-01-02 14:43:16,235	44k	INFO	====> Epoch: 3115, cost 22.80 s
2024-01-02 14:43:26,049	44k	INFO	Train Epoch: 3116 [38%]
2024-01-02 14:43:26,052	44k	INFO	Losses: [2.4408199787139893, 2.4739043712615967, 7.536347389221191, 16.24516487121582, 0.43898147344589233], step: 81000, lr: 6.774636790214459e-05, reference_loss: 29.135217666625977
2024-01-02 14:43:39,408	44k	INFO	====> Epoch: 3116, cost 23.17 s
2024-01-02 14:44:02,263	44k	INFO	====> Epoch: 3117, cost 22.86 s
2024-01-02 14:44:25,016	44k	INFO	====> Epoch: 3118, cost 22.75 s
2024-01-02 14:44:47,844	44k	INFO	====> Epoch: 3119, cost 22.83 s
2024-01-02 14:45:10,646	44k	INFO	====> Epoch: 3120, cost 22.80 s
2024-01-02 14:45:33,343	44k	INFO	====> Epoch: 3121, cost 22.70 s
2024-01-02 14:45:55,878	44k	INFO	====> Epoch: 3122, cost 22.54 s
2024-01-02 14:46:18,642	44k	INFO	====> Epoch: 3123, cost 22.76 s
2024-01-02 14:46:21,320	44k	INFO	Train Epoch: 3124 [8%]
2024-01-02 14:46:21,323	44k	INFO	Losses: [2.282576084136963, 2.3967180252075195, 8.28099250793457, 16.215845108032227, 0.34405672550201416], step: 81200, lr: 6.767865116586977e-05, reference_loss: 29.52018928527832
2024-01-02 14:46:41,855	44k	INFO	====> Epoch: 3124, cost 23.21 s
2024-01-02 14:47:04,729	44k	INFO	====> Epoch: 3125, cost 22.87 s
2024-01-02 14:47:27,398	44k	INFO	====> Epoch: 3126, cost 22.67 s
2024-01-02 14:47:50,362	44k	INFO	====> Epoch: 3127, cost 22.96 s
2024-01-02 14:48:13,045	44k	INFO	====> Epoch: 3128, cost 22.68 s
2024-01-02 14:48:35,744	44k	INFO	====> Epoch: 3129, cost 22.70 s
2024-01-02 14:48:58,576	44k	INFO	====> Epoch: 3130, cost 22.83 s
2024-01-02 14:49:17,208	44k	INFO	Train Epoch: 3131 [77%]
2024-01-02 14:49:17,211	44k	INFO	Losses: [2.1826438903808594, 2.528127908706665, 9.030708312988281, 18.137920379638672, 0.3499957025051117], step: 81400, lr: 6.761945454853114e-05, reference_loss: 32.22939682006836
2024-01-02 14:49:21,801	44k	INFO	====> Epoch: 3131, cost 23.22 s
2024-01-02 14:49:44,630	44k	INFO	====> Epoch: 3132, cost 22.83 s
2024-01-02 14:50:07,407	44k	INFO	====> Epoch: 3133, cost 22.78 s
2024-01-02 14:50:30,236	44k	INFO	====> Epoch: 3134, cost 22.83 s
2024-01-02 14:50:53,072	44k	INFO	====> Epoch: 3135, cost 22.84 s
2024-01-02 14:51:15,880	44k	INFO	====> Epoch: 3136, cost 22.81 s
2024-01-02 14:51:38,838	44k	INFO	====> Epoch: 3137, cost 22.96 s
2024-01-02 14:52:01,643	44k	INFO	====> Epoch: 3138, cost 22.81 s
2024-01-02 14:52:13,123	44k	INFO	Train Epoch: 3139 [46%]
2024-01-02 14:52:13,126	44k	INFO	Losses: [2.386286973953247, 2.327528715133667, 5.918802738189697, 13.932456016540527, 0.38932910561561584], step: 81600, lr: 6.755186467009924e-05, reference_loss: 24.954404830932617
2024-01-02 14:52:18,370	44k	INFO	Saving model and optimizer state at iteration 3139 to ./logs/44k/G_81600.pth
2024-01-02 14:52:19,255	44k	INFO	Saving model and optimizer state at iteration 3139 to ./logs/44k/D_81600.pth
2024-01-02 14:52:19,746	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_79200.pth
2024-01-02 14:52:19,785	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_79200.pth
2024-01-02 14:52:30,961	44k	INFO	====> Epoch: 3139, cost 29.32 s
2024-01-02 14:52:53,670	44k	INFO	====> Epoch: 3140, cost 22.71 s
2024-01-02 14:53:16,492	44k	INFO	====> Epoch: 3141, cost 22.82 s
2024-01-02 14:53:39,284	44k	INFO	====> Epoch: 3142, cost 22.79 s
2024-01-02 14:54:01,926	44k	INFO	====> Epoch: 3143, cost 22.64 s
2024-01-02 14:54:24,760	44k	INFO	====> Epoch: 3144, cost 22.83 s
2024-01-02 14:54:47,312	44k	INFO	====> Epoch: 3145, cost 22.55 s
2024-01-02 14:55:09,895	44k	INFO	====> Epoch: 3146, cost 22.58 s
2024-01-02 14:55:14,319	44k	INFO	Train Epoch: 3147 [15%]
2024-01-02 14:55:14,322	44k	INFO	Losses: [2.3079328536987305, 2.3743441104888916, 7.126894950866699, 14.398873329162598, 0.4546220600605011], step: 81800, lr: 6.748434235198258e-05, reference_loss: 26.662668228149414
2024-01-02 14:55:32,993	44k	INFO	====> Epoch: 3147, cost 23.10 s
2024-01-02 14:55:55,782	44k	INFO	====> Epoch: 3148, cost 22.79 s
2024-01-02 14:56:18,632	44k	INFO	====> Epoch: 3149, cost 22.85 s
2024-01-02 14:56:41,291	44k	INFO	====> Epoch: 3150, cost 22.66 s
2024-01-02 14:57:03,916	44k	INFO	====> Epoch: 3151, cost 22.62 s
2024-01-02 14:57:26,565	44k	INFO	====> Epoch: 3152, cost 22.65 s
2024-01-02 14:57:49,122	44k	INFO	====> Epoch: 3153, cost 22.56 s
2024-01-02 14:58:09,235	44k	INFO	Train Epoch: 3154 [85%]
2024-01-02 14:58:09,238	44k	INFO	Losses: [2.296253204345703, 2.6845781803131104, 7.467796802520752, 16.101533889770508, 0.5928957462310791], step: 82000, lr: 6.742531569111183e-05, reference_loss: 29.143056869506836
2024-01-02 14:58:12,234	44k	INFO	====> Epoch: 3154, cost 23.11 s
2024-01-02 14:58:34,733	44k	INFO	====> Epoch: 3155, cost 22.50 s
2024-01-02 14:58:57,311	44k	INFO	====> Epoch: 3156, cost 22.58 s
2024-01-02 14:59:20,037	44k	INFO	====> Epoch: 3157, cost 22.73 s
2024-01-02 14:59:42,682	44k	INFO	====> Epoch: 3158, cost 22.64 s
2024-01-02 15:00:05,432	44k	INFO	====> Epoch: 3159, cost 22.75 s
2024-01-02 15:00:28,211	44k	INFO	====> Epoch: 3160, cost 22.78 s
2024-01-02 15:00:51,003	44k	INFO	====> Epoch: 3161, cost 22.79 s
2024-01-02 15:01:04,299	44k	INFO	Train Epoch: 3162 [54%]
2024-01-02 15:01:04,302	44k	INFO	Losses: [2.394751787185669, 2.4535160064697266, 6.790706157684326, 14.886801719665527, 0.39616328477859497], step: 82200, lr: 6.735791986662281e-05, reference_loss: 26.921939849853516
2024-01-02 15:01:14,172	44k	INFO	====> Epoch: 3162, cost 23.17 s
2024-01-02 15:01:37,127	44k	INFO	====> Epoch: 3163, cost 22.96 s
2024-01-02 15:01:59,987	44k	INFO	====> Epoch: 3164, cost 22.86 s
2024-01-02 15:02:22,865	44k	INFO	====> Epoch: 3165, cost 22.88 s
2024-01-02 15:02:45,694	44k	INFO	====> Epoch: 3166, cost 22.83 s
2024-01-02 15:03:08,555	44k	INFO	====> Epoch: 3167, cost 22.86 s
2024-01-02 15:03:31,417	44k	INFO	====> Epoch: 3168, cost 22.86 s
2024-01-02 15:03:54,296	44k	INFO	====> Epoch: 3169, cost 22.88 s
2024-01-02 15:04:00,530	44k	INFO	Train Epoch: 3170 [23%]
2024-01-02 15:04:00,533	44k	INFO	Losses: [2.3098487854003906, 2.4821276664733887, 7.294738292694092, 14.311725616455078, 0.4925869405269623], step: 82400, lr: 6.729059140848001e-05, reference_loss: 26.891027450561523
2024-01-02 15:04:05,795	44k	INFO	Saving model and optimizer state at iteration 3170 to ./logs/44k/G_82400.pth
2024-01-02 15:04:06,665	44k	INFO	Saving model and optimizer state at iteration 3170 to ./logs/44k/D_82400.pth
2024-01-02 15:04:07,157	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_80000.pth
2024-01-02 15:04:07,196	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_80000.pth
2024-01-02 15:04:23,940	44k	INFO	====> Epoch: 3170, cost 29.64 s
2024-01-02 15:04:46,659	44k	INFO	====> Epoch: 3171, cost 22.72 s
2024-01-02 15:05:09,321	44k	INFO	====> Epoch: 3172, cost 22.66 s
2024-01-02 15:05:32,072	44k	INFO	====> Epoch: 3173, cost 22.75 s
2024-01-02 15:05:54,866	44k	INFO	====> Epoch: 3174, cost 22.79 s
2024-01-02 15:06:17,693	44k	INFO	====> Epoch: 3175, cost 22.83 s
2024-01-02 15:06:40,425	44k	INFO	====> Epoch: 3176, cost 22.73 s
2024-01-02 15:07:02,497	44k	INFO	Train Epoch: 3177 [92%]
2024-01-02 15:07:02,500	44k	INFO	Losses: [2.28413724899292, 2.7334837913513184, 7.10120153427124, 15.604557991027832, 0.5507221221923828], step: 82600, lr: 6.72317342161235e-05, reference_loss: 28.27410316467285
2024-01-02 15:07:03,583	44k	INFO	====> Epoch: 3177, cost 23.16 s
2024-01-02 15:07:26,375	44k	INFO	====> Epoch: 3178, cost 22.79 s
2024-01-02 15:07:49,058	44k	INFO	====> Epoch: 3179, cost 22.68 s
2024-01-02 15:08:11,830	44k	INFO	====> Epoch: 3180, cost 22.77 s
2024-01-02 15:08:34,582	44k	INFO	====> Epoch: 3181, cost 22.75 s
2024-01-02 15:08:57,457	44k	INFO	====> Epoch: 3182, cost 22.88 s
2024-01-02 15:09:20,224	44k	INFO	====> Epoch: 3183, cost 22.77 s
2024-01-02 15:09:43,006	44k	INFO	====> Epoch: 3184, cost 22.78 s
2024-01-02 15:09:58,067	44k	INFO	Train Epoch: 3185 [62%]
2024-01-02 15:09:58,070	44k	INFO	Losses: [2.334789752960205, 2.5763676166534424, 8.445137023925781, 15.571146965026855, 0.3994283378124237], step: 82800, lr: 6.716453188843875e-05, reference_loss: 29.326868057250977
2024-01-02 15:10:06,198	44k	INFO	====> Epoch: 3185, cost 23.19 s
2024-01-02 15:10:28,980	44k	INFO	====> Epoch: 3186, cost 22.78 s
2024-01-02 15:10:51,770	44k	INFO	====> Epoch: 3187, cost 22.79 s
2024-01-02 15:11:14,561	44k	INFO	====> Epoch: 3188, cost 22.79 s
2024-01-02 15:11:37,303	44k	INFO	====> Epoch: 3189, cost 22.74 s
2024-01-02 15:12:00,028	44k	INFO	====> Epoch: 3190, cost 22.72 s
2024-01-02 15:12:22,859	44k	INFO	====> Epoch: 3191, cost 22.83 s
2024-01-02 15:12:45,762	44k	INFO	====> Epoch: 3192, cost 22.90 s
2024-01-02 15:12:53,772	44k	INFO	Train Epoch: 3193 [31%]
2024-01-02 15:12:53,775	44k	INFO	Losses: [2.382340431213379, 2.428936243057251, 6.780714988708496, 14.549972534179688, 0.3797677755355835], step: 83000, lr: 6.709739673368801e-05, reference_loss: 26.521732330322266
2024-01-02 15:13:08,972	44k	INFO	====> Epoch: 3193, cost 23.21 s
2024-01-02 15:13:31,608	44k	INFO	====> Epoch: 3194, cost 22.64 s
2024-01-02 15:13:54,273	44k	INFO	====> Epoch: 3195, cost 22.67 s
2024-01-02 15:14:16,929	44k	INFO	====> Epoch: 3196, cost 22.66 s
2024-01-02 15:14:39,586	44k	INFO	====> Epoch: 3197, cost 22.66 s
2024-01-02 15:15:02,245	44k	INFO	====> Epoch: 3198, cost 22.66 s
2024-01-02 15:15:24,918	44k	INFO	====> Epoch: 3199, cost 22.67 s
2024-01-02 15:15:47,571	44k	INFO	====> Epoch: 3200, cost 22.65 s
2024-01-02 15:15:48,456	44k	INFO	Train Epoch: 3201 [0%]
2024-01-02 15:15:48,459	44k	INFO	Losses: [2.3852806091308594, 2.4462099075317383, 7.061030864715576, 15.295272827148438, 0.16651193797588348], step: 83200, lr: 6.703032868472774e-05, reference_loss: 27.354305267333984
2024-01-02 15:15:53,910	44k	INFO	Saving model and optimizer state at iteration 3201 to ./logs/44k/G_83200.pth
2024-01-02 15:15:54,779	44k	INFO	Saving model and optimizer state at iteration 3201 to ./logs/44k/D_83200.pth
2024-01-02 15:15:55,276	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_80800.pth
2024-01-02 15:15:55,315	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_80800.pth
2024-01-02 15:16:17,087	44k	INFO	====> Epoch: 3201, cost 29.52 s
2024-01-02 15:16:39,889	44k	INFO	====> Epoch: 3202, cost 22.80 s
2024-01-02 15:17:02,701	44k	INFO	====> Epoch: 3203, cost 22.81 s
2024-01-02 15:17:25,511	44k	INFO	====> Epoch: 3204, cost 22.81 s
2024-01-02 15:17:48,259	44k	INFO	====> Epoch: 3205, cost 22.75 s
2024-01-02 15:18:10,902	44k	INFO	====> Epoch: 3206, cost 22.64 s
2024-01-02 15:18:33,593	44k	INFO	====> Epoch: 3207, cost 22.69 s
2024-01-02 15:18:50,341	44k	INFO	Train Epoch: 3208 [69%]
2024-01-02 15:18:50,344	44k	INFO	Losses: [2.318532943725586, 2.5261831283569336, 7.947289943695068, 15.732563972473145, 0.6273075938224792], step: 83400, lr: 6.69716991368736e-05, reference_loss: 29.151878356933594
2024-01-02 15:18:56,830	44k	INFO	====> Epoch: 3208, cost 23.24 s
2024-01-02 15:19:19,504	44k	INFO	====> Epoch: 3209, cost 22.67 s
2024-01-02 15:19:42,194	44k	INFO	====> Epoch: 3210, cost 22.69 s
2024-01-02 15:20:04,953	44k	INFO	====> Epoch: 3211, cost 22.76 s
2024-01-02 15:20:27,751	44k	INFO	====> Epoch: 3212, cost 22.80 s
2024-01-02 15:20:50,582	44k	INFO	====> Epoch: 3213, cost 22.83 s
2024-01-02 15:21:13,310	44k	INFO	====> Epoch: 3214, cost 22.73 s
2024-01-02 15:21:36,002	44k	INFO	====> Epoch: 3215, cost 22.69 s
2024-01-02 15:21:45,745	44k	INFO	Train Epoch: 3216 [38%]
2024-01-02 15:21:45,748	44k	INFO	Losses: [2.3106346130371094, 2.430755615234375, 8.436784744262695, 16.66050910949707, 0.2645299732685089], step: 83600, lr: 6.690475673053119e-05, reference_loss: 30.103214263916016
2024-01-02 15:21:59,058	44k	INFO	====> Epoch: 3216, cost 23.06 s
2024-01-02 15:22:21,904	44k	INFO	====> Epoch: 3217, cost 22.85 s
2024-01-02 15:22:44,565	44k	INFO	====> Epoch: 3218, cost 22.66 s
2024-01-02 15:23:07,295	44k	INFO	====> Epoch: 3219, cost 22.73 s
2024-01-02 15:23:30,153	44k	INFO	====> Epoch: 3220, cost 22.86 s
2024-01-02 15:23:53,014	44k	INFO	====> Epoch: 3221, cost 22.86 s
2024-01-02 15:24:15,863	44k	INFO	====> Epoch: 3222, cost 22.85 s
2024-01-02 15:24:38,675	44k	INFO	====> Epoch: 3223, cost 22.81 s
2024-01-02 15:24:41,351	44k	INFO	Train Epoch: 3224 [8%]
2024-01-02 15:24:41,354	44k	INFO	Losses: [2.453275203704834, 2.4186346530914307, 7.830697059631348, 15.969338417053223, 0.43663084506988525], step: 83800, lr: 6.683788123731515e-05, reference_loss: 29.10857582092285
2024-01-02 15:25:01,763	44k	INFO	====> Epoch: 3224, cost 23.09 s
2024-01-02 15:25:24,453	44k	INFO	====> Epoch: 3225, cost 22.69 s
2024-01-02 15:25:47,147	44k	INFO	====> Epoch: 3226, cost 22.69 s
2024-01-02 15:26:09,983	44k	INFO	====> Epoch: 3227, cost 22.84 s
2024-01-02 15:26:32,644	44k	INFO	====> Epoch: 3228, cost 22.66 s
2024-01-02 15:26:55,361	44k	INFO	====> Epoch: 3229, cost 22.72 s
2024-01-02 15:27:18,195	44k	INFO	====> Epoch: 3230, cost 22.83 s
2024-01-02 15:27:36,831	44k	INFO	Train Epoch: 3231 [77%]
2024-01-02 15:27:36,834	44k	INFO	Losses: [2.1481971740722656, 2.5783092975616455, 8.964736938476562, 16.98768424987793, 0.6854326128959656], step: 84000, lr: 6.677942001784383e-05, reference_loss: 31.364360809326172
2024-01-02 15:27:42,073	44k	INFO	Saving model and optimizer state at iteration 3231 to ./logs/44k/G_84000.pth
2024-01-02 15:27:42,939	44k	INFO	Saving model and optimizer state at iteration 3231 to ./logs/44k/D_84000.pth
2024-01-02 15:27:43,429	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_81600.pth
2024-01-02 15:27:43,468	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_81600.pth
2024-01-02 15:27:47,645	44k	INFO	====> Epoch: 3231, cost 29.45 s
2024-01-02 15:28:10,311	44k	INFO	====> Epoch: 3232, cost 22.67 s
2024-01-02 15:28:33,011	44k	INFO	====> Epoch: 3233, cost 22.70 s
2024-01-02 15:28:55,912	44k	INFO	====> Epoch: 3234, cost 22.90 s
2024-01-02 15:29:18,694	44k	INFO	====> Epoch: 3235, cost 22.78 s
2024-01-02 15:29:41,345	44k	INFO	====> Epoch: 3236, cost 22.65 s
2024-01-02 15:30:04,113	44k	INFO	====> Epoch: 3237, cost 22.77 s
2024-01-02 15:30:26,920	44k	INFO	====> Epoch: 3238, cost 22.81 s
2024-01-02 15:30:38,346	44k	INFO	Train Epoch: 3239 [46%]
2024-01-02 15:30:38,350	44k	INFO	Losses: [2.3007538318634033, 2.52764892578125, 8.629744529724121, 17.102834701538086, 0.33776402473449707], step: 84200, lr: 6.671266980651937e-05, reference_loss: 30.898746490478516
2024-01-02 15:30:50,034	44k	INFO	====> Epoch: 3239, cost 23.11 s
2024-01-02 15:31:12,715	44k	INFO	====> Epoch: 3240, cost 22.68 s
2024-01-02 15:31:35,342	44k	INFO	====> Epoch: 3241, cost 22.63 s
2024-01-02 15:31:57,868	44k	INFO	====> Epoch: 3242, cost 22.53 s
2024-01-02 15:32:20,589	44k	INFO	====> Epoch: 3243, cost 22.72 s
2024-01-02 15:32:43,374	44k	INFO	====> Epoch: 3244, cost 22.79 s
2024-01-02 15:33:06,295	44k	INFO	====> Epoch: 3245, cost 22.92 s
2024-01-02 15:33:29,134	44k	INFO	====> Epoch: 3246, cost 22.84 s
2024-01-02 15:33:33,563	44k	INFO	Train Epoch: 3247 [15%]
2024-01-02 15:33:33,566	44k	INFO	Losses: [2.297959804534912, 2.6813178062438965, 9.255230903625488, 16.58726692199707, 0.32553762197494507], step: 84400, lr: 6.664598631621032e-05, reference_loss: 31.14731216430664
2024-01-02 15:33:52,291	44k	INFO	====> Epoch: 3247, cost 23.16 s
2024-01-02 15:34:15,105	44k	INFO	====> Epoch: 3248, cost 22.81 s
2024-01-02 15:34:37,920	44k	INFO	====> Epoch: 3249, cost 22.82 s
2024-01-02 15:35:00,638	44k	INFO	====> Epoch: 3250, cost 22.72 s
2024-01-02 15:35:23,421	44k	INFO	====> Epoch: 3251, cost 22.78 s
2024-01-02 15:35:46,278	44k	INFO	====> Epoch: 3252, cost 22.86 s
2024-01-02 15:36:09,127	44k	INFO	====> Epoch: 3253, cost 22.85 s
2024-01-02 15:36:29,446	44k	INFO	Train Epoch: 3254 [85%]
2024-01-02 15:36:29,449	44k	INFO	Losses: [2.5121893882751465, 2.4529290199279785, 8.02226734161377, 15.1808443069458, 0.5194593667984009], step: 84600, lr: 6.658769294184256e-05, reference_loss: 28.68768882751465
2024-01-02 15:36:32,480	44k	INFO	====> Epoch: 3254, cost 23.35 s
2024-01-02 15:36:55,310	44k	INFO	====> Epoch: 3255, cost 22.83 s
2024-01-02 15:37:18,084	44k	INFO	====> Epoch: 3256, cost 22.77 s
2024-01-02 15:37:40,847	44k	INFO	====> Epoch: 3257, cost 22.76 s
2024-01-02 15:38:03,652	44k	INFO	====> Epoch: 3258, cost 22.81 s
2024-01-02 15:38:26,240	44k	INFO	====> Epoch: 3259, cost 22.59 s
2024-01-02 15:38:48,898	44k	INFO	====> Epoch: 3260, cost 22.66 s
2024-01-02 15:39:11,553	44k	INFO	====> Epoch: 3261, cost 22.66 s
2024-01-02 15:39:24,713	44k	INFO	Train Epoch: 3262 [54%]
2024-01-02 15:39:24,716	44k	INFO	Losses: [2.5447118282318115, 2.349468469619751, 7.3095784187316895, 15.5100736618042, 0.23707237839698792], step: 84800, lr: 6.652113437373445e-05, reference_loss: 27.950904846191406
2024-01-02 15:39:30,090	44k	INFO	Saving model and optimizer state at iteration 3262 to ./logs/44k/G_84800.pth
2024-01-02 15:39:31,144	44k	INFO	Saving model and optimizer state at iteration 3262 to ./logs/44k/D_84800.pth
2024-01-02 15:39:31,634	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_82400.pth
2024-01-02 15:39:31,673	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_82400.pth
2024-01-02 15:39:41,184	44k	INFO	====> Epoch: 3262, cost 29.63 s
2024-01-02 15:40:04,018	44k	INFO	====> Epoch: 3263, cost 22.83 s
2024-01-02 15:40:26,884	44k	INFO	====> Epoch: 3264, cost 22.87 s
2024-01-02 15:40:49,666	44k	INFO	====> Epoch: 3265, cost 22.78 s
2024-01-02 15:41:12,466	44k	INFO	====> Epoch: 3266, cost 22.80 s
2024-01-02 15:41:35,115	44k	INFO	====> Epoch: 3267, cost 22.65 s
2024-01-02 15:41:57,762	44k	INFO	====> Epoch: 3268, cost 22.65 s
2024-01-02 15:42:20,427	44k	INFO	====> Epoch: 3269, cost 22.67 s
2024-01-02 15:42:26,621	44k	INFO	Train Epoch: 3270 [23%]
2024-01-02 15:42:26,624	44k	INFO	Losses: [2.542609214782715, 2.1847047805786133, 6.377007484436035, 14.39557933807373, 0.4328874349594116], step: 85000, lr: 6.645464233508238e-05, reference_loss: 25.932788848876953
2024-01-02 15:42:43,521	44k	INFO	====> Epoch: 3270, cost 23.09 s
2024-01-02 15:43:06,323	44k	INFO	====> Epoch: 3271, cost 22.80 s
2024-01-02 15:43:28,966	44k	INFO	====> Epoch: 3272, cost 22.64 s
2024-01-02 15:43:51,528	44k	INFO	====> Epoch: 3273, cost 22.56 s
2024-01-02 15:44:14,147	44k	INFO	====> Epoch: 3274, cost 22.62 s
2024-01-02 15:44:36,988	44k	INFO	====> Epoch: 3275, cost 22.84 s
2024-01-02 15:44:59,785	44k	INFO	====> Epoch: 3276, cost 22.80 s
2024-01-02 15:45:21,883	44k	INFO	Train Epoch: 3277 [92%]
2024-01-02 15:45:21,886	44k	INFO	Losses: [2.3335788249969482, 2.8014907836914062, 8.409698486328125, 18.45502281188965, 0.5389693379402161], step: 85200, lr: 6.639651632392645e-05, reference_loss: 32.538761138916016
2024-01-02 15:45:22,966	44k	INFO	====> Epoch: 3277, cost 23.18 s
2024-01-02 15:45:45,795	44k	INFO	====> Epoch: 3278, cost 22.83 s
2024-01-02 15:46:08,598	44k	INFO	====> Epoch: 3279, cost 22.80 s
2024-01-02 15:46:31,592	44k	INFO	====> Epoch: 3280, cost 22.99 s
2024-01-02 15:46:54,418	44k	INFO	====> Epoch: 3281, cost 22.83 s
2024-01-02 15:47:17,245	44k	INFO	====> Epoch: 3282, cost 22.83 s
2024-01-02 15:47:40,049	44k	INFO	====> Epoch: 3283, cost 22.80 s
2024-01-02 15:48:02,897	44k	INFO	====> Epoch: 3284, cost 22.85 s
2024-01-02 15:48:17,917	44k	INFO	Train Epoch: 3285 [62%]
2024-01-02 15:48:17,920	44k	INFO	Losses: [2.2695817947387695, 2.729417324066162, 7.782007694244385, 15.901674270629883, 0.2653047740459442], step: 85400, lr: 6.633014884881741e-05, reference_loss: 28.947986602783203
2024-01-02 15:48:26,019	44k	INFO	====> Epoch: 3285, cost 23.12 s
2024-01-02 15:48:48,688	44k	INFO	====> Epoch: 3286, cost 22.67 s
2024-01-02 15:49:11,368	44k	INFO	====> Epoch: 3287, cost 22.68 s
2024-01-02 15:49:34,068	44k	INFO	====> Epoch: 3288, cost 22.70 s
2024-01-02 15:49:56,747	44k	INFO	====> Epoch: 3289, cost 22.68 s
2024-01-02 15:50:19,537	44k	INFO	====> Epoch: 3290, cost 22.79 s
2024-01-02 15:50:42,221	44k	INFO	====> Epoch: 3291, cost 22.68 s
2024-01-02 15:51:05,024	44k	INFO	====> Epoch: 3292, cost 22.80 s
2024-01-02 15:51:13,042	44k	INFO	Train Epoch: 3293 [31%]
2024-01-02 15:51:13,045	44k	INFO	Losses: [2.3022890090942383, 2.6270689964294434, 6.855942726135254, 14.139585494995117, 0.5440973043441772], step: 85600, lr: 6.626384771215495e-05, reference_loss: 26.468984603881836
2024-01-02 15:51:18,306	44k	INFO	Saving model and optimizer state at iteration 3293 to ./logs/44k/G_85600.pth
2024-01-02 15:51:19,182	44k	INFO	Saving model and optimizer state at iteration 3293 to ./logs/44k/D_85600.pth
2024-01-02 15:51:19,671	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_83200.pth
2024-01-02 15:51:19,710	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_83200.pth
2024-01-02 15:51:34,358	44k	INFO	====> Epoch: 3293, cost 29.33 s
2024-01-02 15:51:57,080	44k	INFO	====> Epoch: 3294, cost 22.72 s
2024-01-02 15:52:19,864	44k	INFO	====> Epoch: 3295, cost 22.78 s
2024-01-02 15:52:42,573	44k	INFO	====> Epoch: 3296, cost 22.71 s
2024-01-02 15:53:05,551	44k	INFO	====> Epoch: 3297, cost 22.98 s
2024-01-02 15:53:28,313	44k	INFO	====> Epoch: 3298, cost 22.76 s
2024-01-02 15:53:51,102	44k	INFO	====> Epoch: 3299, cost 22.79 s
2024-01-02 15:54:13,857	44k	INFO	====> Epoch: 3300, cost 22.75 s
2024-01-02 15:54:14,747	44k	INFO	Train Epoch: 3301 [0%]
2024-01-02 15:54:14,750	44k	INFO	Losses: [2.1854474544525146, 2.573606252670288, 8.323416709899902, 15.36102294921875, 0.22845706343650818], step: 85800, lr: 6.619761284762966e-05, reference_loss: 28.67194938659668
2024-01-02 15:54:37,021	44k	INFO	====> Epoch: 3301, cost 23.16 s
2024-01-02 15:54:59,676	44k	INFO	====> Epoch: 3302, cost 22.66 s
2024-01-02 15:55:22,262	44k	INFO	====> Epoch: 3303, cost 22.59 s
2024-01-02 15:55:44,890	44k	INFO	====> Epoch: 3304, cost 22.63 s
2024-01-02 15:56:07,699	44k	INFO	====> Epoch: 3305, cost 22.81 s
2024-01-02 15:56:30,455	44k	INFO	====> Epoch: 3306, cost 22.76 s
2024-01-02 15:56:53,149	44k	INFO	====> Epoch: 3307, cost 22.69 s
2024-01-02 15:57:10,015	44k	INFO	Train Epoch: 3308 [69%]
2024-01-02 15:57:10,018	44k	INFO	Losses: [2.324524164199829, 2.4620110988616943, 7.651331901550293, 16.441146850585938, 0.42240679264068604], step: 86000, lr: 6.613971165295502e-05, reference_loss: 29.301420211791992
2024-01-02 15:57:16,416	44k	INFO	====> Epoch: 3308, cost 23.27 s
2024-01-02 15:57:39,002	44k	INFO	====> Epoch: 3309, cost 22.59 s
2024-01-02 15:58:01,767	44k	INFO	====> Epoch: 3310, cost 22.76 s
2024-01-02 15:58:24,450	44k	INFO	====> Epoch: 3311, cost 22.68 s
2024-01-02 15:58:47,021	44k	INFO	====> Epoch: 3312, cost 22.57 s
2024-01-02 15:59:09,629	44k	INFO	====> Epoch: 3313, cost 22.61 s
2024-01-02 15:59:32,223	44k	INFO	====> Epoch: 3314, cost 22.59 s
2024-01-02 15:59:54,837	44k	INFO	====> Epoch: 3315, cost 22.61 s
2024-01-02 16:00:04,561	44k	INFO	Train Epoch: 3316 [38%]
2024-01-02 16:00:04,564	44k	INFO	Losses: [2.320666790008545, 2.314385414123535, 8.908288955688477, 15.950180053710938, 0.37790873646736145], step: 86200, lr: 6.607360087019297e-05, reference_loss: 29.871429443359375
2024-01-02 16:00:18,010	44k	INFO	====> Epoch: 3316, cost 23.17 s
2024-01-02 16:00:40,493	44k	INFO	====> Epoch: 3317, cost 22.48 s
2024-01-02 16:01:03,144	44k	INFO	====> Epoch: 3318, cost 22.65 s
2024-01-02 16:01:25,742	44k	INFO	====> Epoch: 3319, cost 22.60 s
2024-01-02 16:01:48,367	44k	INFO	====> Epoch: 3320, cost 22.62 s
2024-01-02 16:02:10,984	44k	INFO	====> Epoch: 3321, cost 22.62 s
2024-01-02 16:02:33,568	44k	INFO	====> Epoch: 3322, cost 22.58 s
2024-01-02 16:02:56,032	44k	INFO	====> Epoch: 3323, cost 22.46 s
2024-01-02 16:02:58,663	44k	INFO	Train Epoch: 3324 [8%]
2024-01-02 16:02:58,666	44k	INFO	Losses: [2.114715814590454, 2.6463894844055176, 9.164884567260742, 18.14697265625, 0.23889054358005524], step: 86400, lr: 6.600755616929747e-05, reference_loss: 32.31185531616211
2024-01-02 16:03:04,007	44k	INFO	Saving model and optimizer state at iteration 3324 to ./logs/44k/G_86400.pth
2024-01-02 16:03:05,041	44k	INFO	Saving model and optimizer state at iteration 3324 to ./logs/44k/D_86400.pth
2024-01-02 16:03:05,528	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_84000.pth
2024-01-02 16:03:05,567	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_84000.pth
2024-01-02 16:03:25,492	44k	INFO	====> Epoch: 3324, cost 29.46 s
2024-01-02 16:03:47,918	44k	INFO	====> Epoch: 3325, cost 22.43 s
2024-01-02 16:04:10,363	44k	INFO	====> Epoch: 3326, cost 22.45 s
2024-01-02 16:04:32,955	44k	INFO	====> Epoch: 3327, cost 22.59 s
2024-01-02 16:04:55,491	44k	INFO	====> Epoch: 3328, cost 22.54 s
2024-01-02 16:05:17,929	44k	INFO	====> Epoch: 3329, cost 22.44 s
2024-01-02 16:05:40,374	44k	INFO	====> Epoch: 3330, cost 22.44 s
2024-01-02 16:05:58,696	44k	INFO	Train Epoch: 3331 [77%]
2024-01-02 16:05:58,699	44k	INFO	Losses: [2.231668710708618, 2.5261123180389404, 7.41083288192749, 15.312108039855957, 0.5056785941123962], step: 86600, lr: 6.594982121186702e-05, reference_loss: 27.986398696899414
2024-01-02 16:06:03,208	44k	INFO	====> Epoch: 3331, cost 22.83 s
2024-01-02 16:06:25,662	44k	INFO	====> Epoch: 3332, cost 22.45 s
2024-01-02 16:06:48,230	44k	INFO	====> Epoch: 3333, cost 22.57 s
2024-01-02 16:07:10,705	44k	INFO	====> Epoch: 3334, cost 22.47 s
2024-01-02 16:07:33,296	44k	INFO	====> Epoch: 3335, cost 22.59 s
2024-01-02 16:07:55,846	44k	INFO	====> Epoch: 3336, cost 22.55 s
2024-01-02 16:08:18,468	44k	INFO	====> Epoch: 3337, cost 22.62 s
2024-01-02 16:08:41,183	44k	INFO	====> Epoch: 3338, cost 22.72 s
2024-01-02 16:08:52,672	44k	INFO	Train Epoch: 3339 [46%]
2024-01-02 16:08:52,675	44k	INFO	Losses: [2.334547281265259, 2.632366180419922, 7.258720397949219, 15.37346363067627, 0.30052629113197327], step: 86800, lr: 6.588390023648978e-05, reference_loss: 27.89962387084961
2024-01-02 16:09:04,468	44k	INFO	====> Epoch: 3339, cost 23.28 s
2024-01-02 16:09:27,262	44k	INFO	====> Epoch: 3340, cost 22.79 s
2024-01-02 16:09:49,915	44k	INFO	====> Epoch: 3341, cost 22.65 s
2024-01-02 16:10:12,490	44k	INFO	====> Epoch: 3342, cost 22.57 s
2024-01-02 16:10:35,248	44k	INFO	====> Epoch: 3343, cost 22.76 s
2024-01-02 16:10:57,944	44k	INFO	====> Epoch: 3344, cost 22.70 s
2024-01-02 16:11:20,626	44k	INFO	====> Epoch: 3345, cost 22.68 s
2024-01-02 16:11:43,285	44k	INFO	====> Epoch: 3346, cost 22.66 s
2024-01-02 16:11:47,711	44k	INFO	Train Epoch: 3347 [15%]
2024-01-02 16:11:47,714	44k	INFO	Losses: [2.3026797771453857, 2.595522403717041, 7.130158424377441, 15.067992210388184, 0.3877546489238739], step: 87000, lr: 6.581804515325472e-05, reference_loss: 27.484106063842773
2024-01-02 16:12:06,435	44k	INFO	====> Epoch: 3347, cost 23.15 s
2024-01-02 16:12:29,098	44k	INFO	====> Epoch: 3348, cost 22.66 s
2024-01-02 16:12:51,779	44k	INFO	====> Epoch: 3349, cost 22.68 s
2024-01-02 16:13:14,345	44k	INFO	====> Epoch: 3350, cost 22.57 s
2024-01-02 16:13:36,939	44k	INFO	====> Epoch: 3351, cost 22.59 s
2024-01-02 16:13:59,621	44k	INFO	====> Epoch: 3352, cost 22.68 s
2024-01-02 16:14:22,537	44k	INFO	====> Epoch: 3353, cost 22.92 s
2024-01-02 16:14:42,865	44k	INFO	Train Epoch: 3354 [85%]
2024-01-02 16:14:42,868	44k	INFO	Losses: [2.4236395359039307, 2.3805646896362305, 7.730490684509277, 15.760293006896973, 0.5014579892158508], step: 87200, lr: 6.576047595579296e-05, reference_loss: 28.796443939208984
2024-01-02 16:14:48,390	44k	INFO	Saving model and optimizer state at iteration 3354 to ./logs/44k/G_87200.pth
2024-01-02 16:14:49,271	44k	INFO	Saving model and optimizer state at iteration 3354 to ./logs/44k/D_87200.pth
2024-01-02 16:14:49,771	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_84800.pth
2024-01-02 16:14:49,811	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_84800.pth
2024-01-02 16:14:52,275	44k	INFO	====> Epoch: 3354, cost 29.74 s
2024-01-02 16:15:14,954	44k	INFO	====> Epoch: 3355, cost 22.68 s
2024-01-02 16:15:37,646	44k	INFO	====> Epoch: 3356, cost 22.69 s
2024-01-02 16:16:00,184	44k	INFO	====> Epoch: 3357, cost 22.54 s
2024-01-02 16:16:22,763	44k	INFO	====> Epoch: 3358, cost 22.58 s
2024-01-02 16:16:45,429	44k	INFO	====> Epoch: 3359, cost 22.67 s
2024-01-02 16:17:08,319	44k	INFO	====> Epoch: 3360, cost 22.89 s
2024-01-02 16:17:31,174	44k	INFO	====> Epoch: 3361, cost 22.86 s
2024-01-02 16:17:44,482	44k	INFO	Train Epoch: 3362 [54%]
2024-01-02 16:17:44,485	44k	INFO	Losses: [2.1452486515045166, 2.7595698833465576, 8.630086898803711, 16.309709548950195, 0.7082303166389465], step: 87400, lr: 6.569474424285396e-05, reference_loss: 30.552846908569336
2024-01-02 16:17:54,462	44k	INFO	====> Epoch: 3362, cost 23.29 s
2024-01-02 16:18:17,261	44k	INFO	====> Epoch: 3363, cost 22.80 s
2024-01-02 16:18:40,136	44k	INFO	====> Epoch: 3364, cost 22.88 s
2024-01-02 16:19:03,050	44k	INFO	====> Epoch: 3365, cost 22.91 s
2024-01-02 16:19:26,004	44k	INFO	====> Epoch: 3366, cost 22.95 s
2024-01-02 16:19:48,915	44k	INFO	====> Epoch: 3367, cost 22.91 s
2024-01-02 16:20:11,667	44k	INFO	====> Epoch: 3368, cost 22.75 s
2024-01-02 16:20:34,471	44k	INFO	====> Epoch: 3369, cost 22.80 s
2024-01-02 16:20:40,706	44k	INFO	Train Epoch: 3370 [23%]
2024-01-02 16:20:40,709	44k	INFO	Losses: [2.335737943649292, 2.6885969638824463, 7.710246562957764, 14.753166198730469, 0.34474748373031616], step: 87600, lr: 6.562907823287746e-05, reference_loss: 27.832494735717773
2024-01-02 16:20:57,974	44k	INFO	====> Epoch: 3370, cost 23.50 s
2024-01-02 16:21:20,772	44k	INFO	====> Epoch: 3371, cost 22.80 s
2024-01-02 16:21:43,541	44k	INFO	====> Epoch: 3372, cost 22.77 s
2024-01-02 16:22:06,127	44k	INFO	====> Epoch: 3373, cost 22.59 s
2024-01-02 16:22:28,738	44k	INFO	====> Epoch: 3374, cost 22.61 s
2024-01-02 16:22:51,374	44k	INFO	====> Epoch: 3375, cost 22.64 s
2024-01-02 16:23:14,011	44k	INFO	====> Epoch: 3376, cost 22.64 s
2024-01-02 16:23:35,949	44k	INFO	Train Epoch: 3377 [92%]
2024-01-02 16:23:35,951	44k	INFO	Losses: [2.2589426040649414, 2.6872410774230957, 8.091120719909668, 16.137990951538086, 0.4263860285282135], step: 87800, lr: 6.557167431947916e-05, reference_loss: 29.601680755615234
2024-01-02 16:23:37,051	44k	INFO	====> Epoch: 3377, cost 23.04 s
2024-01-02 16:23:59,715	44k	INFO	====> Epoch: 3378, cost 22.66 s
2024-01-02 16:24:22,512	44k	INFO	====> Epoch: 3379, cost 22.80 s
2024-01-02 16:24:45,248	44k	INFO	====> Epoch: 3380, cost 22.74 s
2024-01-02 16:25:07,878	44k	INFO	====> Epoch: 3381, cost 22.63 s
2024-01-02 16:25:30,518	44k	INFO	====> Epoch: 3382, cost 22.64 s
2024-01-02 16:25:53,198	44k	INFO	====> Epoch: 3383, cost 22.68 s
2024-01-02 16:26:15,999	44k	INFO	====> Epoch: 3384, cost 22.80 s
2024-01-02 16:26:31,008	44k	INFO	Train Epoch: 3385 [62%]
2024-01-02 16:26:31,011	44k	INFO	Losses: [2.396118402481079, 2.3535945415496826, 7.1435675621032715, 14.205326080322266, 0.34426814317703247], step: 88000, lr: 6.550613132559641e-05, reference_loss: 26.442874908447266
2024-01-02 16:26:36,336	44k	INFO	Saving model and optimizer state at iteration 3385 to ./logs/44k/G_88000.pth
2024-01-02 16:26:37,214	44k	INFO	Saving model and optimizer state at iteration 3385 to ./logs/44k/D_88000.pth
2024-01-02 16:26:37,705	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_85600.pth
2024-01-02 16:26:37,744	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_85600.pth
2024-01-02 16:26:45,503	44k	INFO	====> Epoch: 3385, cost 29.50 s
2024-01-02 16:27:08,402	44k	INFO	====> Epoch: 3386, cost 22.90 s
2024-01-02 16:27:31,151	44k	INFO	====> Epoch: 3387, cost 22.75 s
2024-01-02 16:27:53,995	44k	INFO	====> Epoch: 3388, cost 22.84 s
2024-01-02 16:28:16,832	44k	INFO	====> Epoch: 3389, cost 22.84 s
2024-01-02 16:28:39,651	44k	INFO	====> Epoch: 3390, cost 22.82 s
2024-01-02 16:29:02,464	44k	INFO	====> Epoch: 3391, cost 22.81 s
2024-01-02 16:29:25,226	44k	INFO	====> Epoch: 3392, cost 22.76 s
2024-01-02 16:29:33,189	44k	INFO	Train Epoch: 3393 [31%]
2024-01-02 16:29:33,192	44k	INFO	Losses: [2.2213563919067383, 2.6202895641326904, 8.322589874267578, 16.115520477294922, 0.3867315351963043], step: 88200, lr: 6.544065384603963e-05, reference_loss: 29.666488647460938
2024-01-02 16:29:48,221	44k	INFO	====> Epoch: 3393, cost 23.00 s
2024-01-02 16:30:10,817	44k	INFO	====> Epoch: 3394, cost 22.60 s
2024-01-02 16:30:33,503	44k	INFO	====> Epoch: 3395, cost 22.69 s
2024-01-02 16:30:56,335	44k	INFO	====> Epoch: 3396, cost 22.83 s
2024-01-02 16:31:19,109	44k	INFO	====> Epoch: 3397, cost 22.77 s
2024-01-02 16:31:42,009	44k	INFO	====> Epoch: 3398, cost 22.90 s
2024-01-02 16:32:04,841	44k	INFO	====> Epoch: 3399, cost 22.83 s
2024-01-02 16:32:27,663	44k	INFO	====> Epoch: 3400, cost 22.82 s
2024-01-02 16:32:28,553	44k	INFO	Train Epoch: 3401 [0%]
2024-01-02 16:32:28,556	44k	INFO	Losses: [2.2342333793640137, 2.5882296562194824, 8.344179153442383, 15.87578010559082, 0.2993581295013428], step: 88400, lr: 6.537524181532318e-05, reference_loss: 29.341781616210938
2024-01-02 16:32:50,761	44k	INFO	====> Epoch: 3401, cost 23.10 s
2024-01-02 16:33:13,439	44k	INFO	====> Epoch: 3402, cost 22.68 s
2024-01-02 16:33:36,100	44k	INFO	====> Epoch: 3403, cost 22.66 s
2024-01-02 16:33:58,779	44k	INFO	====> Epoch: 3404, cost 22.68 s
2024-01-02 16:34:21,560	44k	INFO	====> Epoch: 3405, cost 22.78 s
2024-01-02 16:34:44,106	44k	INFO	====> Epoch: 3406, cost 22.55 s
2024-01-02 16:35:06,722	44k	INFO	====> Epoch: 3407, cost 22.62 s
2024-01-02 16:35:23,687	44k	INFO	Train Epoch: 3408 [69%]
2024-01-02 16:35:23,691	44k	INFO	Losses: [2.151543378829956, 3.117727279663086, 10.370994567871094, 17.779918670654297, 0.388128399848938], step: 88600, lr: 6.531805992551754e-05, reference_loss: 33.80831527709961
2024-01-02 16:35:30,042	44k	INFO	====> Epoch: 3408, cost 23.32 s
2024-01-02 16:35:52,842	44k	INFO	====> Epoch: 3409, cost 22.80 s
2024-01-02 16:36:15,623	44k	INFO	====> Epoch: 3410, cost 22.78 s
2024-01-02 16:36:38,275	44k	INFO	====> Epoch: 3411, cost 22.65 s
2024-01-02 16:37:00,926	44k	INFO	====> Epoch: 3412, cost 22.65 s
2024-01-02 16:37:23,568	44k	INFO	====> Epoch: 3413, cost 22.64 s
2024-01-02 16:37:46,213	44k	INFO	====> Epoch: 3414, cost 22.64 s
2024-01-02 16:38:09,038	44k	INFO	====> Epoch: 3415, cost 22.83 s
2024-01-02 16:38:18,809	44k	INFO	Train Epoch: 3416 [38%]
2024-01-02 16:38:18,812	44k	INFO	Losses: [2.496406316757202, 2.267345428466797, 6.734530925750732, 14.706847190856934, 0.5099329352378845], step: 88800, lr: 6.525277043510016e-05, reference_loss: 26.715065002441406
2024-01-02 16:38:24,214	44k	INFO	Saving model and optimizer state at iteration 3416 to ./logs/44k/G_88800.pth
2024-01-02 16:38:25,083	44k	INFO	Saving model and optimizer state at iteration 3416 to ./logs/44k/D_88800.pth
2024-01-02 16:38:25,584	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_86400.pth
2024-01-02 16:38:25,623	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_86400.pth
2024-01-02 16:38:38,467	44k	INFO	====> Epoch: 3416, cost 29.43 s
2024-01-02 16:39:00,954	44k	INFO	====> Epoch: 3417, cost 22.49 s
2024-01-02 16:39:23,512	44k	INFO	====> Epoch: 3418, cost 22.56 s
2024-01-02 16:39:46,095	44k	INFO	====> Epoch: 3419, cost 22.58 s
2024-01-02 16:40:08,648	44k	INFO	====> Epoch: 3420, cost 22.55 s
2024-01-02 16:40:31,275	44k	INFO	====> Epoch: 3421, cost 22.63 s
2024-01-02 16:40:54,298	44k	INFO	====> Epoch: 3422, cost 23.02 s
2024-01-02 16:41:17,349	44k	INFO	====> Epoch: 3423, cost 23.05 s
2024-01-02 16:41:20,055	44k	INFO	Train Epoch: 3424 [8%]
2024-01-02 16:41:20,056	44k	INFO	Losses: [2.301229953765869, 2.435647964477539, 7.29212760925293, 15.218986511230469, 0.29683566093444824], step: 89000, lr: 6.51875462056162e-05, reference_loss: 27.54482650756836
2024-01-02 16:41:41,042	44k	INFO	====> Epoch: 3424, cost 23.69 s
2024-01-02 16:42:04,114	44k	INFO	====> Epoch: 3425, cost 23.07 s
2024-01-02 16:42:27,232	44k	INFO	====> Epoch: 3426, cost 23.12 s
2024-01-02 16:42:50,368	44k	INFO	====> Epoch: 3427, cost 23.14 s
2024-01-02 16:43:13,461	44k	INFO	====> Epoch: 3428, cost 23.09 s
2024-01-02 16:43:36,629	44k	INFO	====> Epoch: 3429, cost 23.17 s
2024-01-02 16:43:59,838	44k	INFO	====> Epoch: 3430, cost 23.21 s
2024-01-02 16:44:18,821	44k	INFO	Train Epoch: 3431 [77%]
2024-01-02 16:44:18,823	44k	INFO	Losses: [2.3250911235809326, 2.4088783264160156, 9.659996032714844, 17.592267990112305, 0.403364360332489], step: 89200, lr: 6.513052848789427e-05, reference_loss: 32.38959884643555
2024-01-02 16:44:23,489	44k	INFO	====> Epoch: 3431, cost 23.65 s
2024-01-02 16:44:46,654	44k	INFO	====> Epoch: 3432, cost 23.17 s
2024-01-02 16:45:09,922	44k	INFO	====> Epoch: 3433, cost 23.27 s
2024-01-02 16:45:33,082	44k	INFO	====> Epoch: 3434, cost 23.16 s
2024-01-02 16:45:56,166	44k	INFO	====> Epoch: 3435, cost 23.08 s
2024-01-02 16:46:19,317	44k	INFO	====> Epoch: 3436, cost 23.15 s
2024-01-02 16:46:42,241	44k	INFO	====> Epoch: 3437, cost 22.92 s
2024-01-02 16:47:05,021	44k	INFO	====> Epoch: 3438, cost 22.78 s
2024-01-02 16:47:16,515	44k	INFO	Train Epoch: 3439 [46%]
2024-01-02 16:47:16,518	44k	INFO	Losses: [2.372225046157837, 2.3816628456115723, 8.081690788269043, 16.24229621887207, 0.3841554820537567], step: 89400, lr: 6.506542644689001e-05, reference_loss: 29.4620304107666
2024-01-02 16:47:28,149	44k	INFO	====> Epoch: 3439, cost 23.13 s
2024-01-02 16:47:50,815	44k	INFO	====> Epoch: 3440, cost 22.67 s
2024-01-02 16:48:13,621	44k	INFO	====> Epoch: 3441, cost 22.81 s
2024-01-02 16:48:36,490	44k	INFO	====> Epoch: 3442, cost 22.87 s
2024-01-02 16:48:59,513	44k	INFO	====> Epoch: 3443, cost 23.02 s
2024-01-02 16:49:22,342	44k	INFO	====> Epoch: 3444, cost 22.83 s
2024-01-02 16:49:45,151	44k	INFO	====> Epoch: 3445, cost 22.81 s
2024-01-02 16:50:07,892	44k	INFO	====> Epoch: 3446, cost 22.74 s
2024-01-02 16:50:12,321	44k	INFO	Train Epoch: 3447 [15%]
2024-01-02 16:50:12,324	44k	INFO	Losses: [2.296231746673584, 2.650268077850342, 9.382040977478027, 17.018352508544922, 0.3208043873310089], step: 89600, lr: 6.500038947945175e-05, reference_loss: 31.66769790649414
2024-01-02 16:50:17,695	44k	INFO	Saving model and optimizer state at iteration 3447 to ./logs/44k/G_89600.pth
2024-01-02 16:50:18,549	44k	INFO	Saving model and optimizer state at iteration 3447 to ./logs/44k/D_89600.pth
2024-01-02 16:50:19,047	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_87200.pth
2024-01-02 16:50:19,086	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_87200.pth
2024-01-02 16:50:37,311	44k	INFO	====> Epoch: 3447, cost 29.42 s
2024-01-02 16:51:00,046	44k	INFO	====> Epoch: 3448, cost 22.74 s
2024-01-02 16:51:22,692	44k	INFO	====> Epoch: 3449, cost 22.65 s
2024-01-02 16:51:45,507	44k	INFO	====> Epoch: 3450, cost 22.82 s
2024-01-02 16:52:08,218	44k	INFO	====> Epoch: 3451, cost 22.71 s
2024-01-02 16:52:30,880	44k	INFO	====> Epoch: 3452, cost 22.66 s
2024-01-02 16:52:53,650	44k	INFO	====> Epoch: 3453, cost 22.77 s
2024-01-02 16:53:13,933	44k	INFO	Train Epoch: 3454 [85%]
2024-01-02 16:53:13,936	44k	INFO	Losses: [2.2866971492767334, 2.6972384452819824, 6.862656116485596, 15.087862014770508, 0.45718854665756226], step: 89800, lr: 6.494353546246716e-05, reference_loss: 27.39164161682129
2024-01-02 16:53:16,793	44k	INFO	====> Epoch: 3454, cost 23.14 s
2024-01-02 16:53:39,629	44k	INFO	====> Epoch: 3455, cost 22.84 s
2024-01-02 16:54:02,378	44k	INFO	====> Epoch: 3456, cost 22.75 s
2024-01-02 16:54:25,092	44k	INFO	====> Epoch: 3457, cost 22.71 s
2024-01-02 16:54:47,911	44k	INFO	====> Epoch: 3458, cost 22.82 s
2024-01-02 16:55:10,590	44k	INFO	====> Epoch: 3459, cost 22.68 s
2024-01-02 16:55:33,225	44k	INFO	====> Epoch: 3460, cost 22.64 s
2024-01-02 16:55:56,120	44k	INFO	====> Epoch: 3461, cost 22.89 s
2024-01-02 16:56:09,310	44k	INFO	Train Epoch: 3462 [54%]
2024-01-02 16:56:09,313	44k	INFO	Losses: [2.1858105659484863, 2.8377151489257812, 8.37344741821289, 15.99891185760498, 0.4529920816421509], step: 90000, lr: 6.487862033269936e-05, reference_loss: 29.848876953125
2024-01-02 16:56:19,145	44k	INFO	====> Epoch: 3462, cost 23.03 s
2024-01-02 16:56:41,830	44k	INFO	====> Epoch: 3463, cost 22.69 s
2024-01-02 16:57:04,639	44k	INFO	====> Epoch: 3464, cost 22.81 s
2024-01-02 16:57:27,287	44k	INFO	====> Epoch: 3465, cost 22.65 s
2024-01-02 16:57:49,870	44k	INFO	====> Epoch: 3466, cost 22.58 s
2024-01-02 16:58:12,522	44k	INFO	====> Epoch: 3467, cost 22.65 s
2024-01-02 16:58:35,225	44k	INFO	====> Epoch: 3468, cost 22.70 s
2024-01-02 16:58:57,913	44k	INFO	====> Epoch: 3469, cost 22.69 s
2024-01-02 16:59:04,110	44k	INFO	Train Epoch: 3470 [23%]
2024-01-02 16:59:04,113	44k	INFO	Losses: [2.387911081314087, 2.4741806983947754, 7.340646743774414, 13.354155540466309, 0.33255934715270996], step: 90200, lr: 6.481377008966802e-05, reference_loss: 25.889453887939453
2024-01-02 16:59:21,083	44k	INFO	====> Epoch: 3470, cost 23.17 s
2024-01-02 16:59:43,809	44k	INFO	====> Epoch: 3471, cost 22.73 s
2024-01-02 17:00:06,558	44k	INFO	====> Epoch: 3472, cost 22.75 s
2024-01-02 17:00:29,256	44k	INFO	====> Epoch: 3473, cost 22.70 s
2024-01-02 17:00:52,096	44k	INFO	====> Epoch: 3474, cost 22.84 s
2024-01-02 17:01:14,931	44k	INFO	====> Epoch: 3475, cost 22.84 s
2024-01-02 17:01:37,768	44k	INFO	====> Epoch: 3476, cost 22.84 s
2024-01-02 17:01:59,923	44k	INFO	Train Epoch: 3477 [92%]
2024-01-02 17:01:59,926	44k	INFO	Losses: [2.4292585849761963, 2.2596676349639893, 6.943340301513672, 15.611275672912598, 0.4923604726791382], step: 90400, lr: 6.475707930342779e-05, reference_loss: 27.735902786254883
2024-01-02 17:02:05,185	44k	INFO	Saving model and optimizer state at iteration 3477 to ./logs/44k/G_90400.pth
2024-01-02 17:02:06,238	44k	INFO	Saving model and optimizer state at iteration 3477 to ./logs/44k/D_90400.pth
2024-01-02 17:02:06,726	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_88000.pth
2024-01-02 17:02:06,765	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_88000.pth
2024-01-02 17:02:07,458	44k	INFO	====> Epoch: 3477, cost 29.69 s
2024-01-02 17:02:30,205	44k	INFO	====> Epoch: 3478, cost 22.75 s
2024-01-02 17:02:52,920	44k	INFO	====> Epoch: 3479, cost 22.71 s
2024-01-02 17:03:15,559	44k	INFO	====> Epoch: 3480, cost 22.64 s
2024-01-02 17:03:38,310	44k	INFO	====> Epoch: 3481, cost 22.75 s
2024-01-02 17:04:01,128	44k	INFO	====> Epoch: 3482, cost 22.82 s
2024-01-02 17:04:23,960	44k	INFO	====> Epoch: 3483, cost 22.83 s
2024-01-02 17:04:46,809	44k	INFO	====> Epoch: 3484, cost 22.85 s
2024-01-02 17:05:01,897	44k	INFO	Train Epoch: 3485 [62%]
2024-01-02 17:05:01,900	44k	INFO	Losses: [2.5084376335144043, 2.2639517784118652, 6.202121257781982, 13.526986122131348, 0.6543265581130981], step: 90600, lr: 6.469235054826482e-05, reference_loss: 25.15582275390625
2024-01-02 17:05:10,017	44k	INFO	====> Epoch: 3485, cost 23.21 s
2024-01-02 17:05:32,841	44k	INFO	====> Epoch: 3486, cost 22.82 s
2024-01-02 17:05:55,773	44k	INFO	====> Epoch: 3487, cost 22.93 s
2024-01-02 17:06:18,638	44k	INFO	====> Epoch: 3488, cost 22.87 s
2024-01-02 17:06:41,499	44k	INFO	====> Epoch: 3489, cost 22.86 s
2024-01-02 17:07:04,248	44k	INFO	====> Epoch: 3490, cost 22.75 s
2024-01-02 17:07:27,055	44k	INFO	====> Epoch: 3491, cost 22.81 s
2024-01-02 17:07:49,874	44k	INFO	====> Epoch: 3492, cost 22.82 s
2024-01-02 17:07:57,900	44k	INFO	Train Epoch: 3493 [31%]
2024-01-02 17:07:57,903	44k	INFO	Losses: [2.380704641342163, 2.393934726715088, 7.199161052703857, 13.71410083770752, 0.3882463276386261], step: 90800, lr: 6.46276864935453e-05, reference_loss: 26.076147079467773
2024-01-02 17:08:13,121	44k	INFO	====> Epoch: 3493, cost 23.25 s
2024-01-02 17:08:35,937	44k	INFO	====> Epoch: 3494, cost 22.82 s
2024-01-02 17:08:58,635	44k	INFO	====> Epoch: 3495, cost 22.70 s
2024-01-02 17:09:21,587	44k	INFO	====> Epoch: 3496, cost 22.95 s
2024-01-02 17:09:44,482	44k	INFO	====> Epoch: 3497, cost 22.89 s
2024-01-02 17:10:07,337	44k	INFO	====> Epoch: 3498, cost 22.86 s
2024-01-02 17:10:30,141	44k	INFO	====> Epoch: 3499, cost 22.80 s
2024-01-02 17:10:53,086	44k	INFO	====> Epoch: 3500, cost 22.94 s
2024-01-02 17:10:53,982	44k	INFO	Train Epoch: 3501 [0%]
2024-01-02 17:10:53,985	44k	INFO	Losses: [2.355832576751709, 2.4229516983032227, 7.781173229217529, 13.778911590576172, 0.4432344138622284], step: 91000, lr: 6.456308707459703e-05, reference_loss: 26.782102584838867
2024-01-02 17:11:16,412	44k	INFO	====> Epoch: 3501, cost 23.33 s
2024-01-02 17:11:39,336	44k	INFO	====> Epoch: 3502, cost 22.92 s
2024-01-02 17:12:02,280	44k	INFO	====> Epoch: 3503, cost 22.94 s
2024-01-02 17:12:25,176	44k	INFO	====> Epoch: 3504, cost 22.90 s
2024-01-02 17:12:48,110	44k	INFO	====> Epoch: 3505, cost 22.93 s
2024-01-02 17:13:11,186	44k	INFO	====> Epoch: 3506, cost 23.08 s
2024-01-02 17:13:34,076	44k	INFO	====> Epoch: 3507, cost 22.89 s
2024-01-02 17:13:50,883	44k	INFO	Train Epoch: 3508 [69%]
2024-01-02 17:13:50,886	44k	INFO	Losses: [2.551042318344116, 2.214003562927246, 6.541814804077148, 13.871252059936523, 0.33166399598121643], step: 91200, lr: 6.450661555375672e-05, reference_loss: 25.509775161743164
2024-01-02 17:13:56,352	44k	INFO	Saving model and optimizer state at iteration 3508 to ./logs/44k/G_91200.pth
2024-01-02 17:13:57,206	44k	INFO	Saving model and optimizer state at iteration 3508 to ./logs/44k/D_91200.pth
2024-01-02 17:13:57,701	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_88800.pth
2024-01-02 17:13:57,740	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_88800.pth
2024-01-02 17:14:03,674	44k	INFO	====> Epoch: 3508, cost 29.60 s
2024-01-02 17:14:26,488	44k	INFO	====> Epoch: 3509, cost 22.81 s
2024-01-02 17:14:49,386	44k	INFO	====> Epoch: 3510, cost 22.90 s
2024-01-02 17:15:12,209	44k	INFO	====> Epoch: 3511, cost 22.82 s
2024-01-02 17:15:35,101	44k	INFO	====> Epoch: 3512, cost 22.89 s
2024-01-02 17:15:58,169	44k	INFO	====> Epoch: 3513, cost 23.07 s
2024-01-02 17:16:21,019	44k	INFO	====> Epoch: 3514, cost 22.85 s
2024-01-02 17:16:43,911	44k	INFO	====> Epoch: 3515, cost 22.89 s
2024-01-02 17:16:53,727	44k	INFO	Train Epoch: 3516 [38%]
2024-01-02 17:16:53,730	44k	INFO	Losses: [2.391385316848755, 2.347717523574829, 8.137734413146973, 16.442411422729492, 0.4155493676662445], step: 91400, lr: 6.444213715279294e-05, reference_loss: 29.734798431396484
2024-01-02 17:17:07,090	44k	INFO	====> Epoch: 3516, cost 23.18 s
2024-01-02 17:17:29,775	44k	INFO	====> Epoch: 3517, cost 22.69 s
2024-01-02 17:17:52,628	44k	INFO	====> Epoch: 3518, cost 22.85 s
2024-01-02 17:18:15,462	44k	INFO	====> Epoch: 3519, cost 22.83 s
2024-01-02 17:18:38,264	44k	INFO	====> Epoch: 3520, cost 22.80 s
2024-01-02 17:19:01,050	44k	INFO	====> Epoch: 3521, cost 22.79 s
2024-01-02 17:19:23,822	44k	INFO	====> Epoch: 3522, cost 22.77 s
2024-01-02 17:19:46,654	44k	INFO	====> Epoch: 3523, cost 22.83 s
2024-01-02 17:19:49,333	44k	INFO	Train Epoch: 3524 [8%]
2024-01-02 17:19:49,336	44k	INFO	Losses: [2.3075709342956543, 2.622138261795044, 8.454564094543457, 16.007946014404297, 0.37234172224998474], step: 91600, lr: 6.437772320202788e-05, reference_loss: 29.76456069946289
2024-01-02 17:20:09,987	44k	INFO	====> Epoch: 3524, cost 23.33 s
2024-01-02 17:20:32,832	44k	INFO	====> Epoch: 3525, cost 22.84 s
2024-01-02 17:20:55,660	44k	INFO	====> Epoch: 3526, cost 22.83 s
2024-01-02 17:21:18,520	44k	INFO	====> Epoch: 3527, cost 22.86 s
2024-01-02 17:21:41,270	44k	INFO	====> Epoch: 3528, cost 22.75 s
2024-01-02 17:22:04,048	44k	INFO	====> Epoch: 3529, cost 22.78 s
2024-01-02 17:22:26,886	44k	INFO	====> Epoch: 3530, cost 22.84 s
2024-01-02 17:22:45,459	44k	INFO	Train Epoch: 3531 [77%]
2024-01-02 17:22:45,462	44k	INFO	Losses: [2.259138584136963, 2.442141056060791, 9.287656784057617, 18.414154052734375, 0.30406349897384644], step: 91800, lr: 6.432141381376625e-05, reference_loss: 32.7071533203125
2024-01-02 17:22:50,049	44k	INFO	====> Epoch: 3531, cost 23.16 s
2024-01-02 17:23:13,028	44k	INFO	====> Epoch: 3532, cost 22.98 s
2024-01-02 17:23:35,841	44k	INFO	====> Epoch: 3533, cost 22.81 s
2024-01-02 17:23:58,645	44k	INFO	====> Epoch: 3534, cost 22.80 s
2024-01-02 17:24:21,448	44k	INFO	====> Epoch: 3535, cost 22.80 s
2024-01-02 17:24:44,308	44k	INFO	====> Epoch: 3536, cost 22.86 s
2024-01-02 17:25:07,083	44k	INFO	====> Epoch: 3537, cost 22.77 s
2024-01-02 17:25:29,937	44k	INFO	====> Epoch: 3538, cost 22.85 s
2024-01-02 17:25:41,456	44k	INFO	Train Epoch: 3539 [46%]
2024-01-02 17:25:41,459	44k	INFO	Losses: [2.4064788818359375, 2.3386969566345215, 5.691678047180176, 13.437896728515625, 0.2884230315685272], step: 92000, lr: 6.425712053353696e-05, reference_loss: 24.16317367553711
2024-01-02 17:25:46,861	44k	INFO	Saving model and optimizer state at iteration 3539 to ./logs/44k/G_92000.pth
2024-01-02 17:25:47,719	44k	INFO	Saving model and optimizer state at iteration 3539 to ./logs/44k/D_92000.pth
2024-01-02 17:25:48,206	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_89600.pth
2024-01-02 17:25:48,245	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_89600.pth
2024-01-02 17:25:59,615	44k	INFO	====> Epoch: 3539, cost 29.68 s
2024-01-02 17:26:22,346	44k	INFO	====> Epoch: 3540, cost 22.73 s
2024-01-02 17:26:45,202	44k	INFO	====> Epoch: 3541, cost 22.86 s
2024-01-02 17:27:08,014	44k	INFO	====> Epoch: 3542, cost 22.81 s
2024-01-02 17:27:30,791	44k	INFO	====> Epoch: 3543, cost 22.78 s
2024-01-02 17:27:53,436	44k	INFO	====> Epoch: 3544, cost 22.65 s
2024-01-02 17:28:16,121	44k	INFO	====> Epoch: 3545, cost 22.68 s
2024-01-02 17:28:38,838	44k	INFO	====> Epoch: 3546, cost 22.72 s
2024-01-02 17:28:43,270	44k	INFO	Train Epoch: 3547 [15%]
2024-01-02 17:28:43,273	44k	INFO	Losses: [2.202307939529419, 2.5364151000976562, 7.302873611450195, 14.233787536621094, 0.35209208726882935], step: 92200, lr: 6.41928915184666e-05, reference_loss: 26.62747573852539
2024-01-02 17:29:01,976	44k	INFO	====> Epoch: 3547, cost 23.14 s
2024-01-02 17:29:24,811	44k	INFO	====> Epoch: 3548, cost 22.83 s
2024-01-02 17:29:47,652	44k	INFO	====> Epoch: 3549, cost 22.84 s
2024-01-02 17:30:10,486	44k	INFO	====> Epoch: 3550, cost 22.83 s
2024-01-02 17:30:33,192	44k	INFO	====> Epoch: 3551, cost 22.71 s
2024-01-02 17:30:55,999	44k	INFO	====> Epoch: 3552, cost 22.81 s
2024-01-02 17:31:18,673	44k	INFO	====> Epoch: 3553, cost 22.67 s
2024-01-02 17:31:38,885	44k	INFO	Train Epoch: 3554 [85%]
2024-01-02 17:31:38,888	44k	INFO	Losses: [2.3013739585876465, 2.4980623722076416, 7.610171794891357, 15.802647590637207, 0.5837345123291016], step: 92400, lr: 6.413674379729284e-05, reference_loss: 28.795991897583008
2024-01-02 17:31:41,735	44k	INFO	====> Epoch: 3554, cost 23.06 s
2024-01-02 17:32:04,478	44k	INFO	====> Epoch: 3555, cost 22.74 s
2024-01-02 17:32:27,298	44k	INFO	====> Epoch: 3556, cost 22.82 s
2024-01-02 17:32:50,109	44k	INFO	====> Epoch: 3557, cost 22.81 s
2024-01-02 17:33:12,900	44k	INFO	====> Epoch: 3558, cost 22.79 s
2024-01-02 17:33:35,724	44k	INFO	====> Epoch: 3559, cost 22.82 s
2024-01-02 17:33:58,561	44k	INFO	====> Epoch: 3560, cost 22.84 s
2024-01-02 17:34:21,540	44k	INFO	====> Epoch: 3561, cost 22.98 s
2024-01-02 17:34:34,851	44k	INFO	Train Epoch: 3562 [54%]
2024-01-02 17:34:34,854	44k	INFO	Losses: [2.4677650928497314, 2.433981418609619, 6.8308868408203125, 14.722517967224121, 0.3662760555744171], step: 92600, lr: 6.407263510630707e-05, reference_loss: 26.821426391601562
2024-01-02 17:34:44,777	44k	INFO	====> Epoch: 3562, cost 23.24 s
2024-01-02 17:35:07,575	44k	INFO	====> Epoch: 3563, cost 22.80 s
2024-01-02 17:35:30,655	44k	INFO	====> Epoch: 3564, cost 23.08 s
2024-01-02 17:35:53,764	44k	INFO	====> Epoch: 3565, cost 23.11 s
2024-01-02 17:36:16,877	44k	INFO	====> Epoch: 3566, cost 23.11 s
2024-01-02 17:36:39,894	44k	INFO	====> Epoch: 3567, cost 23.02 s
2024-01-02 17:37:02,916	44k	INFO	====> Epoch: 3568, cost 23.02 s
2024-01-02 17:37:25,924	44k	INFO	====> Epoch: 3569, cost 23.01 s
2024-01-02 17:37:32,234	44k	INFO	Train Epoch: 3570 [23%]
2024-01-02 17:37:32,236	44k	INFO	Losses: [2.409306764602661, 2.4810047149658203, 7.435047626495361, 14.324224472045898, 0.5306800603866577], step: 92800, lr: 6.400859049597177e-05, reference_loss: 27.18026351928711
2024-01-02 17:37:38,719	44k	INFO	Saving model and optimizer state at iteration 3570 to ./logs/44k/G_92800.pth
2024-01-02 17:37:39,648	44k	INFO	Saving model and optimizer state at iteration 3570 to ./logs/44k/D_92800.pth
2024-01-02 17:37:40,186	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_90400.pth
2024-01-02 17:37:40,224	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_90400.pth
2024-01-02 17:37:56,975	44k	INFO	====> Epoch: 3570, cost 31.05 s
2024-01-02 17:38:20,236	44k	INFO	====> Epoch: 3571, cost 23.26 s
2024-01-02 17:38:43,504	44k	INFO	====> Epoch: 3572, cost 23.27 s
2024-01-02 17:39:06,754	44k	INFO	====> Epoch: 3573, cost 23.25 s
2024-01-02 17:39:30,000	44k	INFO	====> Epoch: 3574, cost 23.25 s
2024-01-02 17:39:53,250	44k	INFO	====> Epoch: 3575, cost 23.25 s
2024-01-02 17:40:16,274	44k	INFO	====> Epoch: 3576, cost 23.02 s
2024-01-02 17:40:38,467	44k	INFO	Train Epoch: 3577 [92%]
2024-01-02 17:40:38,470	44k	INFO	Losses: [2.458106279373169, 2.345473051071167, 6.992335796356201, 15.384397506713867, 0.5231330394744873], step: 93000, lr: 6.395260397773149e-05, reference_loss: 27.703445434570312
2024-01-02 17:40:39,712	44k	INFO	====> Epoch: 3577, cost 23.44 s
2024-01-02 17:41:02,542	44k	INFO	====> Epoch: 3578, cost 22.83 s
2024-01-02 17:41:25,384	44k	INFO	====> Epoch: 3579, cost 22.84 s
2024-01-02 17:41:48,157	44k	INFO	====> Epoch: 3580, cost 22.77 s
2024-01-02 17:42:10,928	44k	INFO	====> Epoch: 3581, cost 22.77 s
2024-01-02 17:42:33,708	44k	INFO	====> Epoch: 3582, cost 22.78 s
2024-01-02 17:42:56,518	44k	INFO	====> Epoch: 3583, cost 22.81 s
2024-01-02 17:43:19,354	44k	INFO	====> Epoch: 3584, cost 22.84 s
2024-01-02 17:43:34,434	44k	INFO	Train Epoch: 3585 [62%]
2024-01-02 17:43:34,437	44k	INFO	Losses: [2.289808750152588, 2.409749984741211, 7.68697452545166, 14.718454360961914, 0.3154219090938568], step: 93200, lr: 6.388867934602427e-05, reference_loss: 27.42041015625
2024-01-02 17:43:42,566	44k	INFO	====> Epoch: 3585, cost 23.21 s
2024-01-02 17:44:05,478	44k	INFO	====> Epoch: 3586, cost 22.91 s
2024-01-02 17:44:28,171	44k	INFO	====> Epoch: 3587, cost 22.69 s
2024-01-02 17:44:50,861	44k	INFO	====> Epoch: 3588, cost 22.69 s
2024-01-02 17:45:13,558	44k	INFO	====> Epoch: 3589, cost 22.70 s
2024-01-02 17:45:36,241	44k	INFO	====> Epoch: 3590, cost 22.68 s
2024-01-02 17:45:58,892	44k	INFO	====> Epoch: 3591, cost 22.65 s
2024-01-02 17:46:21,602	44k	INFO	====> Epoch: 3592, cost 22.71 s
2024-01-02 17:46:29,629	44k	INFO	Train Epoch: 3593 [31%]
2024-01-02 17:46:29,632	44k	INFO	Losses: [2.401144504547119, 2.422313690185547, 7.383875846862793, 14.331918716430664, 0.35633254051208496], step: 93400, lr: 6.382481861098869e-05, reference_loss: 26.895586013793945
2024-01-02 17:46:44,827	44k	INFO	====> Epoch: 3593, cost 23.23 s
2024-01-02 17:47:07,619	44k	INFO	====> Epoch: 3594, cost 22.79 s
2024-01-02 17:47:30,439	44k	INFO	====> Epoch: 3595, cost 22.82 s
2024-01-02 17:47:53,388	44k	INFO	====> Epoch: 3596, cost 22.95 s
2024-01-02 17:48:16,155	44k	INFO	====> Epoch: 3597, cost 22.77 s
2024-01-02 17:48:38,886	44k	INFO	====> Epoch: 3598, cost 22.73 s
2024-01-02 17:49:01,531	44k	INFO	====> Epoch: 3599, cost 22.65 s
2024-01-02 17:49:24,227	44k	INFO	====> Epoch: 3600, cost 22.70 s
2024-01-02 17:49:25,119	44k	INFO	Train Epoch: 3601 [0%]
2024-01-02 17:49:25,122	44k	INFO	Losses: [2.3490922451019287, 2.3068792819976807, 7.762696266174316, 14.40864086151123, 0.1632653772830963], step: 93600, lr: 6.376102170875608e-05, reference_loss: 26.99057388305664
2024-01-02 17:49:30,385	44k	INFO	Saving model and optimizer state at iteration 3601 to ./logs/44k/G_93600.pth
2024-01-02 17:49:31,253	44k	INFO	Saving model and optimizer state at iteration 3601 to ./logs/44k/D_93600.pth
2024-01-02 17:49:31,743	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_91200.pth
2024-01-02 17:49:31,782	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_91200.pth
2024-01-02 17:49:53,660	44k	INFO	====> Epoch: 3601, cost 29.43 s
2024-01-02 17:50:16,518	44k	INFO	====> Epoch: 3602, cost 22.86 s
2024-01-02 17:50:39,483	44k	INFO	====> Epoch: 3603, cost 22.97 s
2024-01-02 17:51:02,252	44k	INFO	====> Epoch: 3604, cost 22.77 s
2024-01-02 17:51:24,926	44k	INFO	====> Epoch: 3605, cost 22.67 s
2024-01-02 17:51:47,601	44k	INFO	====> Epoch: 3606, cost 22.67 s
2024-01-02 17:52:10,237	44k	INFO	====> Epoch: 3607, cost 22.64 s
2024-01-02 17:52:26,974	44k	INFO	Train Epoch: 3608 [69%]
2024-01-02 17:52:26,977	44k	INFO	Losses: [2.1608052253723145, 2.7485194206237793, 9.19269847869873, 15.731487274169922, 0.5313214659690857], step: 93800, lr: 6.370525173198803e-05, reference_loss: 30.364831924438477
2024-01-02 17:52:33,407	44k	INFO	====> Epoch: 3608, cost 23.17 s
2024-01-02 17:52:56,201	44k	INFO	====> Epoch: 3609, cost 22.79 s
2024-01-02 17:53:19,012	44k	INFO	====> Epoch: 3610, cost 22.81 s
2024-01-02 17:53:41,872	44k	INFO	====> Epoch: 3611, cost 22.86 s
2024-01-02 17:54:04,732	44k	INFO	====> Epoch: 3612, cost 22.86 s
2024-01-02 17:54:27,605	44k	INFO	====> Epoch: 3613, cost 22.87 s
2024-01-02 17:54:50,434	44k	INFO	====> Epoch: 3614, cost 22.83 s
2024-01-02 17:55:13,441	44k	INFO	====> Epoch: 3615, cost 23.01 s
2024-01-02 17:55:23,285	44k	INFO	Train Epoch: 3616 [38%]
2024-01-02 17:55:23,288	44k	INFO	Losses: [2.306675910949707, 2.4976439476013184, 9.047386169433594, 16.286144256591797, 0.21057583391666412], step: 94000, lr: 6.364157434433698e-05, reference_loss: 30.348424911499023
2024-01-02 17:55:36,754	44k	INFO	====> Epoch: 3616, cost 23.31 s
2024-01-02 17:55:59,633	44k	INFO	====> Epoch: 3617, cost 22.88 s
2024-01-02 17:56:22,535	44k	INFO	====> Epoch: 3618, cost 22.90 s
2024-01-02 17:56:45,415	44k	INFO	====> Epoch: 3619, cost 22.88 s
2024-01-02 17:57:08,291	44k	INFO	====> Epoch: 3620, cost 22.88 s
2024-01-02 17:57:31,169	44k	INFO	====> Epoch: 3621, cost 22.88 s
2024-01-02 17:57:54,043	44k	INFO	====> Epoch: 3622, cost 22.87 s
2024-01-02 17:58:16,843	44k	INFO	====> Epoch: 3623, cost 22.80 s
2024-01-02 17:58:19,519	44k	INFO	Train Epoch: 3624 [8%]
2024-01-02 17:58:19,521	44k	INFO	Losses: [2.13724684715271, 2.868645668029785, 9.160902976989746, 15.658613204956055, 0.3886187672615051], step: 94200, lr: 6.357796060622167e-05, reference_loss: 30.214027404785156
2024-01-02 17:58:40,288	44k	INFO	====> Epoch: 3624, cost 23.45 s
2024-01-02 17:59:03,020	44k	INFO	====> Epoch: 3625, cost 22.73 s
2024-01-02 17:59:25,785	44k	INFO	====> Epoch: 3626, cost 22.76 s
2024-01-02 17:59:48,563	44k	INFO	====> Epoch: 3627, cost 22.78 s
2024-01-02 18:00:11,371	44k	INFO	====> Epoch: 3628, cost 22.81 s
2024-01-02 18:00:34,128	44k	INFO	====> Epoch: 3629, cost 22.76 s
2024-01-02 18:00:56,726	44k	INFO	====> Epoch: 3630, cost 22.60 s
2024-01-02 18:01:15,204	44k	INFO	Train Epoch: 3631 [77%]
2024-01-02 18:01:15,207	44k	INFO	Losses: [2.1108267307281494, 2.854362726211548, 10.297215461730957, 17.105281829833984, 0.6667540073394775], step: 94400, lr: 6.352235074786393e-05, reference_loss: 33.03444290161133
2024-01-02 18:01:20,473	44k	INFO	Saving model and optimizer state at iteration 3631 to ./logs/44k/G_94400.pth
2024-01-02 18:01:21,513	44k	INFO	Saving model and optimizer state at iteration 3631 to ./logs/44k/D_94400.pth
2024-01-02 18:01:22,007	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_92000.pth
2024-01-02 18:01:22,045	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_92000.pth
2024-01-02 18:01:26,193	44k	INFO	====> Epoch: 3631, cost 29.47 s
2024-01-02 18:01:48,867	44k	INFO	====> Epoch: 3632, cost 22.67 s
2024-01-02 18:02:11,557	44k	INFO	====> Epoch: 3633, cost 22.69 s
2024-01-02 18:02:34,254	44k	INFO	====> Epoch: 3634, cost 22.70 s
2024-01-02 18:02:57,034	44k	INFO	====> Epoch: 3635, cost 22.78 s
2024-01-02 18:03:19,737	44k	INFO	====> Epoch: 3636, cost 22.70 s
2024-01-02 18:03:42,536	44k	INFO	====> Epoch: 3637, cost 22.80 s
2024-01-02 18:04:05,191	44k	INFO	====> Epoch: 3638, cost 22.66 s
2024-01-02 18:04:16,610	44k	INFO	Train Epoch: 3639 [46%]
2024-01-02 18:04:16,613	44k	INFO	Losses: [2.255311965942383, 2.64840030670166, 9.242671966552734, 17.05051612854004, 0.30030855536460876], step: 94600, lr: 6.345885618119785e-05, reference_loss: 31.497207641601562
2024-01-02 18:04:28,232	44k	INFO	====> Epoch: 3639, cost 23.04 s
2024-01-02 18:04:51,010	44k	INFO	====> Epoch: 3640, cost 22.78 s
2024-01-02 18:05:13,788	44k	INFO	====> Epoch: 3641, cost 22.78 s
2024-01-02 18:05:36,574	44k	INFO	====> Epoch: 3642, cost 22.79 s
2024-01-02 18:05:59,373	44k	INFO	====> Epoch: 3643, cost 22.80 s
2024-01-02 18:06:22,072	44k	INFO	====> Epoch: 3644, cost 22.70 s
2024-01-02 18:06:44,858	44k	INFO	====> Epoch: 3645, cost 22.79 s
2024-01-02 18:07:07,581	44k	INFO	====> Epoch: 3646, cost 22.72 s
2024-01-02 18:07:12,001	44k	INFO	Train Epoch: 3647 [15%]
2024-01-02 18:07:12,004	44k	INFO	Losses: [2.3944437503814697, 2.6811766624450684, 9.400185585021973, 16.67903709411621, 0.3051091730594635], step: 94800, lr: 6.339542508132647e-05, reference_loss: 31.459951400756836
2024-01-02 18:07:30,709	44k	INFO	====> Epoch: 3647, cost 23.13 s
2024-01-02 18:07:53,399	44k	INFO	====> Epoch: 3648, cost 22.69 s
2024-01-02 18:08:16,182	44k	INFO	====> Epoch: 3649, cost 22.78 s
2024-01-02 18:08:38,948	44k	INFO	====> Epoch: 3650, cost 22.77 s
2024-01-02 18:09:01,772	44k	INFO	====> Epoch: 3651, cost 22.82 s
2024-01-02 18:09:24,436	44k	INFO	====> Epoch: 3652, cost 22.66 s
2024-01-02 18:09:47,150	44k	INFO	====> Epoch: 3653, cost 22.71 s
2024-01-02 18:10:07,510	44k	INFO	Train Epoch: 3654 [85%]
2024-01-02 18:10:07,513	44k	INFO	Losses: [2.3020949363708496, 2.517642021179199, 8.2230863571167, 14.839534759521484, 0.5386784076690674], step: 95000, lr: 6.333997488167103e-05, reference_loss: 28.421037673950195
2024-01-02 18:10:10,383	44k	INFO	====> Epoch: 3654, cost 23.23 s
2024-01-02 18:10:33,177	44k	INFO	====> Epoch: 3655, cost 22.79 s
2024-01-02 18:10:56,022	44k	INFO	====> Epoch: 3656, cost 22.84 s
2024-01-02 18:11:18,709	44k	INFO	====> Epoch: 3657, cost 22.69 s
2024-01-02 18:11:41,289	44k	INFO	====> Epoch: 3658, cost 22.58 s
2024-01-02 18:12:04,185	44k	INFO	====> Epoch: 3659, cost 22.90 s
2024-01-02 18:12:26,933	44k	INFO	====> Epoch: 3660, cost 22.75 s
2024-01-02 18:12:49,575	44k	INFO	====> Epoch: 3661, cost 22.64 s
2024-01-02 18:13:02,760	44k	INFO	Train Epoch: 3662 [54%]
2024-01-02 18:13:02,763	44k	INFO	Losses: [2.441152811050415, 2.4365286827087402, 8.365859031677246, 15.753557205200195, 0.22596177458763123], step: 95200, lr: 6.327666261110163e-05, reference_loss: 29.223058700561523
2024-01-02 18:13:08,037	44k	INFO	Saving model and optimizer state at iteration 3662 to ./logs/44k/G_95200.pth
2024-01-02 18:13:08,886	44k	INFO	Saving model and optimizer state at iteration 3662 to ./logs/44k/D_95200.pth
2024-01-02 18:13:09,374	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_92800.pth
2024-01-02 18:13:09,412	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_92800.pth
2024-01-02 18:13:18,943	44k	INFO	====> Epoch: 3662, cost 29.37 s
2024-01-02 18:13:41,817	44k	INFO	====> Epoch: 3663, cost 22.87 s
2024-01-02 18:14:04,546	44k	INFO	====> Epoch: 3664, cost 22.73 s
2024-01-02 18:14:27,358	44k	INFO	====> Epoch: 3665, cost 22.81 s
2024-01-02 18:14:50,339	44k	INFO	====> Epoch: 3666, cost 22.98 s
2024-01-02 18:15:13,013	44k	INFO	====> Epoch: 3667, cost 22.67 s
2024-01-02 18:15:35,669	44k	INFO	====> Epoch: 3668, cost 22.66 s
2024-01-02 18:15:58,297	44k	INFO	====> Epoch: 3669, cost 22.63 s
2024-01-02 18:16:04,495	44k	INFO	Train Epoch: 3670 [23%]
2024-01-02 18:16:04,499	44k	INFO	Losses: [2.517198085784912, 2.1816325187683105, 6.1497650146484375, 14.026021957397461, 0.4175364673137665], step: 95400, lr: 6.32134136251106e-05, reference_loss: 25.29215431213379
2024-01-02 18:16:21,446	44k	INFO	====> Epoch: 3670, cost 23.15 s
2024-01-02 18:16:44,085	44k	INFO	====> Epoch: 3671, cost 22.64 s
2024-01-02 18:17:06,771	44k	INFO	====> Epoch: 3672, cost 22.69 s
2024-01-02 18:17:29,493	44k	INFO	====> Epoch: 3673, cost 22.72 s
2024-01-02 18:17:52,106	44k	INFO	====> Epoch: 3674, cost 22.61 s
2024-01-02 18:18:14,781	44k	INFO	====> Epoch: 3675, cost 22.67 s
2024-01-02 18:18:37,448	44k	INFO	====> Epoch: 3676, cost 22.67 s
2024-01-02 18:18:59,555	44k	INFO	Train Epoch: 3677 [92%]
2024-01-02 18:18:59,558	44k	INFO	Losses: [2.159891366958618, 2.6352035999298096, 9.182317733764648, 18.147077560424805, 0.5435087084770203], step: 95600, lr: 6.315812262576927e-05, reference_loss: 32.667999267578125
2024-01-02 18:19:00,641	44k	INFO	====> Epoch: 3677, cost 23.19 s
2024-01-02 18:19:23,414	44k	INFO	====> Epoch: 3678, cost 22.77 s
2024-01-02 18:19:46,164	44k	INFO	====> Epoch: 3679, cost 22.75 s
2024-01-02 18:20:08,960	44k	INFO	====> Epoch: 3680, cost 22.80 s
2024-01-02 18:20:31,639	44k	INFO	====> Epoch: 3681, cost 22.68 s
2024-01-02 18:20:54,236	44k	INFO	====> Epoch: 3682, cost 22.60 s
2024-01-02 18:21:16,824	44k	INFO	====> Epoch: 3683, cost 22.59 s
2024-01-02 18:21:39,437	44k	INFO	====> Epoch: 3684, cost 22.61 s
2024-01-02 18:21:54,326	44k	INFO	Train Epoch: 3685 [62%]
2024-01-02 18:21:54,329	44k	INFO	Losses: [2.25657320022583, 2.5187673568725586, 7.871369361877441, 15.651220321655273, 0.2623671591281891], step: 95800, lr: 6.30949921279153e-05, reference_loss: 28.5602970123291
2024-01-02 18:22:02,562	44k	INFO	====> Epoch: 3685, cost 23.13 s
2024-01-02 18:22:25,332	44k	INFO	====> Epoch: 3686, cost 22.77 s
2024-01-02 18:22:48,172	44k	INFO	====> Epoch: 3687, cost 22.84 s
2024-01-02 18:23:11,056	44k	INFO	====> Epoch: 3688, cost 22.88 s
2024-01-02 18:23:33,928	44k	INFO	====> Epoch: 3689, cost 22.87 s
2024-01-02 18:23:56,780	44k	INFO	====> Epoch: 3690, cost 22.85 s
2024-01-02 18:24:19,655	44k	INFO	====> Epoch: 3691, cost 22.87 s
2024-01-02 18:24:42,493	44k	INFO	====> Epoch: 3692, cost 22.84 s
2024-01-02 18:24:50,527	44k	INFO	Train Epoch: 3693 [31%]
2024-01-02 18:24:50,530	44k	INFO	Losses: [2.361842632293701, 2.451364755630493, 7.710280895233154, 15.35401439666748, 0.5762472152709961], step: 96000, lr: 6.30319247329465e-05, reference_loss: 28.453750610351562
2024-01-02 18:24:55,763	44k	INFO	Saving model and optimizer state at iteration 3693 to ./logs/44k/G_96000.pth
2024-01-02 18:24:56,799	44k	INFO	Saving model and optimizer state at iteration 3693 to ./logs/44k/D_96000.pth
2024-01-02 18:24:57,301	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_93600.pth
2024-01-02 18:24:57,340	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_93600.pth
2024-01-02 18:25:12,068	44k	INFO	====> Epoch: 3693, cost 29.57 s
2024-01-02 18:25:34,908	44k	INFO	====> Epoch: 3694, cost 22.84 s
2024-01-02 18:25:57,736	44k	INFO	====> Epoch: 3695, cost 22.83 s
2024-01-02 18:26:20,395	44k	INFO	====> Epoch: 3696, cost 22.66 s
2024-01-02 18:26:42,999	44k	INFO	====> Epoch: 3697, cost 22.60 s
2024-01-02 18:27:05,636	44k	INFO	====> Epoch: 3698, cost 22.64 s
2024-01-02 18:27:28,436	44k	INFO	====> Epoch: 3699, cost 22.80 s
2024-01-02 18:27:51,268	44k	INFO	====> Epoch: 3700, cost 22.83 s
2024-01-02 18:27:52,161	44k	INFO	Train Epoch: 3701 [0%]
2024-01-02 18:27:52,164	44k	INFO	Losses: [2.1888506412506104, 2.783397674560547, 8.644445419311523, 15.742305755615234, 0.21400763094425201], step: 96200, lr: 6.296892037778756e-05, reference_loss: 29.573007583618164
2024-01-02 18:28:14,444	44k	INFO	====> Epoch: 3701, cost 23.18 s
2024-01-02 18:28:37,291	44k	INFO	====> Epoch: 3702, cost 22.85 s
2024-01-02 18:29:00,252	44k	INFO	====> Epoch: 3703, cost 22.96 s
2024-01-02 18:29:22,992	44k	INFO	====> Epoch: 3704, cost 22.74 s
2024-01-02 18:29:45,672	44k	INFO	====> Epoch: 3705, cost 22.68 s
2024-01-02 18:30:08,378	44k	INFO	====> Epoch: 3706, cost 22.71 s
2024-01-02 18:30:31,049	44k	INFO	====> Epoch: 3707, cost 22.67 s
2024-01-02 18:30:47,789	44k	INFO	Train Epoch: 3708 [69%]
2024-01-02 18:30:47,792	44k	INFO	Losses: [2.431354284286499, 2.947882890701294, 8.75231647491455, 16.34564781188965, 0.38218191266059875], step: 96400, lr: 6.291384322982998e-05, reference_loss: 30.85938262939453
2024-01-02 18:30:54,105	44k	INFO	====> Epoch: 3708, cost 23.06 s
2024-01-02 18:31:16,777	44k	INFO	====> Epoch: 3709, cost 22.67 s
2024-01-02 18:31:39,403	44k	INFO	====> Epoch: 3710, cost 22.63 s
2024-01-02 18:32:02,085	44k	INFO	====> Epoch: 3711, cost 22.68 s
2024-01-02 18:32:25,041	44k	INFO	====> Epoch: 3712, cost 22.96 s
2024-01-02 18:32:47,879	44k	INFO	====> Epoch: 3713, cost 22.84 s
2024-01-02 18:33:10,595	44k	INFO	====> Epoch: 3714, cost 22.72 s
2024-01-02 18:33:33,154	44k	INFO	====> Epoch: 3715, cost 22.56 s
2024-01-02 18:33:42,839	44k	INFO	Train Epoch: 3716 [38%]
2024-01-02 18:33:42,842	44k	INFO	Losses: [2.3058228492736816, 2.471104145050049, 9.046893119812012, 16.013145446777344, 0.2958742380142212], step: 96600, lr: 6.285095690452642e-05, reference_loss: 30.13283920288086
2024-01-02 18:33:56,280	44k	INFO	====> Epoch: 3716, cost 23.13 s
2024-01-02 18:34:19,149	44k	INFO	====> Epoch: 3717, cost 22.87 s
2024-01-02 18:34:41,939	44k	INFO	====> Epoch: 3718, cost 22.79 s
2024-01-02 18:35:04,657	44k	INFO	====> Epoch: 3719, cost 22.72 s
2024-01-02 18:35:27,470	44k	INFO	====> Epoch: 3720, cost 22.81 s
2024-01-02 18:35:50,226	44k	INFO	====> Epoch: 3721, cost 22.76 s
2024-01-02 18:36:13,157	44k	INFO	====> Epoch: 3722, cost 22.93 s
2024-01-02 18:36:35,989	44k	INFO	====> Epoch: 3723, cost 22.83 s
2024-01-02 18:36:38,661	44k	INFO	Train Epoch: 3724 [8%]
2024-01-02 18:36:38,664	44k	INFO	Losses: [2.250558376312256, 2.768381118774414, 8.484139442443848, 17.09638023376465, 0.2710458040237427], step: 96800, lr: 6.278813343804228e-05, reference_loss: 30.87050437927246
2024-01-02 18:36:44,014	44k	INFO	Saving model and optimizer state at iteration 3724 to ./logs/44k/G_96800.pth
2024-01-02 18:36:44,887	44k	INFO	Saving model and optimizer state at iteration 3724 to ./logs/44k/D_96800.pth
2024-01-02 18:36:45,380	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_94400.pth
2024-01-02 18:36:45,420	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_94400.pth
2024-01-02 18:37:05,536	44k	INFO	====> Epoch: 3724, cost 29.55 s
2024-01-02 18:37:28,460	44k	INFO	====> Epoch: 3725, cost 22.92 s
2024-01-02 18:37:51,223	44k	INFO	====> Epoch: 3726, cost 22.76 s
2024-01-02 18:38:14,041	44k	INFO	====> Epoch: 3727, cost 22.82 s
2024-01-02 18:38:36,644	44k	INFO	====> Epoch: 3728, cost 22.60 s
2024-01-02 18:38:59,621	44k	INFO	====> Epoch: 3729, cost 22.98 s
2024-01-02 18:39:22,447	44k	INFO	====> Epoch: 3730, cost 22.83 s
2024-01-02 18:39:41,061	44k	INFO	Train Epoch: 3731 [77%]
2024-01-02 18:39:41,064	44k	INFO	Losses: [2.3198416233062744, 2.4937150478363037, 8.52042293548584, 15.391446113586426, 0.4763675034046173], step: 97000, lr: 6.273321441934863e-05, reference_loss: 29.201793670654297
2024-01-02 18:39:45,654	44k	INFO	====> Epoch: 3731, cost 23.21 s
2024-01-02 18:40:08,478	44k	INFO	====> Epoch: 3732, cost 22.82 s
2024-01-02 18:40:31,286	44k	INFO	====> Epoch: 3733, cost 22.81 s
2024-01-02 18:40:54,035	44k	INFO	====> Epoch: 3734, cost 22.75 s
2024-01-02 18:41:16,890	44k	INFO	====> Epoch: 3735, cost 22.86 s
2024-01-02 18:41:39,749	44k	INFO	====> Epoch: 3736, cost 22.86 s
2024-01-02 18:42:02,587	44k	INFO	====> Epoch: 3737, cost 22.84 s
2024-01-02 18:42:25,423	44k	INFO	====> Epoch: 3738, cost 22.84 s
2024-01-02 18:42:36,942	44k	INFO	Train Epoch: 3739 [46%]
2024-01-02 18:42:36,945	44k	INFO	Losses: [2.39986252784729, 2.3772242069244385, 7.27134895324707, 15.092911720275879, 0.31454241275787354], step: 97200, lr: 6.267050864385019e-05, reference_loss: 27.455888748168945
2024-01-02 18:42:48,829	44k	INFO	====> Epoch: 3739, cost 23.41 s
2024-01-02 18:43:11,655	44k	INFO	====> Epoch: 3740, cost 22.83 s
2024-01-02 18:43:34,507	44k	INFO	====> Epoch: 3741, cost 22.85 s
2024-01-02 18:43:57,363	44k	INFO	====> Epoch: 3742, cost 22.86 s
2024-01-02 18:44:20,123	44k	INFO	====> Epoch: 3743, cost 22.76 s
2024-01-02 18:44:42,922	44k	INFO	====> Epoch: 3744, cost 22.80 s
2024-01-02 18:45:05,749	44k	INFO	====> Epoch: 3745, cost 22.83 s
2024-01-02 18:45:28,495	44k	INFO	====> Epoch: 3746, cost 22.75 s
2024-01-02 18:45:32,918	44k	INFO	Train Epoch: 3747 [15%]
2024-01-02 18:45:32,921	44k	INFO	Losses: [2.3064403533935547, 2.4247870445251465, 7.754505157470703, 14.879613876342773, 0.3163716793060303], step: 97400, lr: 6.260786554670034e-05, reference_loss: 27.681718826293945
2024-01-02 18:45:51,690	44k	INFO	====> Epoch: 3747, cost 23.20 s
2024-01-02 18:46:14,660	44k	INFO	====> Epoch: 3748, cost 22.97 s
2024-01-02 18:46:37,534	44k	INFO	====> Epoch: 3749, cost 22.87 s
2024-01-02 18:47:00,391	44k	INFO	====> Epoch: 3750, cost 22.86 s
2024-01-02 18:47:23,177	44k	INFO	====> Epoch: 3751, cost 22.79 s
2024-01-02 18:47:46,018	44k	INFO	====> Epoch: 3752, cost 22.84 s
2024-01-02 18:48:08,838	44k	INFO	====> Epoch: 3753, cost 22.82 s
2024-01-02 18:48:29,043	44k	INFO	Train Epoch: 3754 [85%]
2024-01-02 18:48:29,046	44k	INFO	Losses: [2.2872800827026367, 2.4955077171325684, 8.186927795410156, 15.515612602233887, 0.5033169984817505], step: 97600, lr: 6.255310420327356e-05, reference_loss: 28.988645553588867
2024-01-02 18:48:34,293	44k	INFO	Saving model and optimizer state at iteration 3754 to ./logs/44k/G_97600.pth
2024-01-02 18:48:35,190	44k	INFO	Saving model and optimizer state at iteration 3754 to ./logs/44k/D_97600.pth
2024-01-02 18:48:35,684	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_95200.pth
2024-01-02 18:48:35,723	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_95200.pth
2024-01-02 18:48:38,180	44k	INFO	====> Epoch: 3754, cost 29.34 s
2024-01-02 18:49:01,048	44k	INFO	====> Epoch: 3755, cost 22.87 s
2024-01-02 18:49:23,776	44k	INFO	====> Epoch: 3756, cost 22.73 s
2024-01-02 18:49:46,590	44k	INFO	====> Epoch: 3757, cost 22.81 s
2024-01-02 18:50:09,406	44k	INFO	====> Epoch: 3758, cost 22.82 s
2024-01-02 18:50:32,216	44k	INFO	====> Epoch: 3759, cost 22.81 s
2024-01-02 18:50:55,066	44k	INFO	====> Epoch: 3760, cost 22.85 s
2024-01-02 18:51:17,881	44k	INFO	====> Epoch: 3761, cost 22.82 s
2024-01-02 18:51:31,190	44k	INFO	Train Epoch: 3762 [54%]
2024-01-02 18:51:31,193	44k	INFO	Losses: [2.2817063331604004, 2.6762890815734863, 8.937690734863281, 16.316505432128906, 0.6615123152732849], step: 97800, lr: 6.249057845921268e-05, reference_loss: 30.87370491027832
2024-01-02 18:51:41,118	44k	INFO	====> Epoch: 3762, cost 23.24 s
2024-01-02 18:52:03,898	44k	INFO	====> Epoch: 3763, cost 22.78 s
2024-01-02 18:52:26,714	44k	INFO	====> Epoch: 3764, cost 22.82 s
2024-01-02 18:52:49,526	44k	INFO	====> Epoch: 3765, cost 22.81 s
2024-01-02 18:53:12,356	44k	INFO	====> Epoch: 3766, cost 22.83 s
2024-01-02 18:53:35,292	44k	INFO	====> Epoch: 3767, cost 22.94 s
2024-01-02 18:53:58,122	44k	INFO	====> Epoch: 3768, cost 22.83 s
2024-01-02 18:54:20,947	44k	INFO	====> Epoch: 3769, cost 22.83 s
2024-01-02 18:54:27,192	44k	INFO	Train Epoch: 3770 [23%]
2024-01-02 18:54:27,195	44k	INFO	Losses: [2.4749767780303955, 2.6990537643432617, 8.028207778930664, 13.929353713989258, 0.32618337869644165], step: 98000, lr: 6.242811521354769e-05, reference_loss: 27.457775115966797
2024-01-02 18:54:44,121	44k	INFO	====> Epoch: 3770, cost 23.17 s
2024-01-02 18:55:06,776	44k	INFO	====> Epoch: 3771, cost 22.66 s
2024-01-02 18:55:29,406	44k	INFO	====> Epoch: 3772, cost 22.63 s
2024-01-02 18:55:52,192	44k	INFO	====> Epoch: 3773, cost 22.79 s
2024-01-02 18:56:14,983	44k	INFO	====> Epoch: 3774, cost 22.79 s
2024-01-02 18:56:37,698	44k	INFO	====> Epoch: 3775, cost 22.72 s
2024-01-02 18:57:00,400	44k	INFO	====> Epoch: 3776, cost 22.70 s
2024-01-02 18:57:22,635	44k	INFO	Train Epoch: 3777 [92%]
2024-01-02 18:57:22,638	44k	INFO	Losses: [2.250124931335449, 2.6626901626586914, 8.22835922241211, 15.774258613586426, 0.4101497232913971], step: 98200, lr: 6.237351109269412e-05, reference_loss: 29.32558250427246
2024-01-02 18:57:23,730	44k	INFO	====> Epoch: 3777, cost 23.33 s
2024-01-02 18:57:46,551	44k	INFO	====> Epoch: 3778, cost 22.82 s
2024-01-02 18:58:09,260	44k	INFO	====> Epoch: 3779, cost 22.71 s
2024-01-02 18:58:31,909	44k	INFO	====> Epoch: 3780, cost 22.65 s
2024-01-02 18:58:54,581	44k	INFO	====> Epoch: 3781, cost 22.67 s
2024-01-02 18:59:17,213	44k	INFO	====> Epoch: 3782, cost 22.63 s
2024-01-02 18:59:39,963	44k	INFO	====> Epoch: 3783, cost 22.75 s
2024-01-02 19:00:02,762	44k	INFO	====> Epoch: 3784, cost 22.80 s
2024-01-02 19:00:17,811	44k	INFO	Train Epoch: 3785 [62%]
2024-01-02 19:00:17,814	44k	INFO	Losses: [2.320704460144043, 2.2673938274383545, 7.21061372756958, 13.999281883239746, 0.4508751928806305], step: 98400, lr: 6.231116486319148e-05, reference_loss: 26.24886703491211
2024-01-02 19:00:23,233	44k	INFO	Saving model and optimizer state at iteration 3785 to ./logs/44k/G_98400.pth
2024-01-02 19:00:24,114	44k	INFO	Saving model and optimizer state at iteration 3785 to ./logs/44k/D_98400.pth
2024-01-02 19:00:24,609	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_96000.pth
2024-01-02 19:00:24,648	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_96000.pth
2024-01-02 19:00:32,365	44k	INFO	====> Epoch: 3785, cost 29.60 s
2024-01-02 19:00:55,212	44k	INFO	====> Epoch: 3786, cost 22.85 s
2024-01-02 19:01:18,091	44k	INFO	====> Epoch: 3787, cost 22.88 s
2024-01-02 19:01:40,839	44k	INFO	====> Epoch: 3788, cost 22.75 s
2024-01-02 19:02:03,623	44k	INFO	====> Epoch: 3789, cost 22.78 s
2024-01-02 19:02:26,430	44k	INFO	====> Epoch: 3790, cost 22.81 s
2024-01-02 19:02:49,207	44k	INFO	====> Epoch: 3791, cost 22.78 s
2024-01-02 19:03:12,020	44k	INFO	====> Epoch: 3792, cost 22.81 s
2024-01-02 19:03:20,038	44k	INFO	Train Epoch: 3793 [31%]
2024-01-02 19:03:20,041	44k	INFO	Losses: [2.1380555629730225, 2.837864398956299, 9.163909912109375, 16.7642822265625, 0.40737685561180115], step: 98600, lr: 6.224888095264868e-05, reference_loss: 31.31148910522461
2024-01-02 19:03:35,297	44k	INFO	====> Epoch: 3793, cost 23.28 s
2024-01-02 19:03:58,077	44k	INFO	====> Epoch: 3794, cost 22.78 s
2024-01-02 19:04:20,873	44k	INFO	====> Epoch: 3795, cost 22.80 s
2024-01-02 19:04:43,682	44k	INFO	====> Epoch: 3796, cost 22.81 s
2024-01-02 19:05:06,453	44k	INFO	====> Epoch: 3797, cost 22.77 s
2024-01-02 19:05:29,253	44k	INFO	====> Epoch: 3798, cost 22.80 s
2024-01-02 19:05:52,064	44k	INFO	====> Epoch: 3799, cost 22.81 s
2024-01-02 19:06:14,880	44k	INFO	====> Epoch: 3800, cost 22.82 s
2024-01-02 19:06:15,775	44k	INFO	Train Epoch: 3801 [0%]
2024-01-02 19:06:15,778	44k	INFO	Losses: [2.26470947265625, 2.5955233573913574, 8.335895538330078, 14.947853088378906, 0.2758536636829376], step: 98800, lr: 6.218665929877403e-05, reference_loss: 28.419836044311523
2024-01-02 19:06:38,055	44k	INFO	====> Epoch: 3801, cost 23.17 s
2024-01-02 19:07:00,850	44k	INFO	====> Epoch: 3802, cost 22.80 s
2024-01-02 19:07:23,527	44k	INFO	====> Epoch: 3803, cost 22.68 s
2024-01-02 19:07:46,188	44k	INFO	====> Epoch: 3804, cost 22.66 s
2024-01-02 19:08:08,814	44k	INFO	====> Epoch: 3805, cost 22.63 s
2024-01-02 19:08:31,383	44k	INFO	====> Epoch: 3806, cost 22.57 s
2024-01-02 19:08:54,039	44k	INFO	====> Epoch: 3807, cost 22.66 s
2024-01-02 19:09:10,764	44k	INFO	Train Epoch: 3808 [69%]
2024-01-02 19:09:10,767	44k	INFO	Losses: [2.229376792907715, 2.7756905555725098, 9.97694206237793, 17.0478515625, 0.3638303279876709], step: 99000, lr: 6.213226637263466e-05, reference_loss: 32.39369201660156
2024-01-02 19:09:17,092	44k	INFO	====> Epoch: 3808, cost 23.05 s
2024-01-02 19:09:39,739	44k	INFO	====> Epoch: 3809, cost 22.65 s
2024-01-02 19:10:02,497	44k	INFO	====> Epoch: 3810, cost 22.76 s
2024-01-02 19:10:25,315	44k	INFO	====> Epoch: 3811, cost 22.82 s
2024-01-02 19:10:48,241	44k	INFO	====> Epoch: 3812, cost 22.93 s
2024-01-02 19:11:11,032	44k	INFO	====> Epoch: 3813, cost 22.79 s
2024-01-02 19:11:33,788	44k	INFO	====> Epoch: 3814, cost 22.76 s
2024-01-02 19:11:56,473	44k	INFO	====> Epoch: 3815, cost 22.69 s
2024-01-02 19:12:06,275	44k	INFO	Train Epoch: 3816 [38%]
2024-01-02 19:12:06,278	44k	INFO	Losses: [2.4755477905273438, 2.442946434020996, 7.8642778396606445, 14.506020545959473, 0.49156662821769714], step: 99200, lr: 6.207016128233389e-05, reference_loss: 27.780357360839844
2024-01-02 19:12:11,502	44k	INFO	Saving model and optimizer state at iteration 3816 to ./logs/44k/G_99200.pth
2024-01-02 19:12:12,360	44k	INFO	Saving model and optimizer state at iteration 3816 to ./logs/44k/D_99200.pth
2024-01-02 19:12:12,849	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_96800.pth
2024-01-02 19:12:12,888	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_96800.pth
2024-01-02 19:12:25,878	44k	INFO	====> Epoch: 3816, cost 29.40 s
2024-01-02 19:12:48,628	44k	INFO	====> Epoch: 3817, cost 22.75 s
2024-01-02 19:13:11,479	44k	INFO	====> Epoch: 3818, cost 22.85 s
2024-01-02 19:13:34,314	44k	INFO	====> Epoch: 3819, cost 22.84 s
2024-01-02 19:13:57,026	44k	INFO	====> Epoch: 3820, cost 22.71 s
2024-01-02 19:14:19,867	44k	INFO	====> Epoch: 3821, cost 22.84 s
2024-01-02 19:14:42,697	44k	INFO	====> Epoch: 3822, cost 22.83 s
2024-01-02 19:15:05,481	44k	INFO	====> Epoch: 3823, cost 22.78 s
2024-01-02 19:15:08,132	44k	INFO	Train Epoch: 3824 [8%]
2024-01-02 19:15:08,136	44k	INFO	Losses: [2.2996490001678467, 2.395923614501953, 7.406531810760498, 14.903456687927246, 0.35469940304756165], step: 99400, lr: 6.200811826995922e-05, reference_loss: 27.360261917114258
2024-01-02 19:15:28,579	44k	INFO	====> Epoch: 3824, cost 23.10 s
2024-01-02 19:15:51,253	44k	INFO	====> Epoch: 3825, cost 22.67 s
2024-01-02 19:16:13,998	44k	INFO	====> Epoch: 3826, cost 22.74 s
2024-01-02 19:16:36,868	44k	INFO	====> Epoch: 3827, cost 22.87 s
2024-01-02 19:16:59,718	44k	INFO	====> Epoch: 3828, cost 22.85 s
2024-01-02 19:17:22,509	44k	INFO	====> Epoch: 3829, cost 22.79 s
2024-01-02 19:17:45,378	44k	INFO	====> Epoch: 3830, cost 22.87 s
2024-01-02 19:18:04,203	44k	INFO	Train Epoch: 3831 [77%]
2024-01-02 19:18:04,206	44k	INFO	Losses: [2.119734287261963, 2.82270884513855, 10.090561866760254, 17.252483367919922, 0.4843847453594208], step: 99600, lr: 6.195388150864849e-05, reference_loss: 32.769874572753906
2024-01-02 19:18:08,802	44k	INFO	====> Epoch: 3831, cost 23.42 s
2024-01-02 19:18:31,608	44k	INFO	====> Epoch: 3832, cost 22.81 s
2024-01-02 19:18:54,338	44k	INFO	====> Epoch: 3833, cost 22.73 s
2024-01-02 19:19:17,148	44k	INFO	====> Epoch: 3834, cost 22.81 s
2024-01-02 19:19:39,982	44k	INFO	====> Epoch: 3835, cost 22.83 s
2024-01-02 19:20:02,839	44k	INFO	====> Epoch: 3836, cost 22.86 s
2024-01-02 19:20:25,734	44k	INFO	====> Epoch: 3837, cost 22.89 s
2024-01-02 19:20:48,557	44k	INFO	====> Epoch: 3838, cost 22.82 s
2024-01-02 19:21:00,098	44k	INFO	Train Epoch: 3839 [46%]
2024-01-02 19:21:00,101	44k	INFO	Losses: [2.160249710083008, 2.6661062240600586, 8.187532424926758, 16.067073822021484, 0.43491530418395996], step: 99800, lr: 6.189195472518783e-05, reference_loss: 29.515878677368164
2024-01-02 19:21:12,134	44k	INFO	====> Epoch: 3839, cost 23.58 s
2024-01-02 19:21:35,019	44k	INFO	====> Epoch: 3840, cost 22.88 s
2024-01-02 19:21:57,920	44k	INFO	====> Epoch: 3841, cost 22.90 s
2024-01-02 19:22:20,746	44k	INFO	====> Epoch: 3842, cost 22.83 s
2024-01-02 19:22:43,630	44k	INFO	====> Epoch: 3843, cost 22.88 s
2024-01-02 19:23:06,515	44k	INFO	====> Epoch: 3844, cost 22.89 s
2024-01-02 19:23:29,428	44k	INFO	====> Epoch: 3845, cost 22.91 s
2024-01-02 19:23:52,272	44k	INFO	====> Epoch: 3846, cost 22.84 s
2024-01-02 19:23:56,702	44k	INFO	Train Epoch: 3847 [15%]
2024-01-02 19:23:56,705	44k	INFO	Losses: [2.1907105445861816, 2.5508668422698975, 10.135176658630371, 17.00876235961914, 0.30154547095298767], step: 100000, lr: 6.183008984142443e-05, reference_loss: 32.18706130981445
2024-01-02 19:24:02,135	44k	INFO	Saving model and optimizer state at iteration 3847 to ./logs/44k/G_100000.pth
2024-01-02 19:24:03,165	44k	INFO	Saving model and optimizer state at iteration 3847 to ./logs/44k/D_100000.pth
2024-01-02 19:24:03,662	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_97600.pth
2024-01-02 19:24:03,701	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_97600.pth
2024-01-02 19:24:21,960	44k	INFO	====> Epoch: 3847, cost 29.69 s
2024-01-02 19:24:44,757	44k	INFO	====> Epoch: 3848, cost 22.80 s
2024-01-02 19:25:07,655	44k	INFO	====> Epoch: 3849, cost 22.90 s
2024-01-02 19:25:30,591	44k	INFO	====> Epoch: 3850, cost 22.94 s
2024-01-02 19:25:53,428	44k	INFO	====> Epoch: 3851, cost 22.84 s
2024-01-02 19:26:16,164	44k	INFO	====> Epoch: 3852, cost 22.74 s
2024-01-02 19:26:38,915	44k	INFO	====> Epoch: 3853, cost 22.75 s
2024-01-02 19:26:59,126	44k	INFO	Train Epoch: 3854 [85%]
2024-01-02 19:26:59,129	44k	INFO	Losses: [2.316133975982666, 2.639730215072632, 6.63986349105835, 14.515609741210938, 0.46682801842689514], step: 100200, lr: 6.177600879658526e-05, reference_loss: 26.57816505432129
2024-01-02 19:27:02,070	44k	INFO	====> Epoch: 3854, cost 23.15 s
2024-01-02 19:27:24,814	44k	INFO	====> Epoch: 3855, cost 22.74 s
2024-01-02 19:27:47,781	44k	INFO	====> Epoch: 3856, cost 22.97 s
2024-01-02 19:28:10,576	44k	INFO	====> Epoch: 3857, cost 22.79 s
2024-01-02 19:28:33,385	44k	INFO	====> Epoch: 3858, cost 22.81 s
2024-01-02 19:28:56,188	44k	INFO	====> Epoch: 3859, cost 22.80 s
2024-01-02 19:29:18,822	44k	INFO	====> Epoch: 3860, cost 22.63 s
2024-01-02 19:29:41,538	44k	INFO	====> Epoch: 3861, cost 22.72 s
2024-01-02 19:29:54,830	44k	INFO	Train Epoch: 3862 [54%]
2024-01-02 19:29:54,833	44k	INFO	Losses: [2.3335089683532715, 2.5785915851593018, 8.316502571105957, 15.843178749084473, 0.43086186051368713], step: 100400, lr: 6.171425980803679e-05, reference_loss: 29.502643585205078
2024-01-02 19:30:04,787	44k	INFO	====> Epoch: 3862, cost 23.25 s
2024-01-02 19:30:27,522	44k	INFO	====> Epoch: 3863, cost 22.73 s
2024-01-02 19:30:50,265	44k	INFO	====> Epoch: 3864, cost 22.74 s
2024-01-02 19:31:13,218	44k	INFO	====> Epoch: 3865, cost 22.95 s
2024-01-02 19:31:35,984	44k	INFO	====> Epoch: 3866, cost 22.77 s
2024-01-02 19:31:58,798	44k	INFO	====> Epoch: 3867, cost 22.81 s
2024-01-02 19:32:21,511	44k	INFO	====> Epoch: 3868, cost 22.71 s
2024-01-02 19:32:44,201	44k	INFO	====> Epoch: 3869, cost 22.69 s
2024-01-02 19:32:50,445	44k	INFO	Train Epoch: 3870 [23%]
2024-01-02 19:32:50,448	44k	INFO	Losses: [2.56111741065979, 2.346623182296753, 8.273757934570312, 13.83454704284668, 0.3926583230495453], step: 100600, lr: 6.165257254146846e-05, reference_loss: 27.408702850341797
2024-01-02 19:33:07,408	44k	INFO	====> Epoch: 3870, cost 23.21 s
2024-01-02 19:33:30,244	44k	INFO	====> Epoch: 3871, cost 22.84 s
2024-01-02 19:33:53,061	44k	INFO	====> Epoch: 3872, cost 22.82 s
2024-01-02 19:34:15,782	44k	INFO	====> Epoch: 3873, cost 22.72 s
2024-01-02 19:34:38,445	44k	INFO	====> Epoch: 3874, cost 22.66 s
2024-01-02 19:35:01,288	44k	INFO	====> Epoch: 3875, cost 22.84 s
2024-01-02 19:35:24,100	44k	INFO	====> Epoch: 3876, cost 22.81 s
2024-01-02 19:35:46,250	44k	INFO	Train Epoch: 3877 [92%]
2024-01-02 19:35:46,253	44k	INFO	Losses: [2.4062185287475586, 2.5252487659454346, 8.071822166442871, 15.6759033203125, 0.49169114232063293], step: 100800, lr: 6.159864676603102e-05, reference_loss: 29.170883178710938
2024-01-02 19:35:51,545	44k	INFO	Saving model and optimizer state at iteration 3877 to ./logs/44k/G_100800.pth
2024-01-02 19:35:52,445	44k	INFO	Saving model and optimizer state at iteration 3877 to ./logs/44k/D_100800.pth
2024-01-02 19:35:52,934	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_98400.pth
2024-01-02 19:35:52,973	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_98400.pth
2024-01-02 19:35:53,661	44k	INFO	====> Epoch: 3877, cost 29.56 s
2024-01-02 19:36:16,487	44k	INFO	====> Epoch: 3878, cost 22.83 s
2024-01-02 19:36:39,280	44k	INFO	====> Epoch: 3879, cost 22.79 s
2024-01-02 19:37:02,145	44k	INFO	====> Epoch: 3880, cost 22.87 s
2024-01-02 19:37:25,100	44k	INFO	====> Epoch: 3881, cost 22.95 s
2024-01-02 19:37:48,156	44k	INFO	====> Epoch: 3882, cost 23.06 s
2024-01-02 19:38:10,942	44k	INFO	====> Epoch: 3883, cost 22.79 s
2024-01-02 19:38:33,570	44k	INFO	====> Epoch: 3884, cost 22.63 s
2024-01-02 19:38:48,515	44k	INFO	Train Epoch: 3885 [62%]
2024-01-02 19:38:48,518	44k	INFO	Losses: [2.3109469413757324, 2.7155539989471436, 7.59756326675415, 13.472655296325684, 0.5966400504112244], step: 101000, lr: 6.153707506193665e-05, reference_loss: 26.693357467651367
2024-01-02 19:38:56,622	44k	INFO	====> Epoch: 3885, cost 23.05 s
2024-01-02 19:39:19,332	44k	INFO	====> Epoch: 3886, cost 22.71 s
2024-01-02 19:39:42,026	44k	INFO	====> Epoch: 3887, cost 22.69 s
2024-01-02 19:40:04,676	44k	INFO	====> Epoch: 3888, cost 22.65 s
2024-01-02 19:40:27,429	44k	INFO	====> Epoch: 3889, cost 22.75 s
2024-01-02 19:40:50,270	44k	INFO	====> Epoch: 3890, cost 22.84 s
2024-01-02 19:41:12,871	44k	INFO	====> Epoch: 3891, cost 22.60 s
2024-01-02 19:41:35,572	44k	INFO	====> Epoch: 3892, cost 22.70 s
2024-01-02 19:41:43,589	44k	INFO	Train Epoch: 3893 [31%]
2024-01-02 19:41:43,592	44k	INFO	Losses: [2.2971079349517822, 2.4206762313842773, 7.6659040451049805, 14.007211685180664, 0.36382436752319336], step: 101200, lr: 6.147556490261547e-05, reference_loss: 26.754724502563477
2024-01-02 19:41:58,949	44k	INFO	====> Epoch: 3893, cost 23.38 s
2024-01-02 19:42:21,729	44k	INFO	====> Epoch: 3894, cost 22.78 s
2024-01-02 19:42:44,592	44k	INFO	====> Epoch: 3895, cost 22.86 s
2024-01-02 19:43:07,440	44k	INFO	====> Epoch: 3896, cost 22.85 s
2024-01-02 19:43:30,143	44k	INFO	====> Epoch: 3897, cost 22.70 s
2024-01-02 19:43:52,752	44k	INFO	====> Epoch: 3898, cost 22.61 s
2024-01-02 19:44:15,455	44k	INFO	====> Epoch: 3899, cost 22.70 s
2024-01-02 19:44:38,238	44k	INFO	====> Epoch: 3900, cost 22.78 s
2024-01-02 19:44:39,135	44k	INFO	Train Epoch: 3901 [0%]
2024-01-02 19:44:39,138	44k	INFO	Losses: [2.3266079425811768, 2.589123249053955, 8.264810562133789, 13.588789939880371, 0.4386617839336395], step: 101400, lr: 6.141411622654964e-05, reference_loss: 27.20799446105957
2024-01-02 19:45:01,686	44k	INFO	====> Epoch: 3901, cost 23.45 s
2024-01-02 19:45:24,559	44k	INFO	====> Epoch: 3902, cost 22.87 s
2024-01-02 19:45:47,737	44k	INFO	====> Epoch: 3903, cost 23.18 s
2024-01-02 19:46:10,984	44k	INFO	====> Epoch: 3904, cost 23.25 s
2024-01-02 19:46:34,195	44k	INFO	====> Epoch: 3905, cost 23.21 s
2024-01-02 19:46:57,425	44k	INFO	====> Epoch: 3906, cost 23.23 s
2024-01-02 19:47:20,586	44k	INFO	====> Epoch: 3907, cost 23.16 s
2024-01-02 19:47:37,576	44k	INFO	Train Epoch: 3908 [69%]
2024-01-02 19:47:37,578	44k	INFO	Losses: [2.351633310317993, 2.446950912475586, 6.848130226135254, 14.11927318572998, 0.40764328837394714], step: 101600, lr: 6.136039902216059e-05, reference_loss: 26.173629760742188
2024-01-02 19:47:43,674	44k	INFO	Saving model and optimizer state at iteration 3908 to ./logs/44k/G_101600.pth
2024-01-02 19:47:44,609	44k	INFO	Saving model and optimizer state at iteration 3908 to ./logs/44k/D_101600.pth
2024-01-02 19:47:45,145	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_99200.pth
2024-01-02 19:47:45,184	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_99200.pth
2024-01-02 19:47:51,170	44k	INFO	====> Epoch: 3908, cost 30.58 s
2024-01-02 19:48:14,522	44k	INFO	====> Epoch: 3909, cost 23.35 s
2024-01-02 19:48:37,584	44k	INFO	====> Epoch: 3910, cost 23.06 s
2024-01-02 19:49:00,712	44k	INFO	====> Epoch: 3911, cost 23.13 s
2024-01-02 19:49:23,857	44k	INFO	====> Epoch: 3912, cost 23.14 s
2024-01-02 19:49:47,059	44k	INFO	====> Epoch: 3913, cost 23.20 s
2024-01-02 19:50:10,250	44k	INFO	====> Epoch: 3914, cost 23.19 s
2024-01-02 19:50:33,162	44k	INFO	====> Epoch: 3915, cost 22.91 s
2024-01-02 19:50:42,896	44k	INFO	Train Epoch: 3916 [38%]
2024-01-02 19:50:42,899	44k	INFO	Losses: [2.284496307373047, 2.4891762733459473, 8.510604858398438, 15.883942604064941, 0.3695797622203827], step: 101800, lr: 6.129906546160274e-05, reference_loss: 29.537799835205078
2024-01-02 19:50:56,319	44k	INFO	====> Epoch: 3916, cost 23.16 s
2024-01-02 19:51:19,010	44k	INFO	====> Epoch: 3917, cost 22.69 s
2024-01-02 19:51:41,696	44k	INFO	====> Epoch: 3918, cost 22.69 s
2024-01-02 19:52:04,520	44k	INFO	====> Epoch: 3919, cost 22.82 s
2024-01-02 19:52:27,195	44k	INFO	====> Epoch: 3920, cost 22.67 s
2024-01-02 19:52:50,079	44k	INFO	====> Epoch: 3921, cost 22.88 s
2024-01-02 19:53:12,928	44k	INFO	====> Epoch: 3922, cost 22.85 s
2024-01-02 19:53:35,784	44k	INFO	====> Epoch: 3923, cost 22.86 s
2024-01-02 19:53:38,459	44k	INFO	Train Epoch: 3924 [8%]
2024-01-02 19:53:38,462	44k	INFO	Losses: [2.213390827178955, 2.531557559967041, 8.708649635314941, 15.827736854553223, 0.3124590218067169], step: 102000, lr: 6.123779320777873e-05, reference_loss: 29.593793869018555
2024-01-02 19:53:58,816	44k	INFO	====> Epoch: 3924, cost 23.03 s
2024-01-02 19:54:21,446	44k	INFO	====> Epoch: 3925, cost 22.63 s
2024-01-02 19:54:44,113	44k	INFO	====> Epoch: 3926, cost 22.67 s
2024-01-02 19:55:06,894	44k	INFO	====> Epoch: 3927, cost 22.78 s
2024-01-02 19:55:29,712	44k	INFO	====> Epoch: 3928, cost 22.82 s
2024-01-02 19:55:52,538	44k	INFO	====> Epoch: 3929, cost 22.83 s
2024-01-02 19:56:15,379	44k	INFO	====> Epoch: 3930, cost 22.84 s
2024-01-02 19:56:34,183	44k	INFO	Train Epoch: 3931 [77%]
2024-01-02 19:56:34,186	44k	INFO	Losses: [2.144023895263672, 2.6564650535583496, 9.98895263671875, 18.41259765625, 0.366550475358963], step: 102200, lr: 6.118423022818714e-05, reference_loss: 33.5685920715332
2024-01-02 19:56:38,766	44k	INFO	====> Epoch: 3931, cost 23.39 s
2024-01-02 19:57:01,618	44k	INFO	====> Epoch: 3932, cost 22.85 s
2024-01-02 19:57:24,474	44k	INFO	====> Epoch: 3933, cost 22.86 s
2024-01-02 19:57:47,332	44k	INFO	====> Epoch: 3934, cost 22.86 s
2024-01-02 19:58:10,177	44k	INFO	====> Epoch: 3935, cost 22.85 s
2024-01-02 19:58:32,970	44k	INFO	====> Epoch: 3936, cost 22.79 s
2024-01-02 19:58:55,803	44k	INFO	====> Epoch: 3937, cost 22.83 s
2024-01-02 19:59:18,533	44k	INFO	====> Epoch: 3938, cost 22.73 s
2024-01-02 19:59:29,958	44k	INFO	Train Epoch: 3939 [46%]
2024-01-02 19:59:29,961	44k	INFO	Losses: [2.3254306316375732, 2.3126838207244873, 5.861399173736572, 13.242416381835938, 0.2681589126586914], step: 102400, lr: 6.11230727593687e-05, reference_loss: 24.010089874267578
2024-01-02 19:59:35,391	44k	INFO	Saving model and optimizer state at iteration 3939 to ./logs/44k/G_102400.pth
2024-01-02 19:59:36,265	44k	INFO	Saving model and optimizer state at iteration 3939 to ./logs/44k/D_102400.pth
2024-01-02 19:59:36,752	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_100000.pth
2024-01-02 19:59:36,791	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_100000.pth
2024-01-02 19:59:48,015	44k	INFO	====> Epoch: 3939, cost 29.48 s
2024-01-02 20:00:10,815	44k	INFO	====> Epoch: 3940, cost 22.80 s
2024-01-02 20:00:33,610	44k	INFO	====> Epoch: 3941, cost 22.79 s
2024-01-02 20:00:56,358	44k	INFO	====> Epoch: 3942, cost 22.75 s
2024-01-02 20:01:19,131	44k	INFO	====> Epoch: 3943, cost 22.77 s
2024-01-02 20:01:41,911	44k	INFO	====> Epoch: 3944, cost 22.78 s
2024-01-02 20:02:04,724	44k	INFO	====> Epoch: 3945, cost 22.81 s
2024-01-02 20:02:27,541	44k	INFO	====> Epoch: 3946, cost 22.82 s
2024-01-02 20:02:31,991	44k	INFO	Train Epoch: 3947 [15%]
2024-01-02 20:02:31,994	44k	INFO	Losses: [2.1233890056610107, 2.7204136848449707, 8.380477905273438, 14.140870094299316, 0.3012855052947998], step: 102600, lr: 6.106197642126934e-05, reference_loss: 27.66643524169922
2024-01-02 20:02:50,837	44k	INFO	====> Epoch: 3947, cost 23.30 s
2024-01-02 20:03:13,521	44k	INFO	====> Epoch: 3948, cost 22.68 s
2024-01-02 20:03:36,352	44k	INFO	====> Epoch: 3949, cost 22.83 s
2024-01-02 20:03:59,169	44k	INFO	====> Epoch: 3950, cost 22.82 s
2024-01-02 20:04:21,941	44k	INFO	====> Epoch: 3951, cost 22.77 s
2024-01-02 20:04:44,695	44k	INFO	====> Epoch: 3952, cost 22.75 s
2024-01-02 20:05:07,376	44k	INFO	====> Epoch: 3953, cost 22.68 s
2024-01-02 20:05:27,519	44k	INFO	Train Epoch: 3954 [85%]
2024-01-02 20:05:27,522	44k	INFO	Losses: [2.365948438644409, 2.498392105102539, 7.895369529724121, 15.809386253356934, 0.5507939457893372], step: 102800, lr: 6.100856722368809e-05, reference_loss: 29.119890213012695
2024-01-02 20:05:30,348	44k	INFO	====> Epoch: 3954, cost 22.97 s
2024-01-02 20:05:53,167	44k	INFO	====> Epoch: 3955, cost 22.82 s
2024-01-02 20:06:16,083	44k	INFO	====> Epoch: 3956, cost 22.92 s
2024-01-02 20:06:38,724	44k	INFO	====> Epoch: 3957, cost 22.64 s
2024-01-02 20:07:01,398	44k	INFO	====> Epoch: 3958, cost 22.67 s
2024-01-02 20:07:24,067	44k	INFO	====> Epoch: 3959, cost 22.67 s
2024-01-02 20:07:46,731	44k	INFO	====> Epoch: 3960, cost 22.66 s
2024-01-02 20:08:09,388	44k	INFO	====> Epoch: 3961, cost 22.66 s
2024-01-02 20:08:22,593	44k	INFO	Train Epoch: 3962 [54%]
2024-01-02 20:08:22,596	44k	INFO	Losses: [2.5647616386413574, 2.2173941135406494, 6.073546886444092, 13.546789169311523, 0.38375356793403625], step: 103000, lr: 6.094758534104077e-05, reference_loss: 24.786245346069336
2024-01-02 20:08:32,444	44k	INFO	====> Epoch: 3962, cost 23.06 s
2024-01-02 20:08:55,109	44k	INFO	====> Epoch: 3963, cost 22.66 s
2024-01-02 20:09:17,744	44k	INFO	====> Epoch: 3964, cost 22.64 s
2024-01-02 20:09:40,521	44k	INFO	====> Epoch: 3965, cost 22.78 s
2024-01-02 20:10:03,151	44k	INFO	====> Epoch: 3966, cost 22.63 s
2024-01-02 20:10:25,944	44k	INFO	====> Epoch: 3967, cost 22.79 s
2024-01-02 20:10:48,762	44k	INFO	====> Epoch: 3968, cost 22.82 s
2024-01-02 20:11:11,585	44k	INFO	====> Epoch: 3969, cost 22.82 s
2024-01-02 20:11:17,822	44k	INFO	Train Epoch: 3970 [23%]
2024-01-02 20:11:17,825	44k	INFO	Losses: [2.289785146713257, 2.5670931339263916, 7.852532386779785, 13.997480392456055, 0.4650416970252991], step: 103200, lr: 6.088666441360319e-05, reference_loss: 27.171932220458984
2024-01-02 20:11:23,257	44k	INFO	Saving model and optimizer state at iteration 3970 to ./logs/44k/G_103200.pth
2024-01-02 20:11:24,128	44k	INFO	Saving model and optimizer state at iteration 3970 to ./logs/44k/D_103200.pth
2024-01-02 20:11:24,618	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_100800.pth
2024-01-02 20:11:24,657	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_100800.pth
2024-01-02 20:11:41,122	44k	INFO	====> Epoch: 3970, cost 29.54 s
2024-01-02 20:12:03,886	44k	INFO	====> Epoch: 3971, cost 22.76 s
2024-01-02 20:12:26,705	44k	INFO	====> Epoch: 3972, cost 22.82 s
2024-01-02 20:12:49,667	44k	INFO	====> Epoch: 3973, cost 22.96 s
2024-01-02 20:13:12,468	44k	INFO	====> Epoch: 3974, cost 22.80 s
2024-01-02 20:13:35,085	44k	INFO	====> Epoch: 3975, cost 22.62 s
2024-01-02 20:13:57,777	44k	INFO	====> Epoch: 3976, cost 22.69 s
2024-01-02 20:14:19,786	44k	INFO	Train Epoch: 3977 [92%]
2024-01-02 20:14:19,789	44k	INFO	Losses: [2.4077625274658203, 2.6349353790283203, 7.629416465759277, 15.254714012145996, 0.4976761043071747], step: 103400, lr: 6.083340855651638e-05, reference_loss: 28.42450523376465
2024-01-02 20:14:20,874	44k	INFO	====> Epoch: 3977, cost 23.10 s
2024-01-02 20:14:43,529	44k	INFO	====> Epoch: 3978, cost 22.65 s
2024-01-02 20:15:06,264	44k	INFO	====> Epoch: 3979, cost 22.74 s
2024-01-02 20:15:29,072	44k	INFO	====> Epoch: 3980, cost 22.81 s
2024-01-02 20:15:51,737	44k	INFO	====> Epoch: 3981, cost 22.66 s
2024-01-02 20:16:14,425	44k	INFO	====> Epoch: 3982, cost 22.69 s
2024-01-02 20:16:37,107	44k	INFO	====> Epoch: 3983, cost 22.68 s
2024-01-02 20:16:59,912	44k	INFO	====> Epoch: 3984, cost 22.80 s
2024-01-02 20:17:14,880	44k	INFO	Train Epoch: 3985 [62%]
2024-01-02 20:17:14,883	44k	INFO	Losses: [2.4406490325927734, 2.3101093769073486, 8.30265998840332, 14.60214614868164, 0.43595632910728455], step: 103600, lr: 6.077260175592348e-05, reference_loss: 28.091520309448242
2024-01-02 20:17:22,982	44k	INFO	====> Epoch: 3985, cost 23.07 s
2024-01-02 20:17:45,773	44k	INFO	====> Epoch: 3986, cost 22.79 s
2024-01-02 20:18:08,553	44k	INFO	====> Epoch: 3987, cost 22.78 s
2024-01-02 20:18:31,343	44k	INFO	====> Epoch: 3988, cost 22.79 s
2024-01-02 20:18:54,187	44k	INFO	====> Epoch: 3989, cost 22.84 s
2024-01-02 20:19:17,031	44k	INFO	====> Epoch: 3990, cost 22.84 s
2024-01-02 20:19:39,738	44k	INFO	====> Epoch: 3991, cost 22.71 s
2024-01-02 20:20:02,176	44k	INFO	====> Epoch: 3992, cost 22.44 s
2024-01-02 20:20:10,194	44k	INFO	Train Epoch: 3993 [31%]
2024-01-02 20:20:10,197	44k	INFO	Losses: [2.3409478664398193, 2.475104570388794, 7.182673931121826, 13.594877243041992, 0.3765193819999695], step: 103800, lr: 6.0711855735534843e-05, reference_loss: 25.970123291015625
2024-01-02 20:20:25,566	44k	INFO	====> Epoch: 3993, cost 23.39 s
2024-01-02 20:20:48,426	44k	INFO	====> Epoch: 3994, cost 22.86 s
2024-01-02 20:21:11,276	44k	INFO	====> Epoch: 3995, cost 22.85 s
2024-01-02 20:21:34,118	44k	INFO	====> Epoch: 3996, cost 22.84 s
2024-01-02 20:21:56,956	44k	INFO	====> Epoch: 3997, cost 22.84 s
2024-01-02 20:22:19,758	44k	INFO	====> Epoch: 3998, cost 22.80 s
2024-01-02 20:22:42,531	44k	INFO	====> Epoch: 3999, cost 22.77 s
2024-01-02 20:23:05,218	44k	INFO	====> Epoch: 4000, cost 22.69 s
2024-01-02 20:23:06,112	44k	INFO	Train Epoch: 4001 [0%]
2024-01-02 20:23:06,115	44k	INFO	Losses: [2.3897383213043213, 2.5062644481658936, 7.8349480628967285, 13.789337158203125, 0.14083431661128998], step: 104000, lr: 6.065117043459685e-05, reference_loss: 26.661123275756836
2024-01-02 20:23:11,390	44k	INFO	Saving model and optimizer state at iteration 4001 to ./logs/44k/G_104000.pth
2024-01-02 20:23:12,444	44k	INFO	Saving model and optimizer state at iteration 4001 to ./logs/44k/D_104000.pth
2024-01-02 20:23:12,935	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_101600.pth
2024-01-02 20:23:12,973	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_101600.pth
2024-01-02 20:23:34,782	44k	INFO	====> Epoch: 4001, cost 29.56 s
2024-01-02 20:23:57,466	44k	INFO	====> Epoch: 4002, cost 22.68 s
2024-01-02 20:24:20,291	44k	INFO	====> Epoch: 4003, cost 22.83 s
2024-01-02 20:24:43,122	44k	INFO	====> Epoch: 4004, cost 22.83 s
2024-01-02 20:25:05,945	44k	INFO	====> Epoch: 4005, cost 22.82 s
2024-01-02 20:25:28,620	44k	INFO	====> Epoch: 4006, cost 22.68 s
2024-01-02 20:25:51,284	44k	INFO	====> Epoch: 4007, cost 22.66 s
2024-01-02 20:26:08,098	44k	INFO	Train Epoch: 4008 [69%]
2024-01-02 20:26:08,101	44k	INFO	Losses: [2.1775295734405518, 2.7295703887939453, 9.333735466003418, 15.591160774230957, 0.6921781301498413], step: 104200, lr: 6.05981205574863e-05, reference_loss: 30.5241756439209
2024-01-02 20:26:14,429	44k	INFO	====> Epoch: 4008, cost 23.15 s
2024-01-02 20:26:37,271	44k	INFO	====> Epoch: 4009, cost 22.84 s
2024-01-02 20:27:00,068	44k	INFO	====> Epoch: 4010, cost 22.80 s
2024-01-02 20:27:22,923	44k	INFO	====> Epoch: 4011, cost 22.85 s
2024-01-02 20:27:45,732	44k	INFO	====> Epoch: 4012, cost 22.81 s
2024-01-02 20:28:08,541	44k	INFO	====> Epoch: 4013, cost 22.81 s
2024-01-02 20:28:31,204	44k	INFO	====> Epoch: 4014, cost 22.66 s
2024-01-02 20:28:53,842	44k	INFO	====> Epoch: 4015, cost 22.64 s
2024-01-02 20:29:03,573	44k	INFO	Train Epoch: 4016 [38%]
2024-01-02 20:29:03,576	44k	INFO	Losses: [2.4112706184387207, 2.3528292179107666, 9.706480979919434, 16.452957153320312, 0.1946142017841339], step: 104400, lr: 6.0537548941979654e-05, reference_loss: 31.118152618408203
2024-01-02 20:29:16,976	44k	INFO	====> Epoch: 4016, cost 23.13 s
2024-01-02 20:29:39,616	44k	INFO	====> Epoch: 4017, cost 22.64 s
2024-01-02 20:30:02,284	44k	INFO	====> Epoch: 4018, cost 22.67 s
2024-01-02 20:30:25,001	44k	INFO	====> Epoch: 4019, cost 22.72 s
2024-01-02 20:30:47,655	44k	INFO	====> Epoch: 4020, cost 22.65 s
2024-01-02 20:31:10,271	44k	INFO	====> Epoch: 4021, cost 22.62 s
2024-01-02 20:31:32,871	44k	INFO	====> Epoch: 4022, cost 22.60 s
2024-01-02 20:31:55,539	44k	INFO	====> Epoch: 4023, cost 22.67 s
2024-01-02 20:31:58,191	44k	INFO	Train Epoch: 4024 [8%]
2024-01-02 20:31:58,194	44k	INFO	Losses: [2.0851340293884277, 2.9000260829925537, 9.581253051757812, 15.492993354797363, 0.4045194387435913], step: 104600, lr: 6.0477037871595065e-05, reference_loss: 30.463926315307617
2024-01-02 20:32:18,728	44k	INFO	====> Epoch: 4024, cost 23.19 s
2024-01-02 20:32:41,545	44k	INFO	====> Epoch: 4025, cost 22.82 s
2024-01-02 20:33:04,360	44k	INFO	====> Epoch: 4026, cost 22.81 s
2024-01-02 20:33:27,034	44k	INFO	====> Epoch: 4027, cost 22.67 s
2024-01-02 20:33:49,805	44k	INFO	====> Epoch: 4028, cost 22.77 s
2024-01-02 20:34:12,792	44k	INFO	====> Epoch: 4029, cost 22.99 s
2024-01-02 20:34:35,682	44k	INFO	====> Epoch: 4030, cost 22.89 s
2024-01-02 20:34:54,311	44k	INFO	Train Epoch: 4031 [77%]
2024-01-02 20:34:54,314	44k	INFO	Losses: [2.151667356491089, 2.579310178756714, 10.035802841186523, 16.45052719116211, 0.6163822412490845], step: 104800, lr: 6.042414030335179e-05, reference_loss: 31.833690643310547
2024-01-02 20:34:59,600	44k	INFO	Saving model and optimizer state at iteration 4031 to ./logs/44k/G_104800.pth
2024-01-02 20:35:00,468	44k	INFO	Saving model and optimizer state at iteration 4031 to ./logs/44k/D_104800.pth
2024-01-02 20:35:00,956	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_102400.pth
2024-01-02 20:35:00,995	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_102400.pth
2024-01-02 20:35:05,175	44k	INFO	====> Epoch: 4031, cost 29.49 s
2024-01-02 20:35:27,956	44k	INFO	====> Epoch: 4032, cost 22.78 s
2024-01-02 20:35:50,840	44k	INFO	====> Epoch: 4033, cost 22.88 s
2024-01-02 20:36:13,440	44k	INFO	====> Epoch: 4034, cost 22.60 s
2024-01-02 20:36:36,095	44k	INFO	====> Epoch: 4035, cost 22.65 s
2024-01-02 20:36:59,088	44k	INFO	====> Epoch: 4036, cost 22.99 s
2024-01-02 20:37:21,912	44k	INFO	====> Epoch: 4037, cost 22.82 s
2024-01-02 20:37:44,707	44k	INFO	====> Epoch: 4038, cost 22.80 s
2024-01-02 20:37:56,118	44k	INFO	Train Epoch: 4039 [46%]
2024-01-02 20:37:56,121	44k	INFO	Losses: [2.2138242721557617, 2.6112775802612305, 9.418854713439941, 16.70271110534668, 0.31382450461387634], step: 105000, lr: 6.036374259200194e-05, reference_loss: 31.26049041748047
2024-01-02 20:38:07,705	44k	INFO	====> Epoch: 4039, cost 23.00 s
2024-01-02 20:38:30,379	44k	INFO	====> Epoch: 4040, cost 22.67 s
2024-01-02 20:38:53,058	44k	INFO	====> Epoch: 4041, cost 22.68 s
2024-01-02 20:39:15,697	44k	INFO	====> Epoch: 4042, cost 22.64 s
2024-01-02 20:39:38,363	44k	INFO	====> Epoch: 4043, cost 22.67 s
2024-01-02 20:40:01,109	44k	INFO	====> Epoch: 4044, cost 22.75 s
2024-01-02 20:40:23,931	44k	INFO	====> Epoch: 4045, cost 22.82 s
2024-01-02 20:40:46,728	44k	INFO	====> Epoch: 4046, cost 22.80 s
2024-01-02 20:40:51,308	44k	INFO	Train Epoch: 4047 [15%]
2024-01-02 20:40:51,311	44k	INFO	Losses: [2.460885524749756, 2.418079137802124, 9.662410736083984, 16.421165466308594, 0.40070030093193054], step: 105200, lr: 6.030340525194605e-05, reference_loss: 31.363239288330078
2024-01-02 20:41:10,025	44k	INFO	====> Epoch: 4047, cost 23.30 s
2024-01-02 20:41:32,854	44k	INFO	====> Epoch: 4048, cost 22.83 s
2024-01-02 20:41:55,627	44k	INFO	====> Epoch: 4049, cost 22.77 s
2024-01-02 20:42:18,444	44k	INFO	====> Epoch: 4050, cost 22.82 s
2024-01-02 20:42:41,286	44k	INFO	====> Epoch: 4051, cost 22.84 s
2024-01-02 20:43:04,071	44k	INFO	====> Epoch: 4052, cost 22.78 s
2024-01-02 20:43:26,873	44k	INFO	====> Epoch: 4053, cost 22.80 s
2024-01-02 20:43:47,232	44k	INFO	Train Epoch: 4054 [85%]
2024-01-02 20:43:47,235	44k	INFO	Losses: [2.1890435218811035, 2.668473243713379, 8.506758689880371, 15.00928783416748, 0.5649852156639099], step: 105400, lr: 6.025065955528364e-05, reference_loss: 28.938547134399414
2024-01-02 20:43:50,202	44k	INFO	====> Epoch: 4054, cost 23.33 s
2024-01-02 20:44:13,095	44k	INFO	====> Epoch: 4055, cost 22.89 s
2024-01-02 20:44:35,756	44k	INFO	====> Epoch: 4056, cost 22.66 s
2024-01-02 20:44:58,432	44k	INFO	====> Epoch: 4057, cost 22.68 s
2024-01-02 20:45:21,252	44k	INFO	====> Epoch: 4058, cost 22.82 s
2024-01-02 20:45:43,997	44k	INFO	====> Epoch: 4059, cost 22.74 s
2024-01-02 20:46:06,685	44k	INFO	====> Epoch: 4060, cost 22.69 s
2024-01-02 20:46:29,568	44k	INFO	====> Epoch: 4061, cost 22.88 s
2024-01-02 20:46:42,864	44k	INFO	Train Epoch: 4062 [54%]
2024-01-02 20:46:42,867	44k	INFO	Losses: [2.469712257385254, 2.353217124938965, 8.101332664489746, 14.470357894897461, 0.2084147185087204], step: 105600, lr: 6.0190435248803e-05, reference_loss: 27.6030330657959
2024-01-02 20:46:48,312	44k	INFO	Saving model and optimizer state at iteration 4062 to ./logs/44k/G_105600.pth
2024-01-02 20:46:49,342	44k	INFO	Saving model and optimizer state at iteration 4062 to ./logs/44k/D_105600.pth
2024-01-02 20:46:49,847	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_103200.pth
2024-01-02 20:46:49,886	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_103200.pth
2024-01-02 20:46:59,384	44k	INFO	====> Epoch: 4062, cost 29.82 s
2024-01-02 20:47:22,160	44k	INFO	====> Epoch: 4063, cost 22.78 s
2024-01-02 20:47:45,017	44k	INFO	====> Epoch: 4064, cost 22.86 s
2024-01-02 20:48:07,927	44k	INFO	====> Epoch: 4065, cost 22.91 s
2024-01-02 20:48:30,753	44k	INFO	====> Epoch: 4066, cost 22.83 s
2024-01-02 20:48:53,510	44k	INFO	====> Epoch: 4067, cost 22.76 s
2024-01-02 20:49:16,297	44k	INFO	====> Epoch: 4068, cost 22.79 s
2024-01-02 20:49:39,136	44k	INFO	====> Epoch: 4069, cost 22.84 s
2024-01-02 20:49:45,399	44k	INFO	Train Epoch: 4070 [23%]
2024-01-02 20:49:45,402	44k	INFO	Losses: [2.434060573577881, 2.5465214252471924, 6.570301532745361, 13.585637092590332, 0.3573666214942932], step: 105800, lr: 6.013027114028731e-05, reference_loss: 25.493886947631836
2024-01-02 20:50:02,452	44k	INFO	====> Epoch: 4070, cost 23.32 s
2024-01-02 20:50:25,352	44k	INFO	====> Epoch: 4071, cost 22.90 s
2024-01-02 20:50:48,392	44k	INFO	====> Epoch: 4072, cost 23.04 s
2024-01-02 20:51:11,344	44k	INFO	====> Epoch: 4073, cost 22.95 s
2024-01-02 20:51:34,296	44k	INFO	====> Epoch: 4074, cost 22.95 s
2024-01-02 20:51:57,239	44k	INFO	====> Epoch: 4075, cost 22.94 s
2024-01-02 20:52:20,168	44k	INFO	====> Epoch: 4076, cost 22.93 s
2024-01-02 20:52:42,367	44k	INFO	Train Epoch: 4077 [92%]
2024-01-02 20:52:42,370	44k	INFO	Losses: [2.2370095252990723, 2.5565292835235596, 9.064557075500488, 17.815288543701172, 0.5344280004501343], step: 106000, lr: 6.00776768791748e-05, reference_loss: 32.20781326293945
2024-01-02 20:52:43,465	44k	INFO	====> Epoch: 4077, cost 23.30 s
2024-01-02 20:53:06,392	44k	INFO	====> Epoch: 4078, cost 22.93 s
2024-01-02 20:53:29,231	44k	INFO	====> Epoch: 4079, cost 22.84 s
2024-01-02 20:53:52,086	44k	INFO	====> Epoch: 4080, cost 22.86 s
2024-01-02 20:54:15,128	44k	INFO	====> Epoch: 4081, cost 23.04 s
2024-01-02 20:54:38,010	44k	INFO	====> Epoch: 4082, cost 22.88 s
2024-01-02 20:55:00,880	44k	INFO	====> Epoch: 4083, cost 22.87 s
2024-01-02 20:55:23,734	44k	INFO	====> Epoch: 4084, cost 22.85 s
2024-01-02 20:55:38,839	44k	INFO	Train Epoch: 4085 [62%]
2024-01-02 20:55:38,842	44k	INFO	Losses: [2.3700997829437256, 2.5090503692626953, 8.114869117736816, 15.365851402282715, 0.2600228190422058], step: 106200, lr: 6.001762547970927e-05, reference_loss: 28.61989402770996
2024-01-02 20:55:47,011	44k	INFO	====> Epoch: 4085, cost 23.28 s
2024-01-02 20:56:09,847	44k	INFO	====> Epoch: 4086, cost 22.84 s
2024-01-02 20:56:32,722	44k	INFO	====> Epoch: 4087, cost 22.88 s
2024-01-02 20:56:55,600	44k	INFO	====> Epoch: 4088, cost 22.88 s
2024-01-02 20:57:18,433	44k	INFO	====> Epoch: 4089, cost 22.83 s
2024-01-02 20:57:41,245	44k	INFO	====> Epoch: 4090, cost 22.81 s
2024-01-02 20:58:04,122	44k	INFO	====> Epoch: 4091, cost 22.88 s
2024-01-02 20:58:26,979	44k	INFO	====> Epoch: 4092, cost 22.86 s
2024-01-02 20:58:34,986	44k	INFO	Train Epoch: 4093 [31%]
2024-01-02 20:58:34,989	44k	INFO	Losses: [2.414484739303589, 2.4710311889648438, 7.421417236328125, 14.435842514038086, 0.5039973855018616], step: 106400, lr: 5.9957634105377285e-05, reference_loss: 27.24677276611328
2024-01-02 20:58:40,292	44k	INFO	Saving model and optimizer state at iteration 4093 to ./logs/44k/G_106400.pth
2024-01-02 20:58:41,122	44k	INFO	Saving model and optimizer state at iteration 4093 to ./logs/44k/D_106400.pth
2024-01-02 20:58:41,616	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_104000.pth
2024-01-02 20:58:41,654	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_104000.pth
2024-01-02 20:58:56,414	44k	INFO	====> Epoch: 4093, cost 29.44 s
2024-01-02 20:59:19,251	44k	INFO	====> Epoch: 4094, cost 22.84 s
2024-01-02 20:59:42,053	44k	INFO	====> Epoch: 4095, cost 22.80 s
2024-01-02 21:00:04,830	44k	INFO	====> Epoch: 4096, cost 22.78 s
2024-01-02 21:00:27,644	44k	INFO	====> Epoch: 4097, cost 22.81 s
2024-01-02 21:00:50,573	44k	INFO	====> Epoch: 4098, cost 22.93 s
2024-01-02 21:01:13,373	44k	INFO	====> Epoch: 4099, cost 22.80 s
2024-01-02 21:01:36,183	44k	INFO	====> Epoch: 4100, cost 22.81 s
2024-01-02 21:01:37,073	44k	INFO	Train Epoch: 4101 [0%]
2024-01-02 21:01:37,076	44k	INFO	Losses: [2.164797067642212, 2.69576096534729, 9.014299392700195, 15.124800682067871, 0.22315913438796997], step: 106600, lr: 5.9897702696179964e-05, reference_loss: 29.222816467285156
2024-01-02 21:01:59,278	44k	INFO	====> Epoch: 4101, cost 23.10 s
2024-01-02 21:02:21,996	44k	INFO	====> Epoch: 4102, cost 22.72 s
2024-01-02 21:02:44,779	44k	INFO	====> Epoch: 4103, cost 22.78 s
2024-01-02 21:03:07,413	44k	INFO	====> Epoch: 4104, cost 22.63 s
2024-01-02 21:03:30,030	44k	INFO	====> Epoch: 4105, cost 22.62 s
2024-01-02 21:03:52,687	44k	INFO	====> Epoch: 4106, cost 22.66 s
2024-01-02 21:04:15,350	44k	INFO	====> Epoch: 4107, cost 22.66 s
2024-01-02 21:04:32,077	44k	INFO	Train Epoch: 4108 [69%]
2024-01-02 21:04:32,080	44k	INFO	Losses: [2.3238296508789062, 2.5163650512695312, 8.18404769897461, 15.602192878723145, 0.3861943781375885], step: 106800, lr: 5.984531185616042e-05, reference_loss: 29.01262855529785
2024-01-02 21:04:38,649	44k	INFO	====> Epoch: 4108, cost 23.30 s
2024-01-02 21:05:01,324	44k	INFO	====> Epoch: 4109, cost 22.68 s
2024-01-02 21:05:24,071	44k	INFO	====> Epoch: 4110, cost 22.75 s
2024-01-02 21:05:46,867	44k	INFO	====> Epoch: 4111, cost 22.80 s
2024-01-02 21:06:09,557	44k	INFO	====> Epoch: 4112, cost 22.69 s
2024-01-02 21:06:32,166	44k	INFO	====> Epoch: 4113, cost 22.61 s
2024-01-02 21:06:54,816	44k	INFO	====> Epoch: 4114, cost 22.65 s
2024-01-02 21:07:17,460	44k	INFO	====> Epoch: 4115, cost 22.64 s
2024-01-02 21:07:27,269	44k	INFO	Train Epoch: 4116 [38%]
2024-01-02 21:07:27,272	44k	INFO	Losses: [2.2192392349243164, 2.627833604812622, 9.710014343261719, 15.895535469055176, 0.29904669523239136], step: 107000, lr: 5.9785492720083624e-05, reference_loss: 30.75166893005371
2024-01-02 21:07:40,669	44k	INFO	====> Epoch: 4116, cost 23.21 s
2024-01-02 21:08:03,589	44k	INFO	====> Epoch: 4117, cost 22.92 s
2024-01-02 21:08:26,267	44k	INFO	====> Epoch: 4118, cost 22.68 s
2024-01-02 21:08:48,961	44k	INFO	====> Epoch: 4119, cost 22.69 s
2024-01-02 21:09:11,687	44k	INFO	====> Epoch: 4120, cost 22.73 s
2024-01-02 21:09:34,508	44k	INFO	====> Epoch: 4121, cost 22.82 s
2024-01-02 21:09:57,342	44k	INFO	====> Epoch: 4122, cost 22.83 s
2024-01-02 21:10:20,174	44k	INFO	====> Epoch: 4123, cost 22.83 s
2024-01-02 21:10:22,844	44k	INFO	Train Epoch: 4124 [8%]
2024-01-02 21:10:22,847	44k	INFO	Losses: [2.125401020050049, 2.7092952728271484, 9.50235366821289, 17.502639770507812, 0.260921835899353], step: 107200, lr: 5.9725733376978566e-05, reference_loss: 32.10061264038086
2024-01-02 21:10:28,241	44k	INFO	Saving model and optimizer state at iteration 4124 to ./logs/44k/G_107200.pth
2024-01-02 21:10:29,130	44k	INFO	Saving model and optimizer state at iteration 4124 to ./logs/44k/D_107200.pth
2024-01-02 21:10:29,625	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_104800.pth
2024-01-02 21:10:29,664	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_104800.pth
2024-01-02 21:10:49,937	44k	INFO	====> Epoch: 4124, cost 29.76 s
2024-01-02 21:11:12,784	44k	INFO	====> Epoch: 4125, cost 22.85 s
2024-01-02 21:11:35,618	44k	INFO	====> Epoch: 4126, cost 22.83 s
2024-01-02 21:11:58,427	44k	INFO	====> Epoch: 4127, cost 22.81 s
2024-01-02 21:12:21,093	44k	INFO	====> Epoch: 4128, cost 22.67 s
2024-01-02 21:12:43,924	44k	INFO	====> Epoch: 4129, cost 22.83 s
2024-01-02 21:13:06,659	44k	INFO	====> Epoch: 4130, cost 22.74 s
2024-01-02 21:13:25,249	44k	INFO	Train Epoch: 4131 [77%]
2024-01-02 21:13:25,252	44k	INFO	Losses: [2.496201515197754, 2.4890828132629395, 8.714011192321777, 15.850119590759277, 0.46908998489379883], step: 107400, lr: 5.967349295369766e-05, reference_loss: 30.018505096435547
2024-01-02 21:13:29,822	44k	INFO	====> Epoch: 4131, cost 23.16 s
2024-01-02 21:13:52,645	44k	INFO	====> Epoch: 4132, cost 22.82 s
2024-01-02 21:14:15,669	44k	INFO	====> Epoch: 4133, cost 23.02 s
2024-01-02 21:14:38,816	44k	INFO	====> Epoch: 4134, cost 23.15 s
2024-01-02 21:15:01,982	44k	INFO	====> Epoch: 4135, cost 23.17 s
2024-01-02 21:15:25,198	44k	INFO	====> Epoch: 4136, cost 23.22 s
2024-01-02 21:15:48,378	44k	INFO	====> Epoch: 4137, cost 23.18 s
2024-01-02 21:16:11,543	44k	INFO	====> Epoch: 4138, cost 23.17 s
2024-01-02 21:16:23,161	44k	INFO	Train Epoch: 4139 [46%]
2024-01-02 21:16:23,163	44k	INFO	Losses: [2.413054943084717, 2.516749620437622, 7.351150035858154, 14.90969467163086, 0.34083864092826843], step: 107600, lr: 5.961384556137134e-05, reference_loss: 27.5314884185791
2024-01-02 21:16:35,003	44k	INFO	====> Epoch: 4139, cost 23.46 s
2024-01-02 21:16:58,053	44k	INFO	====> Epoch: 4140, cost 23.05 s
2024-01-02 21:17:20,968	44k	INFO	====> Epoch: 4141, cost 22.92 s
2024-01-02 21:17:43,980	44k	INFO	====> Epoch: 4142, cost 23.01 s
2024-01-02 21:18:06,928	44k	INFO	====> Epoch: 4143, cost 22.95 s
2024-01-02 21:18:29,883	44k	INFO	====> Epoch: 4144, cost 22.95 s
2024-01-02 21:18:53,105	44k	INFO	====> Epoch: 4145, cost 23.22 s
2024-01-02 21:19:16,523	44k	INFO	====> Epoch: 4146, cost 23.42 s
2024-01-02 21:19:21,007	44k	INFO	Train Epoch: 4147 [15%]
2024-01-02 21:19:21,009	44k	INFO	Losses: [2.3538198471069336, 2.300168752670288, 7.3204240798950195, 14.399389266967773, 0.3434517979621887], step: 107800, lr: 5.9554257790348136e-05, reference_loss: 26.717254638671875
2024-01-02 21:19:39,962	44k	INFO	====> Epoch: 4147, cost 23.44 s
2024-01-02 21:20:02,847	44k	INFO	====> Epoch: 4148, cost 22.88 s
2024-01-02 21:20:25,605	44k	INFO	====> Epoch: 4149, cost 22.76 s
2024-01-02 21:20:48,274	44k	INFO	====> Epoch: 4150, cost 22.67 s
2024-01-02 21:21:10,936	44k	INFO	====> Epoch: 4151, cost 22.66 s
2024-01-02 21:21:33,592	44k	INFO	====> Epoch: 4152, cost 22.66 s
2024-01-02 21:21:56,256	44k	INFO	====> Epoch: 4153, cost 22.66 s
2024-01-02 21:22:16,468	44k	INFO	Train Epoch: 4154 [85%]
2024-01-02 21:22:16,471	44k	INFO	Losses: [2.4276535511016846, 2.2977142333984375, 8.551966667175293, 15.403505325317383, 0.5292060971260071], step: 108000, lr: 5.950216735195181e-05, reference_loss: 29.210044860839844
2024-01-02 21:22:21,992	44k	INFO	Saving model and optimizer state at iteration 4154 to ./logs/44k/G_108000.pth
2024-01-02 21:22:22,873	44k	INFO	Saving model and optimizer state at iteration 4154 to ./logs/44k/D_108000.pth
2024-01-02 21:22:23,365	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_105600.pth
2024-01-02 21:22:23,404	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_105600.pth
2024-01-02 21:22:25,872	44k	INFO	====> Epoch: 4154, cost 29.62 s
2024-01-02 21:22:48,574	44k	INFO	====> Epoch: 4155, cost 22.70 s
2024-01-02 21:23:11,400	44k	INFO	====> Epoch: 4156, cost 22.83 s
2024-01-02 21:23:34,194	44k	INFO	====> Epoch: 4157, cost 22.79 s
2024-01-02 21:23:56,870	44k	INFO	====> Epoch: 4158, cost 22.68 s
2024-01-02 21:24:19,665	44k	INFO	====> Epoch: 4159, cost 22.79 s
2024-01-02 21:24:42,515	44k	INFO	====> Epoch: 4160, cost 22.85 s
2024-01-02 21:25:05,373	44k	INFO	====> Epoch: 4161, cost 22.86 s
2024-01-02 21:25:18,575	44k	INFO	Train Epoch: 4162 [54%]
2024-01-02 21:25:18,578	44k	INFO	Losses: [2.209369421005249, 2.839533805847168, 9.501321792602539, 15.69430923461914, 0.6987482309341431], step: 108200, lr: 5.944269121029102e-05, reference_loss: 30.943281173706055
2024-01-02 21:25:28,580	44k	INFO	====> Epoch: 4162, cost 23.21 s
2024-01-02 21:25:51,431	44k	INFO	====> Epoch: 4163, cost 22.85 s
2024-01-02 21:26:14,302	44k	INFO	====> Epoch: 4164, cost 22.87 s
2024-01-02 21:26:37,186	44k	INFO	====> Epoch: 4165, cost 22.88 s
2024-01-02 21:27:00,046	44k	INFO	====> Epoch: 4166, cost 22.86 s
2024-01-02 21:27:22,732	44k	INFO	====> Epoch: 4167, cost 22.69 s
2024-01-02 21:27:45,411	44k	INFO	====> Epoch: 4168, cost 22.68 s
2024-01-02 21:28:08,090	44k	INFO	====> Epoch: 4169, cost 22.68 s
2024-01-02 21:28:14,289	44k	INFO	Train Epoch: 4170 [23%]
2024-01-02 21:28:14,292	44k	INFO	Losses: [2.4846510887145996, 2.4290685653686523, 7.710587978363037, 13.473756790161133, 0.3333796560764313], step: 108400, lr: 5.938327451875759e-05, reference_loss: 26.43144416809082
2024-01-02 21:28:31,157	44k	INFO	====> Epoch: 4170, cost 23.07 s
2024-01-02 21:28:53,857	44k	INFO	====> Epoch: 4171, cost 22.70 s
2024-01-02 21:29:16,673	44k	INFO	====> Epoch: 4172, cost 22.82 s
2024-01-02 21:29:39,350	44k	INFO	====> Epoch: 4173, cost 22.68 s
2024-01-02 21:30:02,180	44k	INFO	====> Epoch: 4174, cost 22.83 s
2024-01-02 21:30:24,954	44k	INFO	====> Epoch: 4175, cost 22.77 s
2024-01-02 21:30:47,761	44k	INFO	====> Epoch: 4176, cost 22.81 s
2024-01-02 21:31:09,905	44k	INFO	Train Epoch: 4177 [92%]
2024-01-02 21:31:09,908	44k	INFO	Losses: [2.3615949153900146, 2.399688482284546, 7.661063194274902, 15.128239631652832, 0.3783400058746338], step: 108600, lr: 5.933133363463171e-05, reference_loss: 27.928926467895508
2024-01-02 21:31:11,003	44k	INFO	====> Epoch: 4177, cost 23.24 s
2024-01-02 21:31:33,822	44k	INFO	====> Epoch: 4178, cost 22.82 s
2024-01-02 21:31:56,676	44k	INFO	====> Epoch: 4179, cost 22.85 s
2024-01-02 21:32:19,496	44k	INFO	====> Epoch: 4180, cost 22.82 s
2024-01-02 21:32:42,430	44k	INFO	====> Epoch: 4181, cost 22.93 s
2024-01-02 21:33:05,266	44k	INFO	====> Epoch: 4182, cost 22.84 s
2024-01-02 21:33:27,975	44k	INFO	====> Epoch: 4183, cost 22.71 s
2024-01-02 21:33:50,709	44k	INFO	====> Epoch: 4184, cost 22.73 s
2024-01-02 21:34:05,700	44k	INFO	Train Epoch: 4185 [62%]
2024-01-02 21:34:05,703	44k	INFO	Losses: [2.418994188308716, 2.482499361038208, 7.376184463500977, 13.51539421081543, 0.3885357081890106], step: 108800, lr: 5.9272028251967176e-05, reference_loss: 26.181608200073242
2024-01-02 21:34:10,959	44k	INFO	Saving model and optimizer state at iteration 4185 to ./logs/44k/G_108800.pth
2024-01-02 21:34:11,824	44k	INFO	Saving model and optimizer state at iteration 4185 to ./logs/44k/D_108800.pth
2024-01-02 21:34:12,320	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_106400.pth
2024-01-02 21:34:12,358	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_106400.pth
2024-01-02 21:34:20,055	44k	INFO	====> Epoch: 4185, cost 29.35 s
2024-01-02 21:34:42,718	44k	INFO	====> Epoch: 4186, cost 22.66 s
2024-01-02 21:35:05,492	44k	INFO	====> Epoch: 4187, cost 22.77 s
2024-01-02 21:35:28,205	44k	INFO	====> Epoch: 4188, cost 22.71 s
2024-01-02 21:35:50,984	44k	INFO	====> Epoch: 4189, cost 22.78 s
2024-01-02 21:36:13,846	44k	INFO	====> Epoch: 4190, cost 22.86 s
2024-01-02 21:36:36,679	44k	INFO	====> Epoch: 4191, cost 22.83 s
2024-01-02 21:36:59,496	44k	INFO	====> Epoch: 4192, cost 22.82 s
2024-01-02 21:37:07,526	44k	INFO	Train Epoch: 4193 [31%]
2024-01-02 21:37:07,527	44k	INFO	Losses: [2.1700427532196045, 2.7946643829345703, 9.142980575561523, 15.934853553771973, 0.382339209318161], step: 109000, lr: 5.921278214874569e-05, reference_loss: 30.424880981445312
2024-01-02 21:37:22,723	44k	INFO	====> Epoch: 4193, cost 23.23 s
2024-01-02 21:37:45,432	44k	INFO	====> Epoch: 4194, cost 22.71 s
2024-01-02 21:38:08,267	44k	INFO	====> Epoch: 4195, cost 22.83 s
2024-01-02 21:38:31,090	44k	INFO	====> Epoch: 4196, cost 22.82 s
2024-01-02 21:38:53,929	44k	INFO	====> Epoch: 4197, cost 22.84 s
2024-01-02 21:39:16,688	44k	INFO	====> Epoch: 4198, cost 22.76 s
2024-01-02 21:39:39,493	44k	INFO	====> Epoch: 4199, cost 22.80 s
2024-01-02 21:40:02,464	44k	INFO	====> Epoch: 4200, cost 22.97 s
2024-01-02 21:40:03,356	44k	INFO	Train Epoch: 4201 [0%]
2024-01-02 21:40:03,360	44k	INFO	Losses: [2.0442333221435547, 2.97652530670166, 9.629055976867676, 15.543933868408203, 0.3273129165172577], step: 109200, lr: 5.9153595265713716e-05, reference_loss: 30.521060943603516
2024-01-02 21:40:25,707	44k	INFO	====> Epoch: 4201, cost 23.24 s
2024-01-02 21:40:48,477	44k	INFO	====> Epoch: 4202, cost 22.77 s
2024-01-02 21:41:11,173	44k	INFO	====> Epoch: 4203, cost 22.70 s
2024-01-02 21:41:33,915	44k	INFO	====> Epoch: 4204, cost 22.74 s
2024-01-02 21:41:56,569	44k	INFO	====> Epoch: 4205, cost 22.65 s
2024-01-02 21:42:19,234	44k	INFO	====> Epoch: 4206, cost 22.67 s
2024-01-02 21:42:41,985	44k	INFO	====> Epoch: 4207, cost 22.75 s
2024-01-02 21:42:58,843	44k	INFO	Train Epoch: 4208 [69%]
2024-01-02 21:42:58,846	44k	INFO	Losses: [2.206127643585205, 2.7727112770080566, 9.882583618164062, 16.595144271850586, 0.34131360054016113], step: 109400, lr: 5.9101855275586446e-05, reference_loss: 31.797880172729492
2024-01-02 21:43:05,356	44k	INFO	====> Epoch: 4208, cost 23.37 s
2024-01-02 21:43:28,191	44k	INFO	====> Epoch: 4209, cost 22.84 s
2024-01-02 21:43:50,897	44k	INFO	====> Epoch: 4210, cost 22.71 s
2024-01-02 21:44:13,572	44k	INFO	====> Epoch: 4211, cost 22.68 s
2024-01-02 21:44:36,249	44k	INFO	====> Epoch: 4212, cost 22.68 s
2024-01-02 21:44:58,920	44k	INFO	====> Epoch: 4213, cost 22.67 s
2024-01-02 21:45:21,605	44k	INFO	====> Epoch: 4214, cost 22.68 s
2024-01-02 21:45:44,402	44k	INFO	====> Epoch: 4215, cost 22.80 s
2024-01-02 21:45:54,216	44k	INFO	Train Epoch: 4216 [38%]
2024-01-02 21:45:54,218	44k	INFO	Losses: [2.395590305328369, 2.580446481704712, 8.484127044677734, 14.412757873535156, 0.46208950877189636], step: 109600, lr: 5.9042779270909264e-05, reference_loss: 28.335010528564453
2024-01-02 21:45:59,497	44k	INFO	Saving model and optimizer state at iteration 4216 to ./logs/44k/G_109600.pth
2024-01-02 21:46:00,521	44k	INFO	Saving model and optimizer state at iteration 4216 to ./logs/44k/D_109600.pth
2024-01-02 21:46:01,007	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_107200.pth
2024-01-02 21:46:01,046	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_107200.pth
2024-01-02 21:46:14,014	44k	INFO	====> Epoch: 4216, cost 29.61 s
2024-01-02 21:46:36,867	44k	INFO	====> Epoch: 4217, cost 22.85 s
2024-01-02 21:46:59,616	44k	INFO	====> Epoch: 4218, cost 22.75 s
2024-01-02 21:47:22,421	44k	INFO	====> Epoch: 4219, cost 22.81 s
2024-01-02 21:47:45,213	44k	INFO	====> Epoch: 4220, cost 22.79 s
2024-01-02 21:48:08,022	44k	INFO	====> Epoch: 4221, cost 22.81 s
2024-01-02 21:48:30,845	44k	INFO	====> Epoch: 4222, cost 22.82 s
2024-01-02 21:48:53,680	44k	INFO	====> Epoch: 4223, cost 22.84 s
2024-01-02 21:48:56,357	44k	INFO	Train Epoch: 4224 [8%]
2024-01-02 21:48:56,360	44k	INFO	Losses: [2.2469823360443115, 2.5712735652923584, 8.289185523986816, 14.89136028289795, 0.29442933201789856], step: 109800, lr: 5.898376231639747e-05, reference_loss: 28.293231964111328
2024-01-02 21:49:16,979	44k	INFO	====> Epoch: 4224, cost 23.30 s
2024-01-02 21:49:39,950	44k	INFO	====> Epoch: 4225, cost 22.97 s
2024-01-02 21:50:02,789	44k	INFO	====> Epoch: 4226, cost 22.84 s
2024-01-02 21:50:25,559	44k	INFO	====> Epoch: 4227, cost 22.77 s
2024-01-02 21:50:48,242	44k	INFO	====> Epoch: 4228, cost 22.68 s
2024-01-02 21:51:10,847	44k	INFO	====> Epoch: 4229, cost 22.61 s
2024-01-02 21:51:33,557	44k	INFO	====> Epoch: 4230, cost 22.71 s
2024-01-02 21:51:52,146	44k	INFO	Train Epoch: 4231 [77%]
2024-01-02 21:51:52,149	44k	INFO	Losses: [2.10172438621521, 2.7897891998291016, 10.72552490234375, 17.228519439697266, 0.48945188522338867], step: 110000, lr: 5.8932170874386036e-05, reference_loss: 33.33501052856445
2024-01-02 21:51:56,808	44k	INFO	====> Epoch: 4231, cost 23.25 s
2024-01-02 21:52:19,609	44k	INFO	====> Epoch: 4232, cost 22.80 s
2024-01-02 21:52:42,370	44k	INFO	====> Epoch: 4233, cost 22.76 s
2024-01-02 21:53:05,162	44k	INFO	====> Epoch: 4234, cost 22.79 s
2024-01-02 21:53:28,103	44k	INFO	====> Epoch: 4235, cost 22.94 s
2024-01-02 21:53:50,767	44k	INFO	====> Epoch: 4236, cost 22.66 s
2024-01-02 21:54:13,580	44k	INFO	====> Epoch: 4237, cost 22.81 s
2024-01-02 21:54:36,394	44k	INFO	====> Epoch: 4238, cost 22.81 s
2024-01-02 21:54:47,914	44k	INFO	Train Epoch: 4239 [46%]
2024-01-02 21:54:47,917	44k	INFO	Losses: [2.2531814575195312, 2.6370019912719727, 8.293556213378906, 15.670039176940918, 0.3877836763858795], step: 110200, lr: 5.887326447989169e-05, reference_loss: 29.241561889648438
2024-01-02 21:54:59,600	44k	INFO	====> Epoch: 4239, cost 23.21 s
2024-01-02 21:55:22,406	44k	INFO	====> Epoch: 4240, cost 22.81 s
2024-01-02 21:55:45,186	44k	INFO	====> Epoch: 4241, cost 22.78 s
2024-01-02 21:56:07,983	44k	INFO	====> Epoch: 4242, cost 22.80 s
2024-01-02 21:56:30,766	44k	INFO	====> Epoch: 4243, cost 22.78 s
2024-01-02 21:56:53,574	44k	INFO	====> Epoch: 4244, cost 22.81 s
2024-01-02 21:57:16,543	44k	INFO	====> Epoch: 4245, cost 22.97 s
2024-01-02 21:57:39,368	44k	INFO	====> Epoch: 4246, cost 22.82 s
2024-01-02 21:57:43,814	44k	INFO	Train Epoch: 4247 [15%]
2024-01-02 21:57:43,817	44k	INFO	Losses: [2.1381773948669434, 2.6457624435424805, 10.121706008911133, 16.229360580444336, 0.21639718115329742], step: 110400, lr: 5.881441696602673e-05, reference_loss: 31.351402282714844
2024-01-02 21:57:49,099	44k	INFO	Saving model and optimizer state at iteration 4247 to ./logs/44k/G_110400.pth
2024-01-02 21:57:49,956	44k	INFO	Saving model and optimizer state at iteration 4247 to ./logs/44k/D_110400.pth
2024-01-02 21:57:50,444	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_108000.pth
2024-01-02 21:57:50,483	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_108000.pth
2024-01-02 21:58:08,606	44k	INFO	====> Epoch: 4247, cost 29.24 s
2024-01-02 21:58:31,270	44k	INFO	====> Epoch: 4248, cost 22.66 s
2024-01-02 21:58:54,096	44k	INFO	====> Epoch: 4249, cost 22.83 s
2024-01-02 21:59:16,938	44k	INFO	====> Epoch: 4250, cost 22.84 s
2024-01-02 21:59:39,584	44k	INFO	====> Epoch: 4251, cost 22.65 s
2024-01-02 22:00:02,371	44k	INFO	====> Epoch: 4252, cost 22.79 s
2024-01-02 22:00:25,035	44k	INFO	====> Epoch: 4253, cost 22.66 s
2024-01-02 22:00:45,241	44k	INFO	Train Epoch: 4254 [85%]
2024-01-02 22:00:45,244	44k	INFO	Losses: [2.3579108715057373, 2.6849725246429443, 7.019220352172852, 14.577569007873535, 0.434497207403183], step: 110600, lr: 5.876297364564199e-05, reference_loss: 27.074169158935547
2024-01-02 22:00:48,107	44k	INFO	====> Epoch: 4254, cost 23.07 s
2024-01-02 22:01:10,782	44k	INFO	====> Epoch: 4255, cost 22.68 s
2024-01-02 22:01:33,566	44k	INFO	====> Epoch: 4256, cost 22.78 s
2024-01-02 22:01:56,254	44k	INFO	====> Epoch: 4257, cost 22.69 s
2024-01-02 22:02:18,935	44k	INFO	====> Epoch: 4258, cost 22.68 s
2024-01-02 22:02:41,604	44k	INFO	====> Epoch: 4259, cost 22.67 s
2024-01-02 22:03:04,232	44k	INFO	====> Epoch: 4260, cost 22.63 s
2024-01-02 22:03:26,944	44k	INFO	====> Epoch: 4261, cost 22.71 s
2024-01-02 22:03:40,133	44k	INFO	Train Epoch: 4262 [54%]
2024-01-02 22:03:40,136	44k	INFO	Losses: [2.3378007411956787, 2.469923734664917, 8.210823059082031, 16.25642967224121, 0.4888809025287628], step: 110800, lr: 5.8704236374371105e-05, reference_loss: 29.763856887817383
2024-01-02 22:03:50,157	44k	INFO	====> Epoch: 4262, cost 23.21 s
2024-01-02 22:04:12,796	44k	INFO	====> Epoch: 4263, cost 22.64 s
2024-01-02 22:04:35,545	44k	INFO	====> Epoch: 4264, cost 22.75 s
2024-01-02 22:04:58,341	44k	INFO	====> Epoch: 4265, cost 22.80 s
2024-01-02 22:05:20,991	44k	INFO	====> Epoch: 4266, cost 22.65 s
2024-01-02 22:05:43,623	44k	INFO	====> Epoch: 4267, cost 22.63 s
2024-01-02 22:06:06,334	44k	INFO	====> Epoch: 4268, cost 22.71 s
2024-01-02 22:06:29,095	44k	INFO	====> Epoch: 4269, cost 22.76 s
2024-01-02 22:06:35,311	44k	INFO	Train Epoch: 4270 [23%]
2024-01-02 22:06:35,314	44k	INFO	Losses: [2.243009328842163, 2.588162422180176, 8.510843276977539, 13.911853790283203, 0.303231805562973], step: 111000, lr: 5.8645557814680357e-05, reference_loss: 27.557100296020508
2024-01-02 22:06:52,294	44k	INFO	====> Epoch: 4270, cost 23.20 s
2024-01-02 22:07:15,212	44k	INFO	====> Epoch: 4271, cost 22.92 s
2024-01-02 22:07:38,029	44k	INFO	====> Epoch: 4272, cost 22.82 s
2024-01-02 22:08:00,860	44k	INFO	====> Epoch: 4273, cost 22.83 s
2024-01-02 22:08:23,697	44k	INFO	====> Epoch: 4274, cost 22.84 s
2024-01-02 22:08:46,489	44k	INFO	====> Epoch: 4275, cost 22.79 s
2024-01-02 22:09:09,303	44k	INFO	====> Epoch: 4276, cost 22.81 s
2024-01-02 22:09:31,419	44k	INFO	Train Epoch: 4277 [92%]
2024-01-02 22:09:31,422	44k	INFO	Losses: [2.4098823070526123, 2.3260295391082764, 7.754487037658691, 15.20205020904541, 0.47464045882225037], step: 111200, lr: 5.859426219065768e-05, reference_loss: 28.16708755493164
2024-01-02 22:09:36,745	44k	INFO	Saving model and optimizer state at iteration 4277 to ./logs/44k/G_111200.pth
2024-01-02 22:09:37,586	44k	INFO	Saving model and optimizer state at iteration 4277 to ./logs/44k/D_111200.pth
2024-01-02 22:09:38,074	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_108800.pth
2024-01-02 22:09:38,113	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_108800.pth
2024-01-02 22:09:38,801	44k	INFO	====> Epoch: 4277, cost 29.50 s
2024-01-02 22:10:01,796	44k	INFO	====> Epoch: 4278, cost 23.00 s
2024-01-02 22:10:24,715	44k	INFO	====> Epoch: 4279, cost 22.92 s
2024-01-02 22:10:47,551	44k	INFO	====> Epoch: 4280, cost 22.84 s
2024-01-02 22:11:10,268	44k	INFO	====> Epoch: 4281, cost 22.72 s
2024-01-02 22:11:32,871	44k	INFO	====> Epoch: 4282, cost 22.60 s
2024-01-02 22:11:55,535	44k	INFO	====> Epoch: 4283, cost 22.66 s
2024-01-02 22:12:18,198	44k	INFO	====> Epoch: 4284, cost 22.66 s
2024-01-02 22:12:33,157	44k	INFO	Train Epoch: 4285 [62%]
2024-01-02 22:12:33,160	44k	INFO	Losses: [2.356994152069092, 2.686274528503418, 6.819055557250977, 13.253668785095215, 0.6550787091255188], step: 111400, lr: 5.853569355704897e-05, reference_loss: 25.771072387695312
2024-01-02 22:12:41,298	44k	INFO	====> Epoch: 4285, cost 23.10 s
2024-01-02 22:13:04,032	44k	INFO	====> Epoch: 4286, cost 22.73 s
2024-01-02 22:13:26,761	44k	INFO	====> Epoch: 4287, cost 22.73 s
2024-01-02 22:13:49,501	44k	INFO	====> Epoch: 4288, cost 22.74 s
2024-01-02 22:14:12,341	44k	INFO	====> Epoch: 4289, cost 22.84 s
2024-01-02 22:14:35,306	44k	INFO	====> Epoch: 4290, cost 22.96 s
2024-01-02 22:14:58,128	44k	INFO	====> Epoch: 4291, cost 22.82 s
2024-01-02 22:15:20,949	44k	INFO	====> Epoch: 4292, cost 22.82 s
2024-01-02 22:15:28,974	44k	INFO	Train Epoch: 4293 [31%]
2024-01-02 22:15:28,977	44k	INFO	Losses: [2.3877768516540527, 2.453152894973755, 7.554075717926025, 13.756778717041016, 0.42011407017707825], step: 111600, lr: 5.8477183466456494e-05, reference_loss: 26.5718994140625
2024-01-02 22:15:44,196	44k	INFO	====> Epoch: 4293, cost 23.25 s
2024-01-02 22:16:06,988	44k	INFO	====> Epoch: 4294, cost 22.79 s
2024-01-02 22:16:29,757	44k	INFO	====> Epoch: 4295, cost 22.77 s
2024-01-02 22:16:52,569	44k	INFO	====> Epoch: 4296, cost 22.81 s
2024-01-02 22:17:15,303	44k	INFO	====> Epoch: 4297, cost 22.73 s
2024-01-02 22:17:37,953	44k	INFO	====> Epoch: 4298, cost 22.65 s
2024-01-02 22:18:00,613	44k	INFO	====> Epoch: 4299, cost 22.66 s
2024-01-02 22:18:23,572	44k	INFO	====> Epoch: 4300, cost 22.96 s
2024-01-02 22:18:24,466	44k	INFO	Train Epoch: 4301 [0%]
2024-01-02 22:18:24,469	44k	INFO	Losses: [2.504533052444458, 2.2554545402526855, 7.53549861907959, 13.237833023071289, 0.39005765318870544], step: 111800, lr: 5.8418731860362835e-05, reference_loss: 25.923377990722656
2024-01-02 22:18:46,784	44k	INFO	====> Epoch: 4301, cost 23.21 s
2024-01-02 22:19:09,648	44k	INFO	====> Epoch: 4302, cost 22.86 s
2024-01-02 22:19:32,418	44k	INFO	====> Epoch: 4303, cost 22.77 s
2024-01-02 22:19:55,207	44k	INFO	====> Epoch: 4304, cost 22.79 s
2024-01-02 22:20:17,947	44k	INFO	====> Epoch: 4305, cost 22.74 s
2024-01-02 22:20:40,636	44k	INFO	====> Epoch: 4306, cost 22.69 s
2024-01-02 22:21:03,280	44k	INFO	====> Epoch: 4307, cost 22.64 s
2024-01-02 22:21:20,019	44k	INFO	Train Epoch: 4308 [69%]
2024-01-02 22:21:20,022	44k	INFO	Losses: [2.3046751022338867, 2.422126531600952, 7.187557220458984, 13.338781356811523, 0.33958399295806885], step: 112000, lr: 5.8367634634638426e-05, reference_loss: 25.592723846435547
2024-01-02 22:21:25,464	44k	INFO	Saving model and optimizer state at iteration 4308 to ./logs/44k/G_112000.pth
2024-01-02 22:21:26,327	44k	INFO	Saving model and optimizer state at iteration 4308 to ./logs/44k/D_112000.pth
2024-01-02 22:21:26,824	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_109600.pth
2024-01-02 22:21:26,863	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_109600.pth
2024-01-02 22:21:32,774	44k	INFO	====> Epoch: 4308, cost 29.49 s
2024-01-02 22:21:55,446	44k	INFO	====> Epoch: 4309, cost 22.67 s
2024-01-02 22:22:18,280	44k	INFO	====> Epoch: 4310, cost 22.83 s
2024-01-02 22:22:41,109	44k	INFO	====> Epoch: 4311, cost 22.83 s
2024-01-02 22:23:03,888	44k	INFO	====> Epoch: 4312, cost 22.78 s
2024-01-02 22:23:26,605	44k	INFO	====> Epoch: 4313, cost 22.72 s
2024-01-02 22:23:49,289	44k	INFO	====> Epoch: 4314, cost 22.68 s
2024-01-02 22:24:11,904	44k	INFO	====> Epoch: 4315, cost 22.61 s
2024-01-02 22:24:21,651	44k	INFO	Train Epoch: 4316 [38%]
2024-01-02 22:24:21,654	44k	INFO	Losses: [2.3099684715270996, 2.5928516387939453, 8.88473892211914, 16.065610885620117, 0.37523916363716125], step: 112200, lr: 5.830929252946096e-05, reference_loss: 30.228408813476562
2024-01-02 22:24:35,189	44k	INFO	====> Epoch: 4316, cost 23.29 s
2024-01-02 22:24:57,999	44k	INFO	====> Epoch: 4317, cost 22.81 s
2024-01-02 22:25:20,853	44k	INFO	====> Epoch: 4318, cost 22.85 s
2024-01-02 22:25:43,689	44k	INFO	====> Epoch: 4319, cost 22.84 s
2024-01-02 22:26:06,526	44k	INFO	====> Epoch: 4320, cost 22.84 s
2024-01-02 22:26:29,364	44k	INFO	====> Epoch: 4321, cost 22.84 s
2024-01-02 22:26:52,221	44k	INFO	====> Epoch: 4322, cost 22.86 s
2024-01-02 22:27:15,002	44k	INFO	====> Epoch: 4323, cost 22.78 s
2024-01-02 22:27:17,653	44k	INFO	Train Epoch: 4324 [8%]
2024-01-02 22:27:17,655	44k	INFO	Losses: [2.2363953590393066, 2.708254814147949, 9.104616165161133, 15.619475364685059, 0.3129281997680664], step: 112400, lr: 5.8251008740870375e-05, reference_loss: 29.981670379638672
2024-01-02 22:27:38,092	44k	INFO	====> Epoch: 4324, cost 23.09 s
2024-01-02 22:28:01,111	44k	INFO	====> Epoch: 4325, cost 23.02 s
2024-01-02 22:28:23,947	44k	INFO	====> Epoch: 4326, cost 22.84 s
2024-01-02 22:28:46,776	44k	INFO	====> Epoch: 4327, cost 22.83 s
2024-01-02 22:29:09,605	44k	INFO	====> Epoch: 4328, cost 22.83 s
2024-01-02 22:29:32,413	44k	INFO	====> Epoch: 4329, cost 22.81 s
2024-01-02 22:29:55,204	44k	INFO	====> Epoch: 4330, cost 22.79 s
2024-01-02 22:30:13,839	44k	INFO	Train Epoch: 4331 [77%]
2024-01-02 22:30:13,842	44k	INFO	Losses: [2.060523748397827, 2.7757959365844727, 10.659064292907715, 17.159849166870117, 0.36945775151252747], step: 112600, lr: 5.820005821785283e-05, reference_loss: 33.02469253540039
2024-01-02 22:30:18,513	44k	INFO	====> Epoch: 4331, cost 23.31 s
2024-01-02 22:30:41,246	44k	INFO	====> Epoch: 4332, cost 22.73 s
2024-01-02 22:31:03,893	44k	INFO	====> Epoch: 4333, cost 22.65 s
2024-01-02 22:31:26,768	44k	INFO	====> Epoch: 4334, cost 22.87 s
2024-01-02 22:31:49,577	44k	INFO	====> Epoch: 4335, cost 22.81 s
2024-01-02 22:32:12,248	44k	INFO	====> Epoch: 4336, cost 22.67 s
2024-01-02 22:32:34,960	44k	INFO	====> Epoch: 4337, cost 22.71 s
2024-01-02 22:32:57,637	44k	INFO	====> Epoch: 4338, cost 22.68 s
2024-01-02 22:33:09,122	44k	INFO	Train Epoch: 4339 [46%]
2024-01-02 22:33:09,125	44k	INFO	Losses: [2.424603223800659, 2.452603340148926, 6.075351715087891, 13.052298545837402, 0.24853432178497314], step: 112800, lr: 5.81418836157958e-05, reference_loss: 24.25339126586914
2024-01-02 22:33:14,373	44k	INFO	Saving model and optimizer state at iteration 4339 to ./logs/44k/G_112800.pth
2024-01-02 22:33:15,248	44k	INFO	Saving model and optimizer state at iteration 4339 to ./logs/44k/D_112800.pth
2024-01-02 22:33:15,742	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_110400.pth
2024-01-02 22:33:15,781	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_110400.pth
2024-01-02 22:33:27,071	44k	INFO	====> Epoch: 4339, cost 29.43 s
2024-01-02 22:33:49,953	44k	INFO	====> Epoch: 4340, cost 22.88 s
2024-01-02 22:34:12,829	44k	INFO	====> Epoch: 4341, cost 22.88 s
2024-01-02 22:34:35,782	44k	INFO	====> Epoch: 4342, cost 22.95 s
2024-01-02 22:34:58,600	44k	INFO	====> Epoch: 4343, cost 22.82 s
2024-01-02 22:35:21,404	44k	INFO	====> Epoch: 4344, cost 22.80 s
2024-01-02 22:35:44,241	44k	INFO	====> Epoch: 4345, cost 22.84 s
2024-01-02 22:36:06,944	44k	INFO	====> Epoch: 4346, cost 22.70 s
2024-01-02 22:36:11,364	44k	INFO	Train Epoch: 4347 [15%]
2024-01-02 22:36:11,367	44k	INFO	Losses: [2.2615301609039307, 2.5414748191833496, 8.011579513549805, 13.54376220703125, 0.3114793002605438], step: 113000, lr: 5.80837671628958e-05, reference_loss: 26.66982650756836
2024-01-02 22:36:29,995	44k	INFO	====> Epoch: 4347, cost 23.05 s
2024-01-02 22:36:52,658	44k	INFO	====> Epoch: 4348, cost 22.66 s
2024-01-02 22:37:15,455	44k	INFO	====> Epoch: 4349, cost 22.80 s
2024-01-02 22:37:38,290	44k	INFO	====> Epoch: 4350, cost 22.83 s
2024-01-02 22:38:00,967	44k	INFO	====> Epoch: 4351, cost 22.68 s
2024-01-02 22:38:23,765	44k	INFO	====> Epoch: 4352, cost 22.80 s
2024-01-02 22:38:46,669	44k	INFO	====> Epoch: 4353, cost 22.90 s
2024-01-02 22:39:06,970	44k	INFO	Train Epoch: 4354 [85%]
2024-01-02 22:39:06,973	44k	INFO	Losses: [2.275155544281006, 2.400268316268921, 8.574028015136719, 15.669246673583984, 0.576096773147583], step: 113200, lr: 5.8032962921394276e-05, reference_loss: 29.494794845581055
2024-01-02 22:39:09,831	44k	INFO	====> Epoch: 4354, cost 23.16 s
2024-01-02 22:39:32,640	44k	INFO	====> Epoch: 4355, cost 22.81 s
2024-01-02 22:39:55,423	44k	INFO	====> Epoch: 4356, cost 22.78 s
2024-01-02 22:40:18,054	44k	INFO	====> Epoch: 4357, cost 22.63 s
2024-01-02 22:40:40,710	44k	INFO	====> Epoch: 4358, cost 22.66 s
2024-01-02 22:41:03,421	44k	INFO	====> Epoch: 4359, cost 22.71 s
2024-01-02 22:41:26,215	44k	INFO	====> Epoch: 4360, cost 22.79 s
2024-01-02 22:41:49,027	44k	INFO	====> Epoch: 4361, cost 22.81 s
2024-01-02 22:42:02,280	44k	INFO	Train Epoch: 4362 [54%]
2024-01-02 22:42:02,283	44k	INFO	Losses: [2.469165325164795, 2.423375368118286, 7.173881530761719, 13.93876838684082, 0.37139037251472473], step: 113400, lr: 5.797495534154778e-05, reference_loss: 26.376583099365234
2024-01-02 22:42:12,358	44k	INFO	====> Epoch: 4362, cost 23.33 s
2024-01-02 22:42:35,131	44k	INFO	====> Epoch: 4363, cost 22.77 s
2024-01-02 22:42:57,825	44k	INFO	====> Epoch: 4364, cost 22.69 s
2024-01-02 22:43:20,631	44k	INFO	====> Epoch: 4365, cost 22.81 s
2024-01-02 22:43:43,398	44k	INFO	====> Epoch: 4366, cost 22.77 s
2024-01-02 22:44:06,221	44k	INFO	====> Epoch: 4367, cost 22.82 s
2024-01-02 22:44:28,925	44k	INFO	====> Epoch: 4368, cost 22.70 s
2024-01-02 22:44:51,553	44k	INFO	====> Epoch: 4369, cost 22.63 s
2024-01-02 22:44:57,717	44k	INFO	Train Epoch: 4370 [23%]
2024-01-02 22:44:57,720	44k	INFO	Losses: [2.2009456157684326, 2.747201919555664, 8.126046180725098, 13.832520484924316, 0.47302311658859253], step: 113600, lr: 5.791700574390915e-05, reference_loss: 27.379737854003906
2024-01-02 22:45:02,928	44k	INFO	Saving model and optimizer state at iteration 4370 to ./logs/44k/G_113600.pth
2024-01-02 22:45:03,981	44k	INFO	Saving model and optimizer state at iteration 4370 to ./logs/44k/D_113600.pth
2024-01-02 22:45:04,470	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_111200.pth
2024-01-02 22:45:04,508	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_111200.pth
2024-01-02 22:45:21,083	44k	INFO	====> Epoch: 4370, cost 29.53 s
2024-01-02 22:45:43,974	44k	INFO	====> Epoch: 4371, cost 22.89 s
2024-01-02 22:46:06,847	44k	INFO	====> Epoch: 4372, cost 22.87 s
2024-01-02 22:46:29,584	44k	INFO	====> Epoch: 4373, cost 22.74 s
2024-01-02 22:46:52,396	44k	INFO	====> Epoch: 4374, cost 22.81 s
2024-01-02 22:47:15,124	44k	INFO	====> Epoch: 4375, cost 22.73 s
2024-01-02 22:47:37,799	44k	INFO	====> Epoch: 4376, cost 22.67 s
2024-01-02 22:47:59,783	44k	INFO	Train Epoch: 4377 [92%]
2024-01-02 22:47:59,786	44k	INFO	Losses: [2.284675359725952, 3.2004199028015137, 8.064149856567383, 14.792444229125977, 0.49190711975097656], step: 113800, lr: 5.786634736394204e-05, reference_loss: 28.83359718322754
2024-01-02 22:48:00,959	44k	INFO	====> Epoch: 4377, cost 23.16 s
2024-01-02 22:48:23,763	44k	INFO	====> Epoch: 4378, cost 22.80 s
2024-01-02 22:48:46,447	44k	INFO	====> Epoch: 4379, cost 22.68 s
2024-01-02 22:49:09,143	44k	INFO	====> Epoch: 4380, cost 22.70 s
2024-01-02 22:49:31,954	44k	INFO	====> Epoch: 4381, cost 22.81 s
2024-01-02 22:49:54,787	44k	INFO	====> Epoch: 4382, cost 22.83 s
2024-01-02 22:50:17,524	44k	INFO	====> Epoch: 4383, cost 22.74 s
2024-01-02 22:50:40,212	44k	INFO	====> Epoch: 4384, cost 22.69 s
2024-01-02 22:50:55,242	44k	INFO	Train Epoch: 4385 [62%]
2024-01-02 22:50:55,245	44k	INFO	Losses: [2.2554943561553955, 2.5408637523651123, 8.949945449829102, 14.65477466583252, 0.31255635619163513], step: 114000, lr: 5.780850632677691e-05, reference_loss: 28.713634490966797
2024-01-02 22:51:03,318	44k	INFO	====> Epoch: 4385, cost 23.11 s
2024-01-02 22:51:25,969	44k	INFO	====> Epoch: 4386, cost 22.65 s
2024-01-02 22:51:48,804	44k	INFO	====> Epoch: 4387, cost 22.83 s
2024-01-02 22:52:11,781	44k	INFO	====> Epoch: 4388, cost 22.98 s
2024-01-02 22:52:34,579	44k	INFO	====> Epoch: 4389, cost 22.80 s
2024-01-02 22:52:57,375	44k	INFO	====> Epoch: 4390, cost 22.80 s
2024-01-02 22:53:19,997	44k	INFO	====> Epoch: 4391, cost 22.62 s
2024-01-02 22:53:42,646	44k	INFO	====> Epoch: 4392, cost 22.65 s
2024-01-02 22:53:50,605	44k	INFO	Train Epoch: 4393 [31%]
2024-01-02 22:53:50,608	44k	INFO	Losses: [2.335783004760742, 2.574711799621582, 8.316933631896973, 13.985523223876953, 0.40146517753601074], step: 114200, lr: 5.77507231053498e-05, reference_loss: 27.614416122436523
2024-01-02 22:54:05,679	44k	INFO	====> Epoch: 4393, cost 23.03 s
2024-01-02 22:54:28,495	44k	INFO	====> Epoch: 4394, cost 22.82 s
2024-01-02 22:54:51,317	44k	INFO	====> Epoch: 4395, cost 22.82 s
2024-01-02 22:55:14,132	44k	INFO	====> Epoch: 4396, cost 22.81 s
2024-01-02 22:55:36,910	44k	INFO	====> Epoch: 4397, cost 22.78 s
2024-01-02 22:55:59,885	44k	INFO	====> Epoch: 4398, cost 22.98 s
2024-01-02 22:56:22,635	44k	INFO	====> Epoch: 4399, cost 22.75 s
2024-01-02 22:56:45,488	44k	INFO	====> Epoch: 4400, cost 22.85 s
2024-01-02 22:56:46,381	44k	INFO	Train Epoch: 4401 [0%]
2024-01-02 22:56:46,384	44k	INFO	Losses: [2.3606908321380615, 2.484755516052246, 8.839737892150879, 14.959702491760254, 0.21182028949260712], step: 114400, lr: 5.7692997641870295e-05, reference_loss: 28.856706619262695
2024-01-02 22:56:51,642	44k	INFO	Saving model and optimizer state at iteration 4401 to ./logs/44k/G_114400.pth
2024-01-02 22:56:52,503	44k	INFO	Saving model and optimizer state at iteration 4401 to ./logs/44k/D_114400.pth
2024-01-02 22:56:52,997	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_112000.pth
2024-01-02 22:56:53,035	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_112000.pth
2024-01-02 22:57:14,779	44k	INFO	====> Epoch: 4401, cost 29.29 s
2024-01-02 22:57:37,462	44k	INFO	====> Epoch: 4402, cost 22.68 s
2024-01-02 22:58:00,187	44k	INFO	====> Epoch: 4403, cost 22.72 s
2024-01-02 22:58:22,959	44k	INFO	====> Epoch: 4404, cost 22.77 s
2024-01-02 22:58:45,922	44k	INFO	====> Epoch: 4405, cost 22.96 s
2024-01-02 22:59:08,714	44k	INFO	====> Epoch: 4406, cost 22.79 s
2024-01-02 22:59:31,544	44k	INFO	====> Epoch: 4407, cost 22.83 s
2024-01-02 22:59:48,357	44k	INFO	Train Epoch: 4408 [69%]
2024-01-02 22:59:48,360	44k	INFO	Losses: [2.387202501296997, 2.4703729152679443, 9.325008392333984, 16.030391693115234, 0.4858739674091339], step: 114600, lr: 5.764253519550512e-05, reference_loss: 30.698848724365234
2024-01-02 22:59:54,722	44k	INFO	====> Epoch: 4408, cost 23.18 s
2024-01-02 23:00:17,465	44k	INFO	====> Epoch: 4409, cost 22.74 s
2024-01-02 23:00:40,304	44k	INFO	====> Epoch: 4410, cost 22.84 s
2024-01-02 23:01:03,107	44k	INFO	====> Epoch: 4411, cost 22.80 s
2024-01-02 23:01:25,858	44k	INFO	====> Epoch: 4412, cost 22.75 s
2024-01-02 23:01:48,704	44k	INFO	====> Epoch: 4413, cost 22.85 s
2024-01-02 23:02:11,573	44k	INFO	====> Epoch: 4414, cost 22.87 s
2024-01-02 23:02:34,427	44k	INFO	====> Epoch: 4415, cost 22.85 s
2024-01-02 23:02:44,380	44k	INFO	Train Epoch: 4416 [38%]
2024-01-02 23:02:44,383	44k	INFO	Losses: [2.383904457092285, 2.5174789428710938, 10.019548416137695, 16.30508041381836, 0.2126101404428482], step: 114800, lr: 5.758491787261508e-05, reference_loss: 31.438623428344727
2024-01-02 23:02:57,731	44k	INFO	====> Epoch: 4416, cost 23.30 s
2024-01-02 23:03:20,597	44k	INFO	====> Epoch: 4417, cost 22.87 s
2024-01-02 23:03:43,339	44k	INFO	====> Epoch: 4418, cost 22.74 s
2024-01-02 23:04:06,012	44k	INFO	====> Epoch: 4419, cost 22.67 s
2024-01-02 23:04:28,772	44k	INFO	====> Epoch: 4420, cost 22.76 s
2024-01-02 23:04:51,493	44k	INFO	====> Epoch: 4421, cost 22.72 s
2024-01-02 23:05:14,156	44k	INFO	====> Epoch: 4422, cost 22.66 s
2024-01-02 23:05:36,793	44k	INFO	====> Epoch: 4423, cost 22.64 s
2024-01-02 23:05:39,448	44k	INFO	Train Epoch: 4424 [8%]
2024-01-02 23:05:39,450	44k	INFO	Losses: [2.121927261352539, 2.7973694801330566, 9.800954818725586, 15.09089469909668, 0.3877964913845062], step: 115000, lr: 5.752735814184665e-05, reference_loss: 30.198942184448242
2024-01-02 23:06:00,087	44k	INFO	====> Epoch: 4424, cost 23.29 s
2024-01-02 23:06:22,783	44k	INFO	====> Epoch: 4425, cost 22.70 s
2024-01-02 23:06:45,515	44k	INFO	====> Epoch: 4426, cost 22.73 s
2024-01-02 23:07:08,216	44k	INFO	====> Epoch: 4427, cost 22.70 s
2024-01-02 23:07:31,030	44k	INFO	====> Epoch: 4428, cost 22.81 s
2024-01-02 23:07:53,813	44k	INFO	====> Epoch: 4429, cost 22.78 s
2024-01-02 23:08:16,598	44k	INFO	====> Epoch: 4430, cost 22.78 s
2024-01-02 23:08:35,093	44k	INFO	Train Epoch: 4431 [77%]
2024-01-02 23:08:35,096	44k	INFO	Losses: [2.2287259101867676, 2.510979652404785, 9.956140518188477, 15.938834190368652, 0.5979055762290955], step: 115200, lr: 5.747704057570486e-05, reference_loss: 31.232587814331055
2024-01-02 23:08:40,432	44k	INFO	Saving model and optimizer state at iteration 4431 to ./logs/44k/G_115200.pth
2024-01-02 23:08:41,485	44k	INFO	Saving model and optimizer state at iteration 4431 to ./logs/44k/D_115200.pth
2024-01-02 23:08:41,973	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_112800.pth
2024-01-02 23:08:42,012	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_112800.pth
2024-01-02 23:08:46,163	44k	INFO	====> Epoch: 4431, cost 29.57 s
2024-01-02 23:09:08,845	44k	INFO	====> Epoch: 4432, cost 22.68 s
2024-01-02 23:09:31,715	44k	INFO	====> Epoch: 4433, cost 22.87 s
2024-01-02 23:09:54,492	44k	INFO	====> Epoch: 4434, cost 22.78 s
2024-01-02 23:10:17,282	44k	INFO	====> Epoch: 4435, cost 22.79 s
2024-01-02 23:10:40,076	44k	INFO	====> Epoch: 4436, cost 22.79 s
2024-01-02 23:11:02,901	44k	INFO	====> Epoch: 4437, cost 22.82 s
2024-01-02 23:11:25,720	44k	INFO	====> Epoch: 4438, cost 22.82 s
2024-01-02 23:11:37,234	44k	INFO	Train Epoch: 4439 [46%]
2024-01-02 23:11:37,237	44k	INFO	Losses: [2.1806588172912598, 2.867396831512451, 9.810578346252441, 16.473812103271484, 0.3514569103717804], step: 115400, lr: 5.741958867504882e-05, reference_loss: 31.68390464782715
2024-01-02 23:11:48,896	44k	INFO	====> Epoch: 4439, cost 23.18 s
2024-01-02 23:12:11,635	44k	INFO	====> Epoch: 4440, cost 22.74 s
2024-01-02 23:12:34,587	44k	INFO	====> Epoch: 4441, cost 22.95 s
2024-01-02 23:12:57,382	44k	INFO	====> Epoch: 4442, cost 22.79 s
2024-01-02 23:13:20,139	44k	INFO	====> Epoch: 4443, cost 22.76 s
2024-01-02 23:13:42,818	44k	INFO	====> Epoch: 4444, cost 22.68 s
2024-01-02 23:14:05,642	44k	INFO	====> Epoch: 4445, cost 22.82 s
2024-01-02 23:14:28,470	44k	INFO	====> Epoch: 4446, cost 22.83 s
2024-01-02 23:14:32,912	44k	INFO	Train Epoch: 4447 [15%]
2024-01-02 23:14:32,915	44k	INFO	Losses: [2.292710781097412, 2.4395980834960938, 9.672750473022461, 16.266223907470703, 0.31162211298942566], step: 115600, lr: 5.736219420116451e-05, reference_loss: 30.982906341552734
2024-01-02 23:14:51,610	44k	INFO	====> Epoch: 4447, cost 23.14 s
2024-01-02 23:15:14,401	44k	INFO	====> Epoch: 4448, cost 22.79 s
2024-01-02 23:15:37,145	44k	INFO	====> Epoch: 4449, cost 22.74 s
2024-01-02 23:15:59,818	44k	INFO	====> Epoch: 4450, cost 22.67 s
2024-01-02 23:16:22,609	44k	INFO	====> Epoch: 4451, cost 22.79 s
2024-01-02 23:16:45,235	44k	INFO	====> Epoch: 4452, cost 22.63 s
2024-01-02 23:17:07,964	44k	INFO	====> Epoch: 4453, cost 22.73 s
2024-01-02 23:17:28,311	44k	INFO	Train Epoch: 4454 [85%]
2024-01-02 23:17:28,314	44k	INFO	Losses: [2.265385627746582, 2.602886438369751, 8.482935905456543, 14.116009712219238, 0.5349588394165039], step: 115800, lr: 5.731202109928769e-05, reference_loss: 28.002174377441406
2024-01-02 23:17:31,166	44k	INFO	====> Epoch: 4454, cost 23.20 s
2024-01-02 23:17:53,833	44k	INFO	====> Epoch: 4455, cost 22.67 s
2024-01-02 23:18:16,496	44k	INFO	====> Epoch: 4456, cost 22.66 s
2024-01-02 23:18:39,141	44k	INFO	====> Epoch: 4457, cost 22.64 s
2024-01-02 23:19:01,880	44k	INFO	====> Epoch: 4458, cost 22.74 s
2024-01-02 23:19:24,696	44k	INFO	====> Epoch: 4459, cost 22.82 s
2024-01-02 23:19:47,576	44k	INFO	====> Epoch: 4460, cost 22.88 s
2024-01-02 23:20:10,247	44k	INFO	====> Epoch: 4461, cost 22.67 s
2024-01-02 23:20:23,439	44k	INFO	Train Epoch: 4462 [54%]
2024-01-02 23:20:23,442	44k	INFO	Losses: [2.4544429779052734, 2.3343775272369385, 7.982189178466797, 13.82817554473877, 0.196156308054924], step: 116000, lr: 5.7254734145930094e-05, reference_loss: 26.79534149169922
2024-01-02 23:20:28,780	44k	INFO	Saving model and optimizer state at iteration 4462 to ./logs/44k/G_116000.pth
2024-01-02 23:20:29,652	44k	INFO	Saving model and optimizer state at iteration 4462 to ./logs/44k/D_116000.pth
2024-01-02 23:20:30,137	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_113600.pth
2024-01-02 23:20:30,176	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_113600.pth
2024-01-02 23:20:39,631	44k	INFO	====> Epoch: 4462, cost 29.38 s
2024-01-02 23:21:02,448	44k	INFO	====> Epoch: 4463, cost 22.82 s
2024-01-02 23:21:25,312	44k	INFO	====> Epoch: 4464, cost 22.86 s
2024-01-02 23:21:48,141	44k	INFO	====> Epoch: 4465, cost 22.83 s
2024-01-02 23:22:10,800	44k	INFO	====> Epoch: 4466, cost 22.66 s
2024-01-02 23:22:33,662	44k	INFO	====> Epoch: 4467, cost 22.86 s
2024-01-02 23:22:56,614	44k	INFO	====> Epoch: 4468, cost 22.95 s
2024-01-02 23:23:19,426	44k	INFO	====> Epoch: 4469, cost 22.81 s
2024-01-02 23:23:25,620	44k	INFO	Train Epoch: 4470 [23%]
2024-01-02 23:23:25,624	44k	INFO	Losses: [2.380364418029785, 2.5432488918304443, 7.1680707931518555, 13.716446876525879, 0.4408060908317566], step: 116200, lr: 5.719750445446907e-05, reference_loss: 26.248937606811523
2024-01-02 23:23:42,546	44k	INFO	====> Epoch: 4470, cost 23.12 s
2024-01-02 23:24:05,329	44k	INFO	====> Epoch: 4471, cost 22.78 s
2024-01-02 23:24:28,129	44k	INFO	====> Epoch: 4472, cost 22.80 s
2024-01-02 23:24:50,904	44k	INFO	====> Epoch: 4473, cost 22.78 s
2024-01-02 23:25:13,739	44k	INFO	====> Epoch: 4474, cost 22.84 s
2024-01-02 23:25:36,602	44k	INFO	====> Epoch: 4475, cost 22.86 s
2024-01-02 23:25:59,363	44k	INFO	====> Epoch: 4476, cost 22.76 s
2024-01-02 23:26:21,328	44k	INFO	Train Epoch: 4477 [92%]
2024-01-02 23:26:21,331	44k	INFO	Losses: [2.1644492149353027, 2.5777556896209717, 9.452967643737793, 17.58768653869629, 0.5813177227973938], step: 116400, lr: 5.714747540209304e-05, reference_loss: 32.36417770385742
2024-01-02 23:26:22,574	44k	INFO	====> Epoch: 4477, cost 23.21 s
2024-01-02 23:26:45,398	44k	INFO	====> Epoch: 4478, cost 22.82 s
2024-01-02 23:27:08,138	44k	INFO	====> Epoch: 4479, cost 22.74 s
2024-01-02 23:27:30,933	44k	INFO	====> Epoch: 4480, cost 22.79 s
2024-01-02 23:27:53,752	44k	INFO	====> Epoch: 4481, cost 22.82 s
2024-01-02 23:28:16,591	44k	INFO	====> Epoch: 4482, cost 22.84 s
2024-01-02 23:28:39,325	44k	INFO	====> Epoch: 4483, cost 22.73 s
2024-01-02 23:29:01,973	44k	INFO	====> Epoch: 4484, cost 22.65 s
2024-01-02 23:29:17,024	44k	INFO	Train Epoch: 4485 [62%]
2024-01-02 23:29:17,027	44k	INFO	Losses: [2.1802265644073486, 2.673370599746704, 8.343192100524902, 15.149073600769043, 0.2687321603298187], step: 116600, lr: 5.709035292246189e-05, reference_loss: 28.614595413208008
2024-01-02 23:29:25,161	44k	INFO	====> Epoch: 4485, cost 23.19 s
2024-01-02 23:29:48,108	44k	INFO	====> Epoch: 4486, cost 22.95 s
2024-01-02 23:30:10,936	44k	INFO	====> Epoch: 4487, cost 22.83 s
2024-01-02 23:30:33,778	44k	INFO	====> Epoch: 4488, cost 22.84 s
2024-01-02 23:30:56,604	44k	INFO	====> Epoch: 4489, cost 22.83 s
2024-01-02 23:31:19,411	44k	INFO	====> Epoch: 4490, cost 22.81 s
2024-01-02 23:31:42,225	44k	INFO	====> Epoch: 4491, cost 22.81 s
2024-01-02 23:32:04,931	44k	INFO	====> Epoch: 4492, cost 22.71 s
2024-01-02 23:32:12,935	44k	INFO	Train Epoch: 4493 [31%]
2024-01-02 23:32:12,938	44k	INFO	Losses: [2.7608835697174072, 2.460092067718506, 7.698988914489746, 14.287065505981445, 0.5040113925933838], step: 116800, lr: 5.703328754032552e-05, reference_loss: 27.711042404174805
2024-01-02 23:32:18,216	44k	INFO	Saving model and optimizer state at iteration 4493 to ./logs/44k/G_116800.pth
2024-01-02 23:32:19,115	44k	INFO	Saving model and optimizer state at iteration 4493 to ./logs/44k/D_116800.pth
2024-01-02 23:32:19,609	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_114400.pth
2024-01-02 23:32:19,648	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_114400.pth
2024-01-02 23:32:34,392	44k	INFO	====> Epoch: 4493, cost 29.46 s
2024-01-02 23:32:57,547	44k	INFO	====> Epoch: 4494, cost 23.15 s
2024-01-02 23:33:20,502	44k	INFO	====> Epoch: 4495, cost 22.96 s
2024-01-02 23:33:43,416	44k	INFO	====> Epoch: 4496, cost 22.91 s
2024-01-02 23:34:06,340	44k	INFO	====> Epoch: 4497, cost 22.92 s
2024-01-02 23:34:29,250	44k	INFO	====> Epoch: 4498, cost 22.91 s
2024-01-02 23:34:52,184	44k	INFO	====> Epoch: 4499, cost 22.93 s
2024-01-02 23:35:15,002	44k	INFO	====> Epoch: 4500, cost 22.82 s
2024-01-02 23:35:15,894	44k	INFO	Train Epoch: 4501 [0%]
2024-01-02 23:35:15,897	44k	INFO	Losses: [2.313870906829834, 2.4942808151245117, 8.264153480529785, 14.744768142700195, 0.21996015310287476], step: 117000, lr: 5.6976279198611426e-05, reference_loss: 28.037033081054688
2024-01-02 23:35:38,260	44k	INFO	====> Epoch: 4501, cost 23.26 s
2024-01-02 23:36:01,187	44k	INFO	====> Epoch: 4502, cost 22.93 s
2024-01-02 23:36:24,081	44k	INFO	====> Epoch: 4503, cost 22.89 s
2024-01-02 23:36:46,946	44k	INFO	====> Epoch: 4504, cost 22.87 s
2024-01-02 23:37:09,776	44k	INFO	====> Epoch: 4505, cost 22.83 s
2024-01-02 23:37:32,819	44k	INFO	====> Epoch: 4506, cost 23.04 s
2024-01-02 23:37:55,745	44k	INFO	====> Epoch: 4507, cost 22.93 s
2024-01-02 23:38:12,671	44k	INFO	Train Epoch: 4508 [69%]
2024-01-02 23:38:12,674	44k	INFO	Losses: [2.218524217605591, 2.681572198867798, 9.09151554107666, 15.823148727416992, 0.35625800490379333], step: 117200, lr: 5.692644364575987e-05, reference_loss: 30.171018600463867
2024-01-02 23:38:19,039	44k	INFO	====> Epoch: 4508, cost 23.29 s
2024-01-02 23:38:41,796	44k	INFO	====> Epoch: 4509, cost 22.76 s
2024-01-02 23:39:04,572	44k	INFO	====> Epoch: 4510, cost 22.78 s
2024-01-02 23:39:27,308	44k	INFO	====> Epoch: 4511, cost 22.74 s
2024-01-02 23:39:50,013	44k	INFO	====> Epoch: 4512, cost 22.71 s
2024-01-02 23:40:12,739	44k	INFO	====> Epoch: 4513, cost 22.73 s
2024-01-02 23:40:35,467	44k	INFO	====> Epoch: 4514, cost 22.73 s
2024-01-02 23:40:58,359	44k	INFO	====> Epoch: 4515, cost 22.89 s
2024-01-02 23:41:08,119	44k	INFO	Train Epoch: 4516 [38%]
2024-01-02 23:41:08,122	44k	INFO	Losses: [2.246011972427368, 2.489048957824707, 10.440662384033203, 15.889344215393066, 0.29107049107551575], step: 117400, lr: 5.686954210120783e-05, reference_loss: 31.356138229370117
2024-01-02 23:41:21,458	44k	INFO	====> Epoch: 4516, cost 23.10 s
2024-01-02 23:41:44,089	44k	INFO	====> Epoch: 4517, cost 22.63 s
2024-01-02 23:42:06,755	44k	INFO	====> Epoch: 4518, cost 22.67 s
2024-01-02 23:42:29,395	44k	INFO	====> Epoch: 4519, cost 22.64 s
2024-01-02 23:42:52,088	44k	INFO	====> Epoch: 4520, cost 22.69 s
2024-01-02 23:43:14,907	44k	INFO	====> Epoch: 4521, cost 22.82 s
2024-01-02 23:43:37,675	44k	INFO	====> Epoch: 4522, cost 22.77 s
2024-01-02 23:44:00,408	44k	INFO	====> Epoch: 4523, cost 22.73 s
2024-01-02 23:44:03,058	44k	INFO	Train Epoch: 4524 [8%]
2024-01-02 23:44:03,061	44k	INFO	Losses: [2.0547893047332764, 2.829500436782837, 9.817352294921875, 17.52646255493164, 0.21420235931873322], step: 117600, lr: 5.6812697433312136e-05, reference_loss: 32.44230651855469
2024-01-02 23:44:08,531	44k	INFO	Saving model and optimizer state at iteration 4524 to ./logs/44k/G_117600.pth
2024-01-02 23:44:09,379	44k	INFO	Saving model and optimizer state at iteration 4524 to ./logs/44k/D_117600.pth
2024-01-02 23:44:09,867	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_115200.pth
2024-01-02 23:44:09,906	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_115200.pth
2024-01-02 23:44:29,941	44k	INFO	====> Epoch: 4524, cost 29.53 s
2024-01-02 23:44:52,826	44k	INFO	====> Epoch: 4525, cost 22.89 s
2024-01-02 23:45:15,647	44k	INFO	====> Epoch: 4526, cost 22.82 s
2024-01-02 23:45:38,425	44k	INFO	====> Epoch: 4527, cost 22.78 s
2024-01-02 23:46:01,139	44k	INFO	====> Epoch: 4528, cost 22.71 s
2024-01-02 23:46:23,945	44k	INFO	====> Epoch: 4529, cost 22.81 s
2024-01-02 23:46:46,766	44k	INFO	====> Epoch: 4530, cost 22.82 s
2024-01-02 23:47:05,412	44k	INFO	Train Epoch: 4531 [77%]
2024-01-02 23:47:05,415	44k	INFO	Losses: [2.244624376296997, 2.5612435340881348, 9.022176742553711, 15.447336196899414, 0.46566078066825867], step: 117800, lr: 5.676300496084111e-05, reference_loss: 29.74104118347168
2024-01-02 23:47:10,196	44k	INFO	====> Epoch: 4531, cost 23.43 s
2024-01-02 23:47:33,039	44k	INFO	====> Epoch: 4532, cost 22.84 s
2024-01-02 23:47:55,877	44k	INFO	====> Epoch: 4533, cost 22.84 s
2024-01-02 23:48:18,717	44k	INFO	====> Epoch: 4534, cost 22.84 s
2024-01-02 23:48:41,399	44k	INFO	====> Epoch: 4535, cost 22.68 s
2024-01-02 23:49:04,178	44k	INFO	====> Epoch: 4536, cost 22.78 s
2024-01-02 23:49:26,995	44k	INFO	====> Epoch: 4537, cost 22.82 s
2024-01-02 23:49:49,827	44k	INFO	====> Epoch: 4538, cost 22.83 s
2024-01-02 23:50:01,246	44k	INFO	Train Epoch: 4539 [46%]
2024-01-02 23:50:01,249	44k	INFO	Losses: [2.2898073196411133, 2.4299416542053223, 7.465584754943848, 14.974075317382812, 0.30345895886421204], step: 118000, lr: 5.670626678348743e-05, reference_loss: 27.462867736816406
2024-01-02 23:50:12,949	44k	INFO	====> Epoch: 4539, cost 23.12 s
2024-01-02 23:50:35,680	44k	INFO	====> Epoch: 4540, cost 22.73 s
2024-01-02 23:50:58,640	44k	INFO	====> Epoch: 4541, cost 22.96 s
2024-01-02 23:51:21,385	44k	INFO	====> Epoch: 4542, cost 22.74 s
2024-01-02 23:51:44,133	44k	INFO	====> Epoch: 4543, cost 22.75 s
2024-01-02 23:52:06,933	44k	INFO	====> Epoch: 4544, cost 22.80 s
2024-01-02 23:52:29,620	44k	INFO	====> Epoch: 4545, cost 22.69 s
2024-01-02 23:52:52,289	44k	INFO	====> Epoch: 4546, cost 22.67 s
2024-01-02 23:52:56,701	44k	INFO	Train Epoch: 4547 [15%]
2024-01-02 23:52:56,704	44k	INFO	Losses: [2.4712600708007812, 2.2227513790130615, 7.733817100524902, 14.437408447265625, 0.3568863272666931], step: 118200, lr: 5.6649585319494356e-05, reference_loss: 27.222124099731445
2024-01-02 23:53:15,325	44k	INFO	====> Epoch: 4547, cost 23.04 s
2024-01-02 23:53:38,052	44k	INFO	====> Epoch: 4548, cost 22.73 s
2024-01-02 23:54:00,935	44k	INFO	====> Epoch: 4549, cost 22.88 s
2024-01-02 23:54:23,672	44k	INFO	====> Epoch: 4550, cost 22.74 s
2024-01-02 23:54:46,469	44k	INFO	====> Epoch: 4551, cost 22.80 s
2024-01-02 23:55:09,245	44k	INFO	====> Epoch: 4552, cost 22.78 s
2024-01-02 23:55:31,981	44k	INFO	====> Epoch: 4553, cost 22.74 s
2024-01-02 23:55:52,145	44k	INFO	Train Epoch: 4554 [85%]
2024-01-02 23:55:52,148	44k	INFO	Losses: [2.297689914703369, 2.611617088317871, 8.933154106140137, 15.169930458068848, 0.4806275963783264], step: 118400, lr: 5.6600035516612926e-05, reference_loss: 29.493017196655273
2024-01-02 23:55:57,512	44k	INFO	Saving model and optimizer state at iteration 4554 to ./logs/44k/G_118400.pth
2024-01-02 23:55:58,394	44k	INFO	Saving model and optimizer state at iteration 4554 to ./logs/44k/D_118400.pth
2024-01-02 23:55:58,884	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_116000.pth
2024-01-02 23:55:58,922	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_116000.pth
2024-01-02 23:56:01,377	44k	INFO	====> Epoch: 4554, cost 29.40 s
2024-01-02 23:56:24,108	44k	INFO	====> Epoch: 4555, cost 22.73 s
2024-01-02 23:56:46,837	44k	INFO	====> Epoch: 4556, cost 22.73 s
2024-01-02 23:57:09,515	44k	INFO	====> Epoch: 4557, cost 22.68 s
2024-01-02 23:57:32,354	44k	INFO	====> Epoch: 4558, cost 22.84 s
2024-01-02 23:57:55,159	44k	INFO	====> Epoch: 4559, cost 22.81 s
2024-01-02 23:58:17,934	44k	INFO	====> Epoch: 4560, cost 22.78 s
2024-01-02 23:58:40,819	44k	INFO	====> Epoch: 4561, cost 22.89 s
2024-01-02 23:58:54,100	44k	INFO	Train Epoch: 4562 [54%]
2024-01-02 23:58:54,103	44k	INFO	Losses: [2.2129693031311035, 3.0113658905029297, 8.889811515808105, 14.836369514465332, 0.6636431813240051], step: 118600, lr: 5.654346023742217e-05, reference_loss: 29.614158630371094
2024-01-02 23:59:04,041	44k	INFO	====> Epoch: 4562, cost 23.22 s
2024-01-02 23:59:27,215	44k	INFO	====> Epoch: 4563, cost 23.17 s
2024-01-02 23:59:50,450	44k	INFO	====> Epoch: 4564, cost 23.23 s
2024-01-03 00:00:13,551	44k	INFO	====> Epoch: 4565, cost 23.10 s
2024-01-03 00:00:36,719	44k	INFO	====> Epoch: 4566, cost 23.17 s
2024-01-03 00:00:59,869	44k	INFO	====> Epoch: 4567, cost 23.15 s
2024-01-03 00:01:23,055	44k	INFO	====> Epoch: 4568, cost 23.19 s
2024-01-03 00:01:46,350	44k	INFO	====> Epoch: 4569, cost 23.29 s
2024-01-03 00:01:52,693	44k	INFO	Train Epoch: 4570 [23%]
2024-01-03 00:01:52,696	44k	INFO	Losses: [2.364933729171753, 2.6203150749206543, 7.888662338256836, 12.961418151855469, 0.3533783555030823], step: 118800, lr: 5.6486941508765103e-05, reference_loss: 26.18870735168457
2024-01-03 00:02:09,901	44k	INFO	====> Epoch: 4570, cost 23.55 s
2024-01-03 00:02:32,904	44k	INFO	====> Epoch: 4571, cost 23.00 s
2024-01-03 00:02:55,907	44k	INFO	====> Epoch: 4572, cost 23.00 s
2024-01-03 00:03:19,058	44k	INFO	====> Epoch: 4573, cost 23.15 s
2024-01-03 00:03:42,240	44k	INFO	====> Epoch: 4574, cost 23.18 s
2024-01-03 00:04:05,304	44k	INFO	====> Epoch: 4575, cost 23.06 s
2024-01-03 00:04:28,624	44k	INFO	====> Epoch: 4576, cost 23.32 s
2024-01-03 00:04:50,967	44k	INFO	Train Epoch: 4577 [92%]
2024-01-03 00:04:50,969	44k	INFO	Losses: [2.3086295127868652, 2.696164131164551, 8.403556823730469, 15.477580070495605, 0.4713829755783081], step: 119000, lr: 5.6437533965861675e-05, reference_loss: 29.357311248779297
2024-01-03 00:04:52,290	44k	INFO	====> Epoch: 4577, cost 23.67 s
2024-01-03 00:05:15,167	44k	INFO	====> Epoch: 4578, cost 22.88 s
2024-01-03 00:05:37,897	44k	INFO	====> Epoch: 4579, cost 22.73 s
2024-01-03 00:06:00,689	44k	INFO	====> Epoch: 4580, cost 22.79 s
2024-01-03 00:06:23,505	44k	INFO	====> Epoch: 4581, cost 22.82 s
2024-01-03 00:06:46,317	44k	INFO	====> Epoch: 4582, cost 22.81 s
2024-01-03 00:07:09,088	44k	INFO	====> Epoch: 4583, cost 22.77 s
2024-01-03 00:07:31,874	44k	INFO	====> Epoch: 4584, cost 22.79 s
2024-01-03 00:07:46,862	44k	INFO	Train Epoch: 4585 [62%]
2024-01-03 00:07:46,864	44k	INFO	Losses: [2.1878645420074463, 2.609750509262085, 8.135931968688965, 13.630219459533691, 0.3598349094390869], step: 119200, lr: 5.6381121117145014e-05, reference_loss: 26.923601150512695
2024-01-03 00:07:52,250	44k	INFO	Saving model and optimizer state at iteration 4585 to ./logs/44k/G_119200.pth
2024-01-03 00:07:53,272	44k	INFO	Saving model and optimizer state at iteration 4585 to ./logs/44k/D_119200.pth
2024-01-03 00:07:53,765	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_116800.pth
2024-01-03 00:07:53,804	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_116800.pth
2024-01-03 00:08:01,484	44k	INFO	====> Epoch: 4585, cost 29.61 s
2024-01-03 00:08:24,212	44k	INFO	====> Epoch: 4586, cost 22.73 s
2024-01-03 00:08:46,920	44k	INFO	====> Epoch: 4587, cost 22.71 s
2024-01-03 00:09:09,641	44k	INFO	====> Epoch: 4588, cost 22.72 s
2024-01-03 00:09:32,443	44k	INFO	====> Epoch: 4589, cost 22.80 s
2024-01-03 00:09:55,247	44k	INFO	====> Epoch: 4590, cost 22.80 s
2024-01-03 00:10:18,100	44k	INFO	====> Epoch: 4591, cost 22.85 s
2024-01-03 00:10:40,941	44k	INFO	====> Epoch: 4592, cost 22.84 s
2024-01-03 00:10:48,961	44k	INFO	Train Epoch: 4593 [31%]
2024-01-03 00:10:48,964	44k	INFO	Losses: [2.203949213027954, 2.592026710510254, 8.740878105163574, 15.29035758972168, 0.38389891386032104], step: 119400, lr: 5.632476465660262e-05, reference_loss: 29.211111068725586
2024-01-03 00:11:04,133	44k	INFO	====> Epoch: 4593, cost 23.19 s
2024-01-03 00:11:26,986	44k	INFO	====> Epoch: 4594, cost 22.85 s
2024-01-03 00:11:49,672	44k	INFO	====> Epoch: 4595, cost 22.69 s
2024-01-03 00:12:12,330	44k	INFO	====> Epoch: 4596, cost 22.66 s
2024-01-03 00:12:35,021	44k	INFO	====> Epoch: 4597, cost 22.69 s
2024-01-03 00:12:57,784	44k	INFO	====> Epoch: 4598, cost 22.76 s
2024-01-03 00:13:20,537	44k	INFO	====> Epoch: 4599, cost 22.75 s
2024-01-03 00:13:43,345	44k	INFO	====> Epoch: 4600, cost 22.81 s
2024-01-03 00:13:44,239	44k	INFO	Train Epoch: 4601 [0%]
2024-01-03 00:13:44,242	44k	INFO	Losses: [2.185272216796875, 2.63163685798645, 8.7527494430542, 14.13837718963623, 0.2451835721731186], step: 119600, lr: 5.626846452787098e-05, reference_loss: 27.953218460083008
2024-01-03 00:14:06,534	44k	INFO	====> Epoch: 4601, cost 23.19 s
2024-01-03 00:14:29,374	44k	INFO	====> Epoch: 4602, cost 22.84 s
2024-01-03 00:14:52,236	44k	INFO	====> Epoch: 4603, cost 22.86 s
2024-01-03 00:15:15,239	44k	INFO	====> Epoch: 4604, cost 23.00 s
2024-01-03 00:15:38,093	44k	INFO	====> Epoch: 4605, cost 22.85 s
2024-01-03 00:16:00,910	44k	INFO	====> Epoch: 4606, cost 22.82 s
2024-01-03 00:16:23,696	44k	INFO	====> Epoch: 4607, cost 22.79 s
2024-01-03 00:16:40,428	44k	INFO	Train Epoch: 4608 [69%]
2024-01-03 00:16:40,431	44k	INFO	Losses: [2.2137420177459717, 2.896425485610962, 10.614319801330566, 17.184093475341797, 0.36013102531433105], step: 119800, lr: 5.6219248080653e-05, reference_loss: 33.26871109008789
2024-01-03 00:16:46,795	44k	INFO	====> Epoch: 4608, cost 23.10 s
2024-01-03 00:17:09,573	44k	INFO	====> Epoch: 4609, cost 22.78 s
2024-01-03 00:17:32,294	44k	INFO	====> Epoch: 4610, cost 22.72 s
2024-01-03 00:17:54,943	44k	INFO	====> Epoch: 4611, cost 22.65 s
2024-01-03 00:18:17,604	44k	INFO	====> Epoch: 4612, cost 22.66 s
2024-01-03 00:18:40,241	44k	INFO	====> Epoch: 4613, cost 22.64 s
2024-01-03 00:19:03,215	44k	INFO	====> Epoch: 4614, cost 22.97 s
2024-01-03 00:19:26,051	44k	INFO	====> Epoch: 4615, cost 22.84 s
2024-01-03 00:19:35,870	44k	INFO	Train Epoch: 4616 [38%]
2024-01-03 00:19:35,873	44k	INFO	Losses: [2.347287654876709, 2.5419843196868896, 8.24919319152832, 14.412003517150879, 0.4727751314640045], step: 120000, lr: 5.6163053422345355e-05, reference_loss: 28.023242950439453
2024-01-03 00:19:41,141	44k	INFO	Saving model and optimizer state at iteration 4616 to ./logs/44k/G_120000.pth
2024-01-03 00:19:42,001	44k	INFO	Saving model and optimizer state at iteration 4616 to ./logs/44k/D_120000.pth
2024-01-03 00:19:42,492	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_117600.pth
2024-01-03 00:19:42,531	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_117600.pth
2024-01-03 00:19:55,433	44k	INFO	====> Epoch: 4616, cost 29.38 s
2024-01-03 00:20:18,296	44k	INFO	====> Epoch: 4617, cost 22.86 s
2024-01-03 00:20:41,219	44k	INFO	====> Epoch: 4618, cost 22.92 s
2024-01-03 00:21:04,077	44k	INFO	====> Epoch: 4619, cost 22.86 s
2024-01-03 00:21:26,875	44k	INFO	====> Epoch: 4620, cost 22.80 s
2024-01-03 00:21:49,868	44k	INFO	====> Epoch: 4621, cost 22.99 s
2024-01-03 00:22:12,506	44k	INFO	====> Epoch: 4622, cost 22.64 s
2024-01-03 00:22:35,263	44k	INFO	====> Epoch: 4623, cost 22.76 s
2024-01-03 00:22:37,921	44k	INFO	Train Epoch: 4624 [8%]
2024-01-03 00:22:37,924	44k	INFO	Losses: [2.2342491149902344, 2.3401427268981934, 7.936382293701172, 14.607666015625, 0.2870672047138214], step: 120200, lr: 5.610691493411699e-05, reference_loss: 27.405508041381836
2024-01-03 00:22:58,411	44k	INFO	====> Epoch: 4624, cost 23.15 s
2024-01-03 00:23:21,197	44k	INFO	====> Epoch: 4625, cost 22.79 s
2024-01-03 00:23:43,892	44k	INFO	====> Epoch: 4626, cost 22.70 s
2024-01-03 00:24:06,560	44k	INFO	====> Epoch: 4627, cost 22.67 s
2024-01-03 00:24:29,337	44k	INFO	====> Epoch: 4628, cost 22.78 s
2024-01-03 00:24:52,005	44k	INFO	====> Epoch: 4629, cost 22.67 s
2024-01-03 00:25:14,861	44k	INFO	====> Epoch: 4630, cost 22.86 s
2024-01-03 00:25:33,473	44k	INFO	Train Epoch: 4631 [77%]
2024-01-03 00:25:33,476	44k	INFO	Losses: [2.2016987800598145, 2.4849724769592285, 10.395780563354492, 16.60836410522461, 0.395815908908844], step: 120400, lr: 5.605783978979613e-05, reference_loss: 32.086631774902344
2024-01-03 00:25:38,197	44k	INFO	====> Epoch: 4631, cost 23.34 s
2024-01-03 00:26:00,945	44k	INFO	====> Epoch: 4632, cost 22.75 s
2024-01-03 00:26:23,721	44k	INFO	====> Epoch: 4633, cost 22.78 s
2024-01-03 00:26:46,397	44k	INFO	====> Epoch: 4634, cost 22.68 s
2024-01-03 00:27:09,092	44k	INFO	====> Epoch: 4635, cost 22.69 s
2024-01-03 00:27:31,779	44k	INFO	====> Epoch: 4636, cost 22.69 s
2024-01-03 00:27:54,442	44k	INFO	====> Epoch: 4637, cost 22.66 s
2024-01-03 00:28:17,096	44k	INFO	====> Epoch: 4638, cost 22.65 s
2024-01-03 00:28:28,504	44k	INFO	Train Epoch: 4639 [46%]
2024-01-03 00:28:28,507	44k	INFO	Losses: [2.16483211517334, 2.6869630813598633, 9.076120376586914, 15.709504127502441, 0.39640572667121887], step: 120600, lr: 5.600180646918086e-05, reference_loss: 30.03382682800293
2024-01-03 00:28:40,237	44k	INFO	====> Epoch: 4639, cost 23.14 s
2024-01-03 00:29:03,257	44k	INFO	====> Epoch: 4640, cost 23.02 s
2024-01-03 00:29:26,113	44k	INFO	====> Epoch: 4641, cost 22.86 s
2024-01-03 00:29:48,897	44k	INFO	====> Epoch: 4642, cost 22.78 s
2024-01-03 00:30:11,573	44k	INFO	====> Epoch: 4643, cost 22.68 s
2024-01-03 00:30:34,237	44k	INFO	====> Epoch: 4644, cost 22.66 s
2024-01-03 00:30:57,033	44k	INFO	====> Epoch: 4645, cost 22.80 s
2024-01-03 00:31:19,718	44k	INFO	====> Epoch: 4646, cost 22.68 s
2024-01-03 00:31:24,140	44k	INFO	Train Epoch: 4647 [15%]
2024-01-03 00:31:24,143	44k	INFO	Losses: [2.195718288421631, 2.611067295074463, 10.666648864746094, 16.19239044189453, 0.21408206224441528], step: 120800, lr: 5.5945829157377754e-05, reference_loss: 31.879907608032227
2024-01-03 00:31:29,559	44k	INFO	Saving model and optimizer state at iteration 4647 to ./logs/44k/G_120800.pth
2024-01-03 00:31:30,420	44k	INFO	Saving model and optimizer state at iteration 4647 to ./logs/44k/D_120800.pth
2024-01-03 00:31:30,915	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_118400.pth
2024-01-03 00:31:30,954	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_118400.pth
2024-01-03 00:31:49,480	44k	INFO	====> Epoch: 4647, cost 29.76 s
2024-01-03 00:32:12,424	44k	INFO	====> Epoch: 4648, cost 22.94 s
2024-01-03 00:32:35,180	44k	INFO	====> Epoch: 4649, cost 22.76 s
2024-01-03 00:32:57,980	44k	INFO	====> Epoch: 4650, cost 22.80 s
2024-01-03 00:33:20,737	44k	INFO	====> Epoch: 4651, cost 22.76 s
2024-01-03 00:33:43,592	44k	INFO	====> Epoch: 4652, cost 22.85 s
2024-01-03 00:34:06,448	44k	INFO	====> Epoch: 4653, cost 22.86 s
2024-01-03 00:34:26,800	44k	INFO	Train Epoch: 4654 [85%]
2024-01-03 00:34:26,803	44k	INFO	Losses: [2.3351047039031982, 2.6143696308135986, 7.166653633117676, 14.157678604125977, 0.5005387663841248], step: 121000, lr: 5.589689491026628e-05, reference_loss: 26.77434539794922
2024-01-03 00:34:29,761	44k	INFO	====> Epoch: 4654, cost 23.31 s
2024-01-03 00:34:52,432	44k	INFO	====> Epoch: 4655, cost 22.67 s
2024-01-03 00:35:15,031	44k	INFO	====> Epoch: 4656, cost 22.60 s
2024-01-03 00:35:37,768	44k	INFO	====> Epoch: 4657, cost 22.74 s
2024-01-03 00:36:00,468	44k	INFO	====> Epoch: 4658, cost 22.70 s
2024-01-03 00:36:23,363	44k	INFO	====> Epoch: 4659, cost 22.90 s
2024-01-03 00:36:46,145	44k	INFO	====> Epoch: 4660, cost 22.78 s
2024-01-03 00:37:09,037	44k	INFO	====> Epoch: 4661, cost 22.89 s
2024-01-03 00:37:22,282	44k	INFO	Train Epoch: 4662 [54%]
2024-01-03 00:37:22,285	44k	INFO	Losses: [2.318946361541748, 2.483163356781006, 8.306797981262207, 15.53307056427002, 0.44155624508857727], step: 121200, lr: 5.584102246413474e-05, reference_loss: 29.08353614807129
2024-01-03 00:37:32,155	44k	INFO	====> Epoch: 4662, cost 23.12 s
2024-01-03 00:37:54,973	44k	INFO	====> Epoch: 4663, cost 22.82 s
2024-01-03 00:38:17,733	44k	INFO	====> Epoch: 4664, cost 22.76 s
2024-01-03 00:38:40,426	44k	INFO	====> Epoch: 4665, cost 22.69 s
2024-01-03 00:39:03,172	44k	INFO	====> Epoch: 4666, cost 22.75 s
2024-01-03 00:39:25,792	44k	INFO	====> Epoch: 4667, cost 22.62 s
2024-01-03 00:39:48,452	44k	INFO	====> Epoch: 4668, cost 22.66 s
2024-01-03 00:40:11,362	44k	INFO	====> Epoch: 4669, cost 22.91 s
2024-01-03 00:40:17,606	44k	INFO	Train Epoch: 4670 [23%]
2024-01-03 00:40:17,609	44k	INFO	Losses: [2.37475848197937, 2.3124608993530273, 7.993753433227539, 13.174349784851074, 0.33497318625450134], step: 121400, lr: 5.578520586601125e-05, reference_loss: 26.190296173095703
2024-01-03 00:40:34,437	44k	INFO	====> Epoch: 4670, cost 23.07 s
2024-01-03 00:40:57,210	44k	INFO	====> Epoch: 4671, cost 22.77 s
2024-01-03 00:41:20,024	44k	INFO	====> Epoch: 4672, cost 22.81 s
2024-01-03 00:41:42,719	44k	INFO	====> Epoch: 4673, cost 22.70 s
2024-01-03 00:42:05,496	44k	INFO	====> Epoch: 4674, cost 22.78 s
2024-01-03 00:42:28,186	44k	INFO	====> Epoch: 4675, cost 22.69 s
2024-01-03 00:42:50,844	44k	INFO	====> Epoch: 4676, cost 22.66 s
2024-01-03 00:43:13,002	44k	INFO	Train Epoch: 4677 [92%]
2024-01-03 00:43:13,005	44k	INFO	Losses: [2.280362129211426, 2.656327962875366, 8.144987106323242, 15.139321327209473, 0.4749160706996918], step: 121600, lr: 5.573641211158618e-05, reference_loss: 28.69591522216797
2024-01-03 00:43:18,520	44k	INFO	Saving model and optimizer state at iteration 4677 to ./logs/44k/G_121600.pth
2024-01-03 00:43:19,397	44k	INFO	Saving model and optimizer state at iteration 4677 to ./logs/44k/D_121600.pth
2024-01-03 00:43:19,890	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/G_119200.pth
2024-01-03 00:43:19,929	44k	INFO	.. Free up space by deleting ckpt ./logs/44k/D_119200.pth
2024-01-03 00:43:20,617	44k	INFO	====> Epoch: 4677, cost 29.77 s
2024-01-03 00:43:43,439	44k	INFO	====> Epoch: 4678, cost 22.82 s
2024-01-03 00:44:06,273	44k	INFO	====> Epoch: 4679, cost 22.83 s
2024-01-03 00:44:29,148	44k	INFO	====> Epoch: 4680, cost 22.87 s
2024-01-03 00:44:51,845	44k	INFO	====> Epoch: 4681, cost 22.70 s
2024-01-03 00:45:14,649	44k	INFO	====> Epoch: 4682, cost 22.80 s
2024-01-03 00:45:37,495	44k	INFO	====> Epoch: 4683, cost 22.85 s
2024-01-03 00:46:00,364	44k	INFO	====> Epoch: 4684, cost 22.87 s
2024-01-03 00:46:15,384	44k	INFO	Train Epoch: 4685 [62%]
2024-01-03 00:46:15,388	44k	INFO	Losses: [2.437129497528076, 2.4464516639709473, 6.895501613616943, 12.932876586914062, 0.6630792021751404], step: 121800, lr: 5.568070007805965e-05, reference_loss: 25.375038146972656
2024-01-03 00:46:23,599	44k	INFO	====> Epoch: 4685, cost 23.23 s
2024-01-03 00:46:46,345	44k	INFO	====> Epoch: 4686, cost 22.75 s
2024-01-03 00:47:09,090	44k	INFO	====> Epoch: 4687, cost 22.75 s
